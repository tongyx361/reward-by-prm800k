{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.environ[\"CUDA_VISIBLE_DEVICES\"] = 5\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import importlib\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "gpu_ids = [4, 5]\n",
    "num_gpus = len(gpu_ids)\n",
    "utils.set_gpu_ids(gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re\n",
    "import subprocess\n",
    "import multiprocessing as mp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "train_models_dirpath = \"/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "# output: utils.best_of_n_results_jsonl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_2000', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_1900', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_1800', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_1700', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_1600', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_1500', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_1400', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_1300', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_1200', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_1100', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_1000', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_900', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_800', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_700', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_600', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_500', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_400', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_300', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_200', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_100']\n"
     ]
    }
   ],
   "source": [
    "model_variant_paths = []\n",
    "for name in os.listdir(train_models_dirpath):\n",
    "    path = os.path.join(train_models_dirpath, name)\n",
    "    if not os.path.isdir(path):\n",
    "        continue\n",
    "    if not utils.is_zero3_parameters(path):\n",
    "        continue\n",
    "    model_variant_paths.append(path)\n",
    "\n",
    "\n",
    "def extract_step_or_epoch_num(path):\n",
    "    return int(re.search(r\".*?(?:step|epoch)_([0-9]+)\", path).group(1))\n",
    "\n",
    "\n",
    "model_variant_paths.sort(key=extract_step_or_epoch_num, reverse=True)\n",
    "\n",
    "model_variant_paths = [\n",
    "    model_variant_path\n",
    "    for model_variant_path in model_variant_paths\n",
    "    # if 1 < extract_step_or_epoch_num(model_variant_path) < 100\n",
    "    # or extract_step_or_epoch_num(model_variant_path) >= 100\n",
    "]\n",
    "\n",
    "print(model_variant_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.environ[\"CUDA_VISIBLE_DEVICES\"] = 5\n",
      "ZeRO-3 model weights detected at /data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_2000.\n",
      "ZeRO-3 model weights converted to HF model weights at /data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_2000_fp16_hf\n",
      "len(prompts) = 83944\n",
      "prompts[0] = A $90^\\circ$ rotation around the origin in the counter-clockwise direction is applied to $7 + 2i.$  What is the resulting complex number?\n",
      "I know that multiplying a complex number by $i$ rotates it $90^\\circ$ counter-clockwise in the complex plane, so I can use that to find the answer.\n",
      "INFO 08-24 01:40:16 llm_engine.py:70] Initializing an LLM engine with config: model='/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_2000_fp16_hf', tokenizer='/data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--hf-internal-testing--llama-tokenizer/snapshots/99eceeba6e8289bee767f0771166b5917e70e470', tokenizer_mode=auto, trust_remote_code=True, dtype=torch.float16, use_dummy_weights=False, download_dir=None, use_np_weights=False, tensor_parallel_size=1, seed=0)\n",
      "INFO 08-24 01:40:16 tokenizer.py:29] For some LLaMA-based models, initializing the fast tokenizer may take a long time. To eliminate the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "INFO 08-24 01:40:29 llm_engine.py:196] # GPU blocks: 7439, # CPU blocks: 512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m model_variant_path \u001b[39min\u001b[39;00m model_variant_paths:\n\u001b[0;32m----> 2\u001b[0m     eval_process_results \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m      3\u001b[0m         args\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      4\u001b[0m             utils\u001b[39m.\u001b[39;49mpython_path,\n\u001b[1;32m      5\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39m/data/users/zhangjunlei/tyx/reward-by-prm800k/src/eval-one-model-with-best-of-n.py\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39m--model_name_or_path\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m             model_variant_path,\n\u001b[1;32m      8\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39m--gpu_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin([\u001b[39mstr\u001b[39;49m(gpu_id) \u001b[39mfor\u001b[39;49;00m gpu_id \u001b[39min\u001b[39;49;00m gpu_ids]),\n\u001b[1;32m     10\u001b[0m         ]\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m eval_process_results\u001b[39m.\u001b[39mreturncode \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     13\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to evaluate model variant \u001b[39m\u001b[39m{\u001b[39;00mmodel_variant_path\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/open-instruct/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39;49mcommunicate(\u001b[39minput\u001b[39;49m, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    506\u001b[0m     \u001b[39mexcept\u001b[39;00m TimeoutExpired \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[39m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/anaconda3/envs/open-instruct/lib/python3.10/subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mread()\n\u001b[1;32m   1145\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mclose()\n\u001b[0;32m-> 1146\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m   1147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/open-instruct/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[39m=\u001b[39m _time() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[39m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[39m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[39m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/open-instruct/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_wait(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m   1960\u001b[0m \u001b[39m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[39m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[39m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[39mif\u001b[39;00m pid \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/anaconda3/envs/open-instruct/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mwaitpid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpid, wait_flags)\n\u001b[1;32m   1918\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[39m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[39m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[39m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model_variant_path in model_variant_paths:\n",
    "    eval_process_results = subprocess.run(\n",
    "        args=[\n",
    "            utils.python_path,\n",
    "            \"/data/users/zhangjunlei/tyx/reward-by-prm800k/src/eval-one-model-with-best-of-n.py\",\n",
    "            \"--model_name_or_path\",\n",
    "            model_variant_path,\n",
    "            \"--gpu_ids\",\n",
    "            \",\".join([str(gpu_id) for gpu_id in gpu_ids]),\n",
    "        ]\n",
    "    )\n",
    "    if eval_process_results.returncode != 0:\n",
    "        raise RuntimeError(f\"Failed to evaluate model variant {model_variant_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_fn(gpu_id, func, *args, **kwargs):\n",
    "#     torch.cuda.set_device(gpu_id)\n",
    "#     func(*args, **kwargs)\n",
    "\n",
    "\n",
    "# # if __name__ == '__main__':\n",
    "# with mp.Pool(num_gpus) as pool:\n",
    "#     pool.map(process_fn, gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeRO-3 model weights detected at /data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_2000.\n",
      "ZeRO-3 model weights converted to HF model weights at /data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_2000_fp16_hf\n",
      "Loading /data/users/zhangjunlei/tyx/reward-by-prm800k/datasets/problem-solution-hierarchical-samples.pkl...\n",
      "Loaded\n",
      "Extracting 16 subsamples...\n",
      "Extracted\n",
      "Resuming vLLM outputs from /data/users/zhangjunlei/tyx/reward-by-prm800k/tmp/vllm-outputs.pkl\n",
      "Resumed\n",
      "len(rating2prob_list) = 82595\n",
      "rating2prob_list[0] = {'1': 0.6280793064277469, '-1': 0.3635044258009806, '0': 0.008416267771272466}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_variant_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_2000\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m utils\u001b[39m.\u001b[39;49meval_model_with_best_of_n(\n\u001b[1;32m      4\u001b[0m     model_name_or_path\u001b[39m=\u001b[39;49mmodel_variant_path,\n\u001b[1;32m      5\u001b[0m     metrics\u001b[39m=\u001b[39;49m[metric \u001b[39mfor\u001b[39;49;00m metric \u001b[39min\u001b[39;49;00m utils\u001b[39m.\u001b[39;49mall_metrics \u001b[39mif\u001b[39;49;00m metric \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mmajority_voting\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      6\u001b[0m     debug_for\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mresume_vllm_outputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m},\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m~/tyx/reward-by-prm800k/src/utils.py:602\u001b[0m, in \u001b[0;36meval_model_with_best_of_n\u001b[0;34m(model_name_or_path, problem_solution_hierarchical_samples_path, num_solution_samples_to_rate_per_problem, best_of_n_results_jsonl_path, metrics, num_trials, debug_for)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval_model_with_best_of_n\u001b[39m(\n\u001b[1;32m    591\u001b[0m     model_name_or_path\u001b[39m=\u001b[39mmodel_name_or_path,\n\u001b[1;32m    592\u001b[0m     problem_solution_hierarchical_samples_path\u001b[39m=\u001b[39mgpt4_generated_problem_solution_hierarchical_samples_path_wo_basename\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m ):\n\u001b[1;32m    600\u001b[0m     \u001b[39m# eval\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m     rated_problem_solution_hierarchical_samples \u001b[39m=\u001b[39m rate_n_samples(\n\u001b[1;32m    603\u001b[0m         model_name_or_path\u001b[39m=\u001b[39;49mmodel_name_or_path,\n\u001b[1;32m    604\u001b[0m         problem_solution_hierarchical_samples_path\u001b[39m=\u001b[39;49mproblem_solution_hierarchical_samples_path,\n\u001b[1;32m    605\u001b[0m         num_solution_samples_to_rate_per_problem\u001b[39m=\u001b[39;49mnum_solution_samples_to_rate_per_problem,\n\u001b[1;32m    606\u001b[0m         rated_problem_solution_hierarchical_samples_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdefault\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    607\u001b[0m         lib\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvllm\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    608\u001b[0m         debug_for\u001b[39m=\u001b[39;49mdebug_for,\n\u001b[1;32m    609\u001b[0m     )\n\u001b[1;32m    611\u001b[0m     _ \u001b[39m=\u001b[39m eval_best_of_n_on_rated_problem_solution_samples(\n\u001b[1;32m    612\u001b[0m         rated_problem_solution_samples\u001b[39m=\u001b[39mrated_problem_solution_hierarchical_samples,\n\u001b[1;32m    613\u001b[0m         num_trials\u001b[39m=\u001b[39mnum_trials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    620\u001b[0m         debug_for\u001b[39m=\u001b[39mdebug_for,\n\u001b[1;32m    621\u001b[0m     )\n",
      "File \u001b[0;32m~/tyx/reward-by-prm800k/src/utils.py:566\u001b[0m, in \u001b[0;36mrate_n_samples\u001b[0;34m(model_name_or_path, problem_solution_hierarchical_samples_path, num_solution_samples_to_rate_per_problem, rated_problem_solution_hierarchical_samples_path, lib, debug_for)\u001b[0m\n\u001b[1;32m    564\u001b[0m solution_step_num \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(solution_rating2prob_list)\n\u001b[1;32m    565\u001b[0m \u001b[39mfor\u001b[39;00m step_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(solution_step_num):\n\u001b[0;32m--> 566\u001b[0m     solution_rating2prob_list[step_idx] \u001b[39m=\u001b[39m rating2prob_list[\n\u001b[1;32m    567\u001b[0m         num_step_so_far \u001b[39m+\u001b[39;49m step_idx\n\u001b[1;32m    568\u001b[0m     ]\n\u001b[1;32m    569\u001b[0m num_step_so_far \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m solution_step_num\n\u001b[1;32m    570\u001b[0m \u001b[39m# print(f\"num_step_so_far = {num_step_so_far}\")\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# model_variant_path = \"/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_2000\"\n",
    "\n",
    "# utils.eval_model_with_best_of_n(\n",
    "#     model_name_or_path=model_variant_path,\n",
    "#     metrics=[metric for metric in utils.all_metrics if metric != \"majority_voting\"],\n",
    "#     debug_for={\"resume_vllm_outputs\": True},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-instruct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
