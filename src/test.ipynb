{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.environ[\"CUDA_VISIBLE_DEVICES\"] = 6\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import importlib\n",
    "\n",
    "importlib.reload(utils)\n",
    "utils.set_gpu_ids([6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 0, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个示例的 mask 张量\n",
    "mask = torch.tensor([1, 1, 0, 1, 0], dtype=torch.bool)\n",
    "\n",
    "# 将 mask 向左移动一位\n",
    "shifted_mask = mask << 1\n",
    "\n",
    "print(shifted_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head_tokens = <unk><s></s>\u0000\u0001\n",
      "tokenizer.vocab_size = 32000\n",
      "len(tokenizer.vocab) = 32000\n",
      "tokenizer.special_tokens_map = {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}\n",
      "num_added_tokens = 1\n",
      "head_tokens = <unk><s></s>\u0000\u0001\n",
      "tokenizer.vocab_size = 32000\n",
      "len(tokenizer.vocab) = 32001\n",
      "tokenizer.special_tokens_map = {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}\n",
      "LlamaTokenizerFast(name_or_path='/data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--hf-internal-testing--llama-tokenizer/snapshots/99eceeba6e8289bee767f0771166b5917e70e470', vocab_size=32000, model_max_length=4096, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False)\n"
     ]
    }
   ],
   "source": [
    "# import transformers\n",
    "\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "#     \"/data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--hf-internal-testing--llama-tokenizer/snapshots/99eceeba6e8289bee767f0771166b5917e70e470\"\n",
    "# )\n",
    "\n",
    "# print(tokenizer)\n",
    "# print(tokenizer.pad_token_id)\n",
    "# print(len(tokenizer.vocab))\n",
    "\n",
    "tokenizer = utils.get_complete_tokenizer()\n",
    "# print(tokenizer)\n",
    "# print(tokenizer.pad_token_id)\n",
    "# print(len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1536])\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = tokenizer(\"positive\" * 768, return_tensors=\"pt\")\n",
    "print(encoded_inputs[\"input_ids\"].shape)\n",
    "tokenizer.prepare_for_model(encoded_inputs[\"input_ids\"], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeRO-3 model weights detected at /data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_100.\n",
      "ZeRO-3 model weights converted to HF model weights at /data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_100_fp16_hf\n",
      "/data/users/zhangjunlei/tyx/reward-by-prm800k/eval/rated-samples/gpt-4-generatations/direct-prediction/meta-llama/Llama-2-7b-hf/step_100_fp16_hf/16-samples-per-problem.pkl exists.\n",
      "Trial 1:\n",
      "           majority_voting, [0.472, 0.564, 0.61, 0.646]\n",
      "    positive_probs_product, [0.5, 0.542, 0.55, 0.554]\n",
      "    positive_probs_minimum, [0.496, 0.528, 0.54, 0.536]\n",
      "non_negative_probs_product, [0.498, 0.546, 0.542, 0.548]\n",
      "non_negative_probs_minimum, [0.488, 0.534, 0.538, 0.544]\n",
      "Trial 2:\n",
      "           majority_voting, [0.476, 0.536, 0.61, 0.66]\n",
      "    positive_probs_product, [0.512, 0.526, 0.538, 0.554]\n",
      "    positive_probs_minimum, [0.514, 0.522, 0.528, 0.536]\n",
      "non_negative_probs_product, [0.512, 0.526, 0.55, 0.548]\n",
      "non_negative_probs_minimum, [0.516, 0.518, 0.53, 0.544]\n",
      "Trial 3:\n",
      "           majority_voting, [0.472, 0.564, 0.63, 0.654]\n",
      "    positive_probs_product, [0.482, 0.55, 0.556, 0.554]\n",
      "    positive_probs_minimum, [0.482, 0.528, 0.546, 0.536]\n",
      "non_negative_probs_product, [0.484, 0.538, 0.55, 0.548]\n",
      "non_negative_probs_minimum, [0.486, 0.526, 0.554, 0.544]\n",
      "Trial 4:\n",
      "           majority_voting, [0.462, 0.536, 0.606, 0.66]\n",
      "    positive_probs_product, [0.506, 0.538, 0.562, 0.554]\n",
      "    positive_probs_minimum, [0.494, 0.526, 0.544, 0.536]\n",
      "non_negative_probs_product, [0.5, 0.532, 0.55, 0.548]\n",
      "non_negative_probs_minimum, [0.5, 0.512, 0.524, 0.544]\n",
      "Trial 5:\n",
      "           majority_voting, [0.496, 0.532, 0.622, 0.658]\n",
      "    positive_probs_product, [0.506, 0.512, 0.562, 0.554]\n",
      "    positive_probs_minimum, [0.502, 0.508, 0.532, 0.536]\n",
      "non_negative_probs_product, [0.51, 0.504, 0.564, 0.548]\n",
      "non_negative_probs_minimum, [0.506, 0.506, 0.536, 0.544]\n",
      "Trial 6:\n",
      "           majority_voting, [0.476, 0.546, 0.618, 0.646]\n",
      "    positive_probs_product, [0.504, 0.532, 0.55, 0.554]\n",
      "    positive_probs_minimum, [0.502, 0.528, 0.524, 0.536]\n",
      "non_negative_probs_product, [0.502, 0.53, 0.546, 0.548]\n",
      "non_negative_probs_minimum, [0.496, 0.526, 0.526, 0.544]\n",
      "Trial 7:\n",
      "           majority_voting, [0.466, 0.552, 0.596, 0.648]\n",
      "    positive_probs_product, [0.488, 0.534, 0.56, 0.554]\n",
      "    positive_probs_minimum, [0.476, 0.536, 0.534, 0.536]\n",
      "non_negative_probs_product, [0.48, 0.544, 0.554, 0.548]\n",
      "non_negative_probs_minimum, [0.476, 0.528, 0.546, 0.544]\n",
      "Trial 8:\n",
      "           majority_voting, [0.448, 0.542, 0.602, 0.652]\n",
      "    positive_probs_product, [0.478, 0.532, 0.556, 0.554]\n",
      "    positive_probs_minimum, [0.474, 0.526, 0.542, 0.536]\n",
      "non_negative_probs_product, [0.476, 0.526, 0.54, 0.548]\n",
      "non_negative_probs_minimum, [0.464, 0.52, 0.55, 0.544]\n",
      "Trial 9:\n",
      "           majority_voting, [0.484, 0.54, 0.602, 0.652]\n",
      "    positive_probs_product, [0.494, 0.526, 0.544, 0.554]\n",
      "    positive_probs_minimum, [0.484, 0.522, 0.532, 0.536]\n",
      "non_negative_probs_product, [0.484, 0.508, 0.536, 0.548]\n",
      "non_negative_probs_minimum, [0.482, 0.522, 0.518, 0.544]\n",
      "Trial 10:\n",
      "           majority_voting, [0.47, 0.554, 0.614, 0.646]\n",
      "    positive_probs_product, [0.504, 0.532, 0.516, 0.554]\n",
      "    positive_probs_minimum, [0.492, 0.538, 0.514, 0.536]\n",
      "non_negative_probs_product, [0.498, 0.538, 0.52, 0.548]\n",
      "non_negative_probs_minimum, [0.492, 0.536, 0.516, 0.544]\n",
      "Results:\n",
      "\tns  : [2, 4, 8, 16]\n",
      "majority_voting\n",
      "\tMean: [0.47220000000000006, 0.5466000000000001, 0.611, 0.6522]\n",
      "\tStd : [0.47220000000000006, 0.5466000000000001, 0.611, 0.6522]\n",
      "positive_probs_product\n",
      "\tMean: [0.4974, 0.5324, 0.5494000000000001, 0.5540000000000002]\n",
      "\tStd : [0.4974, 0.5324, 0.5494000000000001, 0.5540000000000002]\n",
      "positive_probs_minimum\n",
      "\tMean: [0.49160000000000004, 0.5262, 0.5336000000000001, 0.5359999999999999]\n",
      "\tStd : [0.49160000000000004, 0.5262, 0.5336000000000001, 0.5359999999999999]\n",
      "non_negative_probs_product\n",
      "\tMean: [0.4944, 0.5292000000000001, 0.5452, 0.548]\n",
      "\tStd : [0.4944, 0.5292000000000001, 0.5452, 0.548]\n",
      "non_negative_probs_minimum\n",
      "\tMean: [0.4906, 0.5227999999999999, 0.5338, 0.5440000000000002]\n",
      "\tStd : [0.4906, 0.5227999999999999, 0.5338, 0.5440000000000002]\n"
     ]
    }
   ],
   "source": [
    "# utils.eval_model_with_best_of_n(model_name_or_path=model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-22 23:54:21,092] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "# llama_config = transformers.LlamaConfig.from_pretrained(model_dirpath)\n",
    "\n",
    "# llama_model = transformers.LlamaForCausalLM.from_pretrained(\n",
    "#     pretrained_model_name_or_path=step_model_name_or_path,\n",
    "#     config=llama_config,\n",
    "#     device_map=\"auto\",\n",
    "#     low_cpu_mem_usage=True,\n",
    "# )\n",
    "# # 39.5s\n",
    "# print(llama_model.config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-instruct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
