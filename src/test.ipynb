{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-12 15:00:22,415] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"] = 6\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "importlib.reload(utils)\n",
    "utils.set_gpu_ids([6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "query_set_name = \"prm800k-002validation-seed42\"\n",
    "queries_path = os.path.join(\n",
    "    utils.project_root, \"datasets\", f\"{query_set_name}-openai-queries.jsonl\"\n",
    ")\n",
    "with open(queries_path, \"r+\") as f:\n",
    "    print(len(f.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Path.glob at 0x7f5a117c6810>\n",
      "[PosixPath('/data/users/zhangjunlei/tyx/reward-by-prm800k/src/utils.py')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 创建一个Path对象，表示当前目录\n",
    "current_directory = Path.cwd()\n",
    "\n",
    "# 使用glob方法查找所有以.py为扩展名的文件\n",
    "python_files = current_directory.glob(\"*utils.py\")\n",
    "\n",
    "print(python_files)\n",
    "print(list(python_files))\n",
    "# 迭代生成器并输出匹配的文件的路径\n",
    "for file_path in python_files:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "init() got an unexpected keyword argument 'run_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wandb\u001b[39m.\u001b[39;49minit(run_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mkidrain61/test/mpe5aes6\u001b[39;49m\u001b[39m\"\u001b[39;49m, resume\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmust\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: init() got an unexpected keyword argument 'run_path'"
     ]
    }
   ],
   "source": [
    "wandb.init(run_path=\"kidrain61/test/mpe5aes6\", resume=\"must\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.3 0.5]\n",
      " [0.6 0.4 0.2]\n",
      " [0.2 0.7 0.1]\n",
      " [0.1 0.5 0.4]\n",
      " [0.3 0.8 0.4]\n",
      " [0.6 0.9 0.2]]\n"
     ]
    }
   ],
   "source": [
    "metric_name = \"roc_-1\"\n",
    "\n",
    "# 给定的 y_true 列表\n",
    "y_true = [-1, 0, 1, 1, 1, 1]\n",
    "\n",
    "# 生成三个类别的概率或分数\n",
    "class_0_prob = [0.2, 0.6, 0.2, 0.1, 0.3, 0.6]\n",
    "class_1_prob = [0.3, 0.4, 0.7, 0.4, 0.8, 0.9]\n",
    "class_2_prob = [0.5, 0.2, 0.1, 0.4, 0.4, 0.2]\n",
    "\n",
    "# 将这些概率或分数存储在一个嵌套的列表中\n",
    "y_probas = [class_0_prob, class_1_prob, class_2_prob]\n",
    "\n",
    "# 将嵌套列表转换为 NumPy 数组\n",
    "y_probas = np.array(y_probas).transpose()\n",
    "\n",
    "# 打印生成的 y_probas\n",
    "print(y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wandb.viz.CustomChart object at 0x7f19712b1cc0>\n"
     ]
    }
   ],
   "source": [
    "roc = wandb.plot.roc_curve(y_true, y_probas, title=metric_name.upper())\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({metric_name: roc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4.410743713378906e-05 seconds to execute print(1)\n",
      "2\n",
      "1.430511474609375e-05 seconds to execute print(2)\n",
      "7.319450378417969e-05 seconds to execute all codes\n"
     ]
    }
   ],
   "source": [
    "utils.check_time_cost([\"print(1)\", \"print(2)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    bar()\n",
    "\n",
    "\n",
    "def bar():\n",
    "    print(233)\n",
    "\n",
    "\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "exec(\"a = 1\")\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False False]\n",
      "(array([0, 1, 2]),)\n"
     ]
    }
   ],
   "source": [
    "cond = np.isin([1, 2, 3, 4, 5], [1, 2, 3])\n",
    "print(cond)\n",
    "chosen = np.where(cond)\n",
    "print(chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"/data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 0, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个示例的 mask 张量\n",
    "mask = torch.tensor([1, 1, 0, 1, 0], dtype=torch.bool)\n",
    "\n",
    "# 将 mask 向左移动一位\n",
    "shifted_mask = mask << 1\n",
    "\n",
    "print(shifted_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head_tokens = <unk><s></s>\u0000\u0001\n",
      "tokenizer.vocab_size = 32000\n",
      "len(tokenizer.vocab) = 32000\n",
      "tokenizer.special_tokens_map = {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}\n",
      "num_added_tokens = 1\n",
      "head_tokens = <unk><s></s>\u0000\u0001\n",
      "tokenizer.vocab_size = 32000\n",
      "len(tokenizer.vocab) = 32001\n",
      "tokenizer.special_tokens_map = {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}\n",
      "LlamaTokenizerFast(name_or_path='/data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--hf-internal-testing--llama-tokenizer/snapshots/99eceeba6e8289bee767f0771166b5917e70e470', vocab_size=32000, model_max_length=4096, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False)\n"
     ]
    }
   ],
   "source": [
    "# import transformers\n",
    "\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "#     \"/data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--hf-internal-testing--llama-tokenizer/snapshots/99eceeba6e8289bee767f0771166b5917e70e470\"\n",
    "# )\n",
    "\n",
    "# print(tokenizer)\n",
    "# print(tokenizer.pad_token_id)\n",
    "# print(len(tokenizer.vocab))\n",
    "\n",
    "tokenizer = utils.get_complete_tokenizer()\n",
    "# print(tokenizer)\n",
    "# print(tokenizer.pad_token_id)\n",
    "# print(len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1536])\n"
     ]
    }
   ],
   "source": [
    "encoded_inputs = tokenizer(\"positive\" * 768, return_tensors=\"pt\")\n",
    "print(encoded_inputs[\"input_ids\"].shape)\n",
    "tokenizer.prepare_for_model(encoded_inputs[\"input_ids\"], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeRO-3 model weights detected at /data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_100.\n",
      "ZeRO-3 model weights converted to HF model weights at /data/users/zhangjunlei/tyx/reward-by-prm800k/models/direct-prediction/meta-llama/Llama-2-7b-hf/step_100_fp16_hf\n",
      "/data/users/zhangjunlei/tyx/reward-by-prm800k/eval/rated-samples/gpt-4-generatations/direct-prediction/meta-llama/Llama-2-7b-hf/step_100_fp16_hf/16-samples-per-problem.pkl exists.\n",
      "Trial 1:\n",
      "           majority_voting, [0.472, 0.564, 0.61, 0.646]\n",
      "    positive_probs_product, [0.5, 0.542, 0.55, 0.554]\n",
      "    positive_probs_minimum, [0.496, 0.528, 0.54, 0.536]\n",
      "non_negative_probs_product, [0.498, 0.546, 0.542, 0.548]\n",
      "non_negative_probs_minimum, [0.488, 0.534, 0.538, 0.544]\n",
      "Trial 2:\n",
      "           majority_voting, [0.476, 0.536, 0.61, 0.66]\n",
      "    positive_probs_product, [0.512, 0.526, 0.538, 0.554]\n",
      "    positive_probs_minimum, [0.514, 0.522, 0.528, 0.536]\n",
      "non_negative_probs_product, [0.512, 0.526, 0.55, 0.548]\n",
      "non_negative_probs_minimum, [0.516, 0.518, 0.53, 0.544]\n",
      "Trial 3:\n",
      "           majority_voting, [0.472, 0.564, 0.63, 0.654]\n",
      "    positive_probs_product, [0.482, 0.55, 0.556, 0.554]\n",
      "    positive_probs_minimum, [0.482, 0.528, 0.546, 0.536]\n",
      "non_negative_probs_product, [0.484, 0.538, 0.55, 0.548]\n",
      "non_negative_probs_minimum, [0.486, 0.526, 0.554, 0.544]\n",
      "Trial 4:\n",
      "           majority_voting, [0.462, 0.536, 0.606, 0.66]\n",
      "    positive_probs_product, [0.506, 0.538, 0.562, 0.554]\n",
      "    positive_probs_minimum, [0.494, 0.526, 0.544, 0.536]\n",
      "non_negative_probs_product, [0.5, 0.532, 0.55, 0.548]\n",
      "non_negative_probs_minimum, [0.5, 0.512, 0.524, 0.544]\n",
      "Trial 5:\n",
      "           majority_voting, [0.496, 0.532, 0.622, 0.658]\n",
      "    positive_probs_product, [0.506, 0.512, 0.562, 0.554]\n",
      "    positive_probs_minimum, [0.502, 0.508, 0.532, 0.536]\n",
      "non_negative_probs_product, [0.51, 0.504, 0.564, 0.548]\n",
      "non_negative_probs_minimum, [0.506, 0.506, 0.536, 0.544]\n",
      "Trial 6:\n",
      "           majority_voting, [0.476, 0.546, 0.618, 0.646]\n",
      "    positive_probs_product, [0.504, 0.532, 0.55, 0.554]\n",
      "    positive_probs_minimum, [0.502, 0.528, 0.524, 0.536]\n",
      "non_negative_probs_product, [0.502, 0.53, 0.546, 0.548]\n",
      "non_negative_probs_minimum, [0.496, 0.526, 0.526, 0.544]\n",
      "Trial 7:\n",
      "           majority_voting, [0.466, 0.552, 0.596, 0.648]\n",
      "    positive_probs_product, [0.488, 0.534, 0.56, 0.554]\n",
      "    positive_probs_minimum, [0.476, 0.536, 0.534, 0.536]\n",
      "non_negative_probs_product, [0.48, 0.544, 0.554, 0.548]\n",
      "non_negative_probs_minimum, [0.476, 0.528, 0.546, 0.544]\n",
      "Trial 8:\n",
      "           majority_voting, [0.448, 0.542, 0.602, 0.652]\n",
      "    positive_probs_product, [0.478, 0.532, 0.556, 0.554]\n",
      "    positive_probs_minimum, [0.474, 0.526, 0.542, 0.536]\n",
      "non_negative_probs_product, [0.476, 0.526, 0.54, 0.548]\n",
      "non_negative_probs_minimum, [0.464, 0.52, 0.55, 0.544]\n",
      "Trial 9:\n",
      "           majority_voting, [0.484, 0.54, 0.602, 0.652]\n",
      "    positive_probs_product, [0.494, 0.526, 0.544, 0.554]\n",
      "    positive_probs_minimum, [0.484, 0.522, 0.532, 0.536]\n",
      "non_negative_probs_product, [0.484, 0.508, 0.536, 0.548]\n",
      "non_negative_probs_minimum, [0.482, 0.522, 0.518, 0.544]\n",
      "Trial 10:\n",
      "           majority_voting, [0.47, 0.554, 0.614, 0.646]\n",
      "    positive_probs_product, [0.504, 0.532, 0.516, 0.554]\n",
      "    positive_probs_minimum, [0.492, 0.538, 0.514, 0.536]\n",
      "non_negative_probs_product, [0.498, 0.538, 0.52, 0.548]\n",
      "non_negative_probs_minimum, [0.492, 0.536, 0.516, 0.544]\n",
      "Results:\n",
      "\tns  : [2, 4, 8, 16]\n",
      "majority_voting\n",
      "\tMean: [0.47220000000000006, 0.5466000000000001, 0.611, 0.6522]\n",
      "\tStd : [0.47220000000000006, 0.5466000000000001, 0.611, 0.6522]\n",
      "positive_probs_product\n",
      "\tMean: [0.4974, 0.5324, 0.5494000000000001, 0.5540000000000002]\n",
      "\tStd : [0.4974, 0.5324, 0.5494000000000001, 0.5540000000000002]\n",
      "positive_probs_minimum\n",
      "\tMean: [0.49160000000000004, 0.5262, 0.5336000000000001, 0.5359999999999999]\n",
      "\tStd : [0.49160000000000004, 0.5262, 0.5336000000000001, 0.5359999999999999]\n",
      "non_negative_probs_product\n",
      "\tMean: [0.4944, 0.5292000000000001, 0.5452, 0.548]\n",
      "\tStd : [0.4944, 0.5292000000000001, 0.5452, 0.548]\n",
      "non_negative_probs_minimum\n",
      "\tMean: [0.4906, 0.5227999999999999, 0.5338, 0.5440000000000002]\n",
      "\tStd : [0.4906, 0.5227999999999999, 0.5338, 0.5440000000000002]\n"
     ]
    }
   ],
   "source": [
    "# utils.eval_model_with_best_of_n(model_name_or_path=model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-22 23:54:21,092] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "# llama_config = transformers.LlamaConfig.from_pretrained(model_dirpath)\n",
    "\n",
    "# llama_model = transformers.LlamaForCausalLM.from_pretrained(\n",
    "#     pretrained_model_name_or_path=step_model_name_or_path,\n",
    "#     config=llama_config,\n",
    "#     device_map=\"auto\",\n",
    "#     low_cpu_mem_usage=True,\n",
    "# )\n",
    "# # 39.5s\n",
    "# print(llama_model.config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-instruct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
