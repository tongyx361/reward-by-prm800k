nohup: ignoring input
[2023-09-02 22:43:53,465] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-09-02 22:43:57,961] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-02 22:43:57,977] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-02 22:43:57,985] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-02 22:43:58,002] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-02 22:43:59,518] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-09-02 22:43:59,518] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-09-02 22:43:59,612] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-09-02 22:43:59,612] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-09-02 22:43:59,621] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-09-02 22:43:59,621] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-09-02 22:43:59,624] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-09-02 22:43:59,624] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-09-02 22:43:59,624] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
09/02/2023 22:43:59 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

09/02/2023 22:43:59 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

09/02/2023 22:43:59 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

09/02/2023 22:43:59 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

09/02/2023 22:44:05 - DEBUG - evaluate.loading - Checking /data/users/zhangjunlei/tyx/.cache/huggingface/evaluate/downloads/96cba97f346e44af314163a75259842d567a1e87cf5b208754598a47f8c5f531.cfd6b2fbd44256c2b82392f9e38ab60b0f49c187db643eb761fb625fe8a3303c.py for additional imports.
09/02/2023 22:44:05 - DEBUG - evaluate.loading - Created importable dataset file at /data/users/zhangjunlei/tyx/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14/accuracy.py
09/02/2023 22:44:08 - DEBUG - evaluate.loading - Checking /data/users/zhangjunlei/tyx/.cache/huggingface/evaluate/downloads/498d31a4e66ca154bf5332fcbc8dd35c18a5ea36090d6be3b2d3aacc7794d5cc.39d17ba2a627a7569cf0b5b78be67e3176df05857da937b236a4ee081bbb92ec.py for additional imports.
09/02/2023 22:44:08 - DEBUG - evaluate.loading - Created importable dataset file at /data/users/zhangjunlei/tyx/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--f1/0ca73f6cf92ef5a268320c697f7b940d1030f8471714bffdb6856c641b818974/f1.py
09/02/2023 22:44:11 - DEBUG - evaluate.loading - Checking /data/users/zhangjunlei/tyx/.cache/huggingface/evaluate/downloads/3475eb8bf47bed300d80c02f82bb340aa0cb078031fbd39c731005d74d707c24.68cf5e93118a075768a83fb255d6e1e2ed7c1a6a6c2a15efc3bdb64051e98654.py for additional imports.
09/02/2023 22:44:11 - DEBUG - evaluate.loading - Created importable dataset file at /data/users/zhangjunlei/tyx/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--precision/4e7f439a346715f68500ce6f2be82bf3272abd3f20bdafd203a2c4f85b61dd5f/precision.py
Traceback (most recent call last):
  File "/data/users/zhangjunlei/tyx/reward-by-prm800k/open-instruct/open_instruct/finetune.py", line 1275, in <module>
    train(config, args)
  File "/data/users/zhangjunlei/tyx/reward-by-prm800k/open-instruct/open_instruct/finetune.py", line 699, in train
    model = AutoModelForCausalLM.from_config(config)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 430, in from_config
    return model_class._from_config(config, **kwargs)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/modeling_utils.py", line 1140, in _from_config
    model = cls(config, **kwargs)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 434, in wrapper
    f(module, *args, **kwargs)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 732, in __init__
    self.model = LlamaModel(config)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 434, in wrapper
    f(module, *args, **kwargs)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 560, in __init__
    self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size, self.padding_idx)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 441, in wrapper
    self._post_init_method(module)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 924, in _post_init_method
    param.partition()
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1157, in partition
    self._partition(param_list, has_been_updated=has_been_updated)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1296, in _partition
    self._partition_param(param, has_been_updated=has_been_updated)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1381, in _partition_param
    param.ds_tensor.copy_(src_tensor)
NotImplementedError: Cannot copy out of meta tensor; no data!
09/02/2023 22:44:14 - INFO - evaluate.utils.file_utils - HEAD request to https://huggingface.co/spaces/evaluate-metric/recall/resolve/v0.4.0/recall.py timed out, retrying... [1.0]
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 4110076 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 4110079 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 4110080 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 4110078) of binary: /data/users/zhangjunlei/anaconda3/envs/open-instruct/bin/python
Traceback (most recent call last):
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 45, in main
    args.func(args)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py", line 964, in launch_command
    deepspeed_launcher(args)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py", line 687, in deepspeed_launcher
    distrib_run.run(args)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/data/users/zhangjunlei/tyx/reward-by-prm800k/open-instruct/open_instruct/finetune.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-09-02_22:44:15
  host      : a100
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 4110078)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
