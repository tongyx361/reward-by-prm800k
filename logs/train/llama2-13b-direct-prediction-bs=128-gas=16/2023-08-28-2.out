nohup: ignoring input
[2023-08-28 20:25:16,961] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-08-28 20:25:21,775] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 20:25:21,812] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 20:25:21,823] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-08-28 20:25:21,838] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Using flash attention v2
Using flash attention v2
Using flash attention v2
Using flash attention v2
[2023-08-28 20:25:23,292] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-08-28 20:25:23,292] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-08-28 20:25:23,304] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-08-28 20:25:23,304] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-08-28 20:25:23,314] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-08-28 20:25:23,314] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-08-28 20:25:23,314] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-08-28 20:25:23,316] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-08-28 20:25:23,316] [INFO] [comm.py:616:init_distributed] cdb=None
08/28/2023 20:25:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

08/28/2023 20:25:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

08/28/2023 20:25:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

08/28/2023 20:25:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

loading configuration file /data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--meta-llama--Llama-2-13b-hf/snapshots/db6b8eb1feabb38985fdf785a89895959e944936/config.json
Model config LlamaConfig {
  "_name_or_path": "/data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--meta-llama--Llama-2-13b-hf/snapshots/db6b8eb1feabb38985fdf785a89895959e944936",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13824,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 40,
  "num_hidden_layers": 40,
  "num_key_value_heads": 40,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.31.0",
  "use_cache": true,
  "vocab_size": 32000
}

loading file tokenizer.model
loading file added_tokens.json
loading file special_tokens_map.json
loading file tokenizer_config.json
loading weights file /data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--meta-llama--Llama-2-13b-hf/snapshots/db6b8eb1feabb38985fdf785a89895959e944936/model.safetensors.index.json
Detected DeepSpeed ZeRO-3: activating zero.init() for this model
Generate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "pad_token_id": 0,
  "transformers_version": "4.31.0"
}

[2023-08-28 20:25:31,710] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 13.02B parameters
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:09,  4.90s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:09,  4.95s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:10,  5.01s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:10,  5.42s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.91s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  2.78s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.34s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  2.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.35s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  2.86s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.42s/it]
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:10<00:05,  5.32s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:15<00:00,  4.99s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:15<00:00,  5.09s/it]
All model checkpoint weights were used when initializing LlamaForCausalLM.

All the weights of LlamaForCausalLM were initialized from the model checkpoint at /data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--meta-llama--Llama-2-13b-hf/snapshots/db6b8eb1feabb38985fdf785a89895959e944936.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
Generation config file not found, using a generation config created from the model config.
Assigning <s> to the bos_token key of the tokenizer
Assigning </s> to the eos_token key of the tokenizer
Assigning <unk> to the unk_token key of the tokenizer
Assigning <pad> to the pad_token key of the tokenizer
Adding <pad> to the vocabulary
08/28/2023 20:25:49 - INFO - __main__ - Sample 57805 of the training set: {'input_ids': tensor([    1,   960,   395, 29882, 29898, 29891,  7950, 10779, 29912, 29896,
        29974, 29891,  1157, 29906, 29899, 29891,  4429,   769,   825,   338,
          278,   995,   310,   395, 29882,  3426, 29896,  2119, 29945,  1262,
        29973, 14657,   596,  1234,   297, 20393,   883, 29889,    13,  1762,
         1284,   278, 16402,   310,   263,   740, 29892,   306,   817,   304,
         4607,   278, 16178,   310,   278,  1881,   322,   278,  1962,  3651,
        29889,    13,  7058,  2794,   306,   864,   304, 10683,   278,  6306,
          395, 29882, 29898, 29891,  7950, 10779, 29912, 29896, 29974, 29891,
         1157, 29906, 29899, 29891,  1042,   408,   395, 29891,  2013, 10779,
        29912, 29896, 29974, 29916,  1157, 29906, 29899, 29916,  4429,   988,
          395, 29916, 29938,   338,   278,   716,  1881,   322,   395, 29891,
        29938,   338,   278,   716,  1962, 29889,    13,  1762,   437,   393,
        29892,   306,   817,   304, 11695,   403,   395, 29891, 29938,   373,
          697,  2625,   310,   278,  6306, 29889,    13]), 'labels': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, 6374, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, 8178]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}.
08/28/2023 20:25:49 - INFO - __main__ - Sample 74094 of the training set: {'input_ids': tensor([    1,  2803,   395, 29886, 29898, 29916,  1262,   367,   263, 10159,
          310,  7426, 29871, 29953,  1316,   393,    13, 29905, 29961, 29886,
        29898, 29906, 29985, 29876, 29897,   353,   320,  1154, 29912, 29896,
         1157, 29906, 29985, 29876,  1012, 29962,  1454,   395, 29876,   353,
        29871, 29900,  8209, 29871, 29896, 29892, 29871, 29906, 29892,   779,
         7778,  8209, 29871, 29953, 29889, 29871, 10987,   395, 29886, 29898,
        29900,   467, 29938,    13, 29902,  8369,   393,   278, 10159,   756,
         7426, 29871, 29953,   322,   727,   526, 29871, 29955,  2183,  1819,
          310,   395, 29886, 29898, 29906, 29985, 29876,  4935,    13,  4013,
        14661,   393,   306,  1795,   367,  2221,   304,  1284,   395, 29886,
        29898, 29916,  1262,   491, 29694, 29892,   773,   263,  1788,   310,
        29871, 29955,  5608, 10693,   297, 29871, 29955,  9815, 29879,   313,
         1552, 16127,   310,   395, 29886, 29898, 29916,  1262,   467,    13,
         2499,   725,  6703, 29892,   306,  1033,  1018,   304,  4140,   278,
          883,   310,   395, 29886, 29898, 29916,  1262,   491,  3063,   363,
        15038,   297,   278,  2183,  1819, 29889,    13,  2831,  1342, 29892,
          306,  1074,   393,   395, 29886, 29898, 29906, 29985, 29876,  1262,
          338,  2337,   263,  3081,   310,   779,  1154, 29912, 29896,  1157,
        29906,  4429,   322,   278, 28869,   338,   278,  8178,   310,   395,
        29876,  1504,    13,  4013, 11981,   592,   304, 25466,   545,   393,
          395, 29886, 29898, 29916,  1262,  1795,   367,   310,   278,   883,
          395, 29886, 29898, 29916, 29897,   353,   263, 29898, 29906,  3426,
        29916, 28813, 29890,  1628,   988,   395, 29874, 29938,   322,   395,
        29890, 29938,   526, 17727, 29889,    13]), 'labels': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, 6374, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        6374, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        6374, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, 8178]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}.
08/28/2023 20:25:49 - INFO - __main__ - Sample 3245 of the training set: {'input_ids': tensor([    1,  2803,   395,   317,   395,   367,   278,   731,   310,   599,
        11192,   322,  7936,   265,  1338,   310,   263,  4943, 11137, 12841,
        29889,   319,  5101,   310,  3161,   310,   395,   317,   395,   526,
         4629,   472,  4036,  1728, 16920, 29889,  1724,   338,   278,  6976,
          393,   278,  1023, 10434, 24611,   505,   278,  1021,  3309, 29973,
           13, 29902,  1073,   393,   263,  4943, 11137, 12841,   756,  5320,
          378,  7108,   296, 11192,   322,  5320,   378,  7108,   296, 23619,
        29892,   577,   599,   278, 11192,   505,   278,  1021,  3309, 29889,
           13, 29902,   884,  1073,   393,   263,  4943, 11137, 12841,   756,
         5320,  7936,   265,  1338, 29892,   322,   896,   599,   505,   278,
         1021,  3309,   408,  1532, 29892,   541,  1422,   515,   278,  3309,
          310,   278, 11192, 29889,    13,  6295, 29892,   297,  3001, 29892,
          727,   526,  1023,  1950, 27497,   363,   278, 24611,   297,   395,
          317,   395, 29901,   278,  2625,  3309,   322,   278, 19640,  3309,
        29889,    13,  1762,  1284,   278,  6976,   393,   278,  1023, 10434,
        24611,   505,   278,  1021,  3309, 29892,   306,   817,   304,  2302,
          278,  1353,   310,  5837,   304,  6755,  1023, 24611,   310,   278,
         1021,  3309, 29892,   322, 16429,   393,   491,   278,  3001,  1353,
          310,  5837,   304,  6755,  1023, 24611,   515,   395,   317,  8184,
           13,  1762,  6755,  1023, 24611,   310,   278,  1021,  3309, 29892,
          306,   508,  2845,  6755,  1023, 11192,   470,  1023,  7936,   265,
         1338, 29889,    13,  1762,  6755,  1023, 11192, 29892,   306,   508,
          671,   278, 10296,  7063, 29892,  1951,   278,  1797,   947,   451,
         4383, 29889,  1670,   526,   395, 29871, 29945,   395, 11192, 29892,
          577,   278,  1353,   310,  5837,   304,  6755,  1023,   310,   963,
          338,   395,   320, 16183, 29912, 29945,  1157, 29906, 29913,   353,
        29871, 29896, 29900,  8184,    13,  1762,  6755,  1023,  7936,   265,
         1338, 29892,   306,   508,   884,   671,   278, 10296,  7063, 29889,
         1670,   526,   395, 29871, 29945,   395,  7936,   265,  1338, 29892,
          577,   278,  1353,   310,  5837,   304,  6755,  1023,   310,   963,
          338,   395,   320, 16183, 29912, 29945,  1157, 29906, 29913,   353,
        29871, 29896, 29900,   395,   408,  1532, 29889,    13,  8439,  1079,
        29892,   278,  3001,  1353,   310,  5837,   304,  6755,  1023, 24611,
          310,   278,  1021,  3309,   338,   395, 29871, 29896, 29900,   718,
        29871, 29896, 29900,   353, 29871, 29906, 29900,  8184,    13,  1576,
         3001,  1353,   310,  5837,   304,  6755,  1023, 24611,   515,   395,
          317,   395,   338,   278,  1021,   408,   278,  1353,   310,  5837,
          304,  6755,  1023,  3161,   515,   263,   731,   310,   395, 29871,
        29896, 29900,   395,  3161, 29892,  1951,   395,   317,   395,   756,
          395, 29871, 29945,   395, 11192,   322,   395, 29871, 29945,   395,
         7936,   265,  1338, 29889,    13, 14769,   475, 29892,   306,   508,
          671,   278, 10296,  7063, 29892,  1951,   278,  1797,   947,   451,
         4383, 29889,   450,  1353,   310,  5837,   304,  6755,  1023,  3161,
          515,   263,   731,   310,   395, 29871, 29896, 29900,   395,  3161,
          338,   395,   320, 16183, 29912, 29896, 29900,  1157, 29906, 29913,
          353, 29871, 29946, 29945,  8184,    13,  8439,  1079, 29892,   278,
         6976,   393,   278,  1023, 10434, 24611,   505,   278,  1021,  3309,
          338,   395,   320,  1154, 29912, 29906, 29900,  1157, 29946, 29945,
        29913,   353,   320,  1154, 29912, 29946,  1157, 29929, 29913,  8184,
           13, 29937,   673,    13,    13, 29905,  1154, 29912, 29946,  1157,
        29929, 29913,    13]), 'labels': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, 6374, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        6374, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, 6374, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        6374, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6374,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6374]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}.
08/28/2023 20:25:49 - INFO - accelerate.accelerator - Updating DeepSpeed's gradient accumulation steps to 16 from 1.
[2023-08-28 20:25:49,130] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
08/28/2023 20:25:49 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0
08/28/2023 20:25:49 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1
08/28/2023 20:25:49 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 3
08/28/2023 20:25:49 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 2
08/28/2023 20:25:49 - INFO - torch.distributed.distributed_c10d - Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
08/28/2023 20:25:49 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
08/28/2023 20:25:49 - INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
08/28/2023 20:25:49 - INFO - torch.distributed.distributed_c10d - Rank 3: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[2023-08-28 20:25:50,292] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-08-28 20:25:50,293] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-08-28 20:25:50,293] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-08-28 20:25:50,309] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-08-28 20:25:50,309] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2023-08-28 20:25:50,309] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2023-08-28 20:25:50,309] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2023-08-28 20:25:50,433] [INFO] [utils.py:785:see_memory_usage] Stage 3 initialize beginning
[2023-08-28 20:25:50,434] [INFO] [utils.py:786:see_memory_usage] MA 6.75 GB         Max_MA 7.45 GB         CA 9.48 GB         Max_CA 9 GB 
[2023-08-28 20:25:50,434] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 89.28 GB, percent = 8.9%
[2023-08-28 20:25:50,435] [INFO] [stage3.py:117:__init__] Reduce bucket size 26214400
[2023-08-28 20:25:50,435] [INFO] [stage3.py:118:__init__] Prefetch bucket size 23592960
[2023-08-28 20:25:50,510] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2023-08-28 20:25:50,511] [INFO] [utils.py:786:see_memory_usage] MA 6.75 GB         Max_MA 6.75 GB         CA 9.48 GB         Max_CA 9 GB 
[2023-08-28 20:25:50,511] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 89.29 GB, percent = 8.9%
Parameter Offload: Total persistent parameters: 414720 in 81 params
[2023-08-28 20:25:50,605] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2023-08-28 20:25:50,605] [INFO] [utils.py:786:see_memory_usage] MA 6.29 GB         Max_MA 6.83 GB         CA 9.48 GB         Max_CA 9 GB 
[2023-08-28 20:25:50,605] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 89.29 GB, percent = 8.9%
[2023-08-28 20:25:50,682] [INFO] [utils.py:785:see_memory_usage] Before creating fp16 partitions
[2023-08-28 20:25:50,684] [INFO] [utils.py:786:see_memory_usage] MA 6.29 GB         Max_MA 6.29 GB         CA 9.48 GB         Max_CA 9 GB 
[2023-08-28 20:25:50,684] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 89.3 GB, percent = 8.9%
[2023-08-28 20:25:55,081] [INFO] [utils.py:785:see_memory_usage] After creating fp16 partitions: 4
[2023-08-28 20:25:55,082] [INFO] [utils.py:786:see_memory_usage] MA 6.29 GB         Max_MA 6.29 GB         CA 7.02 GB         Max_CA 9 GB 
[2023-08-28 20:25:55,082] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 107.46 GB, percent = 10.7%
[2023-08-28 20:25:55,196] [INFO] [utils.py:785:see_memory_usage] Before creating fp32 partitions
[2023-08-28 20:25:55,196] [INFO] [utils.py:786:see_memory_usage] MA 6.29 GB         Max_MA 6.29 GB         CA 7.02 GB         Max_CA 7 GB 
[2023-08-28 20:25:55,197] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 107.48 GB, percent = 10.7%
[2023-08-28 20:25:55,334] [INFO] [utils.py:785:see_memory_usage] After creating fp32 partitions
[2023-08-28 20:25:55,335] [INFO] [utils.py:786:see_memory_usage] MA 18.42 GB         Max_MA 19.43 GB         CA 22.03 GB         Max_CA 22 GB 
[2023-08-28 20:25:55,335] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 107.47 GB, percent = 10.7%
[2023-08-28 20:25:57,561] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-08-28 20:25:57,562] [INFO] [utils.py:786:see_memory_usage] MA 18.42 GB         Max_MA 18.42 GB         CA 22.03 GB         Max_CA 22 GB 
[2023-08-28 20:25:57,562] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 89.3 GB, percent = 8.9%
Traceback (most recent call last):
  File "/data/users/zhangjunlei/tyx/reward-by-prm800k/open-instruct/open_instruct/finetune.py", line 1050, in <module>
Traceback (most recent call last):
  File "/data/users/zhangjunlei/tyx/reward-by-prm800k/open-instruct/open_instruct/finetune.py", line 1050, in <module>
Traceback (most recent call last):
  File "/data/users/zhangjunlei/tyx/reward-by-prm800k/open-instruct/open_instruct/finetune.py", line 1050, in <module>
    main()
  File "/data/users/zhangjunlei/tyx/reward-by-prm800k/open-instruct/open_instruct/finetune.py", line 860, in main
    main()
  File "/data/users/zhangjunlei/tyx/reward-by-prm800k/open-instruct/open_instruct/finetune.py", line 860, in main
    main()
  File "/data/users/zhangjunlei/tyx/reward-by-prm800k/open-instruct/open_instruct/finetune.py", line 860, in main
    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py", line 1198, in prepare
    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py", line 1198, in prepare
    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    result = self._prepare_deepspeed(*args)
      File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
result = self._prepare_deepspeed(*args)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 310, in __init__
        engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)

  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py", line 171, in initialize
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py", line 171, in initialize
    self._configure_optimizer(optimizer, model_parameters)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1209, in _configure_optimizer
        engine = DeepSpeedEngine(args=args,engine = DeepSpeedEngine(args=args,

  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 310, in __init__
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 310, in __init__
        self._configure_optimizer(optimizer, model_parameters)self._configure_optimizer(optimizer, model_parameters)

  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1209, in _configure_optimizer
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1209, in _configure_optimizer
    self.optimizer = self._configure_zero_optimizer(basic_optimizer)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1505, in _configure_zero_optimizer
        self.optimizer = self._configure_zero_optimizer(basic_optimizer)self.optimizer = self._configure_zero_optimizer(basic_optimizer)

  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1505, in _configure_zero_optimizer
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1505, in _configure_zero_optimizer
    optimizer = DeepSpeedZeroOptimizer_Stage3(
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 322, in __init__
    self._setup_for_real_optimizer()
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 419, in _setup_for_real_optimizer
        optimizer = DeepSpeedZeroOptimizer_Stage3(optimizer = DeepSpeedZeroOptimizer_Stage3(

  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 322, in __init__
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 322, in __init__
    self.initialize_optimizer_states()
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 929, in initialize_optimizer_states
        self._setup_for_real_optimizer()self._setup_for_real_optimizer()

  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 419, in _setup_for_real_optimizer
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 419, in _setup_for_real_optimizer
    self.initialize_optimizer_states()
      File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 929, in initialize_optimizer_states
self.initialize_optimizer_states()
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 929, in initialize_optimizer_states
    self._optimizer_step(i)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 854, in _optimizer_step
    self._optimizer_step(i)
      File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 854, in _optimizer_step
self._optimizer_step(i)    
self.optimizer.step()  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 854, in _optimizer_step

  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 69, in wrapper
    self.optimizer.step()
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 69, in wrapper
    self.optimizer.step()
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 69, in wrapper
        return wrapped(*args, **kwargs)return wrapped(*args, **kwargs)

  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/optimizer.py", line 280, in wrapper
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/optimizer.py", line 280, in wrapper
    return wrapped(*args, **kwargs)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/optimizer.py", line 280, in wrapper
        out = func(*args, **kwargs)out = func(*args, **kwargs)
    
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/optimizer.py", line 33, in _use_grad
out = func(*args, **kwargs)  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/optimizer.py", line 33, in _use_grad

  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/optimizer.py", line 33, in _use_grad
        ret = func(self, *args, **kwargs)ret = func(self, *args, **kwargs)
    
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/adamw.py", line 160, in step
ret = func(self, *args, **kwargs)  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/adamw.py", line 160, in step

  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/adamw.py", line 160, in step
    self._init_group(        
self._init_group(self._init_group(  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/adamw.py", line 118, in _init_group


  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/adamw.py", line 118, in _init_group
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/adamw.py", line 118, in _init_group
    state["exp_avg_sq"] = torch.zeros_like(
        state["exp_avg_sq"] = torch.zeros_like(torch.cudastate["exp_avg_sq"] = torch.zeros_like(
.
OutOfMemoryErrortorch.cuda: .torch.cudaCUDA out of memory. Tried to allocate 3.75 GiB (GPU 1; 79.20 GiB total capacity; 25.94 GiB already allocated; 1.29 GiB free; 27.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONFOutOfMemoryError.
: OutOfMemoryErrorCUDA out of memory. Tried to allocate 3.75 GiB (GPU 2; 79.20 GiB total capacity; 25.94 GiB already allocated; 1.30 GiB free; 27.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF: 
CUDA out of memory. Tried to allocate 3.75 GiB (GPU 3; 79.20 GiB total capacity; 25.94 GiB already allocated; 1.72 GiB free; 27.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/data/users/zhangjunlei/tyx/reward-by-prm800k/open-instruct/open_instruct/finetune.py", line 1050, in <module>
    main()
  File "/data/users/zhangjunlei/tyx/reward-by-prm800k/open-instruct/open_instruct/finetune.py", line 860, in main
    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py", line 1198, in prepare
    result = self._prepare_deepspeed(*args)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py", line 1537, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py", line 171, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 310, in __init__
    self._configure_optimizer(optimizer, model_parameters)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1209, in _configure_optimizer
    self.optimizer = self._configure_zero_optimizer(basic_optimizer)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1505, in _configure_zero_optimizer
    optimizer = DeepSpeedZeroOptimizer_Stage3(
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 322, in __init__
    self._setup_for_real_optimizer()
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 419, in _setup_for_real_optimizer
    self.initialize_optimizer_states()
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 929, in initialize_optimizer_states
    self._optimizer_step(i)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 854, in _optimizer_step
    self.optimizer.step()
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 69, in wrapper
    return wrapped(*args, **kwargs)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/adamw.py", line 160, in step
    self._init_group(
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/optim/adamw.py", line 118, in _init_group
    state["exp_avg_sq"] = torch.zeros_like(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.75 GiB (GPU 0; 79.20 GiB total capacity; 25.94 GiB already allocated; 1.72 GiB free; 27.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 2234092) of binary: /data/users/zhangjunlei/anaconda3/envs/open-instruct/bin/python
Traceback (most recent call last):
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 45, in main
    args.func(args)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py", line 964, in launch_command
    deepspeed_launcher(args)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py", line 687, in deepspeed_launcher
    distrib_run.run(args)
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/data/users/zhangjunlei/tyx/reward-by-prm800k/open-instruct/open_instruct/finetune.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-28_20:26:03
  host      : a100
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 2234093)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-08-28_20:26:03
  host      : a100
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 2234095)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-08-28_20:26:03
  host      : a100
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 2234096)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-28_20:26:03
  host      : a100
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2234092)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
