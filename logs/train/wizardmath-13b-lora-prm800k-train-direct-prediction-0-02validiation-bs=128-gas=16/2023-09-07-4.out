nohup: ignoring input
[2023-09-07 07:13:23,062] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-07 07:13:24,432] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-07 07:13:24,433] [INFO] [runner.py:555:main] cmd = /data/users/zhangjunlei/anaconda3/envs/open-instruct/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMywgNF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None /data/users/zhangjunlei/tyx/FastChat/fastchat/train/train_all_linear_modules_with_qlora.py --model_name_or_path /data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--WizardLM--WizardMath-13B-V1.0/snapshots/7ef412d2c680ef0fbdcd88d0df31b396d8d3049c --data_path /data/users/zhangjunlei/tyx/reward-by-prm800k/datasets/prm800k-train-direct-prediction-0-02validiation-encoded-datasets --output_dir /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-lora-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16 --model_max_length 1024 --per_device_train_batch_size 2 --per_device_eval_batch_size 4 --gradient_checkpointing True --gradient_accumulation_steps 16 --num_train_epochs 100 --evaluation_strategy steps --eval_steps 100 --eval_first True --save_strategy steps --save_steps 100 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --lora_r 256 --lora_alpha 256 --lora_dropout 0.05 --lora_target_modules all_linear --q_lora True --bf16 True --tf32 True --use_accelerate_lib flash-attn-v2 --logging_strategy steps --logging_steps 1
[2023-09-07 07:13:25,918] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-07 07:13:27,082] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 3, 4]}
[2023-09-07 07:13:27,083] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2023-09-07 07:13:27,083] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2023-09-07 07:13:27,083] [INFO] [launch.py:163:main] dist_world_size=4
[2023-09-07 07:13:27,083] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,3,4
[2023-09-07 07:13:29,113] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-07 07:13:29,113] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-07 07:13:29,117] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-07 07:13:29,167] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:09<00:46,  9.39s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:09<00:47,  9.48s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:09<00:47,  9.58s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:09<00:49,  9.88s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:17<00:35,  8.85s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:18<00:35,  8.92s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:18<00:35,  8.95s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:18<00:35,  8.96s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:26<00:26,  8.80s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:26<00:26,  8.81s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:26<00:26,  8.86s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:26<00:26,  8.80s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:35<00:17,  8.81s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:35<00:17,  8.84s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:35<00:17,  8.80s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:35<00:17,  8.84s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:44<00:08,  8.82s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:44<00:08,  8.82s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:44<00:08,  8.83s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:44<00:08,  8.81s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:45<00:00,  6.40s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:45<00:00,  7.67s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:46<00:00,  6.41s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:46<00:00,  7.68s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:46<00:00,  6.40s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:46<00:00,  7.69s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:46<00:00,  6.44s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:46<00:00,  7.70s/it]
[DEBUG] lora_args.lora_target_modules = ['all_linear']
trainable params: 1,001,390,080 || all params: 7,673,379,840 || trainable%: 13.05018259072654
  0%|          | 0/114 [00:00<?, ?it/s]  2%|▏         | 2/114 [00:00<00:45,  2.44it/s]  3%|▎         | 3/114 [00:01<01:02,  1.77it/s]  4%|▎         | 4/114 [00:02<01:11,  1.54it/s]  4%|▍         | 5/114 [00:03<01:15,  1.44it/s]  5%|▌         | 6/114 [00:03<01:17,  1.39it/s]  6%|▌         | 7/114 [00:04<01:19,  1.35it/s]  7%|▋         | 8/114 [00:05<01:19,  1.33it/s]  8%|▊         | 9/114 [00:06<01:19,  1.32it/s]  9%|▉         | 10/114 [00:07<01:19,  1.31it/s] 10%|▉         | 11/114 [00:07<01:19,  1.30it/s] 11%|█         | 12/114 [00:08<01:18,  1.30it/s] 11%|█▏        | 13/114 [00:09<01:18,  1.29it/s] 12%|█▏        | 14/114 [00:10<01:17,  1.29it/s] 13%|█▎        | 15/114 [00:10<01:16,  1.29it/s] 14%|█▍        | 16/114 [00:11<01:16,  1.29it/s] 15%|█▍        | 17/114 [00:12<01:15,  1.28it/s] 16%|█▌        | 18/114 [00:13<01:14,  1.28it/s] 17%|█▋        | 19/114 [00:14<01:14,  1.28it/s] 18%|█▊        | 20/114 [00:14<01:13,  1.28it/s] 18%|█▊        | 21/114 [00:15<01:12,  1.28it/s] 19%|█▉        | 22/114 [00:16<01:11,  1.28it/s] 20%|██        | 23/114 [00:17<01:11,  1.28it/s] 21%|██        | 24/114 [00:17<01:10,  1.28it/s] 22%|██▏       | 25/114 [00:18<01:09,  1.28it/s] 23%|██▎       | 26/114 [00:19<01:08,  1.28it/s] 24%|██▎       | 27/114 [00:20<01:08,  1.28it/s] 25%|██▍       | 28/114 [00:21<01:07,  1.28it/s] 25%|██▌       | 29/114 [00:21<01:06,  1.28it/s] 26%|██▋       | 30/114 [00:22<01:05,  1.28it/s] 27%|██▋       | 31/114 [00:23<01:04,  1.28it/s] 28%|██▊       | 32/114 [00:24<01:03,  1.28it/s] 29%|██▉       | 33/114 [00:24<01:03,  1.28it/s] 30%|██▉       | 34/114 [00:25<01:02,  1.28it/s] 31%|███       | 35/114 [00:26<01:01,  1.28it/s] 32%|███▏      | 36/114 [00:27<01:00,  1.28it/s] 32%|███▏      | 37/114 [00:28<00:59,  1.28it/s] 33%|███▎      | 38/114 [00:28<00:59,  1.28it/s] 34%|███▍      | 39/114 [00:29<00:58,  1.28it/s] 35%|███▌      | 40/114 [00:30<00:57,  1.28it/s] 36%|███▌      | 41/114 [00:31<00:56,  1.28it/s] 37%|███▋      | 42/114 [00:32<00:56,  1.28it/s] 38%|███▊      | 43/114 [00:32<00:55,  1.28it/s] 39%|███▊      | 44/114 [00:33<00:54,  1.28it/s] 39%|███▉      | 45/114 [00:34<00:53,  1.29it/s] 40%|████      | 46/114 [00:35<00:52,  1.29it/s] 41%|████      | 47/114 [00:35<00:52,  1.29it/s] 42%|████▏     | 48/114 [00:36<00:51,  1.29it/s] 43%|████▎     | 49/114 [00:37<00:50,  1.29it/s] 44%|████▍     | 50/114 [00:38<00:49,  1.28it/s] 45%|████▍     | 51/114 [00:39<00:49,  1.28it/s] 46%|████▌     | 52/114 [00:39<00:48,  1.28it/s] 46%|████▋     | 53/114 [00:40<00:47,  1.29it/s] 47%|████▋     | 54/114 [00:41<00:46,  1.28it/s] 48%|████▊     | 55/114 [00:42<00:45,  1.28it/s] 49%|████▉     | 56/114 [00:42<00:45,  1.28it/s] 50%|█████     | 57/114 [00:43<00:44,  1.28it/s] 51%|█████     | 58/114 [00:44<00:43,  1.29it/s] 52%|█████▏    | 59/114 [00:45<00:42,  1.29it/s] 53%|█████▎    | 60/114 [00:46<00:42,  1.29it/s] 54%|█████▎    | 61/114 [00:46<00:41,  1.29it/s] 54%|█████▍    | 62/114 [00:47<00:40,  1.29it/s] 55%|█████▌    | 63/114 [00:48<00:39,  1.29it/s] 56%|█████▌    | 64/114 [00:49<00:38,  1.28it/s] 57%|█████▋    | 65/114 [00:49<00:38,  1.29it/s] 58%|█████▊    | 66/114 [00:50<00:37,  1.28it/s] 59%|█████▉    | 67/114 [00:51<00:36,  1.28it/s] 60%|█████▉    | 68/114 [00:52<00:35,  1.28it/s] 61%|██████    | 69/114 [00:53<00:35,  1.28it/s] 61%|██████▏   | 70/114 [00:53<00:34,  1.28it/s] 62%|██████▏   | 71/114 [00:54<00:33,  1.28it/s] 63%|██████▎   | 72/114 [00:55<00:32,  1.28it/s] 64%|██████▍   | 73/114 [00:56<00:31,  1.29it/s] 65%|██████▍   | 74/114 [00:56<00:31,  1.29it/s] 66%|██████▌   | 75/114 [00:57<00:30,  1.29it/s] 67%|██████▋   | 76/114 [00:58<00:29,  1.29it/s] 68%|██████▊   | 77/114 [00:59<00:28,  1.29it/s] 68%|██████▊   | 78/114 [01:00<00:28,  1.28it/s] 69%|██████▉   | 79/114 [01:00<00:27,  1.28it/s] 70%|███████   | 80/114 [01:01<00:26,  1.28it/s] 71%|███████   | 81/114 [01:02<00:25,  1.28it/s] 72%|███████▏  | 82/114 [01:03<00:24,  1.28it/s] 73%|███████▎  | 83/114 [01:03<00:24,  1.29it/s] 74%|███████▎  | 84/114 [01:04<00:23,  1.29it/s] 75%|███████▍  | 85/114 [01:05<00:22,  1.29it/s] 75%|███████▌  | 86/114 [01:06<00:21,  1.29it/s] 76%|███████▋  | 87/114 [01:07<00:20,  1.29it/s] 77%|███████▋  | 88/114 [01:07<00:20,  1.29it/s] 78%|███████▊  | 89/114 [01:08<00:19,  1.29it/s] 79%|███████▉  | 90/114 [01:09<00:18,  1.29it/s] 80%|███████▉  | 91/114 [01:10<00:17,  1.29it/s] 81%|████████  | 92/114 [01:10<00:17,  1.29it/s] 82%|████████▏ | 93/114 [01:11<00:16,  1.29it/s] 82%|████████▏ | 94/114 [01:12<00:15,  1.29it/s] 83%|████████▎ | 95/114 [01:13<00:14,  1.29it/s] 84%|████████▍ | 96/114 [01:14<00:13,  1.29it/s] 85%|████████▌ | 97/114 [01:14<00:13,  1.29it/s] 86%|████████▌ | 98/114 [01:15<00:12,  1.29it/s] 87%|████████▋ | 99/114 [01:16<00:11,  1.29it/s] 88%|████████▊ | 100/114 [01:17<00:10,  1.29it/s] 89%|████████▊ | 101/114 [01:17<00:10,  1.29it/s] 89%|████████▉ | 102/114 [01:18<00:09,  1.29it/s] 90%|█████████ | 103/114 [01:19<00:08,  1.29it/s] 91%|█████████ | 104/114 [01:20<00:07,  1.29it/s] 92%|█████████▏| 105/114 [01:21<00:06,  1.29it/s] 93%|█████████▎| 106/114 [01:21<00:06,  1.29it/s] 94%|█████████▍| 107/114 [01:22<00:05,  1.29it/s] 95%|█████████▍| 108/114 [01:23<00:04,  1.29it/s] 96%|█████████▌| 109/114 [01:24<00:03,  1.29it/s] 96%|█████████▋| 110/114 [01:24<00:03,  1.29it/s] 97%|█████████▋| 111/114 [01:25<00:02,  1.29it/s] 98%|█████████▊| 112/114 [01:26<00:01,  1.29it/s] 99%|█████████▉| 113/114 [01:27<00:00,  1.29it/s]100%|██████████| 114/114 [01:28<00:00,  1.29it/s](1818, 1024, 3)
wandb: Currently logged in as: kidrain61. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /data/users/zhangjunlei/tyx/wandb/wandb/run-20230907_071741-dhfru0jk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wizardmath-13b-lora-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16-2023-09-07-4
wandb: ⭐️ View project at https://wandb.ai/kidrain61/step-reward
wandb: 🚀 View run at https://wandb.ai/kidrain61/step-reward/runs/dhfru0jk
100%|██████████| 114/114 [02:06<00:00,  1.11s/it]
  0%|          | 0/66500 [00:00<?, ?it/s]  0%|          | 1/66500 [00:24<456:47:35, 24.73s/it]                                                     {'loss': 20.1936, 'learning_rate': 1.0025062656641605e-08, 'epoch': 0.0}
  0%|          | 1/66500 [00:24<456:47:35, 24.73s/it]  0%|          | 2/66500 [00:48<447:48:08, 24.24s/it]                                                     {'loss': 20.089, 'learning_rate': 2.005012531328321e-08, 'epoch': 0.0}
  0%|          | 2/66500 [00:48<447:48:08, 24.24s/it]  0%|          | 3/66500 [01:12<444:59:00, 24.09s/it]                                                     {'loss': 20.2529, 'learning_rate': 3.0075187969924815e-08, 'epoch': 0.0}
  0%|          | 3/66500 [01:12<444:59:00, 24.09s/it]  0%|          | 4/66500 [01:36<443:51:32, 24.03s/it]                                                     {'loss': 20.1407, 'learning_rate': 4.010025062656642e-08, 'epoch': 0.01}
  0%|          | 4/66500 [01:36<443:51:32, 24.03s/it]  0%|          | 5/66500 [02:00<443:12:52, 24.00s/it]                                                     {'loss': 20.2843, 'learning_rate': 5.0125313283208025e-08, 'epoch': 0.01}
  0%|          | 5/66500 [02:00<443:12:52, 24.00s/it]  0%|          | 6/66500 [02:24<443:00:22, 23.98s/it]                                                     {'loss': 20.2637, 'learning_rate': 6.015037593984963e-08, 'epoch': 0.01}
  0%|          | 6/66500 [02:24<443:00:22, 23.98s/it]