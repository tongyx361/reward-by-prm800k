nohup: ignoring input
[2023-09-10 00:04:38,323] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-10 00:04:41,310] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-10 00:04:41,310] [INFO] [runner.py:555:main] cmd = /data/users/zhangjunlei/anaconda3/envs/open-instruct/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMSwgMywgNCwgNl19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None /data/users/zhangjunlei/tyx/FastChat/fastchat/train/train_qlora_flash_attn_2.py --model_name_or_path /data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--WizardLM--WizardMath-70B-V1.0/snapshots/e089c3f9d2ad9d1acb62425aec3f4126f498f4c5 --data_path /data/users/zhangjunlei/tyx/reward-by-prm800k/datasets/prm800k-train-direct-prediction-0-02validiation-encoded-datasets --output_dir /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-70b-qlora-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16 --model_max_length 1024 --per_device_train_batch_size 2 --per_device_eval_batch_size 4 --gradient_checkpointing True --gradient_accumulation_steps 16 --num_train_epochs 100 --evaluation_strategy steps --eval_steps 100 --eval_first False --save_strategy steps --save_steps 100 --load_best_model_at_end True --metric_for_best_model f1_-1 --greater_is_better True --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type linear --lora_r 16 --lora_alpha 16 --lora_dropout 0.05 --lora_target_modules all_linear --q_lora True --bf16 True --tf32 True --use_accelerate_lib flash-attn-v2 --deepspeed /data/users/zhangjunlei/tyx/reward-by-prm800k/ds_configs/stage2.conf --logging_strategy steps --logging_steps 1
[2023-09-10 00:04:42,768] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-10 00:04:44,316] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [1, 3, 4, 6]}
[2023-09-10 00:04:44,316] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2023-09-10 00:04:44,316] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2023-09-10 00:04:44,316] [INFO] [launch.py:163:main] dist_world_size=4
[2023-09-10 00:04:44,316] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=1,3,4,6
[2023-09-10 00:04:47,333] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-10 00:04:47,448] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-10 00:04:47,487] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-10 00:04:47,526] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-10 00:04:49,019] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-09-10 00:04:49,019] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-09-10 00:04:49,056] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-09-10 00:04:49,056] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-09-10 00:04:49,126] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-09-10 00:04:49,126] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-09-10 00:04:49,126] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-10 00:04:49,131] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-09-10 00:04:49,131] [INFO] [comm.py:616:init_distributed] cdb=None
Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/29 [00:09<04:30,  9.65s/it]Loading checkpoint shards:   3%|▎         | 1/29 [00:10<04:43, 10.11s/it]Loading checkpoint shards:   3%|▎         | 1/29 [00:09<04:37,  9.92s/it]Loading checkpoint shards:   3%|▎         | 1/29 [00:10<04:58, 10.67s/it]Loading checkpoint shards:   7%|▋         | 2/29 [00:15<03:25,  7.60s/it]Loading checkpoint shards:   7%|▋         | 2/29 [00:16<03:35,  7.98s/it]Loading checkpoint shards:   7%|▋         | 2/29 [00:16<03:40,  8.16s/it]Loading checkpoint shards:   7%|▋         | 2/29 [00:16<03:36,  8.01s/it]Loading checkpoint shards:  10%|█         | 3/29 [00:23<03:16,  7.56s/it]Loading checkpoint shards:  10%|█         | 3/29 [00:24<03:20,  7.71s/it]Loading checkpoint shards:  10%|█         | 3/29 [00:24<03:22,  7.80s/it]Loading checkpoint shards:  10%|█         | 3/29 [00:24<03:21,  7.75s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:31<03:14,  7.79s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:32<03:14,  7.78s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:31<03:12,  7.72s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:31<03:14,  7.76s/it]Loading checkpoint shards:  17%|█▋        | 5/29 [00:38<02:59,  7.47s/it]Loading checkpoint shards:  17%|█▋        | 5/29 [00:38<02:55,  7.33s/it]Loading checkpoint shards:  17%|█▋        | 5/29 [00:38<02:58,  7.44s/it]Loading checkpoint shards:  17%|█▋        | 5/29 [00:39<03:00,  7.51s/it]Loading checkpoint shards:  21%|██        | 6/29 [00:47<03:02,  7.95s/it]Loading checkpoint shards:  21%|██        | 6/29 [00:47<03:00,  7.85s/it]Loading checkpoint shards:  21%|██        | 6/29 [00:47<03:00,  7.84s/it]Loading checkpoint shards:  21%|██        | 6/29 [00:47<03:00,  7.84s/it]Loading checkpoint shards:  24%|██▍       | 7/29 [00:54<02:50,  7.77s/it]Loading checkpoint shards:  24%|██▍       | 7/29 [00:54<02:50,  7.73s/it]Loading checkpoint shards:  24%|██▍       | 7/29 [00:55<02:50,  7.76s/it]Loading checkpoint shards:  24%|██▍       | 7/29 [00:54<02:51,  7.78s/it]Loading checkpoint shards:  28%|██▊       | 8/29 [01:03<02:43,  7.80s/it]Loading checkpoint shards:  28%|██▊       | 8/29 [01:02<02:45,  7.88s/it]Loading checkpoint shards:  28%|██▊       | 8/29 [01:03<02:45,  7.89s/it]Loading checkpoint shards:  28%|██▊       | 8/29 [01:02<02:44,  7.85s/it]Loading checkpoint shards:  31%|███       | 9/29 [01:10<02:37,  7.87s/it]Loading checkpoint shards:  31%|███       | 9/29 [01:10<02:36,  7.82s/it]Loading checkpoint shards:  31%|███       | 9/29 [01:10<02:36,  7.83s/it]Loading checkpoint shards:  31%|███       | 9/29 [01:10<02:36,  7.83s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [01:18<02:25,  7.67s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [01:18<02:26,  7.72s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [01:18<02:26,  7.70s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [01:18<02:26,  7.73s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [01:25<02:17,  7.64s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [01:25<02:17,  7.61s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [01:25<02:17,  7.62s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [01:26<02:19,  7.74s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [01:33<02:10,  7.67s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [01:33<02:11,  7.73s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [01:33<02:10,  7.68s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [01:33<02:10,  7.66s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [01:41<02:03,  7.74s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [01:41<02:04,  7.76s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [01:41<02:05,  7.82s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [01:41<02:04,  7.79s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [01:49<01:56,  7.79s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [01:49<01:56,  7.76s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [01:49<01:57,  7.81s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [01:49<01:56,  7.77s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [01:56<01:47,  7.67s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [01:56<01:48,  7.72s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [01:56<01:47,  7.71s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [01:56<01:48,  7.74s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [02:04<01:39,  7.66s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [02:04<01:40,  7.73s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [02:04<01:40,  7.73s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [02:04<01:40,  7.72s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [02:11<01:31,  7.64s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [02:12<01:31,  7.63s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [02:12<01:31,  7.65s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [02:11<01:31,  7.64s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [02:19<01:25,  7.74s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [02:19<01:25,  7.75s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [02:20<01:25,  7.74s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [02:19<01:25,  7.75s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [02:27<01:17,  7.79s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [02:27<01:17,  7.79s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [02:28<01:18,  7.82s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [02:27<01:18,  7.83s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [02:35<01:09,  7.70s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [02:35<01:09,  7.73s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [02:35<01:09,  7.72s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [02:35<01:09,  7.74s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [02:43<01:01,  7.73s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [02:43<01:01,  7.72s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [02:43<01:01,  7.72s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [02:43<01:01,  7.72s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [02:50<00:53,  7.67s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [02:50<00:53,  7.68s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [02:51<00:53,  7.69s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [02:50<00:54,  7.77s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [02:58<00:46,  7.72s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [02:58<00:46,  7.76s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [02:58<00:46,  7.77s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [02:58<00:46,  7.74s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [03:06<00:38,  7.64s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [03:06<00:38,  7.70s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [03:06<00:38,  7.66s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [03:06<00:38,  7.77s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [03:13<00:30,  7.53s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [03:13<00:30,  7.56s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [03:13<00:30,  7.58s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [03:13<00:30,  7.58s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [03:20<00:22,  7.49s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [03:20<00:22,  7.47s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [03:20<00:22,  7.46s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [03:21<00:22,  7.49s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [03:28<00:15,  7.55s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [03:28<00:15,  7.55s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [03:28<00:15,  7.55s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [03:28<00:15,  7.54s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [03:36<00:07,  7.68s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [03:36<00:07,  7.67s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [03:36<00:07,  7.67s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [03:36<00:07,  7.66s/it]Loading checkpoint shards: 100%|██████████| 29/29 [03:41<00:00,  6.90s/it]Loading checkpoint shards: 100%|██████████| 29/29 [03:41<00:00,  7.64s/it]
Loading checkpoint shards: 100%|██████████| 29/29 [03:41<00:00,  6.94s/it]Loading checkpoint shards: 100%|██████████| 29/29 [03:41<00:00,  7.64s/it]
Loading checkpoint shards: 100%|██████████| 29/29 [03:41<00:00,  6.90s/it]Loading checkpoint shards: 100%|██████████| 29/29 [03:41<00:00,  7.65s/it]
Loading checkpoint shards: 100%|██████████| 29/29 [03:41<00:00,  6.92s/it]Loading checkpoint shards: 100%|██████████| 29/29 [03:41<00:00,  7.64s/it]
Traceback (most recent call last):
  File "/data/users/zhangjunlei/tyx/FastChat/fastchat/train/train_qlora_flash_attn_2.py", line 13, in <module>
    train()
  File "/data/users/zhangjunlei/tyx/FastChat/fastchat/train/train_qlora.py", line 229, in train
    data_module = get_data_module_from_encoded_datasets(data_args.data_path)
AttributeError: 'DataArguments' object has no attribute 'data_path'
get_peft_model() took 369.04827547073364 s
trainable params: 207,093,760 || all params: 69,183,774,720 || trainable%: 0.2993386250434414
Traceback (most recent call last):
  File "/data/users/zhangjunlei/tyx/FastChat/fastchat/train/train_qlora_flash_attn_2.py", line 13, in <module>
    train()
  File "/data/users/zhangjunlei/tyx/FastChat/fastchat/train/train_qlora.py", line 229, in train
    data_module = get_data_module_from_encoded_datasets(data_args.data_path)
AttributeError: 'DataArguments' object has no attribute 'data_path'
[2023-09-10 00:14:53,982] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2130723
[2023-09-10 00:14:54,419] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2130724
[2023-09-10 00:14:54,419] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2130725
[2023-09-10 00:14:56,108] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2130726
[2023-09-10 00:14:57,516] [ERROR] [launch.py:321:sigkill_handler] ['/data/users/zhangjunlei/anaconda3/envs/open-instruct/bin/python', '-u', '/data/users/zhangjunlei/tyx/FastChat/fastchat/train/train_qlora_flash_attn_2.py', '--local_rank=3', '--model_name_or_path', '/data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--WizardLM--WizardMath-70B-V1.0/snapshots/e089c3f9d2ad9d1acb62425aec3f4126f498f4c5', '--data_path', '/data/users/zhangjunlei/tyx/reward-by-prm800k/datasets/prm800k-train-direct-prediction-0-02validiation-encoded-datasets', '--output_dir', '/data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-70b-qlora-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16', '--model_max_length', '1024', '--per_device_train_batch_size', '2', '--per_device_eval_batch_size', '4', '--gradient_checkpointing', 'True', '--gradient_accumulation_steps', '16', '--num_train_epochs', '100', '--evaluation_strategy', 'steps', '--eval_steps', '100', '--eval_first', 'False', '--save_strategy', 'steps', '--save_steps', '100', '--load_best_model_at_end', 'True', '--metric_for_best_model', 'f1_-1', '--greater_is_better', 'True', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'linear', '--lora_r', '16', '--lora_alpha', '16', '--lora_dropout', '0.05', '--lora_target_modules', 'all_linear', '--q_lora', 'True', '--bf16', 'True', '--tf32', 'True', '--use_accelerate_lib', 'flash-attn-v2', '--deepspeed', '/data/users/zhangjunlei/tyx/reward-by-prm800k/ds_configs/stage2.conf', '--logging_strategy', 'steps', '--logging_steps', '1'] exits with return code = 1
