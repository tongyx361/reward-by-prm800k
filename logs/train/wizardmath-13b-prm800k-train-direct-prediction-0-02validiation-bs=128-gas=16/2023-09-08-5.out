nohup: ignoring input
[2023-09-08 21:19:09,094] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[2023-09-08 21:19:14,035] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-08 21:19:14,307] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-08 21:19:14,328] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-08 21:19:14,352] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Using xformers
Initializing accelerator...
[2023-09-08 21:19:15,367] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-09-08 21:19:15,367] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-09-08 21:19:15,367] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-09-08 21:19:15,617] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-09-08 21:19:15,617] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-09-08 21:19:15,631] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-09-08 21:19:15,631] [INFO] [comm.py:616:init_distributed] cdb=None
[2023-09-08 21:19:15,638] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2023-09-08 21:19:15,638] [INFO] [comm.py:616:init_distributed] cdb=None
09/08/2023 21:19:15 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

accelerator.state = Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

09/08/2023 21:19:15 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

09/08/2023 21:19:15 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

09/08/2023 21:19:15 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

loading configuration file /data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--WizardLM--WizardMath-13B-V1.0/snapshots/7ef412d2c680ef0fbdcd88d0df31b396d8d3049c/config.json
Model config LlamaConfig {
  "_name_or_path": "/data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--WizardLM--WizardMath-13B-V1.0/snapshots/7ef412d2c680ef0fbdcd88d0df31b396d8d3049c",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 5120,
  "initializer_range": 0.02,
  "intermediate_size": 13824,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 40,
  "num_hidden_layers": 40,
  "num_key_value_heads": 40,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.31.0",
  "use_cache": false,
  "vocab_size": 32001
}

loading file tokenizer.model
loading file added_tokens.json
loading file special_tokens_map.json
loading file tokenizer_config.json
You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
loading weights file /data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--WizardLM--WizardMath-13B-V1.0/snapshots/7ef412d2c680ef0fbdcd88d0df31b396d8d3049c/pytorch_model.bin.index.json
Detected DeepSpeed ZeRO-3: activating zero.init() for this model
Generate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "pad_token_id": 0,
  "transformers_version": "4.31.0",
  "use_cache": false
}

[2023-09-08 21:19:42,476] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 13.02B parameters
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:08<00:42,  8.55s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:08<00:44,  8.94s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:08<00:44,  8.98s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:09<00:45,  9.17s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:17<00:34,  8.68s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:17<00:34,  8.60s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:17<00:34,  8.58s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:17<00:34,  8.60s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:24<00:24,  8.11s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:24<00:24,  8.21s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:24<00:24,  8.15s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:24<00:24,  8.16s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:32<00:15,  7.93s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:32<00:15,  7.99s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:32<00:15,  7.94s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:32<00:15,  7.94s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:40<00:07,  7.84s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:40<00:07,  7.82s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:40<00:07,  7.83s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:40<00:07,  7.83s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:41<00:00,  5.64s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:41<00:00,  6.93s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:41<00:00,  5.65s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:41<00:00,  6.93s/it]
All model checkpoint weights were used when initializing LlamaForCausalLM.

All the weights of LlamaForCausalLM were initialized from the model checkpoint at /data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--WizardLM--WizardMath-13B-V1.0/snapshots/7ef412d2c680ef0fbdcd88d0df31b396d8d3049c.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
loading configuration file /data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--WizardLM--WizardMath-13B-V1.0/snapshots/7ef412d2c680ef0fbdcd88d0df31b396d8d3049c/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.9,
  "top_p": 0.6,
  "transformers_version": "4.31.0"
}

Assigning <s> to the bos_token key of the tokenizer
Assigning </s> to the eos_token key of the tokenizer
Assigning <unk> to the unk_token key of the tokenizer
Assigning <pad> to the pad_token key of the tokenizer
Adding <pad> to the vocabulary
Loading checkpoint shards: 100%|██████████| 6/6 [00:41<00:00,  5.68s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:41<00:00,  6.95s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:41<00:00,  5.66s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:41<00:00,  6.94s/it]
09/08/2023 21:20:24 - INFO - __main__ - Sample 53299 of the training set: {'input_ids': tensor([    1,  2803,   395, 29888, 29898, 29916, 29897,   353,  4853, 29985,
        29955,   718,   289, 29916, 29985, 29941,   718, 28232,   448, 29871,
        29945,  7449, 29871,   960,   395, 29888,  6278, 29955, 29897,   353,
        29871, 29955,  8209,   769,  1284,   395, 29888, 29898, 29955,   467,
        29938,    13, 29902,  8369,   393,   278,   740,   395, 29888, 29898,
        29916,  1262,   756,  7736, 10801,   310,   395, 29916,  8209,  5174,
          363,   278,  4868,  1840, 15727, 29945,  7449,    13,  4013, 14661,
          393,   395, 29888, 29898, 29916,  1262,  1795,   367,   385,  7736,
          740, 29892,  6593,   393,   395, 29888,  6278, 29916, 29897,   353,
          448, 29888, 29898, 29916,  1262,   363,   599,   395, 29916,  7449,
           13,  1762,  1423,   445, 29892,   306,   817,   304,  1074,   565,
          395, 29888, 29898, 29916, 29897,   718,   285,  6278, 29916, 29897,
          353, 29871, 29900, 29938,   363,   599,   395, 29916,  7449,    13,
        29902, 18665,   297,   395, 29916, 29938,   322, 15727, 29916, 29938,
          964,   278,  7063,   363,   395, 29888, 29898, 29916,  1262,   322,
        21092, 29901,    13, 29905,   463, 29912,  2520,  4044,    13, 29888,
        29898, 29916, 29897,   718,   285,  6278, 29916, 29897,  7878,   263,
        29898, 29916, 29985, 29955,   448,  8521, 29916,  4887, 29955, 29897,
          718,   289, 29898, 29916, 29985, 29941,   448,  8521, 29916,  4887,
        29941, 29897,   718,   274, 29898, 29916,   448,  8521, 29916,   876,
          448, 29871, 29945,   448, 29871, 29945,  2474,    13, 20644,   263,
        29898, 29916, 29985, 29955,   718,   921, 29985, 29955, 29897,   718,
          289, 29898, 29916, 29985, 29941,   718,   921, 29985, 29941, 29897,
          718, 29871, 29906, 18904,   448, 29871, 29896, 29900,  2474,    13,
        20644, 29871, 29906, 29874, 29898, 29916, 29985, 29955, 29897,   718,
        29871, 29906, 29890, 29898, 29916, 29985, 29941, 29897,   718, 29871,
        29906, 18904,   448, 29871, 29896, 29900,    13, 29905,   355, 29912,
         2520,  4044,    13,  2831,   445,   304,   367,  5225,   363,   599,
          395, 29916,  8209,   306,   817,   304,   505,   395, 29906, 29874,
          353, 29871, 29900,  8209,   395, 29906, 29890,   353, 29871, 29900,
         8209,   322,   395, 29906, 29883,   353, 29871, 29896, 29900,  7449,
           13]), 'labels': tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100, 21104,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
        21104,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 21104,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  6374,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         8178])}.
09/08/2023 21:20:24 - INFO - __main__ - Sample 74276 of the training set: {'input_ids': tensor([    1,  1724,   338,   278,  1353,   310,  6862, 10340,   297,   278,
         4038,   310,  1020,   412,  2502,   333, 16417, 29928,   411, 13791,
          319, 29898, 29900, 29892, 29900,   511,   350, 29898, 29900,  6653,
        29906,   511,   315, 29898, 29946, 29892, 29900,   511,   322,   360,
        29898, 29946, 29892, 29953,  6877,    13, 29902, 18720,   393,   263,
         1020,   412,  2502,   333,   338,   263, 18890,  4115,  1008,   284,
          411,  1023,  8943, 11192, 29892,   322,   278,  4038,   310,   263,
         1020,   412,  2502,   333,   338,  2183,   491,   278,  7063,   319,
          353,   313, 29890, 29896,   718,   289, 29906, 29897, 29882,   847,
        29871, 29906, 29892,   988,   289, 29896,   322,   289, 29906,   526,
          278, 27497,   310,   278,  8943, 11192,   322,   298,   338,   278,
         3171, 29889,    13,  1762,   671,   445,  7063, 29892,   306,   817,
          304,  1284,   278,  1819,   310,   289, 29896, 29892,   289, 29906,
        29892,   322,   298,   363,   445,  1020,   412,  2502,   333, 29889,
           13, 29902,  8369,   393,   278, 10350,   310,   278, 13791,   526,
         2183, 29892,   577,   306,   508,   671,   278,  5418,  7063,   304,
         1284,   278, 27497,   310,   278, 11192, 29889,    13,  1576,  5418,
         7063,   338,   270,   353, 18074,  2273,  3552, 29916, 29906,   448,
          921, 29896,  4887, 29906,   718,   313, 29891, 29906,   448,   343,
        29896,  4887, 29906,   511,   988,   313, 29916, 29896, 29892,   343,
        29896, 29897,   322,   313, 29916, 29906, 29892,   343, 29906, 29897,
          526,   278,  1095,  9748,   310,   263,  1196, 10768, 29889,    13,
        29902,  1369,   411,  9138,   278,  3309,   310,  2625, 17571, 29892,
          607,   338,   697,   310,   278,  8943, 11192, 29889,    13,  1576,
        10350,   310,   319,   526,   313, 29900, 29892, 29871, 29900, 29897,
          322,   278, 10350,   310,   350,   526,   313, 29900, 29892,   448,
        29906,   511,   577,   773,   278,  5418,  7063, 29892,   306,   679,
        29901,    13, 29881, 29898,  2882, 29897,   353, 18074,  2273,  3552,
        29900,   448, 29871, 29900,  4887, 29906,   718,  8521, 29906,   448,
        29871, 29900,  4887, 29906, 29897,   353, 18074,  2273, 29898, 29900,
          718, 29871, 29946, 29897,   353, 18074,  2273, 29898, 29946, 29897,
          353, 29871, 29906, 29889,    13,  6295,   289, 29896,   353, 29871,
        29906, 29889,    13,  9190, 29892,   306,  1284,   278,  3309,   310,
         2625,  7307, 29892,   607,   338,   278,   916,  8943,  2625, 29889,
           13,  1576, 10350,   310,   315,   526,   313, 29946, 29892, 29871,
        29900, 29897,   322,   278, 10350,   310,   360,   526,   313, 29946,
        29892, 29871, 29953,   511,   577,   773,   278,  5418,  7063, 29892,
          306,   679, 29901,    13, 29881, 29898,  6530, 29897,   353, 18074,
         2273,  3552, 29946,   448, 29871, 29946,  4887, 29906,   718,   313,
        29953,   448, 29871, 29900,  4887, 29906, 29897,   353, 18074,  2273,
        29898, 29900,   718, 29871, 29941, 29953, 29897,   353, 18074,  2273,
        29898, 29941, 29953, 29897,   353, 29871, 29953, 29889,    13,  6295,
          289, 29906,   353, 29871, 29953, 29889,    13, 10454, 29892,   306,
          817,   304,  1284,   278,  3171,   310,   278,  1020,   412,  2502,
          333, 29892,   607,   338,   278,   639, 14081, 16311,  5418,  1546,
          278,  8943, 11192, 29889,    13, 29902,  8369,   393,   278,   921,
        29899,  1111, 24266,   310,   319,   322,   315,   526,  1716, 29871,
        29900, 29892,   322,   278,   921, 29899,  1111, 24266,   310,   350,
          322,   360,   526,  1716, 29871, 29946, 29892,   577,   278,  8943,
        11192,   526, 11408, 29889,    13,  4013,  2794,   393,   278,  3171,
          338,   925,   278,  4328,  1546,   278,   343, 29899,  1111, 24266,
          310,   738,  5101,   310,  3291,   373,   278,  8943, 11192, 29889,
           13]), 'labels': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, 6374, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6374,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, 6374, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, 6374, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, 6374, -100, -100, -100, -100, -100, -100, -100, 6374, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, 6374, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, 6374, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100,
        -100, -100, -100, -100, -100, -100, 6374, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, 6374, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, 8178])}.
09/08/2023 21:20:24 - INFO - __main__ - Sample 69507 of the training set: {'input_ids': tensor([    1, 10987,    13, 29905,  7110,   463, 29912, 12571, 29913, 29871,
        29896,   669, 29871, 29896,  2474, 29871, 29900,   669, 29871, 29896,
          320,   355, 29912, 12571, 29913,   320,   463, 29912, 12571, 29913,
        29871, 29896,   669, 29871, 29941,  2474, 29871, 29900,   669, 29871,
        29896,   320,   355, 29912, 12571, 29913,   320,   463, 29912, 12571,
        29913, 29871, 29896,   669, 29871, 29945,  2474, 29871, 29900,   669,
        29871, 29896,   320,   355, 29912, 12571, 29913,   320,  7778, 29885,
          320,   463, 29912, 12571, 29913, 29871, 29896,   669, 29871, 29929,
        29929,  2474, 29871, 29900,   669, 29871, 29896,   320,   355, 29912,
        12571,  1836, 18899,    13,  4013,  1108, 20789,  6674,  5890,   263,
         5665,   310, 29871, 29906,   491, 29871, 29906, 13516, 29892,  1269,
          310,   278,   883, 10033,   463, 29912, 12571, 29913, 29871, 29896,
          669,   413,  2474, 29871, 29900,   669, 29871, 29896,   320,   355,
        29912, 12571,  1012,   511,   988,  4269, 29895,  7244,   338,   385,
         7736,  1353,   515, 29871, 29896,   304, 29871, 29929, 29929, 29889,
           13, 29902,  8369,   393,  1438, 13516,   505,   263,  4266,  2875,
        29901,   896,   526,  7568,  3367,  6825, 29892,  6593,   393,  1009,
         9976,  2400,   278,  1667, 19640,   526,  5225, 29889,    13,  4013,
         2875,  3732,  4636, 21666,  6775, 29892,  1363,   306,   508,   671,
          278,  1494,  5751, 29901,   565,  4269, 29909,  7244,   322,  4269,
        29933,  7244,   526,  7568,  3367,  6825, 13516, 29892,   769,   577,
          338,  1009,  3234,  4269,  2882, 29905,   511,   322,   278, 19640,
         9976,   310,  4269,  2882,  7244,   526,   278,  1021,   408,   278,
        19640,  9976,   310,  4269, 29909,  7244,   322,  4269, 29933, 29800,
           13,  7058,   338, 29892,   565,  4269, 29909,   353,   320,   463,
        29912, 12571, 29913,   263,   669,   289,  2474, 29871, 29900,   669,
          274,   320,   355, 29912, 12571, 14786,   322,  4269, 29933,   353,
          320,   463, 29912, 12571, 29913,   270,   669,   321,  2474, 29871,
        29900,   669,   285,   320,   355, 29912, 12571,  1012,   511,   769,
         4269,  2882,   353,   320,   463, 29912, 12571, 29913,   594,   669,
          263, 29872,   718,   289, 29888,  2474, 29871, 29900,   669,   274,
        29888,   320,   355, 29912, 12571,  1012,   467,    13, 15156,   445,
         5751, 29892,   306,   508, 21092,   278,  4636,  3234,   297,   278,
         1108,   491,  5330,  8253,   278,  5224,  2175,  9976, 29892,   607,
          526,  2337,  5225, 29892,   322, 12789,  4746,   373,   278, 19640,
          322,  7568,  1492,  9976, 29889,    13,  1762,  1284,   278, 19640,
         9976, 29892,   306,   925,   817,   304, 22932,   278,  6590,  9976,
          310,   278, 13516,  4208, 29889,    13,   797,   445,  1206, 29892,
          896,   526,   599, 29871, 29896, 29892,   577,   278, 19640,  9976,
          310,   278,  3234,   526,   884, 29871, 29896, 29889,    13,  1762,
         1284,   278,  7568,  1492,  6251, 29892,   306,   817,   304,   788,
          278,  9316,   310,   278,  7568,  1948,   310,   278,   937,  4636,
          322,   278,  1492,  1897,   310,   278,  1473,  4636, 29892,   363,
         1269,  5101,   310, 13516, 29889,    13,  2831,  1342, 29892,   363,
          278,   937,  1023, 13516, 29892,   306,   679,  4269, 29896,   320,
         3822, 29871, 29941,   718, 29871, 29896,   320,  3822, 29871, 29896,
          353, 29871, 29946, 29800,    13,  2831,   278,  1473,   322,  4654,
        13516, 29892,   306,   679,  4269, 29896,   320,  3822, 29871, 29945,
          718, 29871, 29941,   320,  3822, 29871, 29896,   353, 29871, 29947,
        29800,    13,  2855,   577,   373, 29889,    13, 29902,  8369,   263,
         4766, 29901,   278,  7568,  1492,  6251,   310,   278,  3234,   310,
          278,   937,  4269, 29876,  7244, 13516,   338,   278,  4269, 29876,
        29905,  6817,   386,  3367,  6825,  1353, 29892,   607,   338,   278,
         2533,   310,   278,   937,  4269, 29876,  7244,  5613,  3694, 29889,
           13]), 'labels': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, 6374, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        6374, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, 6374, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, 6374, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, 6374, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, 6374, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, 6374, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, 6374, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6374,
        -100, -100, -100, -100, 6374, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        8178])}.
09/08/2023 21:20:24 - INFO - accelerate.accelerator - Since you passed both train and evaluation dataloader, `is_train_batch_min` (here True will decide the `train_batch_size` (2).
09/08/2023 21:20:24 - INFO - accelerate.accelerator - Updating DeepSpeed's gradient accumulation steps to 16 from 1.
[2023-09-08 21:20:24,430] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.0, git-hash=unknown, git-branch=unknown
09/08/2023 21:20:24 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0
09/08/2023 21:20:24 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1
09/08/2023 21:20:24 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 3
09/08/2023 21:20:24 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 2
09/08/2023 21:20:24 - INFO - torch.distributed.distributed_c10d - Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
09/08/2023 21:20:24 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[2023-09-08 21:20:24,534] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-09-08 21:20:24,535] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-09-08 21:20:24,535] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
09/08/2023 21:20:24 - INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
09/08/2023 21:20:24 - INFO - torch.distributed.distributed_c10d - Rank 3: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[2023-09-08 21:20:24,551] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-09-08 21:20:24,551] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2023-09-08 21:20:24,551] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2023-09-08 21:20:24,551] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2023-09-08 21:20:24,718] [INFO] [utils.py:785:see_memory_usage] Stage 3 initialize beginning
[2023-09-08 21:20:24,719] [INFO] [utils.py:786:see_memory_usage] MA 6.14 GB         Max_MA 7.06 GB         CA 8.03 GB         Max_CA 8 GB 
[2023-09-08 21:20:24,719] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 114.26 GB, percent = 11.3%
[2023-09-08 21:20:24,721] [INFO] [stage3.py:117:__init__] Reduce bucket size 26214400
[2023-09-08 21:20:24,721] [INFO] [stage3.py:118:__init__] Prefetch bucket size 23592960
[2023-09-08 21:20:24,842] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2023-09-08 21:20:24,842] [INFO] [utils.py:786:see_memory_usage] MA 6.14 GB         Max_MA 6.14 GB         CA 8.03 GB         Max_CA 8 GB 
[2023-09-08 21:20:24,843] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 114.27 GB, percent = 11.3%
Parameter Offload: Total persistent parameters: 414720 in 81 params
[2023-09-08 21:20:24,996] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2023-09-08 21:20:24,996] [INFO] [utils.py:786:see_memory_usage] MA 6.14 GB         Max_MA 6.14 GB         CA 8.03 GB         Max_CA 8 GB 
[2023-09-08 21:20:24,996] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 114.28 GB, percent = 11.3%
[2023-09-08 21:20:25,106] [INFO] [utils.py:785:see_memory_usage] Before creating fp16 partitions
[2023-09-08 21:20:25,107] [INFO] [utils.py:786:see_memory_usage] MA 6.14 GB         Max_MA 6.14 GB         CA 8.03 GB         Max_CA 8 GB 
[2023-09-08 21:20:25,107] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 114.28 GB, percent = 11.3%
[2023-09-08 21:20:28,355] [INFO] [utils.py:785:see_memory_usage] After creating fp16 partitions: 4
[2023-09-08 21:20:28,356] [INFO] [utils.py:786:see_memory_usage] MA 6.14 GB         Max_MA 6.14 GB         CA 6.14 GB         Max_CA 8 GB 
[2023-09-08 21:20:28,356] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 122.16 GB, percent = 12.1%
[2023-09-08 21:20:28,469] [INFO] [utils.py:785:see_memory_usage] Before creating fp32 partitions
[2023-09-08 21:20:28,470] [INFO] [utils.py:786:see_memory_usage] MA 6.14 GB         Max_MA 6.14 GB         CA 6.14 GB         Max_CA 6 GB 
[2023-09-08 21:20:28,470] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 120.33 GB, percent = 11.9%
[2023-09-08 21:20:28,602] [INFO] [utils.py:785:see_memory_usage] After creating fp32 partitions
[2023-09-08 21:20:28,603] [INFO] [utils.py:786:see_memory_usage] MA 18.26 GB         Max_MA 19.27 GB         CA 21.16 GB         Max_CA 21 GB 
[2023-09-08 21:20:28,603] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 114.92 GB, percent = 11.4%
[2023-09-08 21:20:28,811] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-09-08 21:20:28,811] [INFO] [utils.py:786:see_memory_usage] MA 18.26 GB         Max_MA 18.26 GB         CA 21.16 GB         Max_CA 21 GB 
[2023-09-08 21:20:28,811] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 114.26 GB, percent = 11.3%
[2023-09-08 21:20:28,988] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-09-08 21:20:28,989] [INFO] [utils.py:786:see_memory_usage] MA 42.51 GB         Max_MA 52.08 GB         CA 62.48 GB         Max_CA 62 GB 
[2023-09-08 21:20:28,989] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 114.26 GB, percent = 11.3%
[2023-09-08 21:20:29,019] [INFO] [stage3.py:424:_setup_for_real_optimizer] optimizer state initialized
[2023-09-08 21:20:29,351] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt...
[2023-09-08 21:20:29,351] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt...
[2023-09-08 21:20:29,352] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt...
[2023-09-08 21:20:29,360] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt.
[2023-09-08 21:20:29,360] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt.
[2023-09-08 21:20:29,360] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt...
[2023-09-08 21:20:29,360] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt...
[2023-09-08 21:20:29,361] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt.
[2023-09-08 21:20:29,361] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt...
[2023-09-08 21:20:29,368] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt.
[2023-09-08 21:20:29,368] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt.
[2023-09-08 21:20:29,369] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt.
[2023-09-08 21:20:29,376] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2023-09-08 21:20:29,377] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2023-09-08 21:20:29,379] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[2023-09-08 21:20:29,478] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-09-08 21:20:29,479] [INFO] [utils.py:786:see_memory_usage] MA 48.62 GB         Max_MA 49.23 GB         CA 68.54 GB         Max_CA 69 GB 
[2023-09-08 21:20:29,479] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 115.26 GB, percent = 11.4%
[2023-09-08 21:20:29,479] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2023-09-08 21:20:29,479] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-09-08 21:20:29,479] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2023-09-08 21:20:29,479] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]
[2023-09-08 21:20:29,480] [INFO] [config.py:960:print] DeepSpeedEngine configuration:
[2023-09-08 21:20:29,480] [INFO] [config.py:964:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-09-08 21:20:29,480] [INFO] [config.py:964:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-09-08 21:20:29,480] [INFO] [config.py:964:print]   amp_enabled .................. False
[2023-09-08 21:20:29,480] [INFO] [config.py:964:print]   amp_params ................... False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   bfloat16_enabled ............. True
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   checkpoint_parallel_write_pipeline  False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   checkpoint_tag_validation_enabled  True
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   checkpoint_tag_validation_fail  False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fdbc4090d00>
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   communication_data_type ...... None
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   curriculum_enabled_legacy .... False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   curriculum_params_legacy ..... False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   data_efficiency_enabled ...... False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   dataloader_drop_last ......... False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   disable_allgather ............ False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   dump_state ................... False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   dynamic_loss_scale_args ...... None
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   eigenvalue_enabled ........... False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   eigenvalue_gas_boundary_resolution  1
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   eigenvalue_layer_num ......... 0
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   eigenvalue_max_iter .......... 100
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   eigenvalue_stability ......... 1e-06
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   eigenvalue_tol ............... 0.01
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   eigenvalue_verbose ........... False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   elasticity_enabled ........... False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   fp16_auto_cast ............... None
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   fp16_enabled ................. False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   fp16_master_weights_and_gradients  False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   global_rank .................. 0
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   grad_accum_dtype ............. None
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   gradient_accumulation_steps .. 16
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   gradient_clipping ............ 1.0
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   gradient_predivide_factor .... 1.0
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   initial_dynamic_scale ........ 1
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   load_universal_checkpoint .... False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   loss_scale ................... 1.0
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   memory_breakdown ............. False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   mics_hierarchial_params_gather  False
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   mics_shard_size .............. -1
[2023-09-08 21:20:29,481] [INFO] [config.py:964:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   optimizer_legacy_fusion ...... False
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   optimizer_name ............... None
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   optimizer_params ............. None
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   pld_enabled .................. False
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   pld_params ................... False
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   prescale_gradients ........... False
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   scheduler_name ............... None
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   scheduler_params ............. None
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   sparse_attention ............. None
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   sparse_gradients_enabled ..... False
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   steps_per_print .............. inf
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   train_batch_size ............. 128
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   train_micro_batch_size_per_gpu  2
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   use_node_local_storage ....... False
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   wall_clock_breakdown ......... False
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   world_size ................... 4
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   zero_allow_untested_optimizer  True
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=26214400 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=23592960 param_persistence_threshold=51200 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   zero_enabled ................. True
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   zero_force_ds_cpu_optimizer .. True
[2023-09-08 21:20:29,482] [INFO] [config.py:964:print]   zero_optimization_stage ...... 3
[2023-09-08 21:20:29,482] [INFO] [config.py:950:print_user_config]   json = {
    "bf16": {
        "enabled": true
    }, 
    "zero_optimization": {
        "stage": 3, 
        "overlap_comm": true, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09, 
        "reduce_bucket_size": 2.621440e+07, 
        "stage3_prefetch_bucket_size": 2.359296e+07, 
        "stage3_param_persistence_threshold": 5.120000e+04, 
        "stage3_max_live_parameters": 1.000000e+09, 
        "stage3_max_reuse_distance": 1.000000e+09, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_accumulation_steps": 16, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 2, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
wandb: Currently logged in as: kidrain61. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /data/users/zhangjunlei/tyx/wandb/wandb/run-20230908_212031-at6qx3wz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16-2023-09-08-5
wandb: ⭐️ View project at https://wandb.ai/kidrain61/step-reward
wandb: 🚀 View run at https://wandb.ai/kidrain61/step-reward/runs/at6qx3wz
09/08/2023 21:20:39 - INFO - __main__ - ***** Running training *****
09/08/2023 21:20:39 - INFO - __main__ -   Num examples = 85194
09/08/2023 21:20:39 - INFO - __main__ -   Num Epochs = 100
09/08/2023 21:20:39 - INFO - __main__ -   Instantaneous batch size per device = 2
09/08/2023 21:20:39 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 128
09/08/2023 21:20:39 - INFO - __main__ -   Gradient Accumulation steps = 16
09/08/2023 21:20:39 - INFO - __main__ -   Total optimization steps = 66600
09/08/2023 21:20:39 - INFO - __main__ - Resuming from checkpoint: /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1
09/08/2023 21:20:39 - INFO - accelerate.accelerator - Loading states from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1
09/08/2023 21:20:39 - INFO - accelerate.accelerator - Loading DeepSpeed Model and Optimizer
[2023-09-08 21:20:39,402] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-09-08 21:20:39,410] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-09-08 21:20:39,411] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-09-08 21:20:39,419] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-09-08 21:20:39,427] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-09-08 21:20:45,122] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[2023-09-08 21:20:45,122] [INFO] [engine.py:2865:_get_all_zero_checkpoint_state_dicts] successfully read 4 ZeRO state_dicts for rank 2
[2023-09-08 21:20:46,536] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2023-09-08 21:20:46,536] [INFO] [engine.py:2865:_get_all_zero_checkpoint_state_dicts] successfully read 4 ZeRO state_dicts for rank 1
[2023-09-08 21:20:47,179] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[2023-09-08 21:20:47,180] [INFO] [engine.py:2865:_get_all_zero_checkpoint_state_dicts] successfully read 4 ZeRO state_dicts for rank 3
[2023-09-08 21:20:57,565] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-09-08 21:20:57,565] [INFO] [engine.py:2865:_get_all_zero_checkpoint_state_dicts] successfully read 4 ZeRO state_dicts for rank 0
[2023-09-08 21:21:12,095] [INFO] [engine.py:2815:_load_zero_checkpoint] loading 4 zero partition checkpoints for rank 3
[2023-09-08 21:21:12,095] [INFO] [engine.py:2815:_load_zero_checkpoint] loading 4 zero partition checkpoints for rank 2
[2023-09-08 21:21:12,095] [INFO] [engine.py:2815:_load_zero_checkpoint] loading 4 zero partition checkpoints for rank 1
[2023-09-08 21:21:12,095] [INFO] [engine.py:2815:_load_zero_checkpoint] loading 4 zero partition checkpoints for rank 0
09/08/2023 21:21:13 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer loaded from input dir /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/epoch_1/pytorch_model
09/08/2023 21:21:13 - INFO - accelerate.checkpointing - All model weights loaded successfully
09/08/2023 21:21:13 - INFO - accelerate.checkpointing - All optimizer states loaded successfully
09/08/2023 21:21:13 - INFO - accelerate.checkpointing - All scheduler states loaded successfully
09/08/2023 21:21:13 - INFO - accelerate.checkpointing - All random states loaded successfully
09/08/2023 21:21:13 - INFO - accelerate.accelerator - Loading in 0 custom states
09/08/2023 21:21:13 - INFO - __main__ - Resuming from epoch 2
09/08/2023 21:21:13 - INFO - __main__ - ***** Running Validation *****
Evaluating:   0%|          | 0/228 [00:00<?, ?it/s]step: 0
extend+tolist() time: 0.002149820327758789
Evaluating:   0%|          | 1/228 [00:00<03:15,  1.16it/s]step: 1
extend+tolist() time: 0.0014193058013916016
Evaluating:   1%|          | 2/228 [00:01<02:29,  1.51it/s]step: 2
extend+tolist() time: 0.0021572113037109375
Evaluating:   1%|▏         | 3/228 [00:01<02:00,  1.87it/s]step: 3
extend+tolist() time: 0.001798391342163086
Evaluating:   2%|▏         | 4/228 [00:02<01:50,  2.04it/s]step: 4
extend+tolist() time: 0.001003265380859375
Evaluating:   2%|▏         | 5/228 [00:02<01:38,  2.26it/s]step: 5
extend+tolist() time: 0.0021347999572753906
Evaluating:   3%|▎         | 6/228 [00:02<01:35,  2.33it/s]step: 6
extend+tolist() time: 0.0020880699157714844
Evaluating:   3%|▎         | 7/228 [00:03<01:32,  2.38it/s]step: 7
extend+tolist() time: 0.0014612674713134766
Evaluating:   4%|▎         | 8/228 [00:03<01:28,  2.49it/s]step: 8
extend+tolist() time: 0.0008897781372070312
Evaluating:   4%|▍         | 9/228 [00:04<01:27,  2.49it/s]step: 9
extend+tolist() time: 0.0013213157653808594
Evaluating:   4%|▍         | 10/228 [00:04<01:25,  2.54it/s]step: 10
extend+tolist() time: 0.0010340213775634766
Evaluating:   5%|▍         | 11/228 [00:04<01:23,  2.60it/s]step: 11
extend+tolist() time: 0.001064300537109375
Evaluating:   5%|▌         | 12/228 [00:05<01:25,  2.53it/s]step: 12
extend+tolist() time: 0.0007967948913574219
Evaluating:   6%|▌         | 13/228 [00:05<01:22,  2.61it/s]step: 13
extend+tolist() time: 0.0006861686706542969
Evaluating:   6%|▌         | 14/228 [00:06<01:23,  2.56it/s]step: 14
extend+tolist() time: 0.0012791156768798828
Evaluating:   7%|▋         | 15/228 [00:06<01:22,  2.59it/s]step: 15
extend+tolist() time: 0.0006995201110839844
Evaluating:   7%|▋         | 16/228 [00:06<01:20,  2.65it/s]step: 16
extend+tolist() time: 0.0006916522979736328
Evaluating:   7%|▋         | 17/228 [00:07<01:21,  2.60it/s]step: 17
extend+tolist() time: 0.0014612674713134766
Evaluating:   8%|▊         | 18/228 [00:07<01:20,  2.61it/s]step: 18
extend+tolist() time: 0.0016922950744628906
Evaluating:   8%|▊         | 19/228 [00:07<01:18,  2.65it/s]step: 19
extend+tolist() time: 0.0011181831359863281
Evaluating:   9%|▉         | 20/228 [00:08<01:21,  2.55it/s]step: 20
extend+tolist() time: 0.0013072490692138672
Evaluating:   9%|▉         | 21/228 [00:08<01:19,  2.61it/s]step: 21
extend+tolist() time: 0.0007665157318115234
Evaluating:  10%|▉         | 22/228 [00:09<01:20,  2.55it/s]step: 22
extend+tolist() time: 0.0012497901916503906
Evaluating:  10%|█         | 23/228 [00:09<01:19,  2.58it/s]step: 23
extend+tolist() time: 0.0007987022399902344
Evaluating:  11%|█         | 24/228 [00:09<01:17,  2.64it/s]step: 24
extend+tolist() time: 0.1894817352294922
Evaluating:  11%|█         | 25/228 [00:10<01:31,  2.21it/s]step: 25
extend+tolist() time: 0.0020880699157714844
Evaluating:  11%|█▏        | 26/228 [00:10<01:27,  2.32it/s]step: 26
extend+tolist() time: 0.0010914802551269531
Evaluating:  12%|█▏        | 27/228 [00:11<01:25,  2.36it/s]step: 27
extend+tolist() time: 0.0014698505401611328
Evaluating:  12%|█▏        | 28/228 [00:11<01:23,  2.40it/s]step: 28
extend+tolist() time: 0.0007884502410888672
Evaluating:  13%|█▎        | 29/228 [00:12<01:19,  2.49it/s]step: 29
extend+tolist() time: 0.0008215904235839844
Evaluating:  13%|█▎        | 30/228 [00:12<01:21,  2.43it/s]step: 30
extend+tolist() time: 0.0016558170318603516
Evaluating:  14%|█▎        | 31/228 [00:12<01:19,  2.48it/s]step: 31
extend+tolist() time: 0.0006611347198486328
Evaluating:  14%|█▍        | 32/228 [00:13<01:19,  2.46it/s]step: 32
extend+tolist() time: 0.001565694808959961
Evaluating:  14%|█▍        | 33/228 [00:13<01:18,  2.48it/s]step: 33
extend+tolist() time: 0.0019080638885498047
Evaluating:  15%|█▍        | 34/228 [00:14<01:17,  2.51it/s]step: 34
extend+tolist() time: 0.001054525375366211
Evaluating:  15%|█▌        | 35/228 [00:14<01:19,  2.42it/s]step: 35
extend+tolist() time: 0.0012035369873046875
Evaluating:  16%|█▌        | 36/228 [00:14<01:16,  2.50it/s]step: 36
extend+tolist() time: 0.0008931159973144531
Evaluating:  16%|█▌        | 37/228 [00:15<01:18,  2.43it/s]step: 37
extend+tolist() time: 0.0024089813232421875
Evaluating:  17%|█▋        | 38/228 [00:15<01:18,  2.41it/s]step: 38
extend+tolist() time: 0.0009012222290039062
Evaluating:  17%|█▋        | 39/228 [00:16<01:16,  2.47it/s]step: 39
extend+tolist() time: 0.0012598037719726562
Evaluating:  18%|█▊        | 40/228 [00:16<01:17,  2.41it/s]step: 40
extend+tolist() time: 0.0007262229919433594
Evaluating:  18%|█▊        | 41/228 [00:16<01:15,  2.49it/s]step: 41
extend+tolist() time: 0.0013911724090576172
Evaluating:  18%|█▊        | 42/228 [00:17<01:16,  2.43it/s]step: 42
extend+tolist() time: 0.0017347335815429688
Evaluating:  19%|█▉        | 43/228 [00:17<01:16,  2.43it/s]step: 43
extend+tolist() time: 0.002285480499267578
Evaluating:  19%|█▉        | 44/228 [00:18<01:15,  2.44it/s]step: 44
extend+tolist() time: 0.0008523464202880859
Evaluating:  20%|█▉        | 45/228 [00:18<01:15,  2.42it/s]step: 45
extend+tolist() time: 0.0018765926361083984
Evaluating:  20%|██        | 46/228 [00:18<01:13,  2.47it/s]step: 46
extend+tolist() time: 0.0018279552459716797
Evaluating:  21%|██        | 47/228 [00:19<01:15,  2.41it/s]step: 47
extend+tolist() time: 0.0012996196746826172
Evaluating:  21%|██        | 48/228 [00:19<01:13,  2.44it/s]step: 48
extend+tolist() time: 0.002007722854614258
Evaluating:  21%|██▏       | 49/228 [00:20<01:12,  2.47it/s]step: 49
extend+tolist() time: 0.0014591217041015625
Evaluating:  22%|██▏       | 50/228 [00:20<01:13,  2.43it/s]step: 50
extend+tolist() time: 0.001791238784790039
Evaluating:  22%|██▏       | 51/228 [00:21<01:11,  2.46it/s]step: 51
extend+tolist() time: 0.0014209747314453125
Evaluating:  23%|██▎       | 52/228 [00:21<01:14,  2.35it/s]step: 52
extend+tolist() time: 0.0015943050384521484
Evaluating:  23%|██▎       | 53/228 [00:21<01:12,  2.43it/s]step: 53
extend+tolist() time: 0.1979830265045166
Evaluating:  24%|██▎       | 54/228 [00:22<01:22,  2.10it/s]step: 54
extend+tolist() time: 0.0013203620910644531
Evaluating:  24%|██▍       | 55/228 [00:22<01:19,  2.17it/s]step: 55
extend+tolist() time: 0.0009126663208007812
Evaluating:  25%|██▍       | 56/228 [00:23<01:17,  2.21it/s]step: 56
extend+tolist() time: 0.001806497573852539
Evaluating:  25%|██▌       | 57/228 [00:23<01:14,  2.28it/s]step: 57
extend+tolist() time: 0.0007076263427734375
Evaluating:  25%|██▌       | 58/228 [00:24<01:10,  2.40it/s]step: 58
extend+tolist() time: 0.0014193058013916016
Evaluating:  26%|██▌       | 59/228 [00:24<01:12,  2.34it/s]step: 59
extend+tolist() time: 0.0014028549194335938
Evaluating:  26%|██▋       | 60/228 [00:24<01:09,  2.42it/s]step: 60
extend+tolist() time: 0.0008482933044433594
Evaluating:  27%|██▋       | 61/228 [00:25<01:09,  2.40it/s]step: 61
extend+tolist() time: 0.0014472007751464844
Evaluating:  27%|██▋       | 62/228 [00:25<01:08,  2.43it/s]step: 62
extend+tolist() time: 0.0009455680847167969
Evaluating:  28%|██▊       | 63/228 [00:26<01:06,  2.50it/s]step: 63
extend+tolist() time: 0.001405477523803711
Evaluating:  28%|██▊       | 64/228 [00:26<01:07,  2.41it/s]step: 64
extend+tolist() time: 0.0009410381317138672
Evaluating:  29%|██▊       | 65/228 [00:27<01:06,  2.45it/s]step: 65
extend+tolist() time: 0.0014216899871826172
Evaluating:  29%|██▉       | 66/228 [00:27<01:07,  2.39it/s]step: 66
extend+tolist() time: 0.0008907318115234375
Evaluating:  29%|██▉       | 67/228 [00:27<01:07,  2.40it/s]step: 67
extend+tolist() time: 0.0015146732330322266
Evaluating:  30%|██▉       | 68/228 [00:28<01:05,  2.44it/s]step: 68
extend+tolist() time: 0.0008077621459960938
Evaluating:  30%|███       | 69/228 [00:28<01:07,  2.36it/s]step: 69
extend+tolist() time: 0.0017421245574951172
Evaluating:  31%|███       | 70/228 [00:29<01:05,  2.40it/s]step: 70
extend+tolist() time: 0.0016179084777832031
Evaluating:  31%|███       | 71/228 [00:29<01:06,  2.36it/s]step: 71
extend+tolist() time: 0.0011823177337646484
Evaluating:  32%|███▏      | 72/228 [00:29<01:05,  2.39it/s]step: 72
extend+tolist() time: 0.001348733901977539
Evaluating:  32%|███▏      | 73/228 [00:30<01:03,  2.45it/s]step: 73
extend+tolist() time: 0.0005815029144287109
Evaluating:  32%|███▏      | 74/228 [00:30<01:05,  2.37it/s]step: 74
extend+tolist() time: 0.001219034194946289
Evaluating:  33%|███▎      | 75/228 [00:31<01:03,  2.42it/s]step: 75
extend+tolist() time: 0.0015480518341064453
Evaluating:  33%|███▎      | 76/228 [00:31<01:04,  2.35it/s]step: 76
extend+tolist() time: 0.0016858577728271484
Evaluating:  34%|███▍      | 77/228 [00:32<01:03,  2.38it/s]step: 77
extend+tolist() time: 0.002126455307006836
Evaluating:  34%|███▍      | 78/228 [00:32<01:04,  2.31it/s]step: 78
extend+tolist() time: 0.0010077953338623047
Evaluating:  35%|███▍      | 79/228 [00:32<01:03,  2.35it/s]step: 79
extend+tolist() time: 0.0014636516571044922
Evaluating:  35%|███▌      | 80/228 [00:33<01:01,  2.42it/s]step: 80
extend+tolist() time: 0.0014071464538574219
Evaluating:  36%|███▌      | 81/228 [00:33<01:02,  2.36it/s]step: 81
extend+tolist() time: 0.0010025501251220703
Evaluating:  36%|███▌      | 82/228 [00:34<01:00,  2.42it/s]step: 82
extend+tolist() time: 0.0013926029205322266
Evaluating:  36%|███▋      | 83/228 [00:34<01:00,  2.38it/s]step: 83
extend+tolist() time: 0.0008268356323242188
Evaluating:  37%|███▋      | 84/228 [00:34<00:59,  2.42it/s]step: 84
extend+tolist() time: 0.001573801040649414
Evaluating:  37%|███▋      | 85/228 [00:35<00:57,  2.47it/s]step: 85
extend+tolist() time: 0.0010704994201660156
Evaluating:  38%|███▊      | 86/228 [00:35<00:59,  2.38it/s]step: 86
extend+tolist() time: 0.0014867782592773438
Evaluating:  38%|███▊      | 87/228 [00:36<00:57,  2.44it/s]step: 87
extend+tolist() time: 0.001039266586303711
Evaluating:  39%|███▊      | 88/228 [00:36<00:58,  2.39it/s]step: 88
extend+tolist() time: 0.0012812614440917969
Evaluating:  39%|███▉      | 89/228 [00:37<00:57,  2.43it/s]step: 89
extend+tolist() time: 0.0008835792541503906
Evaluating:  39%|███▉      | 90/228 [00:37<00:55,  2.48it/s]step: 90
extend+tolist() time: 0.0015096664428710938
Evaluating:  40%|███▉      | 91/228 [00:37<00:57,  2.40it/s]step: 91
extend+tolist() time: 0.0008680820465087891
Evaluating:  40%|████      | 92/228 [00:38<00:55,  2.46it/s]step: 92
extend+tolist() time: 0.001317739486694336
Evaluating:  41%|████      | 93/228 [00:38<00:55,  2.42it/s]step: 93
extend+tolist() time: 0.001516580581665039
Evaluating:  41%|████      | 94/228 [00:39<00:55,  2.43it/s]step: 94
extend+tolist() time: 0.0008573532104492188
Evaluating:  42%|████▏     | 95/228 [00:39<00:53,  2.48it/s]step: 95
extend+tolist() time: 0.23356890678405762
Evaluating:  42%|████▏     | 96/228 [00:40<01:04,  2.04it/s]step: 96
extend+tolist() time: 0.0010745525360107422
Evaluating:  43%|████▎     | 97/228 [00:40<01:03,  2.07it/s]step: 97
extend+tolist() time: 0.0009582042694091797
Evaluating:  43%|████▎     | 98/228 [00:41<00:59,  2.19it/s]step: 98
extend+tolist() time: 0.0014383792877197266
Evaluating:  43%|████▎     | 99/228 [00:41<00:56,  2.30it/s]step: 99
extend+tolist() time: 0.0010869503021240234
Evaluating:  44%|████▍     | 100/228 [00:41<00:55,  2.30it/s]step: 100
extend+tolist() time: 0.0013134479522705078
Evaluating:  44%|████▍     | 101/228 [00:42<00:53,  2.39it/s]step: 101
extend+tolist() time: 0.0009665489196777344
Evaluating:  45%|████▍     | 102/228 [00:42<00:53,  2.35it/s]step: 102
extend+tolist() time: 0.0012378692626953125
Evaluating:  45%|████▌     | 103/228 [00:43<00:52,  2.39it/s]step: 103
extend+tolist() time: 0.0008935928344726562
Evaluating:  46%|████▌     | 104/228 [00:43<00:50,  2.46it/s]step: 104
extend+tolist() time: 0.0012667179107666016
Evaluating:  46%|████▌     | 105/228 [00:43<00:51,  2.41it/s]step: 105
extend+tolist() time: 0.0009729862213134766
Evaluating:  46%|████▋     | 106/228 [00:44<00:49,  2.47it/s]step: 106
extend+tolist() time: 0.0020868778228759766
Evaluating:  47%|████▋     | 107/228 [00:44<00:50,  2.39it/s]step: 107
extend+tolist() time: 0.001294851303100586
Evaluating:  47%|████▋     | 108/228 [00:45<00:49,  2.43it/s]step: 108
extend+tolist() time: 0.0009427070617675781
Evaluating:  48%|████▊     | 109/228 [00:45<00:47,  2.48it/s]step: 109
extend+tolist() time: 0.001438140869140625
Evaluating:  48%|████▊     | 110/228 [00:45<00:49,  2.40it/s]step: 110
extend+tolist() time: 0.0007245540618896484
Evaluating:  49%|████▊     | 111/228 [00:46<00:47,  2.46it/s]step: 111
extend+tolist() time: 0.002100706100463867
Evaluating:  49%|████▉     | 112/228 [00:46<00:48,  2.38it/s]step: 112
extend+tolist() time: 0.00044465065002441406
Evaluating:  50%|████▉     | 113/228 [00:47<00:47,  2.43it/s]step: 113
extend+tolist() time: 0.001190185546875
Evaluating:  50%|█████     | 114/228 [00:47<00:46,  2.47it/s]step: 114
extend+tolist() time: 0.0013451576232910156
Evaluating:  50%|█████     | 115/228 [00:48<00:47,  2.37it/s]step: 115
extend+tolist() time: 0.0011851787567138672
Evaluating:  51%|█████     | 116/228 [00:48<00:45,  2.44it/s]step: 116
extend+tolist() time: 0.0009860992431640625
Evaluating:  51%|█████▏    | 117/228 [00:48<00:46,  2.39it/s]step: 117
extend+tolist() time: 0.0015721321105957031
Evaluating:  52%|█████▏    | 118/228 [00:49<00:45,  2.42it/s]step: 118
extend+tolist() time: 0.0006611347198486328
Evaluating:  52%|█████▏    | 119/228 [00:49<00:43,  2.48it/s]step: 119
extend+tolist() time: 0.0012726783752441406
Evaluating:  53%|█████▎    | 120/228 [00:50<00:44,  2.40it/s]step: 120
extend+tolist() time: 0.000732421875
Evaluating:  53%|█████▎    | 121/228 [00:50<00:43,  2.45it/s]step: 121
extend+tolist() time: 0.0011589527130126953
Evaluating:  54%|█████▎    | 122/228 [00:50<00:44,  2.40it/s]step: 122
extend+tolist() time: 0.0008075237274169922
Evaluating:  54%|█████▍    | 123/228 [00:51<00:42,  2.44it/s]step: 123
extend+tolist() time: 0.0007309913635253906
Evaluating:  54%|█████▍    | 124/228 [00:51<00:41,  2.49it/s]step: 124
extend+tolist() time: 0.001422882080078125
Evaluating:  55%|█████▍    | 125/228 [00:52<00:42,  2.42it/s]step: 125
extend+tolist() time: 0.0004985332489013672
Evaluating:  55%|█████▌    | 126/228 [00:52<00:40,  2.49it/s]step: 126
extend+tolist() time: 0.001997709274291992
Evaluating:  56%|█████▌    | 127/228 [00:52<00:42,  2.39it/s]step: 127
extend+tolist() time: 0.001873016357421875
Evaluating:  56%|█████▌    | 128/228 [00:53<00:41,  2.40it/s]step: 128
extend+tolist() time: 0.0008475780487060547
Evaluating:  57%|█████▋    | 129/228 [00:53<00:40,  2.46it/s]step: 129
extend+tolist() time: 0.0013320446014404297
Evaluating:  57%|█████▋    | 130/228 [00:54<00:41,  2.39it/s]step: 130
extend+tolist() time: 0.0010502338409423828
Evaluating:  57%|█████▋    | 131/228 [00:54<00:39,  2.44it/s]step: 131
extend+tolist() time: 0.0009260177612304688
Evaluating:  58%|█████▊    | 132/228 [00:55<00:39,  2.40it/s]step: 132
extend+tolist() time: 0.0012612342834472656
Evaluating:  58%|█████▊    | 133/228 [00:55<00:39,  2.41it/s]step: 133
extend+tolist() time: 0.0009508132934570312
Evaluating:  59%|█████▉    | 134/228 [00:55<00:39,  2.40it/s]step: 134
extend+tolist() time: 0.0011467933654785156
Evaluating:  59%|█████▉    | 135/228 [00:56<00:38,  2.40it/s]step: 135
extend+tolist() time: 0.0005204677581787109
Evaluating:  60%|█████▉    | 136/228 [00:56<00:37,  2.47it/s]step: 136
extend+tolist() time: 0.0014848709106445312
Evaluating:  60%|██████    | 137/228 [00:57<00:37,  2.41it/s]step: 137
extend+tolist() time: 0.00043582916259765625
Evaluating:  61%|██████    | 138/228 [00:57<00:36,  2.45it/s]step: 138
extend+tolist() time: 0.0012547969818115234
Evaluating:  61%|██████    | 139/228 [00:57<00:36,  2.44it/s]step: 139
extend+tolist() time: 0.0005381107330322266
Evaluating:  61%|██████▏   | 140/228 [00:58<00:36,  2.44it/s]step: 140
extend+tolist() time: 0.0008778572082519531
Evaluating:  62%|██████▏   | 141/228 [00:58<00:34,  2.49it/s]step: 141
extend+tolist() time: 0.0013806819915771484
Evaluating:  62%|██████▏   | 142/228 [00:59<00:35,  2.43it/s]step: 142
extend+tolist() time: 0.0006480216979980469
Evaluating:  63%|██████▎   | 143/228 [00:59<00:34,  2.46it/s]step: 143
extend+tolist() time: 0.0005865097045898438
Evaluating:  63%|██████▎   | 144/228 [00:59<00:33,  2.52it/s]step: 144
extend+tolist() time: 0.0012652873992919922
Evaluating:  64%|██████▎   | 145/228 [01:00<00:33,  2.45it/s]step: 145
extend+tolist() time: 0.000545501708984375
Evaluating:  64%|██████▍   | 146/228 [01:00<00:32,  2.50it/s]step: 146
extend+tolist() time: 0.0004138946533203125
Evaluating:  64%|██████▍   | 147/228 [01:01<00:33,  2.45it/s]step: 147
extend+tolist() time: 0.0012505054473876953
Evaluating:  65%|██████▍   | 148/228 [01:01<00:32,  2.46it/s]step: 148
extend+tolist() time: 0.0009410381317138672
Evaluating:  65%|██████▌   | 149/228 [01:01<00:31,  2.49it/s]step: 149
extend+tolist() time: 0.0003986358642578125
Evaluating:  66%|██████▌   | 150/228 [01:02<00:31,  2.45it/s]step: 150
extend+tolist() time: 0.0013642311096191406
Evaluating:  66%|██████▌   | 151/228 [01:02<00:30,  2.49it/s]step: 151
extend+tolist() time: 0.0006604194641113281
Evaluating:  67%|██████▋   | 152/228 [01:03<00:30,  2.45it/s]step: 152
extend+tolist() time: 0.001302480697631836
Evaluating:  67%|██████▋   | 153/228 [01:03<00:30,  2.49it/s]step: 153
extend+tolist() time: 0.0010821819305419922
Evaluating:  68%|██████▊   | 154/228 [01:03<00:29,  2.53it/s]step: 154
extend+tolist() time: 0.002077817916870117
Evaluating:  68%|██████▊   | 155/228 [01:04<00:30,  2.40it/s]step: 155
extend+tolist() time: 0.0007162094116210938
Evaluating:  68%|██████▊   | 156/228 [01:04<00:29,  2.47it/s]step: 156
extend+tolist() time: 0.001249551773071289
Evaluating:  69%|██████▉   | 157/228 [01:05<00:29,  2.44it/s]step: 157
extend+tolist() time: 0.0007345676422119141
Evaluating:  69%|██████▉   | 158/228 [01:05<00:28,  2.47it/s]step: 158
extend+tolist() time: 0.0005152225494384766
Evaluating:  70%|██████▉   | 159/228 [01:05<00:27,  2.52it/s]step: 159
extend+tolist() time: 0.26151204109191895
Evaluating:  70%|███████   | 160/228 [01:06<00:37,  1.79it/s]step: 160
extend+tolist() time: 0.0003955364227294922
Evaluating:  71%|███████   | 161/228 [01:07<00:34,  1.95it/s]step: 161
extend+tolist() time: 0.0011720657348632812
Evaluating:  71%|███████   | 162/228 [01:07<00:31,  2.12it/s]step: 162
extend+tolist() time: 0.0005173683166503906
Evaluating:  71%|███████▏  | 163/228 [01:08<00:29,  2.21it/s]step: 163
extend+tolist() time: 0.0004019737243652344
Evaluating:  72%|███████▏  | 164/228 [01:08<00:27,  2.30it/s]step: 164
extend+tolist() time: 0.0005812644958496094
Evaluating:  72%|███████▏  | 165/228 [01:08<00:26,  2.38it/s]step: 165
extend+tolist() time: 0.00045013427734375
Evaluating:  73%|███████▎  | 166/228 [01:09<00:26,  2.36it/s]step: 166
extend+tolist() time: 0.00038552284240722656
Evaluating:  73%|███████▎  | 167/228 [01:09<00:25,  2.43it/s]step: 167
extend+tolist() time: 0.0007941722869873047
Evaluating:  74%|███████▎  | 168/228 [01:10<00:24,  2.49it/s]step: 168
extend+tolist() time: 0.0016889572143554688
Evaluating:  74%|███████▍  | 169/228 [01:10<00:24,  2.43it/s]step: 169
extend+tolist() time: 0.00036787986755371094
Evaluating:  75%|███████▍  | 170/228 [01:10<00:23,  2.50it/s]step: 170
extend+tolist() time: 0.0013098716735839844
Evaluating:  75%|███████▌  | 171/228 [01:11<00:23,  2.45it/s]step: 171
extend+tolist() time: 0.0003085136413574219
Evaluating:  75%|███████▌  | 172/228 [01:11<00:22,  2.48it/s]step: 172
extend+tolist() time: 0.0008320808410644531
Evaluating:  76%|███████▌  | 173/228 [01:12<00:21,  2.52it/s]step: 173
extend+tolist() time: 0.0016460418701171875
Evaluating:  76%|███████▋  | 174/228 [01:12<00:22,  2.41it/s]step: 174
extend+tolist() time: 0.0018274784088134766
Evaluating:  77%|███████▋  | 175/228 [01:12<00:21,  2.44it/s]step: 175
extend+tolist() time: 0.0008244514465332031
Evaluating:  77%|███████▋  | 176/228 [01:13<00:21,  2.41it/s]step: 176
extend+tolist() time: 0.0006468296051025391
Evaluating:  78%|███████▊  | 177/228 [01:13<00:21,  2.40it/s]step: 177
extend+tolist() time: 0.0010416507720947266
Evaluating:  78%|███████▊  | 178/228 [01:14<00:20,  2.44it/s]step: 178
extend+tolist() time: 0.0012559890747070312
Evaluating:  79%|███████▊  | 179/228 [01:14<00:20,  2.41it/s]step: 179
extend+tolist() time: 0.0008482933044433594
Evaluating:  79%|███████▉  | 180/228 [01:14<00:19,  2.48it/s]step: 180
extend+tolist() time: 0.00039315223693847656
Evaluating:  79%|███████▉  | 181/228 [01:15<00:19,  2.44it/s]step: 181
extend+tolist() time: 0.0006380081176757812
Evaluating:  80%|███████▉  | 182/228 [01:15<00:18,  2.43it/s]step: 182
extend+tolist() time: 0.0012047290802001953
Evaluating:  80%|████████  | 183/228 [01:16<00:18,  2.39it/s]step: 183
extend+tolist() time: 0.0006659030914306641
Evaluating:  81%|████████  | 184/228 [01:16<00:18,  2.42it/s]step: 184
extend+tolist() time: 0.00046634674072265625
Evaluating:  81%|████████  | 185/228 [01:17<00:17,  2.47it/s]step: 185
extend+tolist() time: 0.001619577407836914
Evaluating:  82%|████████▏ | 186/228 [01:17<00:17,  2.35it/s]step: 186
extend+tolist() time: 0.0010821819305419922
Evaluating:  82%|████████▏ | 187/228 [01:17<00:16,  2.41it/s]step: 187
extend+tolist() time: 0.0008542537689208984
Evaluating:  82%|████████▏ | 188/228 [01:18<00:16,  2.39it/s]step: 188
extend+tolist() time: 0.0007197856903076172
Evaluating:  83%|████████▎ | 189/228 [01:18<00:16,  2.43it/s]step: 189
extend+tolist() time: 0.0003781318664550781
Evaluating:  83%|████████▎ | 190/228 [01:19<00:15,  2.50it/s]step: 190
extend+tolist() time: 0.0016851425170898438
Evaluating:  84%|████████▍ | 191/228 [01:19<00:15,  2.39it/s]step: 191
extend+tolist() time: 0.0007238388061523438
Evaluating:  84%|████████▍ | 192/228 [01:19<00:14,  2.45it/s]step: 192
extend+tolist() time: 0.0004413127899169922
Evaluating:  85%|████████▍ | 193/228 [01:20<00:14,  2.42it/s]step: 193
extend+tolist() time: 0.0015225410461425781
Evaluating:  85%|████████▌ | 194/228 [01:20<00:14,  2.41it/s]step: 194
extend+tolist() time: 0.0006494522094726562
Evaluating:  86%|████████▌ | 195/228 [01:21<00:13,  2.48it/s]step: 195
extend+tolist() time: 0.0009589195251464844
Evaluating:  86%|████████▌ | 196/228 [01:21<00:13,  2.42it/s]step: 196
extend+tolist() time: 0.000598907470703125
Evaluating:  86%|████████▋ | 197/228 [01:21<00:12,  2.48it/s]step: 197
extend+tolist() time: 0.0006847381591796875
Evaluating:  87%|████████▋ | 198/228 [01:22<00:12,  2.44it/s]step: 198
extend+tolist() time: 0.0010352134704589844
Evaluating:  87%|████████▋ | 199/228 [01:22<00:11,  2.46it/s]step: 199
extend+tolist() time: 0.0015091896057128906
Evaluating:  88%|████████▊ | 200/228 [01:23<00:11,  2.48it/s]step: 200
extend+tolist() time: 0.001178741455078125
Evaluating:  88%|████████▊ | 201/228 [01:23<00:11,  2.38it/s]step: 201
extend+tolist() time: 0.0006306171417236328
Evaluating:  89%|████████▊ | 202/228 [01:24<00:10,  2.43it/s]step: 202
extend+tolist() time: 0.0003960132598876953
Evaluating:  89%|████████▉ | 203/228 [01:24<00:10,  2.39it/s]step: 203
extend+tolist() time: 0.0013666152954101562
Evaluating:  89%|████████▉ | 204/228 [01:24<00:09,  2.41it/s]step: 204
extend+tolist() time: 0.00040650367736816406
Evaluating:  90%|████████▉ | 205/228 [01:25<00:09,  2.46it/s]step: 205
extend+tolist() time: 0.0002999305725097656
Evaluating:  90%|█████████ | 206/228 [01:25<00:09,  2.38it/s]step: 206
extend+tolist() time: 0.0006251335144042969
Evaluating:  91%|█████████ | 207/228 [01:26<00:08,  2.44it/s]step: 207
extend+tolist() time: 0.0010662078857421875
Evaluating:  91%|█████████ | 208/228 [01:26<00:08,  2.40it/s]step: 208
extend+tolist() time: 0.0007026195526123047
Evaluating:  92%|█████████▏| 209/228 [01:26<00:07,  2.46it/s]step: 209
extend+tolist() time: 0.0006227493286132812
Evaluating:  92%|█████████▏| 210/228 [01:27<00:07,  2.51it/s]step: 210
extend+tolist() time: 0.0010919570922851562
Evaluating:  93%|█████████▎| 211/228 [01:27<00:07,  2.41it/s]step: 211
extend+tolist() time: 0.001161336898803711
Evaluating:  93%|█████████▎| 212/228 [01:28<00:06,  2.42it/s]step: 212
extend+tolist() time: 0.00138092041015625
Evaluating:  93%|█████████▎| 213/228 [01:28<00:06,  2.39it/s]step: 213
extend+tolist() time: 0.0007736682891845703
Evaluating:  94%|█████████▍| 214/228 [01:28<00:05,  2.42it/s]step: 214
extend+tolist() time: 0.0015039443969726562
Evaluating:  94%|█████████▍| 215/228 [01:29<00:05,  2.45it/s]step: 215
extend+tolist() time: 0.0006859302520751953
Evaluating:  95%|█████████▍| 216/228 [01:29<00:04,  2.41it/s]step: 216
extend+tolist() time: 0.0005993843078613281
Evaluating:  95%|█████████▌| 217/228 [01:30<00:04,  2.47it/s]step: 217
extend+tolist() time: 0.0010297298431396484
Evaluating:  96%|█████████▌| 218/228 [01:30<00:04,  2.35it/s]step: 218
extend+tolist() time: 0.0011126995086669922
Evaluating:  96%|█████████▌| 219/228 [01:31<00:03,  2.39it/s]step: 219
extend+tolist() time: 0.0005018711090087891
Evaluating:  96%|█████████▋| 220/228 [01:31<00:03,  2.38it/s]step: 220
extend+tolist() time: 0.0008940696716308594
Evaluating:  97%|█████████▋| 221/228 [01:31<00:02,  2.43it/s]step: 221
extend+tolist() time: 0.0006768703460693359
Evaluating:  97%|█████████▋| 222/228 [01:32<00:02,  2.49it/s]step: 222
extend+tolist() time: 0.0004432201385498047
Evaluating:  98%|█████████▊| 223/228 [01:32<00:02,  2.44it/s]step: 223
extend+tolist() time: 0.0003917217254638672
Evaluating:  98%|█████████▊| 224/228 [01:33<00:01,  2.47it/s]step: 224
extend+tolist() time: 0.00084686279296875
Evaluating:  99%|█████████▊| 225/228 [01:33<00:01,  2.44it/s]step: 225
extend+tolist() time: 0.0004444122314453125
Evaluating:  99%|█████████▉| 226/228 [01:33<00:00,  2.47it/s]step: 226
extend+tolist() time: 0.0005812644958496094
Evaluating: 100%|█████████▉| 227/228 [01:34<00:00,  2.53it/s]step: 227
extend+tolist() time: 0.0004937648773193359
Evaluating: 100%|██████████| 228/228 [01:34<00:00,  2.43it/s]09/08/2023 21:22:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 21:22:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:22:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:22:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:22:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:22:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:22:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:22:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:22:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:22:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:22:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:22:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:22:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:22:50 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:22:50 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:22:50 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:22:50 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:36<00:00,  2.36it/s]
09/08/2023 21:22:50 - INFO - __main__ -   Step: 1332, Validation Metrics: {'pred_1_num': 10067, 'pred_-1_num': 723, 'pred_0_num': 11, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.8020553652439589, 'f1_micro': 0.8020553652439589, 'f1_macro': 0.41520753769682744, 'f1_weighted': 0.7553973712769106, 'f1_-1': 0.33114897335080823, 'f1_0': 0.027692307692307693, 'f1_1': 0.8867813320473664, 'precision_micro': 0.8020553652439589, 'precision_macro': 0.7214597233532607, 'precision_weighted': 0.7785919414023468, 'precision_-1': 0.5242047026279392, 'precision_0': 0.8181818181818182, 'precision_1': 0.8219926492500248, 'recall_micro': 0.8020553652439589, 'recall_macro': 0.4062531455939227, 'recall_weighted': 0.8020553652439589, 'recall_-1': 0.24201787994891444, 'recall_0': 0.014084507042253521, 'recall_1': 0.9626570497906003, 'roc_auc_micro': 0.9304946192192236, 'roc_auc_macro': 0.7859904676375832, 'roc_auc_weighted': 0.7853904782040491, 'roc_auc_-1': 0.8479985493026211, 'roc_auc_0': 0.7320208398590717, 'roc_auc_1': 0.7779520137510565}
  0%|          | 0/66600 [00:00<?, ?it/s][2023-09-08 21:23:13,023] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1333/66600 [00:22<18:25, 59.05it/s]09/08/2023 21:23:13 - INFO - __main__ -   Step: 1333, LR: 1.3348353986731757e-05, Loss: 0.4652300477027893
  2%|▏         | 1333/66600 [00:33<18:25, 59.05it/s][2023-09-08 21:23:33,487] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1334/66600 [00:43<42:13, 25.76it/s]09/08/2023 21:23:33 - INFO - __main__ -   Step: 1334, LR: 1.3358367755664039e-05, Loss: 0.46658632159233093
[2023-09-08 21:23:53,952] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1335/66600 [01:03<1:16:09, 14.28it/s]09/08/2023 21:23:53 - INFO - __main__ -   Step: 1335, LR: 1.336838152459632e-05, Loss: 0.45915308594703674
[2023-09-08 21:24:14,566] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1336/66600 [01:24<2:04:47,  8.72it/s]09/08/2023 21:24:14 - INFO - __main__ -   Step: 1336, LR: 1.3378395293528604e-05, Loss: 0.4065861999988556
[2023-09-08 21:24:35,597] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1337/66600 [01:45<3:15:19,  5.57it/s]09/08/2023 21:24:35 - INFO - __main__ -   Step: 1337, LR: 1.3388409062460886e-05, Loss: 0.41969504952430725
[2023-09-08 21:24:56,662] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1338/66600 [02:06<4:55:28,  3.68it/s]09/08/2023 21:24:56 - INFO - __main__ -   Step: 1338, LR: 1.3398422831393167e-05, Loss: 0.35093146562576294
[2023-09-08 21:25:17,529] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1339/66600 [02:27<7:15:41,  2.50it/s]09/08/2023 21:25:17 - INFO - __main__ -   Step: 1339, LR: 1.340843660032545e-05, Loss: 0.4171367883682251
[2023-09-08 21:25:37,614] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1340/66600 [02:47<10:25:25,  1.74it/s]09/08/2023 21:25:37 - INFO - __main__ -   Step: 1340, LR: 1.341845036925773e-05, Loss: 0.44706374406814575
09/08/2023 21:25:37 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0022177696228027344

Evaluating:   0%|          | 1/228 [00:00<01:55,  1.96it/s][Astep: 1
extend+tolist() time: 0.0010120868682861328

Evaluating:   1%|          | 2/228 [00:00<01:45,  2.13it/s][Astep: 2
extend+tolist() time: 0.002032041549682617

Evaluating:   1%|▏         | 3/228 [00:01<01:39,  2.26it/s][Astep: 3
extend+tolist() time: 0.0017848014831542969

Evaluating:   2%|▏         | 4/228 [00:01<01:37,  2.30it/s][Astep: 4
extend+tolist() time: 0.0013127326965332031

Evaluating:   2%|▏         | 5/228 [00:02<01:38,  2.26it/s][Astep: 5
extend+tolist() time: 0.0018160343170166016

Evaluating:   3%|▎         | 6/228 [00:02<01:37,  2.27it/s][Astep: 6
extend+tolist() time: 0.001497030258178711

Evaluating:   3%|▎         | 7/228 [00:03<01:38,  2.24it/s][Astep: 7
extend+tolist() time: 0.0014760494232177734

Evaluating:   4%|▎         | 8/228 [00:03<01:35,  2.32it/s][Astep: 8
extend+tolist() time: 0.0014190673828125

Evaluating:   4%|▍         | 9/228 [00:03<01:36,  2.28it/s][Astep: 9
extend+tolist() time: 0.0008440017700195312

Evaluating:   4%|▍         | 10/228 [00:04<01:32,  2.37it/s][Astep: 10
extend+tolist() time: 0.0012717247009277344

Evaluating:   5%|▍         | 11/228 [00:04<01:30,  2.40it/s][Astep: 11
extend+tolist() time: 0.0005612373352050781

Evaluating:   5%|▌         | 12/228 [00:05<01:30,  2.39it/s][Astep: 12
extend+tolist() time: 0.0006937980651855469

Evaluating:   6%|▌         | 13/228 [00:05<01:27,  2.45it/s][Astep: 13
extend+tolist() time: 0.0010650157928466797

Evaluating:   6%|▌         | 14/228 [00:06<01:29,  2.40it/s][Astep: 14
extend+tolist() time: 0.0005638599395751953

Evaluating:   7%|▋         | 15/228 [00:06<01:26,  2.47it/s][Astep: 15
extend+tolist() time: 0.0006220340728759766

Evaluating:   7%|▋         | 16/228 [00:06<01:25,  2.48it/s][Astep: 16
extend+tolist() time: 0.0011038780212402344

Evaluating:   7%|▋         | 17/228 [00:07<01:26,  2.44it/s][Astep: 17
extend+tolist() time: 0.0008924007415771484

Evaluating:   8%|▊         | 18/228 [00:07<01:24,  2.49it/s][Astep: 18
extend+tolist() time: 0.0016338825225830078

Evaluating:   8%|▊         | 19/228 [00:08<01:27,  2.40it/s][Astep: 19
extend+tolist() time: 0.0013689994812011719

Evaluating:   9%|▉         | 20/228 [00:08<01:24,  2.45it/s][Astep: 20
extend+tolist() time: 0.0007450580596923828

Evaluating:   9%|▉         | 21/228 [00:09<01:37,  2.13it/s][Astep: 21
extend+tolist() time: 0.0010352134704589844

Evaluating:  10%|▉         | 22/228 [00:09<01:31,  2.26it/s][Astep: 22
extend+tolist() time: 0.18518757820129395

Evaluating:  10%|█         | 23/228 [00:10<01:39,  2.06it/s][Astep: 23
extend+tolist() time: 0.001146078109741211

Evaluating:  11%|█         | 24/228 [00:10<01:32,  2.20it/s][Astep: 24
extend+tolist() time: 0.0011038780212402344

Evaluating:  11%|█         | 25/228 [00:10<01:38,  2.07it/s][Astep: 25
extend+tolist() time: 0.0019030570983886719

Evaluating:  11%|█▏        | 26/228 [00:11<01:35,  2.11it/s][Astep: 26
extend+tolist() time: 0.0011088848114013672

Evaluating:  12%|█▏        | 27/228 [00:11<01:29,  2.24it/s][Astep: 27
extend+tolist() time: 0.0016741752624511719

Evaluating:  12%|█▏        | 28/228 [00:12<01:29,  2.23it/s][Astep: 28
extend+tolist() time: 0.0003452301025390625

Evaluating:  13%|█▎        | 29/228 [00:12<01:24,  2.34it/s][Astep: 29
extend+tolist() time: 0.0007004737854003906

Evaluating:  13%|█▎        | 30/228 [00:13<01:23,  2.36it/s][Astep: 30
extend+tolist() time: 0.0015268325805664062

Evaluating:  14%|█▎        | 31/228 [00:13<01:22,  2.39it/s][Astep: 31
extend+tolist() time: 0.0009469985961914062

Evaluating:  14%|█▍        | 32/228 [00:13<01:20,  2.44it/s][Astep: 32
extend+tolist() time: 0.0010068416595458984

Evaluating:  14%|█▍        | 33/228 [00:14<01:22,  2.37it/s][Astep: 33
extend+tolist() time: 0.0017399787902832031

Evaluating:  15%|█▍        | 34/228 [00:14<01:20,  2.41it/s][Astep: 34
extend+tolist() time: 0.0012116432189941406

Evaluating:  15%|█▌        | 35/228 [00:15<01:22,  2.35it/s][Astep: 35
extend+tolist() time: 0.0006587505340576172

Evaluating:  16%|█▌        | 36/228 [00:15<01:19,  2.43it/s][Astep: 36
extend+tolist() time: 0.0007894039154052734

Evaluating:  16%|█▌        | 37/228 [00:15<01:16,  2.48it/s][Astep: 37
extend+tolist() time: 0.0017354488372802734

Evaluating:  17%|█▋        | 38/228 [00:16<01:19,  2.40it/s][Astep: 38
extend+tolist() time: 0.0011448860168457031

Evaluating:  17%|█▋        | 39/228 [00:16<01:17,  2.45it/s][Astep: 39
extend+tolist() time: 0.0007271766662597656

Evaluating:  18%|█▊        | 40/228 [00:17<01:18,  2.40it/s][Astep: 40
extend+tolist() time: 0.001062631607055664

Evaluating:  18%|█▊        | 41/228 [00:17<01:16,  2.45it/s][Astep: 41
extend+tolist() time: 0.0008475780487060547

Evaluating:  18%|█▊        | 42/228 [00:17<01:15,  2.45it/s][Astep: 42
extend+tolist() time: 0.0016510486602783203

Evaluating:  19%|█▉        | 43/228 [00:18<01:17,  2.39it/s][Astep: 43
extend+tolist() time: 0.0018358230590820312

Evaluating:  19%|█▉        | 44/228 [00:18<01:16,  2.41it/s][Astep: 44
extend+tolist() time: 0.0007946491241455078

Evaluating:  20%|█▉        | 45/228 [00:19<01:17,  2.35it/s][Astep: 45
extend+tolist() time: 0.001850128173828125

Evaluating:  20%|██        | 46/228 [00:19<01:16,  2.37it/s][Astep: 46
extend+tolist() time: 0.0015904903411865234

Evaluating:  21%|██        | 47/228 [00:20<01:16,  2.37it/s][Astep: 47
extend+tolist() time: 0.0015082359313964844

Evaluating:  21%|██        | 48/228 [00:20<01:17,  2.33it/s][Astep: 48
extend+tolist() time: 0.0015952587127685547

Evaluating:  21%|██▏       | 49/228 [00:20<01:15,  2.37it/s][Astep: 49
extend+tolist() time: 0.0009372234344482422

Evaluating:  22%|██▏       | 50/228 [00:21<01:17,  2.30it/s][Astep: 50
extend+tolist() time: 0.0017025470733642578

Evaluating:  22%|██▏       | 51/228 [00:21<01:15,  2.34it/s][Astep: 51
extend+tolist() time: 0.2003941535949707

Evaluating:  23%|██▎       | 52/228 [00:22<01:36,  1.83it/s][Astep: 52
extend+tolist() time: 0.0009515285491943359

Evaluating:  23%|██▎       | 53/228 [00:23<01:28,  1.97it/s][Astep: 53
extend+tolist() time: 0.00128173828125

Evaluating:  24%|██▎       | 54/228 [00:23<01:24,  2.05it/s][Astep: 54
extend+tolist() time: 0.0007734298706054688

Evaluating:  24%|██▍       | 55/228 [00:23<01:19,  2.19it/s][Astep: 55
extend+tolist() time: 0.0011935234069824219

Evaluating:  25%|██▍       | 56/228 [00:24<01:25,  2.00it/s][Astep: 56
extend+tolist() time: 0.0011339187622070312

Evaluating:  25%|██▌       | 57/228 [00:24<01:20,  2.13it/s][Astep: 57
extend+tolist() time: 0.0009801387786865234

Evaluating:  25%|██▌       | 58/228 [00:25<01:18,  2.16it/s][Astep: 58
extend+tolist() time: 0.0008652210235595703

Evaluating:  26%|██▌       | 59/228 [00:25<01:14,  2.27it/s][Astep: 59
extend+tolist() time: 0.0013659000396728516

Evaluating:  26%|██▋       | 60/228 [00:26<01:12,  2.33it/s][Astep: 60
extend+tolist() time: 0.0007100105285644531

Evaluating:  27%|██▋       | 61/228 [00:26<01:11,  2.33it/s][Astep: 61
extend+tolist() time: 0.0012111663818359375

Evaluating:  27%|██▋       | 62/228 [00:26<01:09,  2.40it/s][Astep: 62
extend+tolist() time: 0.0007977485656738281

Evaluating:  28%|██▊       | 63/228 [00:27<01:10,  2.35it/s][Astep: 63
extend+tolist() time: 0.0012390613555908203

Evaluating:  28%|██▊       | 64/228 [00:27<01:08,  2.40it/s][Astep: 64
extend+tolist() time: 0.001107931137084961

Evaluating:  29%|██▊       | 65/228 [00:28<01:07,  2.41it/s][Astep: 65
extend+tolist() time: 0.0008280277252197266

Evaluating:  29%|██▉       | 66/228 [00:28<01:08,  2.37it/s][Astep: 66
extend+tolist() time: 0.0011124610900878906

Evaluating:  29%|██▉       | 67/228 [00:29<01:06,  2.42it/s][Astep: 67
extend+tolist() time: 0.0009253025054931641

Evaluating:  30%|██▉       | 68/228 [00:29<01:08,  2.35it/s][Astep: 68
extend+tolist() time: 0.0010743141174316406

Evaluating:  30%|███       | 69/228 [00:29<01:06,  2.41it/s][Astep: 69
extend+tolist() time: 0.00107574462890625

Evaluating:  31%|███       | 70/228 [00:30<01:05,  2.40it/s][Astep: 70
extend+tolist() time: 0.0015578269958496094

Evaluating:  31%|███       | 71/228 [00:30<01:06,  2.36it/s][Astep: 71
extend+tolist() time: 0.0013470649719238281

Evaluating:  32%|███▏      | 72/228 [00:31<01:05,  2.40it/s][Astep: 72
extend+tolist() time: 0.0007882118225097656

Evaluating:  32%|███▏      | 73/228 [00:31<01:05,  2.36it/s][Astep: 73
extend+tolist() time: 0.0005292892456054688

Evaluating:  32%|███▏      | 74/228 [00:31<01:03,  2.41it/s][Astep: 74
extend+tolist() time: 0.001207113265991211

Evaluating:  33%|███▎      | 75/228 [00:32<01:04,  2.36it/s][Astep: 75
extend+tolist() time: 0.0016355514526367188

Evaluating:  33%|███▎      | 76/228 [00:32<01:03,  2.39it/s][Astep: 76
extend+tolist() time: 0.0006151199340820312

Evaluating:  34%|███▍      | 77/228 [00:33<01:02,  2.41it/s][Astep: 77
extend+tolist() time: 0.0018765926361083984

Evaluating:  34%|███▍      | 78/228 [00:33<01:04,  2.33it/s][Astep: 78
extend+tolist() time: 0.0011813640594482422

Evaluating:  35%|███▍      | 79/228 [00:34<01:02,  2.39it/s][Astep: 79
extend+tolist() time: 0.0009005069732666016

Evaluating:  35%|███▌      | 80/228 [00:34<01:03,  2.32it/s][Astep: 80
extend+tolist() time: 0.0013341903686523438

Evaluating:  36%|███▌      | 81/228 [00:34<01:01,  2.37it/s][Astep: 81
extend+tolist() time: 0.0008280277252197266

Evaluating:  36%|███▌      | 82/228 [00:35<01:02,  2.34it/s][Astep: 82
extend+tolist() time: 0.0012655258178710938

Evaluating:  36%|███▋      | 83/228 [00:35<01:01,  2.34it/s][Astep: 83
extend+tolist() time: 0.0006947517395019531

Evaluating:  37%|███▋      | 84/228 [00:36<01:00,  2.37it/s][Astep: 84
extend+tolist() time: 0.0014050006866455078

Evaluating:  37%|███▋      | 85/228 [00:36<01:01,  2.32it/s][Astep: 85
extend+tolist() time: 0.0012202262878417969

Evaluating:  38%|███▊      | 86/228 [00:37<00:59,  2.38it/s][Astep: 86
extend+tolist() time: 0.000881195068359375

Evaluating:  38%|███▊      | 87/228 [00:37<01:00,  2.32it/s][Astep: 87
extend+tolist() time: 0.0013058185577392578

Evaluating:  39%|███▊      | 88/228 [00:37<00:58,  2.37it/s][Astep: 88
extend+tolist() time: 0.0007357597351074219

Evaluating:  39%|███▉      | 89/228 [00:38<00:57,  2.40it/s][Astep: 89
extend+tolist() time: 0.0011730194091796875

Evaluating:  39%|███▉      | 90/228 [00:38<00:59,  2.33it/s][Astep: 90
extend+tolist() time: 0.0011205673217773438

Evaluating:  40%|███▉      | 91/228 [00:39<00:57,  2.38it/s][Astep: 91
extend+tolist() time: 0.0013165473937988281

Evaluating:  40%|████      | 92/228 [00:39<00:58,  2.32it/s][Astep: 92
extend+tolist() time: 0.0009219646453857422

Evaluating:  41%|████      | 93/228 [00:40<01:04,  2.10it/s][Astep: 93
extend+tolist() time: 0.19059157371520996

Evaluating:  41%|████      | 94/228 [00:40<01:10,  1.91it/s][Astep: 94
extend+tolist() time: 0.0007984638214111328

Evaluating:  42%|████▏     | 95/228 [00:41<01:04,  2.07it/s][Astep: 95
extend+tolist() time: 0.0013844966888427734

Evaluating:  42%|████▏     | 96/228 [00:41<01:02,  2.10it/s][Astep: 96
extend+tolist() time: 0.0014660358428955078

Evaluating:  43%|████▎     | 97/228 [00:42<00:59,  2.21it/s][Astep: 97
extend+tolist() time: 0.0013501644134521484

Evaluating:  43%|████▎     | 98/228 [00:42<01:05,  1.97it/s][Astep: 98
extend+tolist() time: 0.0010824203491210938

Evaluating:  43%|████▎     | 99/228 [00:43<01:00,  2.12it/s][Astep: 99
extend+tolist() time: 0.001688241958618164

Evaluating:  44%|████▍     | 100/228 [00:43<00:58,  2.19it/s][Astep: 100
extend+tolist() time: 0.0008523464202880859

Evaluating:  44%|████▍     | 101/228 [00:43<00:55,  2.27it/s][Astep: 101
extend+tolist() time: 0.0013446807861328125

Evaluating:  45%|████▍     | 102/228 [00:44<00:53,  2.34it/s][Astep: 102
extend+tolist() time: 0.0008544921875

Evaluating:  45%|████▌     | 103/228 [00:44<00:53,  2.33it/s][Astep: 103
extend+tolist() time: 0.001295328140258789

Evaluating:  46%|████▌     | 104/228 [00:45<00:51,  2.39it/s][Astep: 104
extend+tolist() time: 0.0008208751678466797

Evaluating:  46%|████▌     | 105/228 [00:45<00:52,  2.34it/s][Astep: 105
extend+tolist() time: 0.0013818740844726562

Evaluating:  46%|████▋     | 106/228 [00:46<00:50,  2.40it/s][Astep: 106
extend+tolist() time: 0.002015352249145508

Evaluating:  47%|████▋     | 107/228 [00:46<00:50,  2.39it/s][Astep: 107
extend+tolist() time: 0.0009129047393798828

Evaluating:  47%|████▋     | 108/228 [00:46<00:50,  2.36it/s][Astep: 108
extend+tolist() time: 0.0012965202331542969

Evaluating:  48%|████▊     | 109/228 [00:47<00:49,  2.42it/s][Astep: 109
extend+tolist() time: 0.0009963512420654297

Evaluating:  48%|████▊     | 110/228 [00:47<00:50,  2.36it/s][Astep: 110
extend+tolist() time: 0.001117706298828125

Evaluating:  49%|████▊     | 111/228 [00:48<00:48,  2.42it/s][Astep: 111
extend+tolist() time: 0.0016567707061767578

Evaluating:  49%|████▉     | 112/228 [00:48<00:48,  2.41it/s][Astep: 112
extend+tolist() time: 0.0008893013000488281

Evaluating:  50%|████▉     | 113/228 [00:48<00:48,  2.38it/s][Astep: 113
extend+tolist() time: 0.0008399486541748047

Evaluating:  50%|█████     | 114/228 [00:49<00:47,  2.42it/s][Astep: 114
extend+tolist() time: 0.0017213821411132812

Evaluating:  50%|█████     | 115/228 [00:49<00:48,  2.34it/s][Astep: 115
extend+tolist() time: 0.0007319450378417969

Evaluating:  51%|█████     | 116/228 [00:50<00:46,  2.40it/s][Astep: 116
extend+tolist() time: 0.0013918876647949219

Evaluating:  51%|█████▏    | 117/228 [00:50<00:46,  2.41it/s][Astep: 117
extend+tolist() time: 0.001020669937133789

Evaluating:  52%|█████▏    | 118/228 [00:51<00:46,  2.37it/s][Astep: 118
extend+tolist() time: 0.001043081283569336

Evaluating:  52%|█████▏    | 119/228 [00:51<00:44,  2.43it/s][Astep: 119
extend+tolist() time: 0.0008339881896972656

Evaluating:  53%|█████▎    | 120/228 [00:51<00:45,  2.36it/s][Astep: 120
extend+tolist() time: 0.0007181167602539062

Evaluating:  53%|█████▎    | 121/228 [00:52<00:44,  2.42it/s][Astep: 121
extend+tolist() time: 0.0014452934265136719

Evaluating:  54%|█████▎    | 122/228 [00:52<00:44,  2.40it/s][Astep: 122
extend+tolist() time: 0.0007982254028320312

Evaluating:  54%|█████▍    | 123/228 [00:53<00:43,  2.42it/s][Astep: 123
extend+tolist() time: 0.0011255741119384766

Evaluating:  54%|█████▍    | 124/228 [00:53<00:42,  2.44it/s][Astep: 124
extend+tolist() time: 0.0009627342224121094

Evaluating:  55%|█████▍    | 125/228 [00:53<00:42,  2.41it/s][Astep: 125
extend+tolist() time: 0.0004954338073730469

Evaluating:  55%|█████▌    | 126/228 [00:54<00:41,  2.47it/s][Astep: 126
extend+tolist() time: 0.0020494461059570312

Evaluating:  56%|█████▌    | 127/228 [00:54<00:42,  2.36it/s][Astep: 127
extend+tolist() time: 0.0018930435180664062

Evaluating:  56%|█████▌    | 128/228 [00:55<00:42,  2.35it/s][Astep: 128
extend+tolist() time: 0.001207113265991211

Evaluating:  57%|█████▋    | 129/228 [00:55<00:41,  2.37it/s][Astep: 129
extend+tolist() time: 0.0008263587951660156

Evaluating:  57%|█████▋    | 130/228 [00:56<00:42,  2.33it/s][Astep: 130
extend+tolist() time: 0.0014452934265136719

Evaluating:  57%|█████▋    | 131/228 [00:56<00:40,  2.37it/s][Astep: 131
extend+tolist() time: 0.0005342960357666016

Evaluating:  58%|█████▊    | 132/228 [00:56<00:41,  2.32it/s][Astep: 132
extend+tolist() time: 0.0016224384307861328

Evaluating:  58%|█████▊    | 133/228 [00:57<00:40,  2.36it/s][Astep: 133
extend+tolist() time: 0.0005023479461669922

Evaluating:  59%|█████▉    | 134/228 [00:57<00:39,  2.37it/s][Astep: 134
extend+tolist() time: 0.0011157989501953125

Evaluating:  59%|█████▉    | 135/228 [00:58<00:39,  2.34it/s][Astep: 135
extend+tolist() time: 0.0009710788726806641

Evaluating:  60%|█████▉    | 136/228 [00:58<00:38,  2.39it/s][Astep: 136
extend+tolist() time: 0.0009543895721435547

Evaluating:  60%|██████    | 137/228 [00:59<00:38,  2.34it/s][Astep: 137
extend+tolist() time: 0.00044989585876464844

Evaluating:  61%|██████    | 138/228 [00:59<00:37,  2.39it/s][Astep: 138
extend+tolist() time: 0.0012700557708740234

Evaluating:  61%|██████    | 139/228 [00:59<00:38,  2.33it/s][Astep: 139
extend+tolist() time: 0.0005319118499755859

Evaluating:  61%|██████▏   | 140/228 [01:00<00:36,  2.40it/s][Astep: 140
extend+tolist() time: 0.0013010501861572266

Evaluating:  62%|██████▏   | 141/228 [01:00<00:35,  2.42it/s][Astep: 141
extend+tolist() time: 0.0008604526519775391

Evaluating:  62%|██████▏   | 142/228 [01:01<00:36,  2.37it/s][Astep: 142
extend+tolist() time: 0.000652313232421875

Evaluating:  63%|██████▎   | 143/228 [01:01<00:35,  2.43it/s][Astep: 143
extend+tolist() time: 0.0008397102355957031

Evaluating:  63%|██████▎   | 144/228 [01:01<00:35,  2.37it/s][Astep: 144
extend+tolist() time: 0.0008223056793212891

Evaluating:  64%|██████▎   | 145/228 [01:02<00:34,  2.43it/s][Astep: 145
extend+tolist() time: 0.00054168701171875

Evaluating:  64%|██████▍   | 146/228 [01:02<00:33,  2.47it/s][Astep: 146
extend+tolist() time: 0.0008759498596191406

Evaluating:  64%|██████▍   | 147/228 [01:03<00:33,  2.43it/s][Astep: 147
extend+tolist() time: 0.0008249282836914062

Evaluating:  65%|██████▍   | 148/228 [01:03<00:32,  2.49it/s][Astep: 148
extend+tolist() time: 0.0007791519165039062

Evaluating:  65%|██████▌   | 149/228 [01:03<00:32,  2.41it/s][Astep: 149
extend+tolist() time: 0.0010061264038085938

Evaluating:  66%|██████▌   | 150/228 [01:04<00:31,  2.48it/s][Astep: 150
extend+tolist() time: 0.0009539127349853516

Evaluating:  66%|██████▌   | 151/228 [01:04<00:30,  2.49it/s][Astep: 151
extend+tolist() time: 0.0006589889526367188

Evaluating:  67%|██████▋   | 152/228 [01:05<00:31,  2.44it/s][Astep: 152
extend+tolist() time: 0.0014083385467529297

Evaluating:  67%|██████▋   | 153/228 [01:05<00:30,  2.48it/s][Astep: 153
extend+tolist() time: 0.0011057853698730469

Evaluating:  68%|██████▊   | 154/228 [01:06<00:30,  2.40it/s][Astep: 154
extend+tolist() time: 0.0021162033081054688

Evaluating:  68%|██████▊   | 155/228 [01:06<00:30,  2.41it/s][Astep: 155
extend+tolist() time: 0.27306103706359863

Evaluating:  68%|██████▊   | 156/228 [01:07<00:41,  1.73it/s][Astep: 156
extend+tolist() time: 0.0005719661712646484

Evaluating:  69%|██████▉   | 157/228 [01:07<00:37,  1.90it/s][Astep: 157
extend+tolist() time: 0.0011332035064697266

Evaluating:  69%|██████▉   | 158/228 [01:08<00:34,  2.02it/s][Astep: 158
extend+tolist() time: 0.0005223751068115234

Evaluating:  70%|██████▉   | 159/228 [01:08<00:32,  2.15it/s][Astep: 159
extend+tolist() time: 0.0007419586181640625

Evaluating:  70%|███████   | 160/228 [01:09<00:31,  2.17it/s][Astep: 160
extend+tolist() time: 0.0008053779602050781

Evaluating:  71%|███████   | 161/228 [01:09<00:29,  2.27it/s][Astep: 161
extend+tolist() time: 0.00084686279296875

Evaluating:  71%|███████   | 162/228 [01:09<00:28,  2.31it/s][Astep: 162
extend+tolist() time: 0.0005373954772949219

Evaluating:  71%|███████▏  | 163/228 [01:10<00:31,  2.05it/s][Astep: 163
extend+tolist() time: 0.0008516311645507812

Evaluating:  72%|███████▏  | 164/228 [01:10<00:29,  2.17it/s][Astep: 164
extend+tolist() time: 0.000553131103515625

Evaluating:  72%|███████▏  | 165/228 [01:11<00:28,  2.22it/s][Astep: 165
extend+tolist() time: 0.0004858970642089844

Evaluating:  73%|███████▎  | 166/228 [01:11<00:26,  2.33it/s][Astep: 166
extend+tolist() time: 0.00040149688720703125

Evaluating:  73%|███████▎  | 167/228 [01:12<00:26,  2.31it/s][Astep: 167
extend+tolist() time: 0.0010962486267089844

Evaluating:  74%|███████▎  | 168/228 [01:12<00:25,  2.39it/s][Astep: 168
extend+tolist() time: 0.001255035400390625

Evaluating:  74%|███████▍  | 169/228 [01:12<00:24,  2.39it/s][Astep: 169
extend+tolist() time: 0.0003638267517089844

Evaluating:  75%|███████▍  | 170/228 [01:13<00:24,  2.38it/s][Astep: 170
extend+tolist() time: 0.0013880729675292969

Evaluating:  75%|███████▌  | 171/228 [01:13<00:23,  2.44it/s][Astep: 171
extend+tolist() time: 0.00031375885009765625

Evaluating:  75%|███████▌  | 172/228 [01:14<00:23,  2.38it/s][Astep: 172
extend+tolist() time: 0.001224517822265625

Evaluating:  76%|███████▌  | 173/228 [01:14<00:22,  2.44it/s][Astep: 173
extend+tolist() time: 0.0011837482452392578

Evaluating:  76%|███████▋  | 174/228 [01:15<00:22,  2.43it/s][Astep: 174
extend+tolist() time: 0.0019078254699707031

Evaluating:  77%|███████▋  | 175/228 [01:15<00:22,  2.37it/s][Astep: 175
extend+tolist() time: 0.0007987022399902344

Evaluating:  77%|███████▋  | 176/228 [01:15<00:21,  2.43it/s][Astep: 176
extend+tolist() time: 0.0010325908660888672

Evaluating:  78%|███████▊  | 177/228 [01:16<00:21,  2.37it/s][Astep: 177
extend+tolist() time: 0.0006117820739746094

Evaluating:  78%|███████▊  | 178/228 [01:16<00:20,  2.44it/s][Astep: 178
extend+tolist() time: 0.0016703605651855469

Evaluating:  79%|███████▊  | 179/228 [01:17<00:20,  2.39it/s][Astep: 179
extend+tolist() time: 0.0004146099090576172

Evaluating:  79%|███████▉  | 180/228 [01:17<00:19,  2.43it/s][Astep: 180
extend+tolist() time: 0.00039696693420410156

Evaluating:  79%|███████▉  | 181/228 [01:17<00:18,  2.48it/s][Astep: 181
extend+tolist() time: 0.0006146430969238281

Evaluating:  80%|███████▉  | 182/228 [01:18<00:19,  2.40it/s][Astep: 182
extend+tolist() time: 0.0012373924255371094

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.44it/s][Astep: 183
extend+tolist() time: 0.0009450912475585938

Evaluating:  81%|████████  | 184/228 [01:19<00:18,  2.41it/s][Astep: 184
extend+tolist() time: 0.00047397613525390625

Evaluating:  81%|████████  | 185/228 [01:19<00:17,  2.44it/s][Astep: 185
extend+tolist() time: 0.0019593238830566406

Evaluating:  82%|████████▏ | 186/228 [01:19<00:17,  2.45it/s][Astep: 186
extend+tolist() time: 0.0014102458953857422

Evaluating:  82%|████████▏ | 187/228 [01:20<00:17,  2.40it/s][Astep: 187
extend+tolist() time: 0.00044274330139160156

Evaluating:  82%|████████▏ | 188/228 [01:20<00:16,  2.46it/s][Astep: 188
extend+tolist() time: 0.0006773471832275391

Evaluating:  83%|████████▎ | 189/228 [01:21<00:16,  2.41it/s][Astep: 189
extend+tolist() time: 0.0003960132598876953

Evaluating:  83%|████████▎ | 190/228 [01:21<00:15,  2.45it/s][Astep: 190
extend+tolist() time: 0.0016324520111083984

Evaluating:  84%|████████▍ | 191/228 [01:22<00:15,  2.44it/s][Astep: 191
extend+tolist() time: 0.0007154941558837891

Evaluating:  84%|████████▍ | 192/228 [01:22<00:15,  2.40it/s][Astep: 192
extend+tolist() time: 0.0008394718170166016

Evaluating:  85%|████████▍ | 193/228 [01:22<00:14,  2.46it/s][Astep: 193
extend+tolist() time: 0.0010652542114257812

Evaluating:  85%|████████▌ | 194/228 [01:23<00:14,  2.40it/s][Astep: 194
extend+tolist() time: 0.0010714530944824219

Evaluating:  86%|████████▌ | 195/228 [01:23<00:13,  2.45it/s][Astep: 195
extend+tolist() time: 0.0005354881286621094

Evaluating:  86%|████████▌ | 196/228 [01:24<00:12,  2.47it/s][Astep: 196
extend+tolist() time: 0.0006089210510253906

Evaluating:  86%|████████▋ | 197/228 [01:24<00:12,  2.42it/s][Astep: 197
extend+tolist() time: 0.001130819320678711

Evaluating:  87%|████████▋ | 198/228 [01:24<00:12,  2.48it/s][Astep: 198
extend+tolist() time: 0.0006532669067382812

Evaluating:  87%|████████▋ | 199/228 [01:25<00:11,  2.43it/s][Astep: 199
extend+tolist() time: 0.0019366741180419922

Evaluating:  88%|████████▊ | 200/228 [01:25<00:11,  2.43it/s][Astep: 200
extend+tolist() time: 0.0007123947143554688

Evaluating:  88%|████████▊ | 201/228 [01:26<00:11,  2.44it/s][Astep: 201
extend+tolist() time: 0.0006091594696044922

Evaluating:  89%|████████▊ | 202/228 [01:26<00:10,  2.41it/s][Astep: 202
extend+tolist() time: 0.0008111000061035156

Evaluating:  89%|████████▉ | 203/228 [01:26<00:10,  2.47it/s][Astep: 203
extend+tolist() time: 0.0005190372467041016

Evaluating:  89%|████████▉ | 204/228 [01:27<00:09,  2.40it/s][Astep: 204
extend+tolist() time: 0.0004017353057861328

Evaluating:  90%|████████▉ | 205/228 [01:27<00:09,  2.46it/s][Astep: 205
extend+tolist() time: 0.0003230571746826172

Evaluating:  90%|█████████ | 206/228 [01:28<00:08,  2.48it/s][Astep: 206
extend+tolist() time: 0.0006082057952880859

Evaluating:  91%|█████████ | 207/228 [01:28<00:08,  2.43it/s][Astep: 207
extend+tolist() time: 0.0005960464477539062

Evaluating:  91%|█████████ | 208/228 [01:28<00:08,  2.48it/s][Astep: 208
extend+tolist() time: 0.0007152557373046875

Evaluating:  92%|█████████▏| 209/228 [01:29<00:07,  2.39it/s][Astep: 209
extend+tolist() time: 0.0010535717010498047

Evaluating:  92%|█████████▏| 210/228 [01:29<00:07,  2.44it/s][Astep: 210
extend+tolist() time: 0.0006003379821777344

Evaluating:  93%|█████████▎| 211/228 [01:30<00:06,  2.46it/s][Astep: 211
extend+tolist() time: 0.0011372566223144531

Evaluating:  93%|█████████▎| 212/228 [01:30<00:06,  2.39it/s][Astep: 212
extend+tolist() time: 0.001363992691040039

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.43it/s][Astep: 213
extend+tolist() time: 0.0007684230804443359

Evaluating:  94%|█████████▍| 214/228 [01:31<00:05,  2.36it/s][Astep: 214
extend+tolist() time: 0.0012843608856201172

Evaluating:  94%|█████████▍| 215/228 [01:31<00:05,  2.41it/s][Astep: 215
extend+tolist() time: 0.000659942626953125

Evaluating:  95%|█████████▍| 216/228 [01:32<00:04,  2.44it/s][Astep: 216
extend+tolist() time: 0.0010311603546142578

Evaluating:  95%|█████████▌| 217/228 [01:32<00:04,  2.39it/s][Astep: 217
extend+tolist() time: 0.0005574226379394531

Evaluating:  96%|█████████▌| 218/228 [01:33<00:04,  2.45it/s][Astep: 218
extend+tolist() time: 0.0010924339294433594

Evaluating:  96%|█████████▌| 219/228 [01:33<00:03,  2.37it/s][Astep: 219
extend+tolist() time: 0.0008931159973144531

Evaluating:  96%|█████████▋| 220/228 [01:33<00:03,  2.44it/s][Astep: 220
extend+tolist() time: 0.0006744861602783203

Evaluating:  97%|█████████▋| 221/228 [01:34<00:02,  2.42it/s][Astep: 221
extend+tolist() time: 0.0006773471832275391

Evaluating:  97%|█████████▋| 222/228 [01:34<00:02,  2.44it/s][Astep: 222
extend+tolist() time: 0.0004949569702148438

Evaluating:  98%|█████████▊| 223/228 [01:35<00:02,  2.49it/s][Astep: 223
extend+tolist() time: 0.0012047290802001953

Evaluating:  98%|█████████▊| 224/228 [01:35<00:01,  2.40it/s][Astep: 224
extend+tolist() time: 0.0004119873046875

Evaluating:  99%|█████████▊| 225/228 [01:35<00:01,  2.46it/s][Astep: 225
extend+tolist() time: 0.0007236003875732422

Evaluating:  99%|█████████▉| 226/228 [01:36<00:00,  2.44it/s][Astep: 226
extend+tolist() time: 0.0005502700805664062

Evaluating: 100%|█████████▉| 227/228 [01:36<00:00,  2.45it/s][Astep: 227
extend+tolist() time: 0.0009171962738037109

Evaluating: 100%|██████████| 228/228 [01:37<00:00,  2.45it/s][A09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:27:15 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:27:16 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:27:16 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:27:17 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:27:17 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:39<00:00,  2.29it/s]
09/08/2023 21:27:17 - INFO - __main__ -   Step: 1340, Validation Metrics: {'pred_1_num': 9809, 'pred_-1_num': 971, 'pred_0_num': 21, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7970558281640588, 'f1_micro': 0.7970558281640588, 'f1_macro': 0.43081817322247223, 'f1_weighted': 0.7587583790027006, 'f1_-1': 0.3665746945210879, 'f1_0': 0.04242424242424243, 'f1_1': 0.8834555827220864, 'precision_micro': 0.7970558281640588, 'precision_macro': 0.6581283589916763, 'precision_weighted': 0.7684998250643892, 'precision_-1': 0.4788877445932029, 'precision_0': 0.6666666666666666, 'precision_1': 0.8288306657151595, 'recall_micro': 0.7970558281640588, 'recall_macro': 0.4215442793418567, 'recall_weighted': 0.7970558281640588, 'recall_-1': 0.29693486590038315, 'recall_0': 0.02190923317683881, 'recall_1': 0.945788738948348, 'roc_auc_micro': 0.9257840782589637, 'roc_auc_macro': 0.7744945378141316, 'roc_auc_weighted': 0.7726825468224134, 'roc_auc_-1': 0.8313908301819734, 'roc_auc_0': 0.726686366311759, 'roc_auc_1': 0.7654064169486624}
09/08/2023 21:27:17 - INFO - __main__ - Saving state to /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879
09/08/2023 21:27:17 - INFO - accelerate.accelerator - Saving current state to /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879
09/08/2023 21:27:17 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2023-09-08 21:27:17,215] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2023-09-08 21:27:17,223] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt...
[2023-09-08 21:27:17,223] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt
[2023-09-08 21:27:17,223] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt...
[2023-09-08 21:27:17,224] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt...
[2023-09-08 21:27:17,224] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt
[2023-09-08 21:27:17,225] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-09-08 21:27:17,238] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt.
[2023-09-08 21:27:17,238] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt.
[2023-09-08 21:27:17,239] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt.
[2023-09-08 21:27:17,239] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-09-08 21:27:17,242] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2023-09-08 21:27:17,242] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[2023-09-08 21:27:17,242] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-09-08 21:27:17,242] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2023-09-08 21:28:02,244] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[2023-09-08 21:28:02,244] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt
[2023-09-08 21:28:05,853] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2023-09-08 21:28:05,853] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2023-09-08 21:28:06,384] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-09-08 21:28:06,384] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2023-09-08 21:28:08,710] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[2023-09-08 21:28:08,710] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt
[2023-09-08 21:28:08,761] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 21:28:08,761] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 21:28:08,761] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 21:28:08,761] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/08/2023 21:28:08 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/pytorch_model
09/08/2023 21:28:08 - INFO - accelerate.checkpointing - Scheduler state saved in /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/scheduler.bin
09/08/2023 21:28:08 - INFO - accelerate.checkpointing - Random states saved in /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1340-best-f1_-1=0.3665746945210879/random_states_0.pkl
[2023-09-08 21:28:29,430] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1341/66600 [05:38<49:13:57,  2.72s/it]09/08/2023 21:28:29 - INFO - __main__ -   Step: 1341, LR: 1.3428464138190012e-05, Loss: 0.3833911418914795
[2023-09-08 21:28:49,829] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1342/66600 [05:59<54:51:22,  3.03s/it]09/08/2023 21:28:49 - INFO - __main__ -   Step: 1342, LR: 1.3438477907122294e-05, Loss: 0.4046165943145752
[2023-09-08 21:29:10,639] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1343/66600 [06:20<62:44:19,  3.46s/it]09/08/2023 21:29:10 - INFO - __main__ -   Step: 1343, LR: 1.3448491676054575e-05, Loss: 0.40790829062461853
[2023-09-08 21:29:31,016] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1344/66600 [06:40<73:05:15,  4.03s/it]09/08/2023 21:29:31 - INFO - __main__ -   Step: 1344, LR: 1.3458505444986858e-05, Loss: 0.39602479338645935
[2023-09-08 21:29:51,859] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1345/66600 [07:01<87:06:18,  4.81s/it]09/08/2023 21:29:51 - INFO - __main__ -   Step: 1345, LR: 1.346851921391914e-05, Loss: 0.3499482572078705
[2023-09-08 21:30:12,184] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1346/66600 [07:21<104:27:02,  5.76s/it]09/08/2023 21:30:12 - INFO - __main__ -   Step: 1346, LR: 1.3478532982851422e-05, Loss: 0.41155070066452026
[2023-09-08 21:30:33,357] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1347/66600 [07:42<127:03:49,  7.01s/it]09/08/2023 21:30:33 - INFO - __main__ -   Step: 1347, LR: 1.3488546751783705e-05, Loss: 0.43357497453689575
[2023-09-08 21:30:54,467] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1348/66600 [08:04<153:33:27,  8.47s/it]09/08/2023 21:30:54 - INFO - __main__ -   Step: 1348, LR: 1.3498560520715987e-05, Loss: 0.3388160765171051
[2023-09-08 21:31:15,148] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1349/66600 [08:24<182:06:02, 10.05s/it]09/08/2023 21:31:15 - INFO - __main__ -   Step: 1349, LR: 1.3508574289648268e-05, Loss: 0.4090524911880493
[2023-09-08 21:31:36,344] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1350/66600 [08:45<213:32:37, 11.78s/it]09/08/2023 21:31:36 - INFO - __main__ -   Step: 1350, LR: 1.3518588058580548e-05, Loss: 0.4203973412513733
[2023-09-08 21:31:57,611] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1351/66600 [09:07<244:48:12, 13.51s/it]09/08/2023 21:31:57 - INFO - __main__ -   Step: 1351, LR: 1.3528601827512831e-05, Loss: 0.4145054221153259
[2023-09-08 21:32:18,434] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1352/66600 [09:27<272:08:46, 15.02s/it]09/08/2023 21:32:18 - INFO - __main__ -   Step: 1352, LR: 1.3538615596445113e-05, Loss: 0.4337325692176819
[2023-09-08 21:32:39,286] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1353/66600 [09:48<296:13:05, 16.34s/it]09/08/2023 21:32:39 - INFO - __main__ -   Step: 1353, LR: 1.3548629365377395e-05, Loss: 0.3893169164657593
[2023-09-08 21:32:59,622] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1354/66600 [10:09<313:57:44, 17.32s/it]09/08/2023 21:32:59 - INFO - __main__ -   Step: 1354, LR: 1.3558643134309676e-05, Loss: 0.34561052918434143
[2023-09-08 21:33:20,588] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1355/66600 [10:30<331:05:32, 18.27s/it]09/08/2023 21:33:20 - INFO - __main__ -   Step: 1355, LR: 1.356865690324196e-05, Loss: 0.35847464203834534
[2023-09-08 21:33:41,562] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1356/66600 [10:51<344:20:58, 19.00s/it]09/08/2023 21:33:41 - INFO - __main__ -   Step: 1356, LR: 1.3578670672174241e-05, Loss: 0.3927159905433655
[2023-09-08 21:34:01,487] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1357/66600 [11:11<349:00:46, 19.26s/it]09/08/2023 21:34:01 - INFO - __main__ -   Step: 1357, LR: 1.3588684441106523e-05, Loss: 0.35928118228912354
[2023-09-08 21:34:22,046] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1358/66600 [11:31<355:43:30, 19.63s/it]09/08/2023 21:34:22 - INFO - __main__ -   Step: 1358, LR: 1.3598698210038806e-05, Loss: 0.3430189788341522
[2023-09-08 21:34:42,962] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1359/66600 [11:52<362:27:50, 20.00s/it]09/08/2023 21:34:42 - INFO - __main__ -   Step: 1359, LR: 1.3608711978971086e-05, Loss: 0.4022406041622162
[2023-09-08 21:35:03,697] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1360/66600 [12:13<366:21:03, 20.22s/it]09/08/2023 21:35:03 - INFO - __main__ -   Step: 1360, LR: 1.3618725747903367e-05, Loss: 0.3388979136943817
09/08/2023 21:35:03 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0020482540130615234

Evaluating:   0%|          | 1/228 [00:00<01:46,  2.14it/s][Astep: 1
extend+tolist() time: 0.0009760856628417969

Evaluating:   1%|          | 2/228 [00:00<01:38,  2.29it/s][Astep: 2
extend+tolist() time: 0.0020666122436523438

Evaluating:   1%|▏         | 3/228 [00:01<01:34,  2.38it/s][Astep: 3
extend+tolist() time: 0.0018391609191894531

Evaluating:   2%|▏         | 4/228 [00:01<01:33,  2.39it/s][Astep: 4
extend+tolist() time: 0.0014123916625976562

Evaluating:   2%|▏         | 5/228 [00:02<01:32,  2.41it/s][Astep: 5
extend+tolist() time: 0.0018105506896972656

Evaluating:   3%|▎         | 6/228 [00:02<01:31,  2.44it/s][Astep: 6
extend+tolist() time: 0.0018608570098876953

Evaluating:   3%|▎         | 7/228 [00:02<01:35,  2.30it/s][Astep: 7
extend+tolist() time: 0.0009570121765136719

Evaluating:   4%|▎         | 8/228 [00:03<01:32,  2.38it/s][Astep: 8
extend+tolist() time: 0.0012004375457763672

Evaluating:   4%|▍         | 9/228 [00:03<01:30,  2.43it/s][Astep: 9
extend+tolist() time: 0.0008015632629394531

Evaluating:   4%|▍         | 10/228 [00:04<01:30,  2.40it/s][Astep: 10
extend+tolist() time: 0.001291513442993164

Evaluating:   5%|▍         | 11/228 [00:04<01:29,  2.43it/s][Astep: 11
extend+tolist() time: 0.0005638599395751953

Evaluating:   5%|▌         | 12/228 [00:05<01:30,  2.38it/s][Astep: 12
extend+tolist() time: 0.0010807514190673828

Evaluating:   6%|▌         | 13/228 [00:05<01:28,  2.44it/s][Astep: 13
extend+tolist() time: 0.0008189678192138672

Evaluating:   6%|▌         | 14/228 [00:05<01:28,  2.41it/s][Astep: 14
extend+tolist() time: 0.0005481243133544922

Evaluating:   7%|▋         | 15/228 [00:06<01:27,  2.44it/s][Astep: 15
extend+tolist() time: 0.0010466575622558594

Evaluating:   7%|▋         | 16/228 [00:06<01:25,  2.48it/s][Astep: 16
extend+tolist() time: 0.0006251335144042969

Evaluating:   7%|▋         | 17/228 [00:07<01:27,  2.41it/s][Astep: 17
extend+tolist() time: 0.0013256072998046875

Evaluating:   8%|▊         | 18/228 [00:07<01:25,  2.45it/s][Astep: 18
extend+tolist() time: 0.0013713836669921875

Evaluating:   8%|▊         | 19/228 [00:07<01:27,  2.40it/s][Astep: 19
extend+tolist() time: 0.0014867782592773438

Evaluating:   9%|▉         | 20/228 [00:08<01:25,  2.43it/s][Astep: 20
extend+tolist() time: 0.0007598400115966797

Evaluating:   9%|▉         | 21/228 [00:08<01:24,  2.46it/s][Astep: 21
extend+tolist() time: 0.0011026859283447266

Evaluating:  10%|▉         | 22/228 [00:09<01:25,  2.42it/s][Astep: 22
extend+tolist() time: 0.0007653236389160156

Evaluating:  10%|█         | 23/228 [00:09<01:23,  2.46it/s][Astep: 23
extend+tolist() time: 0.001161813735961914

Evaluating:  11%|█         | 24/228 [00:09<01:25,  2.39it/s][Astep: 24
extend+tolist() time: 0.0011096000671386719

Evaluating:  11%|█         | 25/228 [00:10<01:23,  2.42it/s][Astep: 25
extend+tolist() time: 0.14683890342712402

Evaluating:  11%|█▏        | 26/228 [00:11<01:46,  1.89it/s][Astep: 26
extend+tolist() time: 0.0007421970367431641

Evaluating:  12%|█▏        | 27/228 [00:11<01:38,  2.04it/s][Astep: 27
extend+tolist() time: 0.001692056655883789

Evaluating:  12%|█▏        | 28/228 [00:12<01:45,  1.89it/s][Astep: 28
extend+tolist() time: 0.000331878662109375

Evaluating:  13%|█▎        | 29/228 [00:12<01:36,  2.05it/s][Astep: 29
extend+tolist() time: 0.0010836124420166016

Evaluating:  13%|█▎        | 30/228 [00:13<01:33,  2.11it/s][Astep: 30
extend+tolist() time: 0.0010864734649658203

Evaluating:  14%|█▎        | 31/228 [00:13<01:28,  2.22it/s][Astep: 31
extend+tolist() time: 0.0009484291076660156

Evaluating:  14%|█▍        | 32/228 [00:13<01:25,  2.30it/s][Astep: 32
extend+tolist() time: 0.0010221004486083984

Evaluating:  14%|█▍        | 33/228 [00:14<01:24,  2.30it/s][Astep: 33
extend+tolist() time: 0.0017282962799072266

Evaluating:  15%|█▍        | 34/228 [00:14<01:22,  2.35it/s][Astep: 34
extend+tolist() time: 0.0012784004211425781

Evaluating:  15%|█▌        | 35/228 [00:15<01:23,  2.32it/s][Astep: 35
extend+tolist() time: 0.0006678104400634766

Evaluating:  16%|█▌        | 36/228 [00:15<01:20,  2.40it/s][Astep: 36
extend+tolist() time: 0.0011792182922363281

Evaluating:  16%|█▌        | 37/228 [00:15<01:18,  2.43it/s][Astep: 37
extend+tolist() time: 0.0016279220581054688

Evaluating:  17%|█▋        | 38/228 [00:16<01:20,  2.36it/s][Astep: 38
extend+tolist() time: 0.0007522106170654297

Evaluating:  17%|█▋        | 39/228 [00:16<01:18,  2.42it/s][Astep: 39
extend+tolist() time: 0.0007243156433105469

Evaluating:  18%|█▊        | 40/228 [00:17<01:18,  2.39it/s][Astep: 40
extend+tolist() time: 0.001119852066040039

Evaluating:  18%|█▊        | 41/228 [00:17<01:16,  2.45it/s][Astep: 41
extend+tolist() time: 0.0009076595306396484

Evaluating:  18%|█▊        | 42/228 [00:17<01:15,  2.45it/s][Astep: 42
extend+tolist() time: 0.0017542839050292969

Evaluating:  19%|█▉        | 43/228 [00:18<01:17,  2.39it/s][Astep: 43
extend+tolist() time: 0.0018444061279296875

Evaluating:  19%|█▉        | 44/228 [00:18<01:16,  2.41it/s][Astep: 44
extend+tolist() time: 0.0011448860168457031

Evaluating:  20%|█▉        | 45/228 [00:19<01:17,  2.37it/s][Astep: 45
extend+tolist() time: 0.001260519027709961

Evaluating:  20%|██        | 46/228 [00:19<01:15,  2.40it/s][Astep: 46
extend+tolist() time: 0.0016922950744628906

Evaluating:  21%|██        | 47/228 [00:20<01:15,  2.41it/s][Astep: 47
extend+tolist() time: 0.0015282630920410156

Evaluating:  21%|██        | 48/228 [00:20<01:16,  2.35it/s][Astep: 48
extend+tolist() time: 0.001542806625366211

Evaluating:  21%|██▏       | 49/228 [00:20<01:15,  2.38it/s][Astep: 49
extend+tolist() time: 0.0009069442749023438

Evaluating:  22%|██▏       | 50/228 [00:21<01:15,  2.36it/s][Astep: 50
extend+tolist() time: 0.0016105175018310547

Evaluating:  22%|██▏       | 51/228 [00:21<01:13,  2.40it/s][Astep: 51
extend+tolist() time: 0.0015773773193359375

Evaluating:  23%|██▎       | 52/228 [00:22<01:15,  2.34it/s][Astep: 52
extend+tolist() time: 0.0013632774353027344

Evaluating:  23%|██▎       | 53/228 [00:22<01:13,  2.37it/s][Astep: 53
extend+tolist() time: 0.0016627311706542969

Evaluating:  24%|██▎       | 54/228 [00:23<01:13,  2.38it/s][Astep: 54
extend+tolist() time: 0.0008189678192138672

Evaluating:  24%|██▍       | 55/228 [00:23<01:13,  2.36it/s][Astep: 55
extend+tolist() time: 0.001207590103149414

Evaluating:  25%|██▍       | 56/228 [00:24<01:21,  2.12it/s][Astep: 56
extend+tolist() time: 0.19449996948242188

Evaluating:  25%|██▌       | 57/228 [00:24<01:29,  1.91it/s][Astep: 57
extend+tolist() time: 0.0010709762573242188

Evaluating:  25%|██▌       | 58/228 [00:25<01:22,  2.05it/s][Astep: 58
extend+tolist() time: 0.0008440017700195312

Evaluating:  26%|██▌       | 59/228 [00:25<01:28,  1.91it/s][Astep: 59
extend+tolist() time: 0.0009219646453857422

Evaluating:  26%|██▋       | 60/228 [00:26<01:22,  2.05it/s][Astep: 60
extend+tolist() time: 0.0011191368103027344

Evaluating:  27%|██▋       | 61/228 [00:26<01:18,  2.12it/s][Astep: 61
extend+tolist() time: 0.0008358955383300781

Evaluating:  27%|██▋       | 62/228 [00:26<01:14,  2.23it/s][Astep: 62
extend+tolist() time: 0.0011982917785644531

Evaluating:  28%|██▊       | 63/228 [00:27<01:14,  2.22it/s][Astep: 63
extend+tolist() time: 0.0008127689361572266

Evaluating:  28%|██▊       | 64/228 [00:27<01:11,  2.31it/s][Astep: 64
extend+tolist() time: 0.0014717578887939453

Evaluating:  29%|██▊       | 65/228 [00:28<01:10,  2.30it/s][Astep: 65
extend+tolist() time: 0.0008134841918945312

Evaluating:  29%|██▉       | 66/228 [00:28<01:09,  2.34it/s][Astep: 66
extend+tolist() time: 0.0011701583862304688

Evaluating:  29%|██▉       | 67/228 [00:29<01:07,  2.40it/s][Astep: 67
extend+tolist() time: 0.0009212493896484375

Evaluating:  30%|██▉       | 68/228 [00:29<01:08,  2.33it/s][Astep: 68
extend+tolist() time: 0.0011060237884521484

Evaluating:  30%|███       | 69/228 [00:29<01:06,  2.39it/s][Astep: 69
extend+tolist() time: 0.0014600753784179688

Evaluating:  31%|███       | 70/228 [00:30<01:08,  2.32it/s][Astep: 70
extend+tolist() time: 0.0010728836059570312

Evaluating:  31%|███       | 71/228 [00:30<01:06,  2.37it/s][Astep: 71
extend+tolist() time: 0.0014388561248779297

Evaluating:  32%|███▏      | 72/228 [00:31<01:05,  2.38it/s][Astep: 72
extend+tolist() time: 0.0007789134979248047

Evaluating:  32%|███▏      | 73/228 [00:31<01:05,  2.36it/s][Astep: 73
extend+tolist() time: 0.0009322166442871094

Evaluating:  32%|███▏      | 74/228 [00:31<01:03,  2.42it/s][Astep: 74
extend+tolist() time: 0.0007207393646240234

Evaluating:  33%|███▎      | 75/228 [00:32<01:05,  2.35it/s][Astep: 75
extend+tolist() time: 0.0017397403717041016

Evaluating:  33%|███▎      | 76/228 [00:32<01:04,  2.35it/s][Astep: 76
extend+tolist() time: 0.0006444454193115234

Evaluating:  34%|███▍      | 77/228 [00:33<01:03,  2.38it/s][Astep: 77
extend+tolist() time: 0.001882791519165039

Evaluating:  34%|███▍      | 78/228 [00:33<01:04,  2.32it/s][Astep: 78
extend+tolist() time: 0.0011951923370361328

Evaluating:  35%|███▍      | 79/228 [00:34<01:02,  2.37it/s][Astep: 79
extend+tolist() time: 0.0008678436279296875

Evaluating:  35%|███▌      | 80/228 [00:34<01:03,  2.32it/s][Astep: 80
extend+tolist() time: 0.0009343624114990234

Evaluating:  36%|███▌      | 81/228 [00:34<01:01,  2.38it/s][Astep: 81
extend+tolist() time: 0.001268148422241211

Evaluating:  36%|███▌      | 82/228 [00:35<01:02,  2.32it/s][Astep: 82
extend+tolist() time: 0.0008232593536376953

Evaluating:  36%|███▋      | 83/228 [00:35<01:00,  2.40it/s][Astep: 83
extend+tolist() time: 0.0011434555053710938

Evaluating:  37%|███▋      | 84/228 [00:36<00:59,  2.42it/s][Astep: 84
extend+tolist() time: 0.0009751319885253906

Evaluating:  37%|███▋      | 85/228 [00:36<01:00,  2.38it/s][Astep: 85
extend+tolist() time: 0.0013170242309570312

Evaluating:  38%|███▊      | 86/228 [00:37<00:58,  2.42it/s][Astep: 86
extend+tolist() time: 0.0008831024169921875

Evaluating:  38%|███▊      | 87/228 [00:37<01:00,  2.35it/s][Astep: 87
extend+tolist() time: 0.001344442367553711

Evaluating:  39%|███▊      | 88/228 [00:37<00:58,  2.41it/s][Astep: 88
extend+tolist() time: 0.0007412433624267578

Evaluating:  39%|███▉      | 89/228 [00:38<00:57,  2.42it/s][Astep: 89
extend+tolist() time: 0.0011627674102783203

Evaluating:  39%|███▉      | 90/228 [00:38<00:57,  2.38it/s][Astep: 90
extend+tolist() time: 0.0012753009796142578

Evaluating:  40%|███▉      | 91/228 [00:39<00:56,  2.42it/s][Astep: 91
extend+tolist() time: 0.0007596015930175781

Evaluating:  40%|████      | 92/228 [00:39<00:57,  2.35it/s][Astep: 92
extend+tolist() time: 0.0012254714965820312

Evaluating:  41%|████      | 93/228 [00:39<00:56,  2.41it/s][Astep: 93
extend+tolist() time: 0.0009639263153076172

Evaluating:  41%|████      | 94/228 [00:40<00:56,  2.38it/s][Astep: 94
extend+tolist() time: 0.0011622905731201172

Evaluating:  42%|████▏     | 95/228 [00:40<00:56,  2.37it/s][Astep: 95
extend+tolist() time: 0.001138448715209961

Evaluating:  42%|████▏     | 96/228 [00:41<00:55,  2.36it/s][Astep: 96
extend+tolist() time: 0.0014061927795410156

Evaluating:  43%|████▎     | 97/228 [00:41<00:56,  2.32it/s][Astep: 97
extend+tolist() time: 0.0008018016815185547

Evaluating:  43%|████▎     | 98/228 [00:42<00:54,  2.37it/s][Astep: 98
extend+tolist() time: 0.0013241767883300781

Evaluating:  43%|████▎     | 99/228 [00:42<00:55,  2.31it/s][Astep: 99
extend+tolist() time: 0.17799830436706543

Evaluating:  44%|████▍     | 100/228 [00:43<01:10,  1.82it/s][Astep: 100
extend+tolist() time: 0.0007379055023193359

Evaluating:  44%|████▍     | 101/228 [00:43<01:04,  1.96it/s][Astep: 101
extend+tolist() time: 0.0012519359588623047

Evaluating:  45%|████▍     | 102/228 [00:44<00:59,  2.10it/s][Astep: 102
extend+tolist() time: 0.0007448196411132812

Evaluating:  45%|████▌     | 103/228 [00:44<00:58,  2.14it/s][Astep: 103
extend+tolist() time: 0.0011839866638183594

Evaluating:  46%|████▌     | 104/228 [00:45<01:03,  1.96it/s][Astep: 104
extend+tolist() time: 0.0006694793701171875

Evaluating:  46%|████▌     | 105/228 [00:45<01:00,  2.05it/s][Astep: 105
extend+tolist() time: 0.001232147216796875

Evaluating:  46%|████▋     | 106/228 [00:46<00:56,  2.18it/s][Astep: 106
extend+tolist() time: 0.002118349075317383

Evaluating:  47%|████▋     | 107/228 [00:46<00:54,  2.23it/s][Astep: 107
extend+tolist() time: 0.0008907318115234375

Evaluating:  47%|████▋     | 108/228 [00:46<00:52,  2.29it/s][Astep: 108
extend+tolist() time: 0.0013568401336669922

Evaluating:  48%|████▊     | 109/228 [00:47<00:50,  2.36it/s][Astep: 109
extend+tolist() time: 0.000993967056274414

Evaluating:  48%|████▊     | 110/228 [00:47<00:51,  2.30it/s][Astep: 110
extend+tolist() time: 0.0011663436889648438

Evaluating:  49%|████▊     | 111/228 [00:48<00:49,  2.37it/s][Astep: 111
extend+tolist() time: 0.0020020008087158203

Evaluating:  49%|████▉     | 112/228 [00:48<00:50,  2.29it/s][Astep: 112
extend+tolist() time: 0.00044989585876464844

Evaluating:  50%|████▉     | 113/228 [00:49<00:48,  2.38it/s][Astep: 113
extend+tolist() time: 0.0008037090301513672

Evaluating:  50%|█████     | 114/228 [00:49<00:47,  2.40it/s][Astep: 114
extend+tolist() time: 0.0017490386962890625

Evaluating:  50%|█████     | 115/228 [00:49<00:48,  2.35it/s][Astep: 115
extend+tolist() time: 0.0007748603820800781

Evaluating:  51%|█████     | 116/228 [00:50<00:46,  2.43it/s][Astep: 116
extend+tolist() time: 0.001361846923828125

Evaluating:  51%|█████▏    | 117/228 [00:50<00:46,  2.37it/s][Astep: 117
extend+tolist() time: 0.0013375282287597656

Evaluating:  52%|█████▏    | 118/228 [00:51<00:45,  2.44it/s][Astep: 118
extend+tolist() time: 0.0006387233734130859

Evaluating:  52%|█████▏    | 119/228 [00:51<00:44,  2.47it/s][Astep: 119
extend+tolist() time: 0.0008161067962646484

Evaluating:  53%|█████▎    | 120/228 [00:51<00:44,  2.43it/s][Astep: 120
extend+tolist() time: 0.0011944770812988281

Evaluating:  53%|█████▎    | 121/228 [00:52<00:42,  2.49it/s][Astep: 121
extend+tolist() time: 0.0007417201995849609

Evaluating:  54%|█████▎    | 122/228 [00:52<00:43,  2.42it/s][Astep: 122
extend+tolist() time: 0.001191854476928711

Evaluating:  54%|█████▍    | 123/228 [00:53<00:42,  2.48it/s][Astep: 123
extend+tolist() time: 0.0007174015045166016

Evaluating:  54%|█████▍    | 124/228 [00:53<00:41,  2.49it/s][Astep: 124
extend+tolist() time: 0.000946044921875

Evaluating:  55%|█████▍    | 125/228 [00:53<00:42,  2.43it/s][Astep: 125
extend+tolist() time: 0.0009799003601074219

Evaluating:  55%|█████▌    | 126/228 [00:54<00:40,  2.49it/s][Astep: 126
extend+tolist() time: 0.0015377998352050781

Evaluating:  56%|█████▌    | 127/228 [00:54<00:42,  2.38it/s][Astep: 127
extend+tolist() time: 0.0015180110931396484

Evaluating:  56%|█████▌    | 128/228 [00:55<00:41,  2.40it/s][Astep: 128
extend+tolist() time: 0.001302957534790039

Evaluating:  57%|█████▋    | 129/228 [00:55<00:41,  2.41it/s][Astep: 129
extend+tolist() time: 0.0008816719055175781

Evaluating:  57%|█████▋    | 130/228 [00:56<00:41,  2.39it/s][Astep: 130
extend+tolist() time: 0.001497507095336914

Evaluating:  57%|█████▋    | 131/228 [00:56<00:40,  2.42it/s][Astep: 131
extend+tolist() time: 0.000518798828125

Evaluating:  58%|█████▊    | 132/228 [00:56<00:40,  2.39it/s][Astep: 132
extend+tolist() time: 0.002086639404296875

Evaluating:  58%|█████▊    | 133/228 [00:57<00:39,  2.43it/s][Astep: 133
extend+tolist() time: 0.0005059242248535156

Evaluating:  59%|█████▉    | 134/228 [00:57<00:38,  2.47it/s][Astep: 134
extend+tolist() time: 0.0014920234680175781

Evaluating:  59%|█████▉    | 135/228 [00:58<00:38,  2.43it/s][Astep: 135
extend+tolist() time: 0.0005307197570800781

Evaluating:  60%|█████▉    | 136/228 [00:58<00:37,  2.48it/s][Astep: 136
extend+tolist() time: 0.0009779930114746094

Evaluating:  60%|██████    | 137/228 [00:58<00:38,  2.39it/s][Astep: 137
extend+tolist() time: 0.0004303455352783203

Evaluating:  61%|██████    | 138/228 [00:59<00:36,  2.45it/s][Astep: 138
extend+tolist() time: 0.0008261203765869141

Evaluating:  61%|██████    | 139/228 [00:59<00:36,  2.47it/s][Astep: 139
extend+tolist() time: 0.0005021095275878906

Evaluating:  61%|██████▏   | 140/228 [01:00<00:36,  2.43it/s][Astep: 140
extend+tolist() time: 0.0013456344604492188

Evaluating:  62%|██████▏   | 141/228 [01:00<00:35,  2.48it/s][Astep: 141
extend+tolist() time: 0.0008761882781982422

Evaluating:  62%|██████▏   | 142/228 [01:00<00:35,  2.40it/s][Astep: 142
extend+tolist() time: 0.0010914802551269531

Evaluating:  63%|██████▎   | 143/228 [01:01<00:34,  2.46it/s][Astep: 143
extend+tolist() time: 0.0003886222839355469

Evaluating:  63%|██████▎   | 144/228 [01:01<00:33,  2.49it/s][Astep: 144
extend+tolist() time: 0.0008249282836914062

Evaluating:  64%|██████▎   | 145/228 [01:02<00:33,  2.45it/s][Astep: 145
extend+tolist() time: 0.0009844303131103516

Evaluating:  64%|██████▍   | 146/228 [01:02<00:32,  2.50it/s][Astep: 146
extend+tolist() time: 0.0004343986511230469

Evaluating:  64%|██████▍   | 147/228 [01:02<00:33,  2.43it/s][Astep: 147
extend+tolist() time: 0.0008323192596435547

Evaluating:  65%|██████▍   | 148/228 [01:03<00:32,  2.48it/s][Astep: 148
extend+tolist() time: 0.0011992454528808594

Evaluating:  65%|██████▌   | 149/228 [01:03<00:31,  2.49it/s][Astep: 149
extend+tolist() time: 0.0004150867462158203

Evaluating:  66%|██████▌   | 150/228 [01:04<00:31,  2.45it/s][Astep: 150
extend+tolist() time: 0.0009441375732421875

Evaluating:  66%|██████▌   | 151/228 [01:04<00:30,  2.49it/s][Astep: 151
extend+tolist() time: 0.0011782646179199219

Evaluating:  67%|██████▋   | 152/228 [01:04<00:31,  2.41it/s][Astep: 152
extend+tolist() time: 0.0009226799011230469

Evaluating:  67%|██████▋   | 153/228 [01:05<00:30,  2.46it/s][Astep: 153
extend+tolist() time: 0.0014386177062988281

Evaluating:  68%|██████▊   | 154/228 [01:05<00:30,  2.46it/s][Astep: 154
extend+tolist() time: 0.002092599868774414

Evaluating:  68%|██████▊   | 155/228 [01:06<00:30,  2.38it/s][Astep: 155
extend+tolist() time: 0.0007150173187255859

Evaluating:  68%|██████▊   | 156/228 [01:06<00:29,  2.43it/s][Astep: 156
extend+tolist() time: 0.0005731582641601562

Evaluating:  69%|██████▉   | 157/228 [01:07<00:29,  2.38it/s][Astep: 157
extend+tolist() time: 0.0012102127075195312

Evaluating:  69%|██████▉   | 158/228 [01:07<00:28,  2.43it/s][Astep: 158
extend+tolist() time: 0.0005311965942382812

Evaluating:  70%|██████▉   | 159/228 [01:07<00:29,  2.37it/s][Astep: 159
extend+tolist() time: 0.0007410049438476562

Evaluating:  70%|███████   | 160/228 [01:08<00:28,  2.42it/s][Astep: 160
extend+tolist() time: 0.0004260540008544922

Evaluating:  71%|███████   | 161/228 [01:08<00:27,  2.41it/s][Astep: 161
extend+tolist() time: 0.0008423328399658203

Evaluating:  71%|███████   | 162/228 [01:09<00:28,  2.35it/s][Astep: 162
extend+tolist() time: 0.0005292892456054688

Evaluating:  71%|███████▏  | 163/228 [01:09<00:27,  2.40it/s][Astep: 163
extend+tolist() time: 0.00042176246643066406

Evaluating:  72%|███████▏  | 164/228 [01:10<00:27,  2.34it/s][Astep: 164
extend+tolist() time: 0.0011181831359863281

Evaluating:  72%|███████▏  | 165/228 [01:10<00:26,  2.40it/s][Astep: 165
extend+tolist() time: 0.0004687309265136719

Evaluating:  73%|███████▎  | 166/228 [01:10<00:25,  2.44it/s][Astep: 166
extend+tolist() time: 0.0004069805145263672

Evaluating:  73%|███████▎  | 167/228 [01:11<00:25,  2.40it/s][Astep: 167
extend+tolist() time: 0.0005896091461181641

Evaluating:  74%|███████▎  | 168/228 [01:11<00:24,  2.44it/s][Astep: 168
extend+tolist() time: 0.0016908645629882812

Evaluating:  74%|███████▍  | 169/228 [01:12<00:25,  2.34it/s][Astep: 169
extend+tolist() time: 0.0003769397735595703

Evaluating:  75%|███████▍  | 170/228 [01:12<00:28,  2.01it/s][Astep: 170
extend+tolist() time: 0.2719426155090332

Evaluating:  75%|███████▌  | 171/228 [01:13<00:32,  1.78it/s][Astep: 171
extend+tolist() time: 0.00031495094299316406

Evaluating:  75%|███████▌  | 172/228 [01:13<00:28,  1.94it/s][Astep: 172
extend+tolist() time: 0.0012423992156982422

Evaluating:  76%|███████▌  | 173/228 [01:14<00:27,  2.03it/s][Astep: 173
extend+tolist() time: 0.0011570453643798828

Evaluating:  76%|███████▋  | 174/228 [01:14<00:25,  2.13it/s][Astep: 174
extend+tolist() time: 0.0019497871398925781

Evaluating:  77%|███████▋  | 175/228 [01:15<00:28,  1.84it/s][Astep: 175
extend+tolist() time: 0.001172780990600586

Evaluating:  77%|███████▋  | 176/228 [01:15<00:26,  1.97it/s][Astep: 176
extend+tolist() time: 0.0006496906280517578

Evaluating:  78%|███████▊  | 177/228 [01:16<00:24,  2.06it/s][Astep: 177
extend+tolist() time: 0.0006029605865478516

Evaluating:  78%|███████▊  | 178/228 [01:16<00:22,  2.20it/s][Astep: 178
extend+tolist() time: 0.0017049312591552734

Evaluating:  79%|███████▊  | 179/228 [01:17<00:22,  2.19it/s][Astep: 179
extend+tolist() time: 0.0004184246063232422

Evaluating:  79%|███████▉  | 180/228 [01:17<00:20,  2.30it/s][Astep: 180
extend+tolist() time: 0.0003917217254638672

Evaluating:  79%|███████▉  | 181/228 [01:17<00:19,  2.37it/s][Astep: 181
extend+tolist() time: 0.0010285377502441406

Evaluating:  80%|███████▉  | 182/228 [01:18<00:19,  2.35it/s][Astep: 182
extend+tolist() time: 0.0007839202880859375

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.41it/s][Astep: 183
extend+tolist() time: 0.0006611347198486328

Evaluating:  81%|████████  | 184/228 [01:19<00:18,  2.35it/s][Astep: 184
extend+tolist() time: 0.0004467964172363281

Evaluating:  81%|████████  | 185/228 [01:19<00:17,  2.42it/s][Astep: 185
extend+tolist() time: 0.0010941028594970703

Evaluating:  82%|████████▏ | 186/228 [01:19<00:17,  2.42it/s][Astep: 186
extend+tolist() time: 0.0015270709991455078

Evaluating:  82%|████████▏ | 187/228 [01:20<00:17,  2.36it/s][Astep: 187
extend+tolist() time: 0.00043463706970214844

Evaluating:  82%|████████▏ | 188/228 [01:20<00:16,  2.42it/s][Astep: 188
extend+tolist() time: 0.0010914802551269531

Evaluating:  83%|████████▎ | 189/228 [01:21<00:16,  2.36it/s][Astep: 189
extend+tolist() time: 0.0003662109375

Evaluating:  83%|████████▎ | 190/228 [01:21<00:15,  2.42it/s][Astep: 190
extend+tolist() time: 0.0011937618255615234

Evaluating:  84%|████████▍ | 191/228 [01:22<00:15,  2.39it/s][Astep: 191
extend+tolist() time: 0.0011925697326660156

Evaluating:  84%|████████▍ | 192/228 [01:22<00:14,  2.41it/s][Astep: 192
extend+tolist() time: 0.0004410743713378906

Evaluating:  85%|████████▍ | 193/228 [01:22<00:14,  2.47it/s][Astep: 193
extend+tolist() time: 0.0014529228210449219

Evaluating:  85%|████████▌ | 194/228 [01:23<00:14,  2.37it/s][Astep: 194
extend+tolist() time: 0.0006296634674072266

Evaluating:  86%|████████▌ | 195/228 [01:23<00:13,  2.42it/s][Astep: 195
extend+tolist() time: 0.0005488395690917969

Evaluating:  86%|████████▌ | 196/228 [01:24<00:13,  2.35it/s][Astep: 196
extend+tolist() time: 0.0006124973297119141

Evaluating:  86%|████████▋ | 197/228 [01:24<00:12,  2.41it/s][Astep: 197
extend+tolist() time: 0.0011086463928222656

Evaluating:  87%|████████▋ | 198/228 [01:24<00:12,  2.43it/s][Astep: 198
extend+tolist() time: 0.000598907470703125

Evaluating:  87%|████████▋ | 199/228 [01:25<00:12,  2.39it/s][Astep: 199
extend+tolist() time: 0.001958608627319336

Evaluating:  88%|████████▊ | 200/228 [01:25<00:11,  2.41it/s][Astep: 200
extend+tolist() time: 0.0007460117340087891

Evaluating:  88%|████████▊ | 201/228 [01:26<00:11,  2.34it/s][Astep: 201
extend+tolist() time: 0.0010273456573486328

Evaluating:  89%|████████▊ | 202/228 [01:26<00:10,  2.40it/s][Astep: 202
extend+tolist() time: 0.00039887428283691406

Evaluating:  89%|████████▉ | 203/228 [01:27<00:10,  2.41it/s][Astep: 203
extend+tolist() time: 0.0005004405975341797

Evaluating:  89%|████████▉ | 204/228 [01:27<00:10,  2.38it/s][Astep: 204
extend+tolist() time: 0.0004074573516845703

Evaluating:  90%|████████▉ | 205/228 [01:27<00:09,  2.44it/s][Astep: 205
extend+tolist() time: 0.000324249267578125

Evaluating:  90%|█████████ | 206/228 [01:28<00:09,  2.38it/s][Astep: 206
extend+tolist() time: 0.001058340072631836

Evaluating:  91%|█████████ | 207/228 [01:28<00:08,  2.44it/s][Astep: 207
extend+tolist() time: 0.0006051063537597656

Evaluating:  91%|█████████ | 208/228 [01:29<00:08,  2.45it/s][Astep: 208
extend+tolist() time: 0.0006804466247558594

Evaluating:  92%|█████████▏| 209/228 [01:29<00:07,  2.40it/s][Astep: 209
extend+tolist() time: 0.0010378360748291016

Evaluating:  92%|█████████▏| 210/228 [01:29<00:07,  2.46it/s][Astep: 210
extend+tolist() time: 0.0006208419799804688

Evaluating:  93%|█████████▎| 211/228 [01:30<00:07,  2.39it/s][Astep: 211
extend+tolist() time: 0.0014688968658447266

Evaluating:  93%|█████████▎| 212/228 [01:30<00:06,  2.42it/s][Astep: 212
extend+tolist() time: 0.0011467933654785156

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.39it/s][Astep: 213
extend+tolist() time: 0.0011219978332519531

Evaluating:  94%|█████████▍| 214/228 [01:31<00:05,  2.42it/s][Astep: 214
extend+tolist() time: 0.0008177757263183594

Evaluating:  94%|█████████▍| 215/228 [01:32<00:05,  2.47it/s][Astep: 215
extend+tolist() time: 0.0006527900695800781

Evaluating:  95%|█████████▍| 216/228 [01:32<00:04,  2.41it/s][Astep: 216
extend+tolist() time: 0.0005578994750976562

Evaluating:  95%|█████████▌| 217/228 [01:32<00:04,  2.46it/s][Astep: 217
extend+tolist() time: 0.0008122920989990234

Evaluating:  96%|█████████▌| 218/228 [01:33<00:04,  2.43it/s][Astep: 218
extend+tolist() time: 0.0014472007751464844

Evaluating:  96%|█████████▌| 219/228 [01:33<00:03,  2.43it/s][Astep: 219
extend+tolist() time: 0.0004820823669433594

Evaluating:  96%|█████████▋| 220/228 [01:34<00:03,  2.48it/s][Astep: 220
extend+tolist() time: 0.00040912628173828125

Evaluating:  97%|█████████▋| 221/228 [01:34<00:02,  2.41it/s][Astep: 221
extend+tolist() time: 0.0006489753723144531

Evaluating:  97%|█████████▋| 222/228 [01:34<00:02,  2.45it/s][Astep: 222
extend+tolist() time: 0.0004398822784423828

Evaluating:  98%|█████████▊| 223/228 [01:35<00:02,  2.41it/s][Astep: 223
extend+tolist() time: 0.0004105567932128906

Evaluating:  98%|█████████▊| 224/228 [01:35<00:01,  2.42it/s][Astep: 224
extend+tolist() time: 0.0003707408905029297

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.47it/s][Astep: 225
extend+tolist() time: 0.0004267692565917969

Evaluating:  99%|█████████▉| 226/228 [01:36<00:00,  2.41it/s][Astep: 226
extend+tolist() time: 0.0010387897491455078

Evaluating: 100%|█████████▉| 227/228 [01:36<00:00,  2.46it/s][Astep: 227
extend+tolist() time: 0.0004811286926269531

Evaluating: 100%|██████████| 228/228 [01:37<00:00,  2.38it/s][A09/08/2023 21:36:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 21:36:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:36:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:36:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:36:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:36:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:36:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:36:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:36:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:36:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:36:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:36:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:36:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:36:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:36:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:36:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:36:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:39<00:00,  2.30it/s]
09/08/2023 21:36:42 - INFO - __main__ -   Step: 1360, Validation Metrics: {'pred_1_num': 9595, 'pred_-1_num': 1169, 'pred_0_num': 37, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7872419220442551, 'f1_micro': 0.7872419220442551, 'f1_macro': 0.43115812889878685, 'f1_weighted': 0.7547367884842161, 'f1_-1': 0.3751371115173674, 'f1_0': 0.04142011834319526, 'f1_1': 0.876917156835798, 'precision_micro': 0.7872419220442551, 'precision_macro': 0.5494937584636249, 'precision_weighted': 0.7475758634111075, 'precision_-1': 0.4388366124893071, 'precision_0': 0.3783783783783784, 'precision_1': 0.8312662845231892, 'recall_micro': 0.7872419220442551, 'recall_macro': 0.42578962319182817, 'recall_weighted': 0.7872419220442551, 'recall_-1': 0.3275862068965517, 'recall_0': 0.02190923317683881, 'recall_1': 0.927873429502094, 'roc_auc_micro': 0.9242197460499448, 'roc_auc_macro': 0.7753135062663589, 'roc_auc_weighted': 0.7734311075792014, 'roc_auc_-1': 0.8372912893850857, 'roc_auc_0': 0.7231114166465697, 'roc_auc_1': 0.7655378127674212}
09/08/2023 21:36:56 - INFO - __main__ - Saving state to /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674
09/08/2023 21:36:56 - INFO - accelerate.accelerator - Saving current state to /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674
09/08/2023 21:36:56 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2023-09-08 21:36:56,849] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2023-09-08 21:36:56,857] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt...
[2023-09-08 21:36:56,857] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt...
[2023-09-08 21:36:56,857] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt
[2023-09-08 21:36:56,857] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt...
[2023-09-08 21:36:56,858] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt
[2023-09-08 21:36:56,859] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-09-08 21:36:56,872] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt.
[2023-09-08 21:36:56,872] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt.
[2023-09-08 21:36:56,872] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt.
[2023-09-08 21:36:56,873] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-09-08 21:36:56,876] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2023-09-08 21:36:56,876] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-09-08 21:36:56,876] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[2023-09-08 21:36:56,876] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2023-09-08 21:37:42,205] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[2023-09-08 21:37:42,205] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt
[2023-09-08 21:37:44,037] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-09-08 21:37:44,037] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2023-09-08 21:37:47,342] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2023-09-08 21:37:47,343] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2023-09-08 21:37:50,524] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[2023-09-08 21:37:50,524] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt
[2023-09-08 21:37:50,572] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 21:37:50,572] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 21:37:50,572] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 21:37:50,572] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/08/2023 21:37:50 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/pytorch_model
09/08/2023 21:37:50 - INFO - accelerate.checkpointing - Scheduler state saved in /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/scheduler.bin
09/08/2023 21:37:50 - INFO - accelerate.checkpointing - Random states saved in /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1360-best-f1_-1=0.3751371115173674/random_states_0.pkl
[2023-09-08 21:38:11,039] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1361/66600 [15:20<1258:34:13, 69.45s/it]09/08/2023 21:38:11 - INFO - __main__ -   Step: 1361, LR: 1.3628739516835649e-05, Loss: 0.42175033688545227
[2023-09-08 21:38:31,935] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1362/66600 [15:41<997:55:54, 55.07s/it] 09/08/2023 21:38:31 - INFO - __main__ -   Step: 1362, LR: 1.3638753285767932e-05, Loss: 0.40452998876571655
[2023-09-08 21:38:52,508] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1363/66600 [16:02<812:03:26, 44.81s/it]09/08/2023 21:38:52 - INFO - __main__ -   Step: 1363, LR: 1.3648767054700214e-05, Loss: 0.3760565221309662
[2023-09-08 21:39:13,313] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1364/66600 [16:22<682:20:57, 37.65s/it]09/08/2023 21:39:13 - INFO - __main__ -   Step: 1364, LR: 1.3658780823632496e-05, Loss: 0.5031043291091919
[2023-09-08 21:39:34,020] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1365/66600 [16:43<590:36:42, 32.59s/it]09/08/2023 21:39:34 - INFO - __main__ -   Step: 1365, LR: 1.3668794592564777e-05, Loss: 0.38813555240631104
[2023-09-08 21:39:55,120] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1366/66600 [17:04<528:18:53, 29.16s/it]09/08/2023 21:39:55 - INFO - __main__ -   Step: 1366, LR: 1.367880836149706e-05, Loss: 0.3959367275238037
[2023-09-08 21:40:15,770] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1367/66600 [17:25<482:10:17, 26.61s/it]09/08/2023 21:40:15 - INFO - __main__ -   Step: 1367, LR: 1.3688822130429342e-05, Loss: 0.39428624510765076
[2023-09-08 21:40:36,343] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1368/66600 [17:45<449:23:49, 24.80s/it]09/08/2023 21:40:36 - INFO - __main__ -   Step: 1368, LR: 1.3698835899361624e-05, Loss: 0.38668763637542725
[2023-09-08 21:40:57,361] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1369/66600 [18:06<428:50:58, 23.67s/it]09/08/2023 21:40:57 - INFO - __main__ -   Step: 1369, LR: 1.3708849668293904e-05, Loss: 0.4403872787952423
[2023-09-08 21:41:18,497] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1370/66600 [18:28<415:05:22, 22.91s/it]09/08/2023 21:41:18 - INFO - __main__ -   Step: 1370, LR: 1.3718863437226187e-05, Loss: 0.3331902027130127
[2023-09-08 21:41:38,946] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1371/66600 [18:48<401:43:13, 22.17s/it]09/08/2023 21:41:38 - INFO - __main__ -   Step: 1371, LR: 1.3728877206158469e-05, Loss: 0.3962446451187134
[2023-09-08 21:41:59,933] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1372/66600 [19:09<395:17:00, 21.82s/it]09/08/2023 21:41:59 - INFO - __main__ -   Step: 1372, LR: 1.373889097509075e-05, Loss: 0.4139510691165924
[2023-09-08 21:42:21,103] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1373/66600 [19:30<391:45:59, 21.62s/it]09/08/2023 21:42:21 - INFO - __main__ -   Step: 1373, LR: 1.3748904744023033e-05, Loss: 0.37895750999450684
[2023-09-08 21:42:41,248] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1374/66600 [19:50<383:43:40, 21.18s/it]09/08/2023 21:42:41 - INFO - __main__ -   Step: 1374, LR: 1.3758918512955315e-05, Loss: 0.4045717120170593
[2023-09-08 21:43:02,121] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1375/66600 [20:11<382:03:48, 21.09s/it]09/08/2023 21:43:02 - INFO - __main__ -   Step: 1375, LR: 1.3768932281887597e-05, Loss: 0.4077798128128052
[2023-09-08 21:43:22,451] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1376/66600 [20:31<377:56:08, 20.86s/it]09/08/2023 21:43:22 - INFO - __main__ -   Step: 1376, LR: 1.377894605081988e-05, Loss: 0.33757832646369934
[2023-09-08 21:43:42,581] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1377/66600 [20:52<373:57:48, 20.64s/it]09/08/2023 21:43:42 - INFO - __main__ -   Step: 1377, LR: 1.3788959819752162e-05, Loss: 0.3761666417121887
[2023-09-08 21:44:03,547] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1378/66600 [21:13<375:43:47, 20.74s/it]09/08/2023 21:44:03 - INFO - __main__ -   Step: 1378, LR: 1.3798973588684441e-05, Loss: 0.3867141604423523
[2023-09-08 21:44:23,788] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1379/66600 [21:33<373:00:50, 20.59s/it]09/08/2023 21:44:23 - INFO - __main__ -   Step: 1379, LR: 1.3808987357616723e-05, Loss: 0.3963663876056671
[2023-09-08 21:44:43,743] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1380/66600 [21:53<369:33:39, 20.40s/it]09/08/2023 21:44:43 - INFO - __main__ -   Step: 1380, LR: 1.3819001126549005e-05, Loss: 0.31302881240844727
09/08/2023 21:44:43 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0024678707122802734

Evaluating:   0%|          | 1/228 [00:00<01:53,  1.99it/s][Astep: 1
extend+tolist() time: 0.0010466575622558594

Evaluating:   1%|          | 2/228 [00:00<01:45,  2.14it/s][Astep: 2
extend+tolist() time: 0.0021796226501464844

Evaluating:   1%|▏         | 3/228 [00:01<01:39,  2.27it/s][Astep: 3
extend+tolist() time: 0.0017910003662109375

Evaluating:   2%|▏         | 4/228 [00:01<01:36,  2.33it/s][Astep: 4
extend+tolist() time: 0.001382589340209961

Evaluating:   2%|▏         | 5/228 [00:02<01:36,  2.32it/s][Astep: 5
extend+tolist() time: 0.0014739036560058594

Evaluating:   3%|▎         | 6/228 [00:02<01:33,  2.37it/s][Astep: 6
extend+tolist() time: 0.0014185905456542969

Evaluating:   3%|▎         | 7/228 [00:03<01:46,  2.07it/s][Astep: 7
extend+tolist() time: 0.0014348030090332031

Evaluating:   4%|▎         | 8/228 [00:03<01:39,  2.21it/s][Astep: 8
extend+tolist() time: 0.001153707504272461

Evaluating:   4%|▍         | 9/228 [00:04<01:48,  2.01it/s][Astep: 9
extend+tolist() time: 0.0008232593536376953

Evaluating:   4%|▍         | 10/228 [00:04<01:40,  2.16it/s][Astep: 10
extend+tolist() time: 0.001340627670288086

Evaluating:   5%|▍         | 11/228 [00:05<01:39,  2.19it/s][Astep: 11
extend+tolist() time: 0.0005536079406738281

Evaluating:   5%|▌         | 12/228 [00:05<01:33,  2.31it/s][Astep: 12
extend+tolist() time: 0.0006797313690185547

Evaluating:   6%|▌         | 13/228 [00:05<01:30,  2.37it/s][Astep: 13
extend+tolist() time: 0.1599431037902832

Evaluating:   6%|▌         | 14/228 [00:06<01:40,  2.12it/s][Astep: 14
extend+tolist() time: 0.0005550384521484375

Evaluating:   7%|▋         | 15/228 [00:06<01:35,  2.24it/s][Astep: 15
extend+tolist() time: 0.0009660720825195312

Evaluating:   7%|▋         | 16/228 [00:07<01:33,  2.28it/s][Astep: 16
extend+tolist() time: 0.0006048679351806641

Evaluating:   7%|▋         | 17/228 [00:07<01:28,  2.38it/s][Astep: 17
extend+tolist() time: 0.0012536048889160156

Evaluating:   8%|▊         | 18/228 [00:08<01:28,  2.36it/s][Astep: 18
extend+tolist() time: 0.0011456012725830078

Evaluating:   8%|▊         | 19/228 [00:08<01:27,  2.39it/s][Astep: 19
extend+tolist() time: 0.0014095306396484375

Evaluating:   9%|▉         | 20/228 [00:08<01:26,  2.42it/s][Astep: 20
extend+tolist() time: 0.0010955333709716797

Evaluating:   9%|▉         | 21/228 [00:09<01:26,  2.39it/s][Astep: 21
extend+tolist() time: 0.0006456375122070312

Evaluating:  10%|▉         | 22/228 [00:09<01:24,  2.44it/s][Astep: 22
extend+tolist() time: 0.0007808208465576172

Evaluating:  10%|█         | 23/228 [00:10<01:26,  2.38it/s][Astep: 23
extend+tolist() time: 0.001173257827758789

Evaluating:  11%|█         | 24/228 [00:10<01:23,  2.44it/s][Astep: 24
extend+tolist() time: 0.0014986991882324219

Evaluating:  11%|█         | 25/228 [00:10<01:23,  2.42it/s][Astep: 25
extend+tolist() time: 0.0017964839935302734

Evaluating:  11%|█▏        | 26/228 [00:11<01:26,  2.33it/s][Astep: 26
extend+tolist() time: 0.0007412433624267578

Evaluating:  12%|█▏        | 27/228 [00:11<01:23,  2.39it/s][Astep: 27
extend+tolist() time: 0.0017192363739013672

Evaluating:  12%|█▏        | 28/228 [00:12<01:26,  2.31it/s][Astep: 28
extend+tolist() time: 0.0003380775451660156

Evaluating:  13%|█▎        | 29/228 [00:12<01:23,  2.39it/s][Astep: 29
extend+tolist() time: 0.0009636878967285156

Evaluating:  13%|█▎        | 30/228 [00:13<01:22,  2.40it/s][Astep: 30
extend+tolist() time: 0.0015840530395507812

Evaluating:  14%|█▎        | 31/228 [00:13<01:23,  2.37it/s][Astep: 31
extend+tolist() time: 0.0009088516235351562

Evaluating:  14%|█▍        | 32/228 [00:13<01:20,  2.42it/s][Astep: 32
extend+tolist() time: 0.0009701251983642578

Evaluating:  14%|█▍        | 33/228 [00:14<01:23,  2.33it/s][Astep: 33
extend+tolist() time: 0.0016868114471435547

Evaluating:  15%|█▍        | 34/228 [00:14<01:21,  2.37it/s][Astep: 34
extend+tolist() time: 0.0012390613555908203

Evaluating:  15%|█▌        | 35/228 [00:15<01:22,  2.33it/s][Astep: 35
extend+tolist() time: 0.0006794929504394531

Evaluating:  16%|█▌        | 36/228 [00:15<01:21,  2.37it/s][Astep: 36
extend+tolist() time: 0.0007891654968261719

Evaluating:  16%|█▌        | 37/228 [00:16<01:31,  2.08it/s][Astep: 37
extend+tolist() time: 0.0017633438110351562

Evaluating:  17%|█▋        | 38/228 [00:16<01:27,  2.16it/s][Astep: 38
extend+tolist() time: 0.001163482666015625

Evaluating:  17%|█▋        | 39/228 [00:17<01:24,  2.24it/s][Astep: 39
extend+tolist() time: 0.0007448196411132812

Evaluating:  18%|█▊        | 40/228 [00:17<01:23,  2.25it/s][Astep: 40
extend+tolist() time: 0.0010743141174316406

Evaluating:  18%|█▊        | 41/228 [00:17<01:20,  2.33it/s][Astep: 41
extend+tolist() time: 0.0008645057678222656

Evaluating:  18%|█▊        | 42/228 [00:18<01:21,  2.28it/s][Astep: 42
extend+tolist() time: 0.0017118453979492188

Evaluating:  19%|█▉        | 43/228 [00:18<01:28,  2.10it/s][Astep: 43
extend+tolist() time: 0.0018095970153808594

Evaluating:  19%|█▉        | 44/228 [00:19<01:27,  2.11it/s][Astep: 44
extend+tolist() time: 0.0007407665252685547

Evaluating:  20%|█▉        | 45/228 [00:19<01:22,  2.23it/s][Astep: 45
extend+tolist() time: 0.0017066001892089844

Evaluating:  20%|██        | 46/228 [00:20<01:20,  2.25it/s][Astep: 46
extend+tolist() time: 0.1572554111480713

Evaluating:  21%|██        | 47/228 [00:20<01:28,  2.04it/s][Astep: 47
extend+tolist() time: 0.0015864372253417969

Evaluating:  21%|██        | 48/228 [00:21<01:24,  2.12it/s][Astep: 48
extend+tolist() time: 0.0015037059783935547

Evaluating:  21%|██▏       | 49/228 [00:21<01:22,  2.17it/s][Astep: 49
extend+tolist() time: 0.0008947849273681641

Evaluating:  22%|██▏       | 50/228 [00:22<01:19,  2.23it/s][Astep: 50
extend+tolist() time: 0.001607656478881836

Evaluating:  22%|██▏       | 51/228 [00:22<01:19,  2.23it/s][Astep: 51
extend+tolist() time: 0.001527547836303711

Evaluating:  23%|██▎       | 52/228 [00:22<01:16,  2.30it/s][Astep: 52
extend+tolist() time: 0.0013396739959716797

Evaluating:  23%|██▎       | 53/228 [00:23<01:17,  2.25it/s][Astep: 53
extend+tolist() time: 0.0016188621520996094

Evaluating:  24%|██▎       | 54/228 [00:23<01:15,  2.31it/s][Astep: 54
extend+tolist() time: 0.001020669937133789

Evaluating:  24%|██▍       | 55/228 [00:24<01:14,  2.33it/s][Astep: 55
extend+tolist() time: 0.0011975765228271484

Evaluating:  25%|██▍       | 56/228 [00:24<01:13,  2.34it/s][Astep: 56
extend+tolist() time: 0.0011551380157470703

Evaluating:  25%|██▌       | 57/228 [00:25<01:11,  2.38it/s][Astep: 57
extend+tolist() time: 0.001024484634399414

Evaluating:  25%|██▌       | 58/228 [00:25<01:13,  2.32it/s][Astep: 58
extend+tolist() time: 0.0008394718170166016

Evaluating:  26%|██▌       | 59/228 [00:25<01:10,  2.38it/s][Astep: 59
extend+tolist() time: 0.0013582706451416016

Evaluating:  26%|██▋       | 60/228 [00:26<01:10,  2.38it/s][Astep: 60
extend+tolist() time: 0.0007336139678955078

Evaluating:  27%|██▋       | 61/228 [00:26<01:09,  2.39it/s][Astep: 61
extend+tolist() time: 0.0012559890747070312

Evaluating:  27%|██▋       | 62/228 [00:27<01:07,  2.46it/s][Astep: 62
extend+tolist() time: 0.0007729530334472656

Evaluating:  28%|██▊       | 63/228 [00:27<01:09,  2.38it/s][Astep: 63
extend+tolist() time: 0.0012488365173339844

Evaluating:  28%|██▊       | 64/228 [00:27<01:06,  2.45it/s][Astep: 64
extend+tolist() time: 0.0011484622955322266

Evaluating:  29%|██▊       | 65/228 [00:28<01:06,  2.45it/s][Astep: 65
extend+tolist() time: 0.0008192062377929688

Evaluating:  29%|██▉       | 66/228 [00:28<01:06,  2.44it/s][Astep: 66
extend+tolist() time: 0.0011191368103027344

Evaluating:  29%|██▉       | 67/228 [00:29<01:04,  2.49it/s][Astep: 67
extend+tolist() time: 0.0009291172027587891

Evaluating:  30%|██▉       | 68/228 [00:29<01:06,  2.41it/s][Astep: 68
extend+tolist() time: 0.0011551380157470703

Evaluating:  30%|███       | 69/228 [00:29<01:04,  2.46it/s][Astep: 69
extend+tolist() time: 0.0011131763458251953

Evaluating:  31%|███       | 70/228 [00:30<01:05,  2.40it/s][Astep: 70
extend+tolist() time: 0.0015375614166259766

Evaluating:  31%|███       | 71/228 [00:30<01:14,  2.11it/s][Astep: 71
extend+tolist() time: 0.0013647079467773438

Evaluating:  32%|███▏      | 72/228 [00:31<01:13,  2.13it/s][Astep: 72
extend+tolist() time: 0.0007581710815429688

Evaluating:  32%|███▏      | 73/228 [00:31<01:09,  2.22it/s][Astep: 73
extend+tolist() time: 0.0005102157592773438

Evaluating:  32%|███▏      | 74/228 [00:32<01:07,  2.29it/s][Astep: 74
extend+tolist() time: 0.0012402534484863281

Evaluating:  33%|███▎      | 75/228 [00:32<01:06,  2.29it/s][Astep: 75
extend+tolist() time: 0.001650094985961914

Evaluating:  33%|███▎      | 76/228 [00:33<01:04,  2.35it/s][Astep: 76
extend+tolist() time: 0.0006711483001708984

Evaluating:  34%|███▍      | 77/228 [00:33<01:13,  2.05it/s][Astep: 77
extend+tolist() time: 0.0018200874328613281

Evaluating:  34%|███▍      | 78/228 [00:34<01:09,  2.17it/s][Astep: 78
extend+tolist() time: 0.0012254714965820312

Evaluating:  35%|███▍      | 79/228 [00:34<01:08,  2.18it/s][Astep: 79
extend+tolist() time: 0.0009005069732666016

Evaluating:  35%|███▌      | 80/228 [00:34<01:04,  2.29it/s][Astep: 80
extend+tolist() time: 0.0016028881072998047

Evaluating:  36%|███▌      | 81/228 [00:35<01:02,  2.35it/s][Astep: 81
extend+tolist() time: 0.0008375644683837891

Evaluating:  36%|███▌      | 82/228 [00:35<01:01,  2.37it/s][Astep: 82
extend+tolist() time: 0.0013020038604736328

Evaluating:  36%|███▋      | 83/228 [00:36<00:59,  2.44it/s][Astep: 83
extend+tolist() time: 0.0007064342498779297

Evaluating:  37%|███▋      | 84/228 [00:36<01:00,  2.38it/s][Astep: 84
extend+tolist() time: 0.18193721771240234

Evaluating:  37%|███▋      | 85/228 [00:37<01:06,  2.15it/s][Astep: 85
extend+tolist() time: 0.0013349056243896484

Evaluating:  38%|███▊      | 86/228 [00:37<01:05,  2.18it/s][Astep: 86
extend+tolist() time: 0.0008490085601806641

Evaluating:  38%|███▊      | 87/228 [00:37<01:01,  2.30it/s][Astep: 87
extend+tolist() time: 0.001499176025390625

Evaluating:  39%|███▊      | 88/228 [00:38<01:00,  2.33it/s][Astep: 88
extend+tolist() time: 0.0010478496551513672

Evaluating:  39%|███▉      | 89/228 [00:38<00:59,  2.35it/s][Astep: 89
extend+tolist() time: 0.0007309913635253906

Evaluating:  39%|███▉      | 90/228 [00:39<00:56,  2.43it/s][Astep: 90
extend+tolist() time: 0.0013034343719482422

Evaluating:  40%|███▉      | 91/228 [00:39<00:57,  2.36it/s][Astep: 91
extend+tolist() time: 0.0007333755493164062

Evaluating:  40%|████      | 92/228 [00:40<00:55,  2.44it/s][Astep: 92
extend+tolist() time: 0.0014371871948242188

Evaluating:  41%|████      | 93/228 [00:40<00:55,  2.44it/s][Astep: 93
extend+tolist() time: 0.00096893310546875

Evaluating:  41%|████      | 94/228 [00:40<00:55,  2.42it/s][Astep: 94
extend+tolist() time: 0.0011663436889648438

Evaluating:  42%|████▏     | 95/228 [00:41<00:53,  2.48it/s][Astep: 95
extend+tolist() time: 0.0014986991882324219

Evaluating:  42%|████▏     | 96/228 [00:41<00:55,  2.40it/s][Astep: 96
extend+tolist() time: 0.0009129047393798828

Evaluating:  43%|████▎     | 97/228 [00:42<00:53,  2.45it/s][Astep: 97
extend+tolist() time: 0.0012943744659423828

Evaluating:  43%|████▎     | 98/228 [00:42<00:53,  2.43it/s][Astep: 98
extend+tolist() time: 0.0008966922760009766

Evaluating:  43%|████▎     | 99/228 [00:42<00:53,  2.41it/s][Astep: 99
extend+tolist() time: 0.0013387203216552734

Evaluating:  44%|████▍     | 100/228 [00:43<00:52,  2.44it/s][Astep: 100
extend+tolist() time: 0.0007290840148925781

Evaluating:  44%|████▍     | 101/228 [00:43<00:53,  2.36it/s][Astep: 101
extend+tolist() time: 0.0012688636779785156

Evaluating:  45%|████▍     | 102/228 [00:44<00:52,  2.41it/s][Astep: 102
extend+tolist() time: 0.0010547637939453125

Evaluating:  45%|████▌     | 103/228 [00:44<00:52,  2.36it/s][Astep: 103
extend+tolist() time: 0.001317739486694336

Evaluating:  46%|████▌     | 104/228 [00:45<00:52,  2.38it/s][Astep: 104
extend+tolist() time: 0.0007259845733642578

Evaluating:  46%|████▌     | 105/228 [00:45<00:50,  2.42it/s][Astep: 105
extend+tolist() time: 0.0012776851654052734

Evaluating:  46%|████▋     | 106/228 [00:45<00:51,  2.37it/s][Astep: 106
extend+tolist() time: 0.0017235279083251953

Evaluating:  47%|████▋     | 107/228 [00:46<00:50,  2.39it/s][Astep: 107
extend+tolist() time: 0.0008268356323242188

Evaluating:  47%|████▋     | 108/228 [00:46<00:51,  2.32it/s][Astep: 108
extend+tolist() time: 0.0012292861938476562

Evaluating:  48%|████▊     | 109/228 [00:47<00:49,  2.39it/s][Astep: 109
extend+tolist() time: 0.0010919570922851562

Evaluating:  48%|████▊     | 110/228 [00:47<00:49,  2.37it/s][Astep: 110
extend+tolist() time: 0.0010330677032470703

Evaluating:  49%|████▊     | 111/228 [00:47<00:49,  2.38it/s][Astep: 111
extend+tolist() time: 0.0014307498931884766

Evaluating:  49%|████▉     | 112/228 [00:48<00:48,  2.40it/s][Astep: 112
extend+tolist() time: 0.0008726119995117188

Evaluating:  50%|████▉     | 113/228 [00:48<00:48,  2.35it/s][Astep: 113
extend+tolist() time: 0.0007195472717285156

Evaluating:  50%|█████     | 114/228 [00:49<00:47,  2.42it/s][Astep: 114
extend+tolist() time: 0.0015842914581298828

Evaluating:  50%|█████     | 115/228 [00:49<00:47,  2.38it/s][Astep: 115
extend+tolist() time: 0.0006754398345947266

Evaluating:  51%|█████     | 116/228 [00:50<00:54,  2.06it/s][Astep: 116
extend+tolist() time: 0.0013003349304199219

Evaluating:  51%|█████▏    | 117/228 [00:50<00:51,  2.14it/s][Astep: 117
extend+tolist() time: 0.0009961128234863281

Evaluating:  52%|█████▏    | 118/228 [00:51<00:49,  2.23it/s][Astep: 118
extend+tolist() time: 0.0010824203491210938

Evaluating:  52%|█████▏    | 119/228 [00:51<00:46,  2.33it/s][Astep: 119
extend+tolist() time: 0.0008223056793212891

Evaluating:  53%|█████▎    | 120/228 [00:51<00:47,  2.29it/s][Astep: 120
extend+tolist() time: 0.0007452964782714844

Evaluating:  53%|█████▎    | 121/228 [00:52<00:45,  2.38it/s][Astep: 121
extend+tolist() time: 0.0011954307556152344

Evaluating:  54%|█████▎    | 122/228 [00:52<00:44,  2.36it/s][Astep: 122
extend+tolist() time: 0.0007555484771728516

Evaluating:  54%|█████▍    | 123/228 [00:53<00:44,  2.38it/s][Astep: 123
extend+tolist() time: 0.001100301742553711

Evaluating:  54%|█████▍    | 124/228 [00:53<00:43,  2.40it/s][Astep: 124
extend+tolist() time: 0.0009517669677734375

Evaluating:  55%|█████▍    | 125/228 [00:54<00:43,  2.37it/s][Astep: 125
extend+tolist() time: 0.0004925727844238281

Evaluating:  55%|█████▌    | 126/228 [00:54<00:41,  2.44it/s][Astep: 126
extend+tolist() time: 0.002005338668823242

Evaluating:  56%|█████▌    | 127/228 [00:54<00:43,  2.34it/s][Astep: 127
extend+tolist() time: 0.0018808841705322266

Evaluating:  56%|█████▌    | 128/228 [00:55<00:48,  2.07it/s][Astep: 128
extend+tolist() time: 0.001165628433227539

Evaluating:  57%|█████▋    | 129/228 [00:55<00:46,  2.13it/s][Astep: 129
extend+tolist() time: 0.0008933544158935547

Evaluating:  57%|█████▋    | 130/228 [00:56<00:43,  2.24it/s][Astep: 130
extend+tolist() time: 0.001468658447265625

Evaluating:  57%|█████▋    | 131/228 [00:56<00:42,  2.27it/s][Astep: 131
extend+tolist() time: 0.0005099773406982422

Evaluating:  58%|█████▊    | 132/228 [00:57<00:41,  2.30it/s][Astep: 132
extend+tolist() time: 0.0016317367553710938

Evaluating:  58%|█████▊    | 133/228 [00:57<00:40,  2.34it/s][Astep: 133
extend+tolist() time: 0.0005004405975341797

Evaluating:  59%|█████▉    | 134/228 [00:58<00:40,  2.30it/s][Astep: 134
extend+tolist() time: 0.0011296272277832031

Evaluating:  59%|█████▉    | 135/228 [00:58<00:39,  2.36it/s][Astep: 135
extend+tolist() time: 0.0009679794311523438

Evaluating:  60%|█████▉    | 136/228 [00:58<00:39,  2.34it/s][Astep: 136
extend+tolist() time: 0.0009739398956298828

Evaluating:  60%|██████    | 137/228 [00:59<00:38,  2.37it/s][Astep: 137
extend+tolist() time: 0.0004334449768066406

Evaluating:  61%|██████    | 138/228 [00:59<00:37,  2.42it/s][Astep: 138
extend+tolist() time: 0.0012240409851074219

Evaluating:  61%|██████    | 139/228 [01:00<00:37,  2.37it/s][Astep: 139
extend+tolist() time: 0.0005135536193847656

Evaluating:  61%|██████▏   | 140/228 [01:00<00:36,  2.42it/s][Astep: 140
extend+tolist() time: 0.25963425636291504

Evaluating:  62%|██████▏   | 141/228 [01:01<00:43,  2.00it/s][Astep: 141
extend+tolist() time: 0.0008780956268310547

Evaluating:  62%|██████▏   | 142/228 [01:01<00:40,  2.13it/s][Astep: 142
extend+tolist() time: 0.0010142326354980469

Evaluating:  63%|██████▎   | 143/228 [01:02<00:39,  2.17it/s][Astep: 143
extend+tolist() time: 0.0003745555877685547

Evaluating:  63%|██████▎   | 144/228 [01:02<00:36,  2.28it/s][Astep: 144
extend+tolist() time: 0.0008254051208496094

Evaluating:  64%|██████▎   | 145/228 [01:02<00:36,  2.31it/s][Astep: 145
extend+tolist() time: 0.0009250640869140625

Evaluating:  64%|██████▍   | 146/228 [01:03<00:35,  2.32it/s][Astep: 146
extend+tolist() time: 0.0004379749298095703

Evaluating:  64%|██████▍   | 147/228 [01:03<00:34,  2.37it/s][Astep: 147
extend+tolist() time: 0.0007987022399902344

Evaluating:  65%|██████▍   | 148/228 [01:04<00:34,  2.29it/s][Astep: 148
extend+tolist() time: 0.0012233257293701172

Evaluating:  65%|██████▌   | 149/228 [01:04<00:33,  2.35it/s][Astep: 149
extend+tolist() time: 0.0003933906555175781

Evaluating:  66%|██████▌   | 150/228 [01:05<00:34,  2.29it/s][Astep: 150
extend+tolist() time: 0.0009491443634033203

Evaluating:  66%|██████▌   | 151/228 [01:05<00:32,  2.34it/s][Astep: 151
extend+tolist() time: 0.001110076904296875

Evaluating:  67%|██████▋   | 152/228 [01:05<00:32,  2.36it/s][Astep: 152
extend+tolist() time: 0.0009009838104248047

Evaluating:  67%|██████▋   | 153/228 [01:06<00:32,  2.32it/s][Astep: 153
extend+tolist() time: 0.0014977455139160156

Evaluating:  68%|██████▊   | 154/228 [01:06<00:31,  2.35it/s][Astep: 154
extend+tolist() time: 0.0020148754119873047

Evaluating:  68%|██████▊   | 155/228 [01:07<00:32,  2.25it/s][Astep: 155
extend+tolist() time: 0.0006947517395019531

Evaluating:  68%|██████▊   | 156/228 [01:07<00:31,  2.31it/s][Astep: 156
extend+tolist() time: 0.0005645751953125

Evaluating:  69%|██████▉   | 157/228 [01:08<00:30,  2.29it/s][Astep: 157
extend+tolist() time: 0.0007157325744628906

Evaluating:  69%|██████▉   | 158/228 [01:08<00:30,  2.33it/s][Astep: 158
extend+tolist() time: 0.0005192756652832031

Evaluating:  70%|██████▉   | 159/228 [01:08<00:29,  2.36it/s][Astep: 159
extend+tolist() time: 0.0011839866638183594

Evaluating:  70%|███████   | 160/228 [01:09<00:29,  2.32it/s][Astep: 160
extend+tolist() time: 0.0003952980041503906

Evaluating:  71%|███████   | 161/228 [01:09<00:27,  2.40it/s][Astep: 161
extend+tolist() time: 0.0008342266082763672

Evaluating:  71%|███████   | 162/228 [01:10<00:28,  2.35it/s][Astep: 162
extend+tolist() time: 0.0005340576171875

Evaluating:  71%|███████▏  | 163/228 [01:10<00:26,  2.42it/s][Astep: 163
extend+tolist() time: 0.0008847713470458984

Evaluating:  72%|███████▏  | 164/228 [01:10<00:26,  2.45it/s][Astep: 164
extend+tolist() time: 0.0005691051483154297

Evaluating:  72%|███████▏  | 165/228 [01:11<00:26,  2.40it/s][Astep: 165
extend+tolist() time: 0.0004756450653076172

Evaluating:  73%|███████▎  | 166/228 [01:11<00:25,  2.47it/s][Astep: 166
extend+tolist() time: 0.0003857612609863281

Evaluating:  73%|███████▎  | 167/228 [01:12<00:25,  2.40it/s][Astep: 167
extend+tolist() time: 0.001062631607055664

Evaluating:  74%|███████▎  | 168/228 [01:12<00:24,  2.46it/s][Astep: 168
extend+tolist() time: 0.0014863014221191406

Evaluating:  74%|███████▍  | 169/228 [01:12<00:24,  2.42it/s][Astep: 169
extend+tolist() time: 0.00037479400634765625

Evaluating:  75%|███████▍  | 170/228 [01:13<00:23,  2.42it/s][Astep: 170
extend+tolist() time: 0.0013785362243652344

Evaluating:  75%|███████▌  | 171/228 [01:13<00:23,  2.45it/s][Astep: 171
extend+tolist() time: 0.00032019615173339844

Evaluating:  75%|███████▌  | 172/228 [01:14<00:23,  2.39it/s][Astep: 172
extend+tolist() time: 0.0012252330780029297

Evaluating:  76%|███████▌  | 173/228 [01:14<00:22,  2.44it/s][Astep: 173
extend+tolist() time: 0.001153707504272461

Evaluating:  76%|███████▋  | 174/228 [01:15<00:22,  2.41it/s][Astep: 174
extend+tolist() time: 0.0019669532775878906

Evaluating:  77%|███████▋  | 175/228 [01:15<00:22,  2.37it/s][Astep: 175
extend+tolist() time: 0.0008168220520019531

Evaluating:  77%|███████▋  | 176/228 [01:15<00:21,  2.42it/s][Astep: 176
extend+tolist() time: 0.0010542869567871094

Evaluating:  78%|███████▊  | 177/228 [01:16<00:21,  2.35it/s][Astep: 177
extend+tolist() time: 0.0006363391876220703

Evaluating:  78%|███████▊  | 178/228 [01:16<00:20,  2.42it/s][Astep: 178
extend+tolist() time: 0.0016529560089111328

Evaluating:  79%|███████▊  | 179/228 [01:17<00:20,  2.38it/s][Astep: 179
extend+tolist() time: 0.00042748451232910156

Evaluating:  79%|███████▉  | 180/228 [01:17<00:19,  2.42it/s][Astep: 180
extend+tolist() time: 0.0003809928894042969

Evaluating:  79%|███████▉  | 181/228 [01:17<00:19,  2.47it/s][Astep: 181
extend+tolist() time: 0.0010406970977783203

Evaluating:  80%|███████▉  | 182/228 [01:18<00:19,  2.35it/s][Astep: 182
extend+tolist() time: 0.0007383823394775391

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.41it/s][Astep: 183
extend+tolist() time: 0.0006585121154785156

Evaluating:  81%|████████  | 184/228 [01:19<00:18,  2.36it/s][Astep: 184
extend+tolist() time: 0.0004627704620361328

Evaluating:  81%|████████  | 185/228 [01:19<00:17,  2.39it/s][Astep: 185
extend+tolist() time: 0.0010485649108886719

Evaluating:  82%|████████▏ | 186/228 [01:20<00:17,  2.40it/s][Astep: 186
extend+tolist() time: 0.0015490055084228516

Evaluating:  82%|████████▏ | 187/228 [01:20<00:17,  2.33it/s][Astep: 187
extend+tolist() time: 0.0004839897155761719

Evaluating:  82%|████████▏ | 188/228 [01:20<00:16,  2.35it/s][Astep: 188
extend+tolist() time: 0.0007505416870117188

Evaluating:  83%|████████▎ | 189/228 [01:21<00:17,  2.28it/s][Astep: 189
extend+tolist() time: 0.0004062652587890625

Evaluating:  83%|████████▎ | 190/228 [01:21<00:16,  2.37it/s][Astep: 190
extend+tolist() time: 0.0019898414611816406

Evaluating:  84%|████████▍ | 191/228 [01:22<00:15,  2.33it/s][Astep: 191
extend+tolist() time: 0.0007293224334716797

Evaluating:  84%|████████▍ | 192/228 [01:22<00:15,  2.37it/s][Astep: 192
extend+tolist() time: 0.0004353523254394531

Evaluating:  85%|████████▍ | 193/228 [01:23<00:14,  2.44it/s][Astep: 193
extend+tolist() time: 0.0010843276977539062

Evaluating:  85%|████████▌ | 194/228 [01:23<00:14,  2.36it/s][Astep: 194
extend+tolist() time: 0.0010793209075927734

Evaluating:  86%|████████▌ | 195/228 [01:23<00:13,  2.42it/s][Astep: 195
extend+tolist() time: 0.0005595684051513672

Evaluating:  86%|████████▌ | 196/228 [01:24<00:13,  2.39it/s][Astep: 196
extend+tolist() time: 0.0005590915679931641

Evaluating:  86%|████████▋ | 197/228 [01:24<00:15,  2.03it/s][Astep: 197
extend+tolist() time: 0.0011258125305175781

Evaluating:  87%|████████▋ | 198/228 [01:25<00:14,  2.10it/s][Astep: 198
extend+tolist() time: 0.0005834102630615234

Evaluating:  87%|████████▋ | 199/228 [01:25<00:13,  2.22it/s][Astep: 199
extend+tolist() time: 0.002159595489501953

Evaluating:  88%|████████▊ | 200/228 [01:26<00:12,  2.27it/s][Astep: 200
extend+tolist() time: 0.0007207393646240234

Evaluating:  88%|████████▊ | 201/228 [01:26<00:11,  2.31it/s][Astep: 201
extend+tolist() time: 0.0006344318389892578

Evaluating:  89%|████████▊ | 202/228 [01:27<00:10,  2.39it/s][Astep: 202
extend+tolist() time: 0.0008246898651123047

Evaluating:  89%|████████▉ | 203/228 [01:27<00:10,  2.35it/s][Astep: 203
extend+tolist() time: 0.0005273818969726562

Evaluating:  89%|████████▉ | 204/228 [01:27<00:09,  2.41it/s][Astep: 204
extend+tolist() time: 0.00040912628173828125

Evaluating:  90%|████████▉ | 205/228 [01:28<00:09,  2.41it/s][Astep: 205
extend+tolist() time: 0.00028896331787109375

Evaluating:  90%|█████████ | 206/228 [01:28<00:09,  2.41it/s][Astep: 206
extend+tolist() time: 0.0010378360748291016

Evaluating:  91%|█████████ | 207/228 [01:29<00:08,  2.47it/s][Astep: 207
extend+tolist() time: 0.0006189346313476562

Evaluating:  91%|█████████ | 208/228 [01:29<00:08,  2.39it/s][Astep: 208
extend+tolist() time: 0.0007021427154541016

Evaluating:  92%|█████████▏| 209/228 [01:29<00:07,  2.45it/s][Astep: 209
extend+tolist() time: 0.0010411739349365234

Evaluating:  92%|█████████▏| 210/228 [01:30<00:07,  2.42it/s][Astep: 210
extend+tolist() time: 0.0005931854248046875

Evaluating:  93%|█████████▎| 211/228 [01:30<00:07,  2.43it/s][Astep: 211
extend+tolist() time: 0.0010933876037597656

Evaluating:  93%|█████████▎| 212/228 [01:31<00:06,  2.45it/s][Astep: 212
extend+tolist() time: 0.0008966922760009766

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.36it/s][Astep: 213
extend+tolist() time: 0.0007395744323730469

Evaluating:  94%|█████████▍| 214/228 [01:32<00:07,  1.99it/s][Astep: 214
extend+tolist() time: 0.0012938976287841797

Evaluating:  94%|█████████▍| 215/228 [01:32<00:06,  2.08it/s][Astep: 215
extend+tolist() time: 0.0006525516510009766

Evaluating:  95%|█████████▍| 216/228 [01:33<00:05,  2.21it/s][Astep: 216
extend+tolist() time: 0.0009610652923583984

Evaluating:  95%|█████████▌| 217/228 [01:33<00:04,  2.21it/s][Astep: 217
extend+tolist() time: 0.0005695819854736328

Evaluating:  96%|█████████▌| 218/228 [01:33<00:04,  2.31it/s][Astep: 218
extend+tolist() time: 0.001283884048461914

Evaluating:  96%|█████████▌| 219/228 [01:34<00:03,  2.34it/s][Astep: 219
extend+tolist() time: 0.0009608268737792969

Evaluating:  96%|█████████▋| 220/228 [01:34<00:03,  2.34it/s][Astep: 220
extend+tolist() time: 0.0003952980041503906

Evaluating:  97%|█████████▋| 221/228 [01:35<00:02,  2.40it/s][Astep: 221
extend+tolist() time: 0.0006494522094726562

Evaluating:  97%|█████████▋| 222/228 [01:35<00:02,  2.33it/s][Astep: 222
extend+tolist() time: 0.0004222393035888672

Evaluating:  98%|█████████▊| 223/228 [01:35<00:02,  2.40it/s][Astep: 223
extend+tolist() time: 0.0008456707000732422

Evaluating:  98%|█████████▊| 224/228 [01:36<00:01,  2.41it/s][Astep: 224
extend+tolist() time: 0.00036978721618652344

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.41it/s][Astep: 225
extend+tolist() time: 0.0004215240478515625

Evaluating:  99%|█████████▉| 226/228 [01:37<00:00,  2.48it/s][Astep: 226
extend+tolist() time: 0.0005478858947753906

Evaluating: 100%|█████████▉| 227/228 [01:37<00:00,  2.40it/s][Astep: 227
extend+tolist() time: 0.00089263916015625

Evaluating: 100%|██████████| 228/228 [01:38<00:00,  2.41it/s][A09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:46:22 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:46:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:46:24 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:46:24 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:46:24 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:40<00:00,  2.27it/s]
09/08/2023 21:46:24 - INFO - __main__ -   Step: 1380, Validation Metrics: {'pred_1_num': 9728, 'pred_-1_num': 1005, 'pred_0_num': 68, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7951115637440977, 'f1_micro': 0.7951115637440977, 'f1_macro': 0.44459785875337404, 'f1_weighted': 0.7606855340631976, 'f1_-1': 0.3757292882147024, 'f1_0': 0.07637906647807638, 'f1_1': 0.8816852215673433, 'precision_micro': 0.7951115637440977, 'precision_macro': 0.5693474505375599, 'precision_weighted': 0.7540355504780752, 'precision_-1': 0.48059701492537316, 'precision_0': 0.39705882352941174, 'precision_1': 0.8303865131578947, 'recall_micro': 0.7951115637440977, 'recall_macro': 0.43014068452716286, 'recall_weighted': 0.7951115637440977, 'recall_-1': 0.30842911877394635, 'recall_0': 0.04225352112676056, 'recall_1': 0.9397394136807817, 'roc_auc_micro': 0.9126792671052063, 'roc_auc_macro': 0.747476147130487, 'roc_auc_weighted': 0.7309196761303397, 'roc_auc_-1': 0.7957550506464869, 'roc_auc_0': 0.7272958972316701, 'roc_auc_1': 0.7193774935133043}
09/08/2023 21:46:38 - INFO - __main__ - Saving state to /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024
09/08/2023 21:46:38 - INFO - accelerate.accelerator - Saving current state to /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024
09/08/2023 21:46:38 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2023-09-08 21:46:38,210] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2023-09-08 21:46:38,217] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt...
[2023-09-08 21:46:38,217] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt...
[2023-09-08 21:46:38,217] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt
[2023-09-08 21:46:38,218] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt...
[2023-09-08 21:46:38,219] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt
[2023-09-08 21:46:38,219] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-09-08 21:46:38,232] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt.
[2023-09-08 21:46:38,232] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt.
[2023-09-08 21:46:38,232] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt.
[2023-09-08 21:46:38,234] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-09-08 21:46:38,237] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2023-09-08 21:46:38,237] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2023-09-08 21:46:38,237] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[2023-09-08 21:46:38,237] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-09-08 21:47:22,793] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[2023-09-08 21:47:22,793] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt
[2023-09-08 21:47:25,677] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[2023-09-08 21:47:25,677] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt
[2023-09-08 21:47:27,408] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-09-08 21:47:27,409] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2023-09-08 21:47:28,914] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2023-09-08 21:47:28,914] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2023-09-08 21:47:28,963] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 21:47:28,963] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 21:47:28,963] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 21:47:28,963] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/08/2023 21:47:28 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/pytorch_model
09/08/2023 21:47:28 - INFO - accelerate.checkpointing - Scheduler state saved in /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/scheduler.bin
09/08/2023 21:47:28 - INFO - accelerate.checkpointing - Random states saved in /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1380-best-f1_-1=0.3757292882147024/random_states_0.pkl
[2023-09-08 21:47:48,869] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1381/66600 [24:58<1264:49:21, 69.82s/it]09/08/2023 21:47:48 - INFO - __main__ -   Step: 1381, LR: 1.3829014895481288e-05, Loss: 0.3200414776802063
[2023-09-08 21:48:09,484] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1382/66600 [25:19<997:24:08, 55.06s/it] 09/08/2023 21:48:09 - INFO - __main__ -   Step: 1382, LR: 1.383902866441357e-05, Loss: 0.40951377153396606
[2023-09-08 21:48:29,825] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1383/66600 [25:39<808:43:10, 44.64s/it]09/08/2023 21:48:29 - INFO - __main__ -   Step: 1383, LR: 1.3849042433345851e-05, Loss: 0.3554113507270813
[2023-09-08 21:48:50,544] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1384/66600 [26:00<678:42:06, 37.47s/it]09/08/2023 21:48:50 - INFO - __main__ -   Step: 1384, LR: 1.3859056202278134e-05, Loss: 0.437910258769989
[2023-09-08 21:49:11,314] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1385/66600 [26:20<587:57:28, 32.46s/it]09/08/2023 21:49:11 - INFO - __main__ -   Step: 1385, LR: 1.3869069971210416e-05, Loss: 0.4314362406730652
[2023-09-08 21:49:31,966] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1386/66600 [26:41<523:47:38, 28.91s/it]09/08/2023 21:49:31 - INFO - __main__ -   Step: 1386, LR: 1.3879083740142698e-05, Loss: 0.4334624707698822
[2023-09-08 21:49:52,533] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1387/66600 [27:02<478:25:25, 26.41s/it]09/08/2023 21:49:52 - INFO - __main__ -   Step: 1387, LR: 1.3889097509074981e-05, Loss: 0.4710139334201813
[2023-09-08 21:50:12,928] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1388/66600 [27:22<445:43:28, 24.61s/it]09/08/2023 21:50:12 - INFO - __main__ -   Step: 1388, LR: 1.3899111278007261e-05, Loss: 0.4759537875652313
[2023-09-08 21:50:33,420] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1389/66600 [27:42<423:21:27, 23.37s/it]09/08/2023 21:50:33 - INFO - __main__ -   Step: 1389, LR: 1.3909125046939542e-05, Loss: 0.38401663303375244
[2023-09-08 21:50:53,830] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1390/66600 [28:03<407:15:33, 22.48s/it]09/08/2023 21:50:53 - INFO - __main__ -   Step: 1390, LR: 1.3919138815871824e-05, Loss: 0.41604018211364746
[2023-09-08 21:51:14,632] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1391/66600 [28:24<398:07:01, 21.98s/it]09/08/2023 21:51:14 - INFO - __main__ -   Step: 1391, LR: 1.3929152584804106e-05, Loss: 0.3998119831085205
[2023-09-08 21:51:35,387] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1392/66600 [28:44<391:27:35, 21.61s/it]09/08/2023 21:51:35 - INFO - __main__ -   Step: 1392, LR: 1.3939166353736389e-05, Loss: 0.39246058464050293
[2023-09-08 21:51:55,292] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1393/66600 [29:04<382:10:54, 21.10s/it]09/08/2023 21:51:55 - INFO - __main__ -   Step: 1393, LR: 1.394918012266867e-05, Loss: 0.3181983232498169
[2023-09-08 21:52:15,617] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1394/66600 [29:25<377:58:01, 20.87s/it]09/08/2023 21:52:15 - INFO - __main__ -   Step: 1394, LR: 1.3959193891600952e-05, Loss: 0.3966139853000641
[2023-09-08 21:52:35,640] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1395/66600 [29:45<373:22:01, 20.61s/it]09/08/2023 21:52:35 - INFO - __main__ -   Step: 1395, LR: 1.3969207660533235e-05, Loss: 0.42837095260620117
[2023-09-08 21:52:55,829] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1396/66600 [30:05<371:03:17, 20.49s/it]09/08/2023 21:52:55 - INFO - __main__ -   Step: 1396, LR: 1.3979221429465517e-05, Loss: 0.4116579592227936
[2023-09-08 21:53:16,389] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1397/66600 [30:25<371:27:08, 20.51s/it]09/08/2023 21:53:16 - INFO - __main__ -   Step: 1397, LR: 1.3989235198397799e-05, Loss: 0.46017590165138245
[2023-09-08 21:53:36,868] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1398/66600 [30:46<371:17:02, 20.50s/it]09/08/2023 21:53:36 - INFO - __main__ -   Step: 1398, LR: 1.3999248967330079e-05, Loss: 0.39653879404067993
[2023-09-08 21:53:56,733] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1399/66600 [31:06<367:49:49, 20.31s/it]09/08/2023 21:53:56 - INFO - __main__ -   Step: 1399, LR: 1.4009262736262362e-05, Loss: 0.4159993529319763
[2023-09-08 21:54:17,496] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1400/66600 [31:27<370:17:14, 20.45s/it]09/08/2023 21:54:17 - INFO - __main__ -   Step: 1400, LR: 1.4019276505194643e-05, Loss: 0.3710067868232727
09/08/2023 21:54:17 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.001829385757446289

Evaluating:   0%|          | 1/228 [00:00<01:54,  1.99it/s][Astep: 1
extend+tolist() time: 0.0010523796081542969

Evaluating:   1%|          | 2/228 [00:00<01:42,  2.22it/s][Astep: 2
extend+tolist() time: 0.002366304397583008

Evaluating:   1%|▏         | 3/228 [00:01<01:39,  2.26it/s][Astep: 3
extend+tolist() time: 0.17266249656677246

Evaluating:   2%|▏         | 4/228 [00:01<01:55,  1.95it/s][Astep: 4
extend+tolist() time: 0.0019497871398925781

Evaluating:   2%|▏         | 5/228 [00:02<01:47,  2.07it/s][Astep: 5
extend+tolist() time: 0.0019023418426513672

Evaluating:   3%|▎         | 6/228 [00:02<01:43,  2.14it/s][Astep: 6
extend+tolist() time: 0.0018646717071533203

Evaluating:   3%|▎         | 7/228 [00:03<01:40,  2.19it/s][Astep: 7
extend+tolist() time: 0.000988006591796875

Evaluating:   4%|▎         | 8/228 [00:03<01:48,  2.03it/s][Astep: 8
extend+tolist() time: 0.0012173652648925781

Evaluating:   4%|▍         | 9/228 [00:04<01:42,  2.15it/s][Astep: 9
extend+tolist() time: 0.0008265972137451172

Evaluating:   4%|▍         | 10/228 [00:04<01:39,  2.18it/s][Astep: 10
extend+tolist() time: 0.001283407211303711

Evaluating:   5%|▍         | 11/228 [00:05<01:35,  2.27it/s][Astep: 11
extend+tolist() time: 0.000576019287109375

Evaluating:   5%|▌         | 12/228 [00:05<01:34,  2.28it/s][Astep: 12
extend+tolist() time: 0.0010919570922851562

Evaluating:   6%|▌         | 13/228 [00:05<01:32,  2.34it/s][Astep: 13
extend+tolist() time: 0.0005915164947509766

Evaluating:   6%|▌         | 14/228 [00:06<01:29,  2.38it/s][Astep: 14
extend+tolist() time: 0.0005621910095214844

Evaluating:   7%|▋         | 15/228 [00:06<01:30,  2.36it/s][Astep: 15
extend+tolist() time: 0.0010716915130615234

Evaluating:   7%|▋         | 16/228 [00:07<01:28,  2.40it/s][Astep: 16
extend+tolist() time: 0.000644683837890625

Evaluating:   7%|▋         | 17/228 [00:07<01:28,  2.37it/s][Astep: 17
extend+tolist() time: 0.0013256072998046875

Evaluating:   8%|▊         | 18/228 [00:08<01:27,  2.39it/s][Astep: 18
extend+tolist() time: 0.0011935234069824219

Evaluating:   8%|▊         | 19/228 [00:08<01:27,  2.40it/s][Astep: 19
extend+tolist() time: 0.001413106918334961

Evaluating:   9%|▉         | 20/228 [00:08<01:28,  2.35it/s][Astep: 20
extend+tolist() time: 0.0007681846618652344

Evaluating:   9%|▉         | 21/228 [00:09<01:25,  2.41it/s][Astep: 21
extend+tolist() time: 0.0010859966278076172

Evaluating:  10%|▉         | 22/228 [00:09<01:26,  2.38it/s][Astep: 22
extend+tolist() time: 0.0007355213165283203

Evaluating:  10%|█         | 23/228 [00:10<01:25,  2.41it/s][Astep: 23
extend+tolist() time: 0.0011334419250488281

Evaluating:  11%|█         | 24/228 [00:10<01:35,  2.14it/s][Astep: 24
extend+tolist() time: 0.0011191368103027344

Evaluating:  11%|█         | 25/228 [00:11<01:31,  2.22it/s][Astep: 25
extend+tolist() time: 0.001931905746459961

Evaluating:  11%|█▏        | 26/228 [00:11<01:29,  2.25it/s][Astep: 26
extend+tolist() time: 0.0010945796966552734

Evaluating:  12%|█▏        | 27/228 [00:11<01:28,  2.26it/s][Astep: 27
extend+tolist() time: 0.0016722679138183594

Evaluating:  12%|█▏        | 28/228 [00:12<01:26,  2.32it/s][Astep: 28
extend+tolist() time: 0.0003409385681152344

Evaluating:  13%|█▎        | 29/228 [00:12<01:24,  2.37it/s][Astep: 29
extend+tolist() time: 0.0007200241088867188

Evaluating:  13%|█▎        | 30/228 [00:13<01:22,  2.40it/s][Astep: 30
extend+tolist() time: 0.0017669200897216797

Evaluating:  14%|█▎        | 31/228 [00:13<01:23,  2.37it/s][Astep: 31
extend+tolist() time: 0.0005919933319091797

Evaluating:  14%|█▍        | 32/228 [00:14<01:21,  2.40it/s][Astep: 32
extend+tolist() time: 0.001428365707397461

Evaluating:  14%|█▍        | 33/228 [00:14<01:19,  2.44it/s][Astep: 33
extend+tolist() time: 0.15541315078735352

Evaluating:  15%|█▍        | 34/228 [00:14<01:30,  2.15it/s][Astep: 34
extend+tolist() time: 0.0012912750244140625

Evaluating:  15%|█▌        | 35/228 [00:15<01:25,  2.25it/s][Astep: 35
extend+tolist() time: 0.0006814002990722656

Evaluating:  16%|█▌        | 36/228 [00:15<01:24,  2.27it/s][Astep: 36
extend+tolist() time: 0.0011472702026367188

Evaluating:  16%|█▌        | 37/228 [00:16<01:22,  2.33it/s][Astep: 37
extend+tolist() time: 0.0018160343170166016

Evaluating:  17%|█▋        | 38/228 [00:16<01:21,  2.33it/s][Astep: 38
extend+tolist() time: 0.0007588863372802734

Evaluating:  17%|█▋        | 39/228 [00:17<01:19,  2.37it/s][Astep: 39
extend+tolist() time: 0.0011341571807861328

Evaluating:  18%|█▊        | 40/228 [00:17<01:18,  2.40it/s][Astep: 40
extend+tolist() time: 0.0006461143493652344

Evaluating:  18%|█▊        | 41/228 [00:17<01:18,  2.37it/s][Astep: 41
extend+tolist() time: 0.0008687973022460938

Evaluating:  18%|█▊        | 42/228 [00:18<01:26,  2.15it/s][Astep: 42
extend+tolist() time: 0.0017116069793701172

Evaluating:  19%|█▉        | 43/228 [00:18<01:24,  2.20it/s][Astep: 43
extend+tolist() time: 0.00213623046875

Evaluating:  19%|█▉        | 44/228 [00:19<01:21,  2.26it/s][Astep: 44
extend+tolist() time: 0.0010886192321777344

Evaluating:  20%|█▉        | 45/228 [00:19<01:20,  2.27it/s][Astep: 45
extend+tolist() time: 0.0016300678253173828

Evaluating:  20%|██        | 46/228 [00:20<01:18,  2.30it/s][Astep: 46
extend+tolist() time: 0.0012352466583251953

Evaluating:  21%|██        | 47/228 [00:20<01:18,  2.31it/s][Astep: 47
extend+tolist() time: 0.0015697479248046875

Evaluating:  21%|██        | 48/228 [00:21<01:19,  2.27it/s][Astep: 48
extend+tolist() time: 0.001611948013305664

Evaluating:  21%|██▏       | 49/228 [00:21<01:17,  2.31it/s][Astep: 49
extend+tolist() time: 0.0009400844573974609

Evaluating:  22%|██▏       | 50/228 [00:21<01:17,  2.29it/s][Astep: 50
extend+tolist() time: 0.0011944770812988281

Evaluating:  22%|██▏       | 51/228 [00:22<01:17,  2.29it/s][Astep: 51
extend+tolist() time: 0.0016865730285644531

Evaluating:  23%|██▎       | 52/228 [00:22<01:17,  2.27it/s][Astep: 52
extend+tolist() time: 0.0013811588287353516

Evaluating:  23%|██▎       | 53/228 [00:23<01:24,  2.08it/s][Astep: 53
extend+tolist() time: 0.0016913414001464844

Evaluating:  24%|██▎       | 54/228 [00:23<01:22,  2.11it/s][Astep: 54
extend+tolist() time: 0.0008134841918945312

Evaluating:  24%|██▍       | 55/228 [00:24<01:18,  2.20it/s][Astep: 55
extend+tolist() time: 0.0012135505676269531

Evaluating:  25%|██▍       | 56/228 [00:24<01:16,  2.26it/s][Astep: 56
extend+tolist() time: 0.0011553764343261719

Evaluating:  25%|██▌       | 57/228 [00:25<01:16,  2.23it/s][Astep: 57
extend+tolist() time: 0.0010557174682617188

Evaluating:  25%|██▌       | 58/228 [00:25<01:13,  2.32it/s][Astep: 58
extend+tolist() time: 0.0008716583251953125

Evaluating:  26%|██▌       | 59/228 [00:25<01:13,  2.30it/s][Astep: 59
extend+tolist() time: 0.0013926029205322266

Evaluating:  26%|██▋       | 60/228 [00:26<01:12,  2.32it/s][Astep: 60
extend+tolist() time: 0.0009284019470214844

Evaluating:  27%|██▋       | 61/228 [00:26<01:11,  2.33it/s][Astep: 61
extend+tolist() time: 0.00127410888671875

Evaluating:  27%|██▋       | 62/228 [00:27<01:11,  2.33it/s][Astep: 62
extend+tolist() time: 0.0007927417755126953

Evaluating:  28%|██▊       | 63/228 [00:27<01:10,  2.34it/s][Astep: 63
extend+tolist() time: 0.0012402534484863281

Evaluating:  28%|██▊       | 64/228 [00:28<01:10,  2.31it/s][Astep: 64
extend+tolist() time: 0.0008313655853271484

Evaluating:  29%|██▊       | 65/228 [00:28<01:08,  2.37it/s][Astep: 65
extend+tolist() time: 0.0012390613555908203

Evaluating:  29%|██▉       | 66/228 [00:28<01:09,  2.32it/s][Astep: 66
extend+tolist() time: 0.0007560253143310547

Evaluating:  29%|██▉       | 67/228 [00:29<01:08,  2.33it/s][Astep: 67
extend+tolist() time: 0.2006545066833496

Evaluating:  30%|██▉       | 68/228 [00:29<01:17,  2.06it/s][Astep: 68
extend+tolist() time: 0.0011661052703857422

Evaluating:  30%|███       | 69/228 [00:30<01:14,  2.15it/s][Astep: 69
extend+tolist() time: 0.0011029243469238281

Evaluating:  31%|███       | 70/228 [00:30<01:11,  2.21it/s][Astep: 70
extend+tolist() time: 0.0014872550964355469

Evaluating:  31%|███       | 71/228 [00:31<01:10,  2.21it/s][Astep: 71
extend+tolist() time: 0.0013494491577148438

Evaluating:  32%|███▏      | 72/228 [00:31<01:09,  2.24it/s][Astep: 72
extend+tolist() time: 0.0007848739624023438

Evaluating:  32%|███▏      | 73/228 [00:32<01:09,  2.23it/s][Astep: 73
extend+tolist() time: 0.0009472370147705078

Evaluating:  32%|███▏      | 74/228 [00:32<01:06,  2.30it/s][Astep: 74
extend+tolist() time: 0.0007565021514892578

Evaluating:  33%|███▎      | 75/228 [00:33<01:07,  2.26it/s][Astep: 75
extend+tolist() time: 0.0017440319061279297

Evaluating:  33%|███▎      | 76/228 [00:33<01:06,  2.28it/s][Astep: 76
extend+tolist() time: 0.0006511211395263672

Evaluating:  34%|███▍      | 77/228 [00:34<01:14,  2.02it/s][Astep: 77
extend+tolist() time: 0.0018544197082519531

Evaluating:  34%|███▍      | 78/228 [00:34<01:11,  2.09it/s][Astep: 78
extend+tolist() time: 0.0012164115905761719

Evaluating:  35%|███▍      | 79/228 [00:34<01:09,  2.15it/s][Astep: 79
extend+tolist() time: 0.0012755393981933594

Evaluating:  35%|███▌      | 80/228 [00:35<01:06,  2.23it/s][Astep: 80
extend+tolist() time: 0.0009417533874511719

Evaluating:  36%|███▌      | 81/228 [00:35<01:05,  2.25it/s][Astep: 81
extend+tolist() time: 0.0013072490692138672

Evaluating:  36%|███▌      | 82/228 [00:36<01:04,  2.25it/s][Astep: 82
extend+tolist() time: 0.0008296966552734375

Evaluating:  36%|███▋      | 83/228 [00:36<01:02,  2.33it/s][Astep: 83
extend+tolist() time: 0.001157522201538086

Evaluating:  37%|███▋      | 84/228 [00:37<01:02,  2.31it/s][Astep: 84
extend+tolist() time: 0.0009419918060302734

Evaluating:  37%|███▋      | 85/228 [00:37<01:01,  2.34it/s][Astep: 85
extend+tolist() time: 0.0013508796691894531

Evaluating:  38%|███▊      | 86/228 [00:37<01:00,  2.37it/s][Astep: 86
extend+tolist() time: 0.0008921623229980469

Evaluating:  38%|███▊      | 87/228 [00:38<01:00,  2.32it/s][Astep: 87
extend+tolist() time: 0.0013267993927001953

Evaluating:  39%|███▊      | 88/228 [00:38<00:59,  2.37it/s][Astep: 88
extend+tolist() time: 0.001093149185180664

Evaluating:  39%|███▉      | 89/228 [00:39<00:59,  2.34it/s][Astep: 89
extend+tolist() time: 0.0007181167602539062

Evaluating:  39%|███▉      | 90/228 [00:39<00:58,  2.37it/s][Astep: 90
extend+tolist() time: 0.0013785362243652344

Evaluating:  40%|███▉      | 91/228 [00:40<00:58,  2.36it/s][Astep: 91
extend+tolist() time: 0.0007510185241699219

Evaluating:  40%|████      | 92/228 [00:40<00:57,  2.37it/s][Astep: 92
extend+tolist() time: 0.0011892318725585938

Evaluating:  41%|████      | 93/228 [00:40<00:56,  2.39it/s][Astep: 93
extend+tolist() time: 0.0009815692901611328

Evaluating:  41%|████      | 94/228 [00:41<00:56,  2.36it/s][Astep: 94
extend+tolist() time: 0.0011742115020751953

Evaluating:  42%|████▏     | 95/228 [00:41<01:04,  2.05it/s][Astep: 95
extend+tolist() time: 0.0011556148529052734

Evaluating:  42%|████▏     | 96/228 [00:42<01:02,  2.12it/s][Astep: 96
extend+tolist() time: 0.0014214515686035156

Evaluating:  43%|████▎     | 97/228 [00:42<00:58,  2.23it/s][Astep: 97
extend+tolist() time: 0.0012061595916748047

Evaluating:  43%|████▎     | 98/228 [00:43<00:57,  2.24it/s][Astep: 98
extend+tolist() time: 0.000881195068359375

Evaluating:  43%|████▎     | 99/228 [00:43<00:56,  2.30it/s][Astep: 99
extend+tolist() time: 0.0013360977172851562

Evaluating:  44%|████▍     | 100/228 [00:44<00:54,  2.34it/s][Astep: 100
extend+tolist() time: 0.0007421970367431641

Evaluating:  44%|████▍     | 101/228 [00:44<00:54,  2.32it/s][Astep: 101
extend+tolist() time: 0.001233816146850586

Evaluating:  45%|████▍     | 102/228 [00:44<00:52,  2.39it/s][Astep: 102
extend+tolist() time: 0.0007102489471435547

Evaluating:  45%|████▌     | 103/228 [00:45<00:52,  2.36it/s][Astep: 103
extend+tolist() time: 0.0012149810791015625

Evaluating:  46%|████▌     | 104/228 [00:45<00:51,  2.39it/s][Astep: 104
extend+tolist() time: 0.0008845329284667969

Evaluating:  46%|████▌     | 105/228 [00:46<00:51,  2.40it/s][Astep: 105
extend+tolist() time: 0.0012805461883544922

Evaluating:  46%|████▋     | 106/228 [00:46<00:51,  2.37it/s][Astep: 106
extend+tolist() time: 0.0013217926025390625

Evaluating:  47%|████▋     | 107/228 [00:46<00:50,  2.39it/s][Astep: 107
extend+tolist() time: 0.0012218952178955078

Evaluating:  47%|████▋     | 108/228 [00:47<00:50,  2.38it/s][Astep: 108
extend+tolist() time: 0.0007805824279785156

Evaluating:  48%|████▊     | 109/228 [00:47<00:49,  2.40it/s][Astep: 109
extend+tolist() time: 0.0013012886047363281

Evaluating:  48%|████▊     | 110/228 [00:48<00:49,  2.37it/s][Astep: 110
extend+tolist() time: 0.0006117820739746094

Evaluating:  49%|████▊     | 111/228 [00:48<00:48,  2.41it/s][Astep: 111
extend+tolist() time: 0.0018436908721923828

Evaluating:  49%|████▉     | 112/228 [00:49<00:48,  2.39it/s][Astep: 112
extend+tolist() time: 0.000762939453125

Evaluating:  50%|████▉     | 113/228 [00:49<00:48,  2.36it/s][Astep: 113
extend+tolist() time: 0.1889479160308838

Evaluating:  50%|█████     | 114/228 [00:50<00:53,  2.13it/s][Astep: 114
extend+tolist() time: 0.0015523433685302734

Evaluating:  50%|█████     | 115/228 [00:50<00:52,  2.16it/s][Astep: 115
extend+tolist() time: 0.0006499290466308594

Evaluating:  51%|█████     | 116/228 [00:50<00:49,  2.27it/s][Astep: 116
extend+tolist() time: 0.0012166500091552734

Evaluating:  51%|█████▏    | 117/228 [00:51<00:48,  2.27it/s][Astep: 117
extend+tolist() time: 0.0008471012115478516

Evaluating:  52%|█████▏    | 118/228 [00:51<00:47,  2.31it/s][Astep: 118
extend+tolist() time: 0.00054931640625

Evaluating:  52%|█████▏    | 119/228 [00:52<00:46,  2.36it/s][Astep: 119
extend+tolist() time: 0.0007216930389404297

Evaluating:  53%|█████▎    | 120/228 [00:52<00:46,  2.34it/s][Astep: 120
extend+tolist() time: 0.0010862350463867188

Evaluating:  53%|█████▎    | 121/228 [00:52<00:44,  2.39it/s][Astep: 121
extend+tolist() time: 0.0007104873657226562

Evaluating:  54%|█████▎    | 122/228 [00:53<00:44,  2.36it/s][Astep: 122
extend+tolist() time: 0.0011625289916992188

Evaluating:  54%|█████▍    | 123/228 [00:53<00:43,  2.39it/s][Astep: 123
extend+tolist() time: 0.0009827613830566406

Evaluating:  54%|█████▍    | 124/228 [00:54<00:43,  2.41it/s][Astep: 124
extend+tolist() time: 0.00095367431640625

Evaluating:  55%|█████▍    | 125/228 [00:54<00:42,  2.40it/s][Astep: 125
extend+tolist() time: 0.0009286403656005859

Evaluating:  55%|█████▌    | 126/228 [00:55<00:41,  2.46it/s][Astep: 126
extend+tolist() time: 0.001882314682006836

Evaluating:  56%|█████▌    | 127/228 [00:55<00:48,  2.06it/s][Astep: 127
extend+tolist() time: 0.0015063285827636719

Evaluating:  56%|█████▌    | 128/228 [00:56<00:46,  2.17it/s][Astep: 128
extend+tolist() time: 0.0012595653533935547

Evaluating:  57%|█████▋    | 129/228 [00:56<00:45,  2.20it/s][Astep: 129
extend+tolist() time: 0.0008943080902099609

Evaluating:  57%|█████▋    | 130/228 [00:56<00:42,  2.29it/s][Astep: 130
extend+tolist() time: 0.0015053749084472656

Evaluating:  57%|█████▋    | 131/228 [00:57<00:42,  2.28it/s][Astep: 131
extend+tolist() time: 0.0005028247833251953

Evaluating:  58%|█████▊    | 132/228 [00:57<00:41,  2.33it/s][Astep: 132
extend+tolist() time: 0.0016138553619384766

Evaluating:  58%|█████▊    | 133/228 [00:58<00:40,  2.35it/s][Astep: 133
extend+tolist() time: 0.0005044937133789062

Evaluating:  59%|█████▉    | 134/228 [00:58<00:40,  2.33it/s][Astep: 134
extend+tolist() time: 0.00151824951171875

Evaluating:  59%|█████▉    | 135/228 [00:59<00:39,  2.34it/s][Astep: 135
extend+tolist() time: 0.0005071163177490234

Evaluating:  60%|█████▉    | 136/228 [00:59<00:39,  2.30it/s][Astep: 136
extend+tolist() time: 0.0013000965118408203

Evaluating:  60%|██████    | 137/228 [00:59<00:39,  2.33it/s][Astep: 137
extend+tolist() time: 0.00043582916259765625

Evaluating:  61%|██████    | 138/228 [01:00<00:39,  2.29it/s][Astep: 138
extend+tolist() time: 0.0008323192596435547

Evaluating:  61%|██████    | 139/228 [01:00<00:37,  2.34it/s][Astep: 139
extend+tolist() time: 0.0004899501800537109

Evaluating:  61%|██████▏   | 140/228 [01:01<00:38,  2.31it/s][Astep: 140
extend+tolist() time: 0.0013320446014404297

Evaluating:  62%|██████▏   | 141/228 [01:01<00:38,  2.28it/s][Astep: 141
extend+tolist() time: 0.0008585453033447266

Evaluating:  62%|██████▏   | 142/228 [01:02<00:36,  2.35it/s][Astep: 142
extend+tolist() time: 0.0010678768157958984

Evaluating:  63%|██████▎   | 143/228 [01:02<00:36,  2.30it/s][Astep: 143
extend+tolist() time: 0.000377655029296875

Evaluating:  63%|██████▎   | 144/228 [01:02<00:35,  2.35it/s][Astep: 144
extend+tolist() time: 0.0010216236114501953

Evaluating:  64%|██████▎   | 145/228 [01:03<00:35,  2.34it/s][Astep: 145
extend+tolist() time: 0.0009357929229736328

Evaluating:  64%|██████▍   | 146/228 [01:03<00:34,  2.35it/s][Astep: 146
extend+tolist() time: 0.0004177093505859375

Evaluating:  64%|██████▍   | 147/228 [01:04<00:33,  2.40it/s][Astep: 147
extend+tolist() time: 0.0008132457733154297

Evaluating:  65%|██████▍   | 148/228 [01:04<00:34,  2.34it/s][Astep: 148
extend+tolist() time: 0.001142740249633789

Evaluating:  65%|██████▌   | 149/228 [01:05<00:33,  2.37it/s][Astep: 149
extend+tolist() time: 0.00041484832763671875

Evaluating:  66%|██████▌   | 150/228 [01:05<00:33,  2.33it/s][Astep: 150
extend+tolist() time: 0.0009365081787109375

Evaluating:  66%|██████▌   | 151/228 [01:05<00:32,  2.37it/s][Astep: 151
extend+tolist() time: 0.0011296272277832031

Evaluating:  67%|██████▋   | 152/228 [01:06<00:32,  2.37it/s][Astep: 152
extend+tolist() time: 0.0008690357208251953

Evaluating:  67%|██████▋   | 153/228 [01:06<00:31,  2.35it/s][Astep: 153
extend+tolist() time: 0.0014345645904541016

Evaluating:  68%|██████▊   | 154/228 [01:07<00:30,  2.40it/s][Astep: 154
extend+tolist() time: 0.002046823501586914

Evaluating:  68%|██████▊   | 155/228 [01:07<00:31,  2.31it/s][Astep: 155
extend+tolist() time: 0.0006778240203857422

Evaluating:  68%|██████▊   | 156/228 [01:08<00:30,  2.34it/s][Astep: 156
extend+tolist() time: 0.0005841255187988281

Evaluating:  69%|██████▉   | 157/228 [01:08<00:35,  2.03it/s][Astep: 157
extend+tolist() time: 0.0011217594146728516

Evaluating:  69%|██████▉   | 158/228 [01:09<00:32,  2.14it/s][Astep: 158
extend+tolist() time: 0.0005304813385009766

Evaluating:  70%|██████▉   | 159/228 [01:09<00:31,  2.17it/s][Astep: 159
extend+tolist() time: 0.0007827281951904297

Evaluating:  70%|███████   | 160/228 [01:09<00:30,  2.24it/s][Astep: 160
extend+tolist() time: 0.0010457038879394531

Evaluating:  71%|███████   | 161/228 [01:10<00:29,  2.28it/s][Astep: 161
extend+tolist() time: 0.0008244514465332031

Evaluating:  71%|███████   | 162/228 [01:10<00:28,  2.28it/s][Astep: 162
extend+tolist() time: 0.0005354881286621094

Evaluating:  71%|███████▏  | 163/228 [01:11<00:27,  2.34it/s][Astep: 163
extend+tolist() time: 0.00045418739318847656

Evaluating:  72%|███████▏  | 164/228 [01:11<00:27,  2.34it/s][Astep: 164
extend+tolist() time: 0.0010313987731933594

Evaluating:  72%|███████▏  | 165/228 [01:12<00:26,  2.38it/s][Astep: 165
extend+tolist() time: 0.0004947185516357422

Evaluating:  73%|███████▎  | 166/228 [01:12<00:25,  2.41it/s][Astep: 166
extend+tolist() time: 0.0003952980041503906

Evaluating:  73%|███████▎  | 167/228 [01:12<00:25,  2.38it/s][Astep: 167
extend+tolist() time: 0.0006146430969238281

Evaluating:  74%|███████▎  | 168/228 [01:13<00:24,  2.43it/s][Astep: 168
extend+tolist() time: 0.0017042160034179688

Evaluating:  74%|███████▍  | 169/228 [01:13<00:24,  2.38it/s][Astep: 169
extend+tolist() time: 0.0003879070281982422

Evaluating:  75%|███████▍  | 170/228 [01:14<00:24,  2.40it/s][Astep: 170
extend+tolist() time: 0.0013499259948730469

Evaluating:  75%|███████▌  | 171/228 [01:14<00:23,  2.42it/s][Astep: 171
extend+tolist() time: 0.00032591819763183594

Evaluating:  75%|███████▌  | 172/228 [01:14<00:23,  2.40it/s][Astep: 172
extend+tolist() time: 0.000835418701171875

Evaluating:  76%|███████▌  | 173/228 [01:15<00:22,  2.46it/s][Astep: 173
extend+tolist() time: 0.00165557861328125

Evaluating:  76%|███████▋  | 174/228 [01:15<00:22,  2.40it/s][Astep: 174
extend+tolist() time: 0.001878499984741211

Evaluating:  77%|███████▋  | 175/228 [01:16<00:22,  2.41it/s][Astep: 175
extend+tolist() time: 0.0010149478912353516

Evaluating:  77%|███████▋  | 176/228 [01:16<00:21,  2.43it/s][Astep: 176
extend+tolist() time: 0.0010595321655273438

Evaluating:  78%|███████▊  | 177/228 [01:16<00:20,  2.44it/s][Astep: 177
extend+tolist() time: 0.0006279945373535156

Evaluating:  78%|███████▊  | 178/228 [01:17<00:20,  2.49it/s][Astep: 178
extend+tolist() time: 0.0016429424285888672

Evaluating:  79%|███████▊  | 179/228 [01:17<00:20,  2.42it/s][Astep: 179
extend+tolist() time: 0.0004336833953857422

Evaluating:  79%|███████▉  | 180/228 [01:18<00:19,  2.45it/s][Astep: 180
extend+tolist() time: 0.0006093978881835938

Evaluating:  79%|███████▉  | 181/228 [01:18<00:19,  2.45it/s][Astep: 181
extend+tolist() time: 0.0006253719329833984

Evaluating:  80%|███████▉  | 182/228 [01:19<00:18,  2.45it/s][Astep: 182
extend+tolist() time: 0.0012440681457519531

Evaluating:  80%|████████  | 183/228 [01:19<00:17,  2.50it/s][Astep: 183
extend+tolist() time: 0.0006377696990966797

Evaluating:  81%|████████  | 184/228 [01:19<00:17,  2.45it/s][Astep: 184
extend+tolist() time: 0.0004668235778808594

Evaluating:  81%|████████  | 185/228 [01:20<00:17,  2.48it/s][Astep: 185
extend+tolist() time: 0.0018038749694824219

Evaluating:  82%|████████▏ | 186/228 [01:20<00:17,  2.44it/s][Astep: 186
extend+tolist() time: 0.001384735107421875

Evaluating:  82%|████████▏ | 187/228 [01:21<00:16,  2.43it/s][Astep: 187
extend+tolist() time: 0.0004744529724121094

Evaluating:  82%|████████▏ | 188/228 [01:21<00:16,  2.48it/s][Astep: 188
extend+tolist() time: 0.0007340908050537109

Evaluating:  83%|████████▎ | 189/228 [01:21<00:16,  2.42it/s][Astep: 189
extend+tolist() time: 0.0003731250762939453

Evaluating:  83%|████████▎ | 190/228 [01:22<00:15,  2.44it/s][Astep: 190
extend+tolist() time: 0.001697540283203125

Evaluating:  84%|████████▍ | 191/228 [01:22<00:15,  2.37it/s][Astep: 191
extend+tolist() time: 0.0007088184356689453

Evaluating:  84%|████████▍ | 192/228 [01:23<00:15,  2.39it/s][Astep: 192
extend+tolist() time: 0.0008637905120849609

Evaluating:  85%|████████▍ | 193/228 [01:23<00:14,  2.38it/s][Astep: 193
extend+tolist() time: 0.28469014167785645

Evaluating:  85%|████████▌ | 194/228 [01:24<00:17,  1.96it/s][Astep: 194
extend+tolist() time: 0.0010318756103515625

Evaluating:  86%|████████▌ | 195/228 [01:24<00:15,  2.10it/s][Astep: 195
extend+tolist() time: 0.0005097389221191406

Evaluating:  86%|████████▌ | 196/228 [01:25<00:14,  2.19it/s][Astep: 196
extend+tolist() time: 0.0006005764007568359

Evaluating:  86%|████████▋ | 197/228 [01:25<00:13,  2.27it/s][Astep: 197
extend+tolist() time: 0.0010123252868652344

Evaluating:  87%|████████▋ | 198/228 [01:25<00:13,  2.29it/s][Astep: 198
extend+tolist() time: 0.0006077289581298828

Evaluating:  87%|████████▋ | 199/228 [01:26<00:12,  2.29it/s][Astep: 199
extend+tolist() time: 0.0018765926361083984

Evaluating:  88%|████████▊ | 200/228 [01:26<00:12,  2.28it/s][Astep: 200
extend+tolist() time: 0.0006954669952392578

Evaluating:  88%|████████▊ | 201/228 [01:27<00:11,  2.29it/s][Astep: 201
extend+tolist() time: 0.0009908676147460938

Evaluating:  89%|████████▊ | 202/228 [01:27<00:11,  2.34it/s][Astep: 202
extend+tolist() time: 0.0004105567932128906

Evaluating:  89%|████████▉ | 203/228 [01:28<00:10,  2.35it/s][Astep: 203
extend+tolist() time: 0.0005061626434326172

Evaluating:  89%|████████▉ | 204/228 [01:28<00:10,  2.35it/s][Astep: 204
extend+tolist() time: 0.00040984153747558594

Evaluating:  90%|████████▉ | 205/228 [01:28<00:09,  2.34it/s][Astep: 205
extend+tolist() time: 0.0003039836883544922

Evaluating:  90%|█████████ | 206/228 [01:29<00:09,  2.39it/s][Astep: 206
extend+tolist() time: 0.0010569095611572266

Evaluating:  91%|█████████ | 207/228 [01:29<00:08,  2.41it/s][Astep: 207
extend+tolist() time: 0.0006127357482910156

Evaluating:  91%|█████████ | 208/228 [01:30<00:08,  2.38it/s][Astep: 208
extend+tolist() time: 0.0006861686706542969

Evaluating:  92%|█████████▏| 209/228 [01:30<00:07,  2.43it/s][Astep: 209
extend+tolist() time: 0.0010154247283935547

Evaluating:  92%|█████████▏| 210/228 [01:31<00:07,  2.36it/s][Astep: 210
extend+tolist() time: 0.0005981922149658203

Evaluating:  93%|█████████▎| 211/228 [01:31<00:07,  2.39it/s][Astep: 211
extend+tolist() time: 0.001714468002319336

Evaluating:  93%|█████████▎| 212/228 [01:31<00:06,  2.38it/s][Astep: 212
extend+tolist() time: 0.0008931159973144531

Evaluating:  93%|█████████▎| 213/228 [01:32<00:07,  1.99it/s][Astep: 213
extend+tolist() time: 0.0011491775512695312

Evaluating:  94%|█████████▍| 214/228 [01:32<00:06,  2.09it/s][Astep: 214
extend+tolist() time: 0.0008220672607421875

Evaluating:  94%|█████████▍| 215/228 [01:33<00:05,  2.18it/s][Astep: 215
extend+tolist() time: 0.0006651878356933594

Evaluating:  95%|█████████▍| 216/228 [01:33<00:05,  2.27it/s][Astep: 216
extend+tolist() time: 0.0005505084991455078

Evaluating:  95%|█████████▌| 217/228 [01:34<00:04,  2.29it/s][Astep: 217
extend+tolist() time: 0.0005495548248291016

Evaluating:  96%|█████████▌| 218/228 [01:34<00:04,  2.38it/s][Astep: 218
extend+tolist() time: 0.0014429092407226562

Evaluating:  96%|█████████▌| 219/228 [01:35<00:03,  2.35it/s][Astep: 219
extend+tolist() time: 0.0004904270172119141

Evaluating:  96%|█████████▋| 220/228 [01:35<00:03,  2.40it/s][Astep: 220
extend+tolist() time: 0.00038933753967285156

Evaluating:  97%|█████████▋| 221/228 [01:35<00:02,  2.43it/s][Astep: 221
extend+tolist() time: 0.0006220340728759766

Evaluating:  97%|█████████▋| 222/228 [01:36<00:02,  2.38it/s][Astep: 222
extend+tolist() time: 0.0004165172576904297

Evaluating:  98%|█████████▊| 223/228 [01:36<00:02,  2.44it/s][Astep: 223
extend+tolist() time: 0.0003952980041503906

Evaluating:  98%|█████████▊| 224/228 [01:37<00:01,  2.40it/s][Astep: 224
extend+tolist() time: 0.0003814697265625

Evaluating:  99%|█████████▊| 225/228 [01:37<00:01,  2.43it/s][Astep: 225
extend+tolist() time: 0.0004246234893798828

Evaluating:  99%|█████████▉| 226/228 [01:37<00:00,  2.43it/s][Astep: 226
extend+tolist() time: 0.0009951591491699219

Evaluating: 100%|█████████▉| 227/228 [01:38<00:00,  2.39it/s][Astep: 227
extend+tolist() time: 0.0004906654357910156

Evaluating: 100%|██████████| 228/228 [01:38<00:00,  2.38it/s][A09/08/2023 21:55:56 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 21:55:56 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:55:56 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:55:56 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:55:56 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 21:55:56 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:55:56 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:55:56 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:55:56 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 21:55:56 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:55:57 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:55:57 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:55:57 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 21:55:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-b564ccc8-b8df-4f02-886e-d90628b0543e-1-0.arrow
09/08/2023 21:55:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:55:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 21:55:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:41<00:00,  2.26it/s]
09/08/2023 21:55:58 - INFO - __main__ -   Step: 1400, Validation Metrics: {'pred_1_num': 9776, 'pred_-1_num': 906, 'pred_0_num': 119, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7927043792241459, 'f1_micro': 0.7927043792241458, 'f1_macro': 0.4467008619145005, 'f1_weighted': 0.7579246168465549, 'f1_-1': 0.34870550161812297, 'f1_0': 0.11081794195250662, 'f1_1': 0.8805791421728718, 'precision_micro': 0.7927043792241459, 'precision_macro': 0.5520310497719138, 'precision_weighted': 0.7483686855020504, 'precision_-1': 0.4757174392935982, 'precision_0': 0.35294117647058826, 'precision_1': 0.8274345335515548, 'recall_micro': 0.7927043792241459, 'recall_macro': 0.4273234258443918, 'recall_weighted': 0.7927043792241459, 'recall_-1': 0.27522349936143037, 'recall_0': 0.06572769953051644, 'recall_1': 0.9410190786412285, 'roc_auc_micro': 0.9144887013851284, 'roc_auc_macro': 0.761580695565467, 'roc_auc_weighted': 0.7397890276938359, 'roc_auc_-1': 0.8220296832874545, 'roc_auc_0': 0.7377545576989237, 'roc_auc_1': 0.7249578457100229}
[2023-09-08 21:56:19,049] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1401/66600 [33:28<919:37:40, 50.78s/it]09/08/2023 21:56:19 - INFO - __main__ -   Step: 1401, LR: 1.4029290274126925e-05, Loss: 0.3491605520248413
[2023-09-08 21:56:40,116] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1402/66600 [33:49<758:11:24, 41.86s/it]09/08/2023 21:56:40 - INFO - __main__ -   Step: 1402, LR: 1.4039304043059208e-05, Loss: 0.36386027932167053
[2023-09-08 21:57:00,701] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1403/66600 [34:10<642:33:41, 35.48s/it]09/08/2023 21:57:00 - INFO - __main__ -   Step: 1403, LR: 1.404931781199149e-05, Loss: 0.3130966126918793
[2023-09-08 21:57:21,165] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1404/66600 [34:30<560:58:06, 30.98s/it]09/08/2023 21:57:21 - INFO - __main__ -   Step: 1404, LR: 1.4059331580923772e-05, Loss: 0.4544965922832489
[2023-09-08 21:57:42,138] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1405/66600 [34:51<506:36:54, 27.97s/it]09/08/2023 21:57:42 - INFO - __main__ -   Step: 1405, LR: 1.4069345349856053e-05, Loss: 0.4842213988304138
[2023-09-08 21:58:02,885] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1406/66600 [35:12<467:20:23, 25.81s/it]09/08/2023 21:58:02 - INFO - __main__ -   Step: 1406, LR: 1.4079359118788336e-05, Loss: 0.4128621518611908
[2023-09-08 21:58:24,086] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1407/66600 [35:33<442:18:46, 24.42s/it]09/08/2023 21:58:24 - INFO - __main__ -   Step: 1407, LR: 1.4089372887720616e-05, Loss: 0.39852720499038696
[2023-09-08 21:58:44,671] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1408/66600 [35:54<421:27:01, 23.27s/it]09/08/2023 21:58:44 - INFO - __main__ -   Step: 1408, LR: 1.4099386656652898e-05, Loss: 0.40925726294517517
[2023-09-08 21:59:04,719] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1409/66600 [36:14<403:55:03, 22.31s/it]09/08/2023 21:59:04 - INFO - __main__ -   Step: 1409, LR: 1.410940042558518e-05, Loss: 0.508446216583252
[2023-09-08 21:59:25,417] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1410/66600 [36:34<395:10:52, 21.82s/it]09/08/2023 21:59:25 - INFO - __main__ -   Step: 1410, LR: 1.4119414194517463e-05, Loss: 0.3636054992675781
[2023-09-08 21:59:45,765] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1411/66600 [36:55<387:09:48, 21.38s/it]09/08/2023 21:59:45 - INFO - __main__ -   Step: 1411, LR: 1.4129427963449745e-05, Loss: 0.390262246131897
[2023-09-08 22:00:05,963] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1412/66600 [37:15<380:43:52, 21.03s/it]09/08/2023 22:00:05 - INFO - __main__ -   Step: 1412, LR: 1.4139441732382026e-05, Loss: 0.3796040415763855
[2023-09-08 22:00:26,408] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1413/66600 [37:35<377:34:15, 20.85s/it]09/08/2023 22:00:26 - INFO - __main__ -   Step: 1413, LR: 1.414945550131431e-05, Loss: 0.398213267326355
[2023-09-08 22:00:46,445] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1414/66600 [37:55<373:08:11, 20.61s/it]09/08/2023 22:00:46 - INFO - __main__ -   Step: 1414, LR: 1.4159469270246591e-05, Loss: 0.38332676887512207
[2023-09-08 22:01:07,124] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1415/66600 [38:16<373:31:23, 20.63s/it]09/08/2023 22:01:07 - INFO - __main__ -   Step: 1415, LR: 1.4169483039178873e-05, Loss: 0.47703081369400024
[2023-09-08 22:01:27,256] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1416/66600 [38:36<370:49:05, 20.48s/it]09/08/2023 22:01:27 - INFO - __main__ -   Step: 1416, LR: 1.4179496808111154e-05, Loss: 0.4802536964416504
[2023-09-08 22:01:47,303] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1417/66600 [38:56<368:27:53, 20.35s/it]09/08/2023 22:01:47 - INFO - __main__ -   Step: 1417, LR: 1.4189510577043434e-05, Loss: 0.37193578481674194
[2023-09-08 22:02:07,661] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1418/66600 [39:17<368:30:12, 20.35s/it]09/08/2023 22:02:07 - INFO - __main__ -   Step: 1418, LR: 1.4199524345975717e-05, Loss: 0.4250115156173706
[2023-09-08 22:02:28,752] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1419/66600 [39:38<372:30:26, 20.57s/it]09/08/2023 22:02:28 - INFO - __main__ -   Step: 1419, LR: 1.4209538114907999e-05, Loss: 0.5019376873970032
[2023-09-08 22:02:49,512] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1420/66600 [39:59<373:30:49, 20.63s/it]09/08/2023 22:02:49 - INFO - __main__ -   Step: 1420, LR: 1.421955188384028e-05, Loss: 0.4159546494483948
09/08/2023 22:02:49 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.001764535903930664

Evaluating:   0%|          | 1/228 [00:00<01:53,  2.01it/s][Astep: 1
extend+tolist() time: 0.00102996826171875

Evaluating:   1%|          | 2/228 [00:00<01:38,  2.30it/s][Astep: 2
extend+tolist() time: 0.002151012420654297

Evaluating:   1%|▏         | 3/228 [00:01<01:36,  2.34it/s][Astep: 3
extend+tolist() time: 0.0018696784973144531

Evaluating:   2%|▏         | 4/228 [00:01<01:34,  2.37it/s][Astep: 4
extend+tolist() time: 0.0009698867797851562

Evaluating:   2%|▏         | 5/228 [00:02<01:32,  2.42it/s][Astep: 5
extend+tolist() time: 0.0023012161254882812

Evaluating:   3%|▎         | 6/228 [00:02<01:33,  2.37it/s][Astep: 6
extend+tolist() time: 0.002027273178100586

Evaluating:   3%|▎         | 7/228 [00:03<01:43,  2.14it/s][Astep: 7
extend+tolist() time: 0.15617847442626953

Evaluating:   4%|▎         | 8/228 [00:03<01:50,  1.99it/s][Astep: 8
extend+tolist() time: 0.0012276172637939453

Evaluating:   4%|▍         | 9/228 [00:04<01:42,  2.13it/s][Astep: 9
extend+tolist() time: 0.0007827281951904297

Evaluating:   4%|▍         | 10/228 [00:04<01:39,  2.20it/s][Astep: 10
extend+tolist() time: 0.0012462139129638672

Evaluating:   5%|▍         | 11/228 [00:04<01:34,  2.31it/s][Astep: 11
extend+tolist() time: 0.0005280971527099609

Evaluating:   5%|▌         | 12/228 [00:05<01:32,  2.34it/s][Astep: 12
extend+tolist() time: 0.0010249614715576172

Evaluating:   6%|▌         | 13/228 [00:05<01:29,  2.40it/s][Astep: 13
extend+tolist() time: 0.0005905628204345703

Evaluating:   6%|▌         | 14/228 [00:06<01:28,  2.42it/s][Astep: 14
extend+tolist() time: 0.0006043910980224609

Evaluating:   7%|▋         | 15/228 [00:06<01:28,  2.41it/s][Astep: 15
extend+tolist() time: 0.001055002212524414

Evaluating:   7%|▋         | 16/228 [00:06<01:26,  2.45it/s][Astep: 16
extend+tolist() time: 0.0006265640258789062

Evaluating:   7%|▋         | 17/228 [00:07<01:27,  2.41it/s][Astep: 17
extend+tolist() time: 0.0013191699981689453

Evaluating:   8%|▊         | 18/228 [00:07<01:37,  2.16it/s][Astep: 18
extend+tolist() time: 0.0011510848999023438

Evaluating:   8%|▊         | 19/228 [00:08<01:35,  2.19it/s][Astep: 19
extend+tolist() time: 0.0014386177062988281

Evaluating:   9%|▉         | 20/228 [00:08<01:33,  2.23it/s][Astep: 20
extend+tolist() time: 0.0007627010345458984

Evaluating:   9%|▉         | 21/228 [00:09<01:30,  2.29it/s][Astep: 21
extend+tolist() time: 0.0011081695556640625

Evaluating:  10%|▉         | 22/228 [00:09<01:30,  2.28it/s][Astep: 22
extend+tolist() time: 0.0007615089416503906

Evaluating:  10%|█         | 23/228 [00:10<01:27,  2.33it/s][Astep: 23
extend+tolist() time: 0.0011487007141113281

Evaluating:  11%|█         | 24/228 [00:10<01:27,  2.33it/s][Astep: 24
extend+tolist() time: 0.0010988712310791016

Evaluating:  11%|█         | 25/228 [00:10<01:26,  2.35it/s][Astep: 25
extend+tolist() time: 0.0018982887268066406

Evaluating:  11%|█▏        | 26/228 [00:11<01:26,  2.34it/s][Astep: 26
extend+tolist() time: 0.001094818115234375

Evaluating:  12%|█▏        | 27/228 [00:11<01:26,  2.32it/s][Astep: 27
extend+tolist() time: 0.0016620159149169922

Evaluating:  12%|█▏        | 28/228 [00:12<01:25,  2.33it/s][Astep: 28
extend+tolist() time: 0.0005476474761962891

Evaluating:  13%|█▎        | 29/228 [00:12<01:25,  2.33it/s][Astep: 29
extend+tolist() time: 0.0006856918334960938

Evaluating:  13%|█▎        | 30/228 [00:13<01:22,  2.39it/s][Astep: 30
extend+tolist() time: 0.0015692710876464844

Evaluating:  14%|█▎        | 31/228 [00:13<01:23,  2.37it/s][Astep: 31
extend+tolist() time: 0.0005750656127929688

Evaluating:  14%|█▍        | 32/228 [00:13<01:22,  2.39it/s][Astep: 32
extend+tolist() time: 0.0014255046844482422

Evaluating:  14%|█▍        | 33/228 [00:14<01:21,  2.38it/s][Astep: 33
extend+tolist() time: 0.0016620159149169922

Evaluating:  15%|█▍        | 34/228 [00:14<01:25,  2.27it/s][Astep: 34
extend+tolist() time: 0.0008890628814697266

Evaluating:  15%|█▌        | 35/228 [00:15<01:23,  2.32it/s][Astep: 35
extend+tolist() time: 0.0010991096496582031

Evaluating:  16%|█▌        | 36/228 [00:15<01:22,  2.33it/s][Astep: 36
extend+tolist() time: 0.0007727146148681641

Evaluating:  16%|█▌        | 37/228 [00:16<01:21,  2.36it/s][Astep: 37
extend+tolist() time: 0.0017764568328857422

Evaluating:  17%|█▋        | 38/228 [00:16<01:31,  2.08it/s][Astep: 38
extend+tolist() time: 0.0011227130889892578

Evaluating:  17%|█▋        | 39/228 [00:17<01:26,  2.19it/s][Astep: 39
extend+tolist() time: 0.0007481575012207031

Evaluating:  18%|█▊        | 40/228 [00:17<01:23,  2.26it/s][Astep: 40
extend+tolist() time: 0.0006339550018310547

Evaluating:  18%|█▊        | 41/228 [00:17<01:22,  2.27it/s][Astep: 41
extend+tolist() time: 0.1677556037902832

Evaluating:  18%|█▊        | 42/228 [00:18<01:29,  2.08it/s][Astep: 42
extend+tolist() time: 0.0017018318176269531

Evaluating:  19%|█▉        | 43/228 [00:18<01:26,  2.13it/s][Astep: 43
extend+tolist() time: 0.00177001953125

Evaluating:  19%|█▉        | 44/228 [00:19<01:23,  2.19it/s][Astep: 44
extend+tolist() time: 0.0012929439544677734

Evaluating:  20%|█▉        | 45/228 [00:19<01:21,  2.25it/s][Astep: 45
extend+tolist() time: 0.0012233257293701172

Evaluating:  20%|██        | 46/228 [00:20<01:18,  2.31it/s][Astep: 46
extend+tolist() time: 0.0016286373138427734

Evaluating:  21%|██        | 47/228 [00:20<01:19,  2.28it/s][Astep: 47
extend+tolist() time: 0.0014634132385253906

Evaluating:  21%|██        | 48/228 [00:21<01:17,  2.32it/s][Astep: 48
extend+tolist() time: 0.0015535354614257812

Evaluating:  21%|██▏       | 49/228 [00:21<01:26,  2.06it/s][Astep: 49
extend+tolist() time: 0.0009343624114990234

Evaluating:  22%|██▏       | 50/228 [00:22<01:21,  2.17it/s][Astep: 50
extend+tolist() time: 0.001199960708618164

Evaluating:  22%|██▏       | 51/228 [00:22<01:19,  2.23it/s][Astep: 51
extend+tolist() time: 0.0016601085662841797

Evaluating:  23%|██▎       | 52/228 [00:22<01:18,  2.23it/s][Astep: 52
extend+tolist() time: 0.0013642311096191406

Evaluating:  23%|██▎       | 53/228 [00:23<01:16,  2.29it/s][Astep: 53
extend+tolist() time: 0.0016553401947021484

Evaluating:  24%|██▎       | 54/228 [00:23<01:15,  2.30it/s][Astep: 54
extend+tolist() time: 0.0008130073547363281

Evaluating:  24%|██▍       | 55/228 [00:24<01:13,  2.34it/s][Astep: 55
extend+tolist() time: 0.0012156963348388672

Evaluating:  25%|██▍       | 56/228 [00:24<01:12,  2.38it/s][Astep: 56
extend+tolist() time: 0.0011620521545410156

Evaluating:  25%|██▌       | 57/228 [00:24<01:13,  2.34it/s][Astep: 57
extend+tolist() time: 0.0010485649108886719

Evaluating:  25%|██▌       | 58/228 [00:25<01:11,  2.38it/s][Astep: 58
extend+tolist() time: 0.0008666515350341797

Evaluating:  26%|██▌       | 59/228 [00:25<01:10,  2.40it/s][Astep: 59
extend+tolist() time: 0.0013508796691894531

Evaluating:  26%|██▋       | 60/228 [00:26<01:09,  2.43it/s][Astep: 60
extend+tolist() time: 0.0007257461547851562

Evaluating:  27%|██▋       | 61/228 [00:26<01:07,  2.47it/s][Astep: 61
extend+tolist() time: 0.001241445541381836

Evaluating:  27%|██▋       | 62/228 [00:27<01:08,  2.42it/s][Astep: 62
extend+tolist() time: 0.0007824897766113281

Evaluating:  28%|██▊       | 63/228 [00:27<01:07,  2.43it/s][Astep: 63
extend+tolist() time: 0.0012564659118652344

Evaluating:  28%|██▊       | 64/228 [00:27<01:07,  2.42it/s][Astep: 64
extend+tolist() time: 0.0007960796356201172

Evaluating:  29%|██▊       | 65/228 [00:28<01:06,  2.45it/s][Astep: 65
extend+tolist() time: 0.0012030601501464844

Evaluating:  29%|██▉       | 66/228 [00:28<01:05,  2.47it/s][Astep: 66
extend+tolist() time: 0.0007395744323730469

Evaluating:  29%|██▉       | 67/228 [00:29<01:06,  2.43it/s][Astep: 67
extend+tolist() time: 0.0013494491577148438

Evaluating:  30%|██▉       | 68/228 [00:29<01:05,  2.44it/s][Astep: 68
extend+tolist() time: 0.0006945133209228516

Evaluating:  30%|███       | 69/228 [00:29<01:04,  2.45it/s][Astep: 69
extend+tolist() time: 0.0015153884887695312

Evaluating:  31%|███       | 70/228 [00:30<01:04,  2.46it/s][Astep: 70
extend+tolist() time: 0.001468658447265625

Evaluating:  31%|███       | 71/228 [00:30<01:13,  2.15it/s][Astep: 71
extend+tolist() time: 0.0009584426879882812

Evaluating:  32%|███▏      | 72/228 [00:31<01:09,  2.25it/s][Astep: 72
extend+tolist() time: 0.0007889270782470703

Evaluating:  32%|███▏      | 73/228 [00:31<01:06,  2.34it/s][Astep: 73
extend+tolist() time: 0.0005018711090087891

Evaluating:  32%|███▏      | 74/228 [00:32<01:05,  2.34it/s][Astep: 74
extend+tolist() time: 0.001253366470336914

Evaluating:  33%|███▎      | 75/228 [00:32<01:03,  2.40it/s][Astep: 75
extend+tolist() time: 0.16650986671447754

Evaluating:  33%|███▎      | 76/228 [00:33<01:11,  2.14it/s][Astep: 76
extend+tolist() time: 0.0006339550018310547

Evaluating:  34%|███▍      | 77/228 [00:33<01:06,  2.25it/s][Astep: 77
extend+tolist() time: 0.0017821788787841797

Evaluating:  34%|███▍      | 78/228 [00:33<01:05,  2.29it/s][Astep: 78
extend+tolist() time: 0.0012619495391845703

Evaluating:  35%|███▍      | 79/228 [00:34<01:03,  2.36it/s][Astep: 79
extend+tolist() time: 0.0008707046508789062

Evaluating:  35%|███▌      | 80/228 [00:34<01:01,  2.40it/s][Astep: 80
extend+tolist() time: 0.0009348392486572266

Evaluating:  36%|███▌      | 81/228 [00:35<01:01,  2.38it/s][Astep: 81
extend+tolist() time: 0.0012576580047607422

Evaluating:  36%|███▌      | 82/228 [00:35<01:00,  2.42it/s][Astep: 82
extend+tolist() time: 0.0008413791656494141

Evaluating:  36%|███▋      | 83/228 [00:35<01:00,  2.41it/s][Astep: 83
extend+tolist() time: 0.001150369644165039

Evaluating:  37%|███▋      | 84/228 [00:36<00:58,  2.44it/s][Astep: 84
extend+tolist() time: 0.0009706020355224609

Evaluating:  37%|███▋      | 85/228 [00:36<00:58,  2.46it/s][Astep: 85
extend+tolist() time: 0.0013670921325683594

Evaluating:  38%|███▊      | 86/228 [00:37<00:58,  2.42it/s][Astep: 86
extend+tolist() time: 0.0008585453033447266

Evaluating:  38%|███▊      | 87/228 [00:37<00:57,  2.44it/s][Astep: 87
extend+tolist() time: 0.0008866786956787109

Evaluating:  39%|███▊      | 88/228 [00:38<01:05,  2.15it/s][Astep: 88
extend+tolist() time: 0.0011641979217529297

Evaluating:  39%|███▉      | 89/228 [00:38<01:01,  2.26it/s][Astep: 89
extend+tolist() time: 0.0007431507110595703

Evaluating:  39%|███▉      | 90/228 [00:38<00:59,  2.30it/s][Astep: 90
extend+tolist() time: 0.0013811588287353516

Evaluating:  40%|███▉      | 91/228 [00:39<00:58,  2.34it/s][Astep: 91
extend+tolist() time: 0.0007569789886474609

Evaluating:  40%|████      | 92/228 [00:39<00:57,  2.38it/s][Astep: 92
extend+tolist() time: 0.0012230873107910156

Evaluating:  41%|████      | 93/228 [00:40<00:57,  2.35it/s][Astep: 93
extend+tolist() time: 0.0009372234344482422

Evaluating:  41%|████      | 94/228 [00:40<00:56,  2.38it/s][Astep: 94
extend+tolist() time: 0.0010912418365478516

Evaluating:  42%|████▏     | 95/228 [00:41<00:56,  2.37it/s][Astep: 95
extend+tolist() time: 0.0011658668518066406

Evaluating:  42%|████▏     | 96/228 [00:41<00:55,  2.38it/s][Astep: 96
extend+tolist() time: 0.0013518333435058594

Evaluating:  43%|████▎     | 97/228 [00:41<00:54,  2.41it/s][Astep: 97
extend+tolist() time: 0.0011591911315917969

Evaluating:  43%|████▎     | 98/228 [00:42<00:54,  2.38it/s][Astep: 98
extend+tolist() time: 0.0008716583251953125

Evaluating:  43%|████▎     | 99/228 [00:42<00:53,  2.41it/s][Astep: 99
extend+tolist() time: 0.0012924671173095703

Evaluating:  44%|████▍     | 100/228 [00:43<00:52,  2.42it/s][Astep: 100
extend+tolist() time: 0.0007264614105224609

Evaluating:  44%|████▍     | 101/228 [00:43<00:51,  2.46it/s][Astep: 101
extend+tolist() time: 0.0012621879577636719

Evaluating:  45%|████▍     | 102/228 [00:43<00:50,  2.49it/s][Astep: 102
extend+tolist() time: 0.000732421875

Evaluating:  45%|████▌     | 103/228 [00:44<00:51,  2.43it/s][Astep: 103
extend+tolist() time: 0.0012013912200927734

Evaluating:  46%|████▌     | 104/228 [00:44<00:50,  2.47it/s][Astep: 104
extend+tolist() time: 0.0007414817810058594

Evaluating:  46%|████▌     | 105/228 [00:45<00:50,  2.45it/s][Astep: 105
extend+tolist() time: 0.001270294189453125

Evaluating:  46%|████▋     | 106/228 [00:45<00:49,  2.45it/s][Astep: 106
extend+tolist() time: 0.0012946128845214844

Evaluating:  47%|████▋     | 107/228 [00:45<00:49,  2.43it/s][Astep: 107
extend+tolist() time: 0.0007579326629638672

Evaluating:  47%|████▋     | 108/228 [00:46<00:50,  2.38it/s][Astep: 108
extend+tolist() time: 0.0011792182922363281

Evaluating:  48%|████▊     | 109/228 [00:46<00:49,  2.41it/s][Astep: 109
extend+tolist() time: 0.0008180141448974609

Evaluating:  48%|████▊     | 110/228 [00:47<00:49,  2.36it/s][Astep: 110
extend+tolist() time: 0.0006248950958251953

Evaluating:  49%|████▊     | 111/228 [00:47<00:48,  2.43it/s][Astep: 111
extend+tolist() time: 0.0018529891967773438

Evaluating:  49%|████▉     | 112/228 [00:48<00:48,  2.39it/s][Astep: 112
extend+tolist() time: 0.000759124755859375

Evaluating:  50%|████▉     | 113/228 [00:48<00:47,  2.42it/s][Astep: 113
extend+tolist() time: 0.0007085800170898438

Evaluating:  50%|█████     | 114/228 [00:48<00:46,  2.43it/s][Astep: 114
extend+tolist() time: 0.001556396484375

Evaluating:  50%|█████     | 115/228 [00:49<00:48,  2.35it/s][Astep: 115
extend+tolist() time: 0.0006556510925292969

Evaluating:  51%|█████     | 116/228 [00:49<00:46,  2.41it/s][Astep: 116
extend+tolist() time: 0.0012388229370117188

Evaluating:  51%|█████▏    | 117/228 [00:50<00:46,  2.38it/s][Astep: 117
extend+tolist() time: 0.0008523464202880859

Evaluating:  52%|█████▏    | 118/228 [00:50<00:45,  2.40it/s][Astep: 118
extend+tolist() time: 0.0010123252868652344

Evaluating:  52%|█████▏    | 119/228 [00:51<00:52,  2.06it/s][Astep: 119
extend+tolist() time: 0.0007224082946777344

Evaluating:  53%|█████▎    | 120/228 [00:51<00:49,  2.16it/s][Astep: 120
extend+tolist() time: 0.0006341934204101562

Evaluating:  53%|█████▎    | 121/228 [00:52<00:47,  2.25it/s][Astep: 121
extend+tolist() time: 0.0011336803436279297

Evaluating:  54%|█████▎    | 122/228 [00:52<00:46,  2.26it/s][Astep: 122
extend+tolist() time: 0.0006685256958007812

Evaluating:  54%|█████▍    | 123/228 [00:52<00:45,  2.33it/s][Astep: 123
extend+tolist() time: 0.0010423660278320312

Evaluating:  54%|█████▍    | 124/228 [00:53<00:44,  2.35it/s][Astep: 124
extend+tolist() time: 0.0008246898651123047

Evaluating:  55%|█████▍    | 125/228 [00:53<00:43,  2.37it/s][Astep: 125
extend+tolist() time: 0.00045013427734375

Evaluating:  55%|█████▌    | 126/228 [00:54<00:42,  2.40it/s][Astep: 126
extend+tolist() time: 0.00194549560546875

Evaluating:  56%|█████▌    | 127/228 [00:54<00:43,  2.33it/s][Astep: 127
extend+tolist() time: 0.2224886417388916

Evaluating:  56%|█████▌    | 128/228 [00:55<00:49,  2.02it/s][Astep: 128
extend+tolist() time: 0.001294851303100586

Evaluating:  57%|█████▋    | 129/228 [00:55<00:46,  2.14it/s][Astep: 129
extend+tolist() time: 0.0008406639099121094

Evaluating:  57%|█████▋    | 130/228 [00:55<00:44,  2.22it/s][Astep: 130
extend+tolist() time: 0.0014562606811523438

Evaluating:  57%|█████▋    | 131/228 [00:56<00:43,  2.25it/s][Astep: 131
extend+tolist() time: 0.0004820823669433594

Evaluating:  58%|█████▊    | 132/228 [00:56<00:40,  2.37it/s][Astep: 132
extend+tolist() time: 0.0016055107116699219

Evaluating:  58%|█████▊    | 133/228 [00:57<00:40,  2.36it/s][Astep: 133
extend+tolist() time: 0.0004975795745849609

Evaluating:  59%|█████▉    | 134/228 [00:57<00:38,  2.42it/s][Astep: 134
extend+tolist() time: 0.0014667510986328125

Evaluating:  59%|█████▉    | 135/228 [00:58<00:38,  2.43it/s][Astep: 135
extend+tolist() time: 0.0005152225494384766

Evaluating:  60%|█████▉    | 136/228 [00:58<00:38,  2.41it/s][Astep: 136
extend+tolist() time: 0.001361846923828125

Evaluating:  60%|██████    | 137/228 [00:58<00:36,  2.47it/s][Astep: 137
extend+tolist() time: 0.00040912628173828125

Evaluating:  61%|██████    | 138/228 [00:59<00:36,  2.44it/s][Astep: 138
extend+tolist() time: 0.0008168220520019531

Evaluating:  61%|██████    | 139/228 [00:59<00:36,  2.47it/s][Astep: 139
extend+tolist() time: 0.0005195140838623047

Evaluating:  61%|██████▏   | 140/228 [01:00<00:35,  2.50it/s][Astep: 140
extend+tolist() time: 0.0008795261383056641

Evaluating:  62%|██████▏   | 141/228 [01:00<00:35,  2.45it/s][Astep: 141
extend+tolist() time: 0.0008897781372070312

Evaluating:  62%|██████▏   | 142/228 [01:00<00:34,  2.51it/s][Astep: 142
extend+tolist() time: 0.0010986328125

Evaluating:  63%|██████▎   | 143/228 [01:01<00:33,  2.52it/s][Astep: 143
extend+tolist() time: 0.0003733634948730469

Evaluating:  63%|██████▎   | 144/228 [01:01<00:33,  2.49it/s][Astep: 144
extend+tolist() time: 0.0008313655853271484

Evaluating:  64%|██████▎   | 145/228 [01:02<00:33,  2.49it/s][Astep: 145
extend+tolist() time: 0.0009949207305908203

Evaluating:  64%|██████▍   | 146/228 [01:02<00:38,  2.11it/s][Astep: 146
extend+tolist() time: 0.0004162788391113281

Evaluating:  64%|██████▍   | 147/228 [01:03<00:36,  2.22it/s][Astep: 147
extend+tolist() time: 0.0008294582366943359

Evaluating:  65%|██████▍   | 148/228 [01:03<00:35,  2.24it/s][Astep: 148
extend+tolist() time: 0.0011763572692871094

Evaluating:  65%|██████▌   | 149/228 [01:03<00:33,  2.34it/s][Astep: 149
extend+tolist() time: 0.0004029273986816406

Evaluating:  66%|██████▌   | 150/228 [01:04<00:33,  2.34it/s][Astep: 150
extend+tolist() time: 0.0009217262268066406

Evaluating:  66%|██████▌   | 151/228 [01:04<00:32,  2.37it/s][Astep: 151
extend+tolist() time: 0.0011281967163085938

Evaluating:  67%|██████▋   | 152/228 [01:05<00:31,  2.40it/s][Astep: 152
extend+tolist() time: 0.00091552734375

Evaluating:  67%|██████▋   | 153/228 [01:05<00:31,  2.37it/s][Astep: 153
extend+tolist() time: 0.0014510154724121094

Evaluating:  68%|██████▊   | 154/228 [01:05<00:30,  2.40it/s][Astep: 154
extend+tolist() time: 0.0020401477813720703

Evaluating:  68%|██████▊   | 155/228 [01:06<00:30,  2.36it/s][Astep: 155
extend+tolist() time: 0.0007193088531494141

Evaluating:  68%|██████▊   | 156/228 [01:06<00:30,  2.40it/s][Astep: 156
extend+tolist() time: 0.0005779266357421875

Evaluating:  69%|██████▉   | 157/228 [01:07<00:29,  2.43it/s][Astep: 157
extend+tolist() time: 0.0011630058288574219

Evaluating:  69%|██████▉   | 158/228 [01:07<00:29,  2.39it/s][Astep: 158
extend+tolist() time: 0.0005083084106445312

Evaluating:  70%|██████▉   | 159/228 [01:08<00:28,  2.42it/s][Astep: 159
extend+tolist() time: 0.0007193088531494141

Evaluating:  70%|███████   | 160/228 [01:08<00:28,  2.41it/s][Astep: 160
extend+tolist() time: 0.0008213520050048828

Evaluating:  71%|███████   | 161/228 [01:08<00:27,  2.44it/s][Astep: 161
extend+tolist() time: 0.0007674694061279297

Evaluating:  71%|███████   | 162/228 [01:09<00:26,  2.45it/s][Astep: 162
extend+tolist() time: 0.0005140304565429688

Evaluating:  71%|███████▏  | 163/228 [01:09<00:26,  2.42it/s][Astep: 163
extend+tolist() time: 0.00042724609375

Evaluating:  72%|███████▏  | 164/228 [01:10<00:26,  2.46it/s][Astep: 164
extend+tolist() time: 0.0010695457458496094

Evaluating:  72%|███████▏  | 165/228 [01:10<00:25,  2.44it/s][Astep: 165
extend+tolist() time: 0.0004918575286865234

Evaluating:  73%|███████▎  | 166/228 [01:10<00:25,  2.46it/s][Astep: 166
extend+tolist() time: 0.0004119873046875

Evaluating:  73%|███████▎  | 167/228 [01:11<00:24,  2.46it/s][Astep: 167
extend+tolist() time: 0.0005924701690673828

Evaluating:  74%|███████▎  | 168/228 [01:11<00:24,  2.41it/s][Astep: 168
extend+tolist() time: 0.001237630844116211

Evaluating:  74%|███████▍  | 169/228 [01:12<00:24,  2.41it/s][Astep: 169
extend+tolist() time: 0.00038170814514160156

Evaluating:  75%|███████▍  | 170/228 [01:12<00:24,  2.40it/s][Astep: 170
extend+tolist() time: 0.001428842544555664

Evaluating:  75%|███████▌  | 171/228 [01:12<00:23,  2.41it/s][Astep: 171
extend+tolist() time: 0.0003020763397216797

Evaluating:  75%|███████▌  | 172/228 [01:13<00:22,  2.44it/s][Astep: 172
extend+tolist() time: 0.0008637905120849609

Evaluating:  76%|███████▌  | 173/228 [01:13<00:23,  2.38it/s][Astep: 173
extend+tolist() time: 0.0016100406646728516

Evaluating:  76%|███████▋  | 174/228 [01:14<00:22,  2.39it/s][Astep: 174
extend+tolist() time: 0.0018582344055175781

Evaluating:  77%|███████▋  | 175/228 [01:14<00:22,  2.35it/s][Astep: 175
extend+tolist() time: 0.0008039474487304688

Evaluating:  77%|███████▋  | 176/228 [01:15<00:21,  2.38it/s][Astep: 176
extend+tolist() time: 0.0010459423065185547

Evaluating:  78%|███████▊  | 177/228 [01:15<00:21,  2.36it/s][Astep: 177
extend+tolist() time: 0.00060272216796875

Evaluating:  78%|███████▊  | 178/228 [01:15<00:20,  2.40it/s][Astep: 178
extend+tolist() time: 0.0016613006591796875

Evaluating:  79%|███████▊  | 179/228 [01:16<00:20,  2.40it/s][Astep: 179
extend+tolist() time: 0.0004127025604248047

Evaluating:  79%|███████▉  | 180/228 [01:16<00:20,  2.37it/s][Astep: 180
extend+tolist() time: 0.0004067420959472656

Evaluating:  79%|███████▉  | 181/228 [01:17<00:19,  2.43it/s][Astep: 181
extend+tolist() time: 0.0006110668182373047

Evaluating:  80%|███████▉  | 182/228 [01:17<00:18,  2.42it/s][Astep: 182
extend+tolist() time: 0.001219034194946289

Evaluating:  80%|████████  | 183/228 [01:17<00:18,  2.44it/s][Astep: 183
extend+tolist() time: 0.00067138671875

Evaluating:  81%|████████  | 184/228 [01:18<00:17,  2.46it/s][Astep: 184
extend+tolist() time: 0.00047850608825683594

Evaluating:  81%|████████  | 185/228 [01:18<00:17,  2.41it/s][Astep: 185
extend+tolist() time: 0.0015988349914550781

Evaluating:  82%|████████▏ | 186/228 [01:19<00:17,  2.41it/s][Astep: 186
extend+tolist() time: 0.0013794898986816406

Evaluating:  82%|████████▏ | 187/228 [01:19<00:17,  2.38it/s][Astep: 187
extend+tolist() time: 0.0004379749298095703

Evaluating:  82%|████████▏ | 188/228 [01:20<00:16,  2.43it/s][Astep: 188
extend+tolist() time: 0.000736236572265625

Evaluating:  83%|████████▎ | 189/228 [01:20<00:15,  2.45it/s][Astep: 189
extend+tolist() time: 0.0003726482391357422

Evaluating:  83%|████████▎ | 190/228 [01:20<00:15,  2.43it/s][Astep: 190
extend+tolist() time: 0.0016903877258300781

Evaluating:  84%|████████▍ | 191/228 [01:21<00:15,  2.43it/s][Astep: 191
extend+tolist() time: 0.0006885528564453125

Evaluating:  84%|████████▍ | 192/228 [01:21<00:14,  2.42it/s][Astep: 192
extend+tolist() time: 0.0008075237274169922

Evaluating:  85%|████████▍ | 193/228 [01:22<00:14,  2.45it/s][Astep: 193
extend+tolist() time: 0.0010709762573242188

Evaluating:  85%|████████▌ | 194/228 [01:22<00:13,  2.44it/s][Astep: 194
extend+tolist() time: 0.0010263919830322266

Evaluating:  86%|████████▌ | 195/228 [01:22<00:13,  2.40it/s][Astep: 195
extend+tolist() time: 0.0005445480346679688

Evaluating:  86%|████████▌ | 196/228 [01:23<00:13,  2.41it/s][Astep: 196
extend+tolist() time: 0.0006093978881835938

Evaluating:  86%|████████▋ | 197/228 [01:23<00:12,  2.40it/s][Astep: 197
extend+tolist() time: 0.0006635189056396484

Evaluating:  87%|████████▋ | 198/228 [01:24<00:12,  2.41it/s][Astep: 198
extend+tolist() time: 0.0010962486267089844

Evaluating:  87%|████████▋ | 199/228 [01:24<00:12,  2.40it/s][Astep: 199
extend+tolist() time: 0.0018663406372070312

Evaluating:  88%|████████▊ | 200/228 [01:25<00:11,  2.36it/s][Astep: 200
extend+tolist() time: 0.000720977783203125

Evaluating:  88%|████████▊ | 201/228 [01:25<00:13,  2.02it/s][Astep: 201
extend+tolist() time: 0.0005984306335449219

Evaluating:  89%|████████▊ | 202/228 [01:26<00:12,  2.15it/s][Astep: 202
extend+tolist() time: 0.0008556842803955078

Evaluating:  89%|████████▉ | 203/228 [01:26<00:11,  2.22it/s][Astep: 203
extend+tolist() time: 0.0005214214324951172

Evaluating:  89%|████████▉ | 204/228 [01:26<00:10,  2.25it/s][Astep: 204
extend+tolist() time: 0.0003991127014160156

Evaluating:  90%|████████▉ | 205/228 [01:27<00:09,  2.30it/s][Astep: 205
extend+tolist() time: 0.0003108978271484375

Evaluating:  90%|█████████ | 206/228 [01:27<00:09,  2.35it/s][Astep: 206
extend+tolist() time: 0.0005834102630615234

Evaluating:  91%|█████████ | 207/228 [01:28<00:08,  2.42it/s][Astep: 207
extend+tolist() time: 0.0011086463928222656

Evaluating:  91%|█████████ | 208/228 [01:28<00:08,  2.45it/s][Astep: 208
extend+tolist() time: 0.0007350444793701172

Evaluating:  92%|█████████▏| 209/228 [01:28<00:07,  2.42it/s][Astep: 209
extend+tolist() time: 0.0005736351013183594

Evaluating:  92%|█████████▏| 210/228 [01:29<00:07,  2.45it/s][Astep: 210
extend+tolist() time: 0.001008749008178711

Evaluating:  93%|█████████▎| 211/228 [01:29<00:06,  2.44it/s][Astep: 211
extend+tolist() time: 0.0011212825775146484

Evaluating:  93%|█████████▎| 212/228 [01:30<00:06,  2.42it/s][Astep: 212
extend+tolist() time: 0.0013194084167480469

Evaluating:  93%|█████████▎| 213/228 [01:30<00:06,  2.44it/s][Astep: 213
extend+tolist() time: 0.0007355213165283203

Evaluating:  94%|█████████▍| 214/228 [01:31<00:05,  2.40it/s][Astep: 214
extend+tolist() time: 0.24440217018127441

Evaluating:  94%|█████████▍| 215/228 [01:31<00:06,  2.07it/s][Astep: 215
extend+tolist() time: 0.0006594657897949219

Evaluating:  95%|█████████▍| 216/228 [01:32<00:05,  2.15it/s][Astep: 216
extend+tolist() time: 0.0009703636169433594

Evaluating:  95%|█████████▌| 217/228 [01:32<00:04,  2.26it/s][Astep: 217
extend+tolist() time: 0.0005235671997070312

Evaluating:  96%|█████████▌| 218/228 [01:32<00:04,  2.32it/s][Astep: 218
extend+tolist() time: 0.001394510269165039

Evaluating:  96%|█████████▌| 219/228 [01:33<00:03,  2.37it/s][Astep: 219
extend+tolist() time: 0.00048351287841796875

Evaluating:  96%|█████████▋| 220/228 [01:33<00:03,  2.42it/s][Astep: 220
extend+tolist() time: 0.0004112720489501953

Evaluating:  97%|█████████▋| 221/228 [01:34<00:02,  2.40it/s][Astep: 221
extend+tolist() time: 0.0010116100311279297

Evaluating:  97%|█████████▋| 222/228 [01:34<00:02,  2.43it/s][Astep: 222
extend+tolist() time: 0.0004527568817138672

Evaluating:  98%|█████████▊| 223/228 [01:34<00:02,  2.44it/s][Astep: 223
extend+tolist() time: 0.00039196014404296875

Evaluating:  98%|█████████▊| 224/228 [01:35<00:01,  2.47it/s][Astep: 224
extend+tolist() time: 0.00039076805114746094

Evaluating:  99%|█████████▊| 225/228 [01:35<00:01,  2.50it/s][Astep: 225
extend+tolist() time: 0.0004525184631347656

Evaluating:  99%|█████████▉| 226/228 [01:36<00:00,  2.46it/s][Astep: 226
extend+tolist() time: 0.0009639263153076172

Evaluating: 100%|█████████▉| 227/228 [01:36<00:00,  2.49it/s][Astep: 227
extend+tolist() time: 0.0004761219024658203

Evaluating: 100%|██████████| 228/228 [01:36<00:00,  2.43it/s][A09/08/2023 22:04:26 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:04:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:04:28 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:04:28 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:38<00:00,  2.31it/s]
09/08/2023 22:04:28 - INFO - __main__ -   Step: 1420, Validation Metrics: {'pred_1_num': 9941, 'pred_-1_num': 765, 'pred_0_num': 95, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7988149245440237, 'f1_micro': 0.7988149245440238, 'f1_macro': 0.43797074171203293, 'f1_weighted': 0.7585209036091735, 'f1_-1': 0.3363363363363363, 'f1_0': 0.09264305177111717, 'f1_1': 0.8849328370286453, 'precision_micro': 0.7988149245440237, 'precision_macro': 0.5651269793697734, 'precision_weighted': 0.7520993861068711, 'precision_-1': 0.5124183006535947, 'precision_0': 0.35789473684210527, 'precision_1': 0.8250679006136203, 'recall_micro': 0.7988149245440237, 'recall_macro': 0.41923071676586215, 'recall_weighted': 0.7988149245440237, 'recall_-1': 0.2503192848020434, 'recall_0': 0.053208137715179966, 'recall_1': 0.954164727780363, 'roc_auc_micro': 0.8999970135846156, 'roc_auc_macro': 0.7219054345532495, 'roc_auc_weighted': 0.6881663952958825, 'roc_auc_-1': 0.7677998770572002, 'roc_auc_0': 0.7271558344798613, 'roc_auc_1': 0.6707605921226873}
[2023-09-08 22:04:49,247] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1421/66600 [41:58<911:48:29, 50.36s/it]09/08/2023 22:04:49 - INFO - __main__ -   Step: 1421, LR: 1.4229565652772564e-05, Loss: 0.3662222623825073
[2023-09-08 22:05:09,384] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1422/66600 [42:18<747:37:31, 41.29s/it]09/08/2023 22:05:09 - INFO - __main__ -   Step: 1422, LR: 1.4239579421704846e-05, Loss: 0.42762771248817444
[2023-09-08 22:05:29,748] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1423/66600 [42:39<633:56:21, 35.02s/it]09/08/2023 22:05:29 - INFO - __main__ -   Step: 1423, LR: 1.4249593190637127e-05, Loss: 0.4041611850261688
[2023-09-08 22:05:50,522] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1424/66600 [43:00<556:34:41, 30.74s/it]09/08/2023 22:05:50 - INFO - __main__ -   Step: 1424, LR: 1.425960695956941e-05, Loss: 0.38226139545440674
[2023-09-08 22:06:11,061] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1425/66600 [43:20<501:09:07, 27.68s/it]09/08/2023 22:06:11 - INFO - __main__ -   Step: 1425, LR: 1.4269620728501692e-05, Loss: 0.4049164354801178
[2023-09-08 22:06:31,052] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1426/66600 [43:40<459:22:40, 25.37s/it]09/08/2023 22:06:31 - INFO - __main__ -   Step: 1426, LR: 1.4279634497433972e-05, Loss: 0.4102778434753418
[2023-09-08 22:06:51,625] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1427/66600 [44:01<433:17:18, 23.93s/it]09/08/2023 22:06:51 - INFO - __main__ -   Step: 1427, LR: 1.4289648266366254e-05, Loss: 0.3997960388660431
[2023-09-08 22:07:11,471] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1428/66600 [44:21<411:04:57, 22.71s/it]09/08/2023 22:07:11 - INFO - __main__ -   Step: 1428, LR: 1.4299662035298537e-05, Loss: 0.386819064617157
[2023-09-08 22:07:32,277] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1429/66600 [44:41<400:45:11, 22.14s/it]09/08/2023 22:07:32 - INFO - __main__ -   Step: 1429, LR: 1.4309675804230818e-05, Loss: 0.42032280564308167
[2023-09-08 22:07:52,437] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1430/66600 [45:01<390:00:14, 21.54s/it]09/08/2023 22:07:52 - INFO - __main__ -   Step: 1430, LR: 1.43196895731631e-05, Loss: 0.3769065737724304
[2023-09-08 22:08:12,931] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1431/66600 [45:22<384:18:00, 21.23s/it]09/08/2023 22:08:12 - INFO - __main__ -   Step: 1431, LR: 1.4329703342095382e-05, Loss: 0.4231157600879669
[2023-09-08 22:08:33,045] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1432/66600 [45:42<378:14:02, 20.89s/it]09/08/2023 22:08:33 - INFO - __main__ -   Step: 1432, LR: 1.4339717111027665e-05, Loss: 0.3252715468406677
[2023-09-08 22:08:53,544] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1433/66600 [46:03<376:04:56, 20.78s/it]09/08/2023 22:08:53 - INFO - __main__ -   Step: 1433, LR: 1.4349730879959947e-05, Loss: 0.3303534984588623
[2023-09-08 22:09:13,628] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1434/66600 [46:23<372:19:19, 20.57s/it]09/08/2023 22:09:13 - INFO - __main__ -   Step: 1434, LR: 1.4359744648892228e-05, Loss: 0.3285510241985321
[2023-09-08 22:09:34,104] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1435/66600 [46:43<371:48:46, 20.54s/it]09/08/2023 22:09:34 - INFO - __main__ -   Step: 1435, LR: 1.4369758417824511e-05, Loss: 0.3790310025215149
[2023-09-08 22:09:54,248] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1436/66600 [47:03<369:39:05, 20.42s/it]09/08/2023 22:09:54 - INFO - __main__ -   Step: 1436, LR: 1.4379772186756791e-05, Loss: 0.3950802683830261
[2023-09-08 22:10:14,828] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1437/66600 [47:24<370:30:35, 20.47s/it]09/08/2023 22:10:14 - INFO - __main__ -   Step: 1437, LR: 1.4389785955689073e-05, Loss: 0.39037418365478516
[2023-09-08 22:10:35,501] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1438/66600 [47:45<371:36:40, 20.53s/it]09/08/2023 22:10:35 - INFO - __main__ -   Step: 1438, LR: 1.4399799724621355e-05, Loss: 0.4352632761001587
[2023-09-08 22:10:56,203] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1439/66600 [48:05<372:32:20, 20.58s/it]09/08/2023 22:10:56 - INFO - __main__ -   Step: 1439, LR: 1.4409813493553638e-05, Loss: 0.3991987109184265
[2023-09-08 22:11:17,378] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1440/66600 [48:26<375:45:13, 20.76s/it]09/08/2023 22:11:17 - INFO - __main__ -   Step: 1440, LR: 1.441982726248592e-05, Loss: 0.3419012725353241
09/08/2023 22:11:17 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.001832723617553711

Evaluating:   0%|          | 1/228 [00:00<01:49,  2.07it/s][Astep: 1
extend+tolist() time: 0.001054525375366211

Evaluating:   1%|          | 2/228 [00:00<01:39,  2.27it/s][Astep: 2
extend+tolist() time: 0.17576336860656738

Evaluating:   1%|▏         | 3/228 [00:01<01:55,  1.94it/s][Astep: 3
extend+tolist() time: 0.0019714832305908203

Evaluating:   2%|▏         | 4/228 [00:01<01:47,  2.09it/s][Astep: 4
extend+tolist() time: 0.0016374588012695312

Evaluating:   2%|▏         | 5/228 [00:02<01:41,  2.20it/s][Astep: 5
extend+tolist() time: 0.002007007598876953

Evaluating:   3%|▎         | 6/228 [00:02<01:38,  2.24it/s][Astep: 6
extend+tolist() time: 0.001901388168334961

Evaluating:   3%|▎         | 7/228 [00:03<01:37,  2.27it/s][Astep: 7
extend+tolist() time: 0.0009806156158447266

Evaluating:   4%|▎         | 8/228 [00:03<01:35,  2.30it/s][Astep: 8
extend+tolist() time: 0.0011792182922363281

Evaluating:   4%|▍         | 9/228 [00:04<01:33,  2.34it/s][Astep: 9
extend+tolist() time: 0.0008189678192138672

Evaluating:   4%|▍         | 10/228 [00:04<01:32,  2.36it/s][Astep: 10
extend+tolist() time: 0.0013194084167480469

Evaluating:   5%|▍         | 11/228 [00:04<01:33,  2.32it/s][Astep: 11
extend+tolist() time: 0.0005719661712646484

Evaluating:   5%|▌         | 12/228 [00:05<01:43,  2.09it/s][Astep: 12
extend+tolist() time: 0.0010662078857421875

Evaluating:   6%|▌         | 13/228 [00:05<01:40,  2.15it/s][Astep: 13
extend+tolist() time: 0.0005764961242675781

Evaluating:   6%|▌         | 14/228 [00:06<01:36,  2.22it/s][Astep: 14
extend+tolist() time: 0.0005466938018798828

Evaluating:   7%|▋         | 15/228 [00:06<01:34,  2.25it/s][Astep: 15
extend+tolist() time: 0.001049041748046875

Evaluating:   7%|▋         | 16/228 [00:07<01:32,  2.28it/s][Astep: 16
extend+tolist() time: 0.0006194114685058594

Evaluating:   7%|▋         | 17/228 [00:07<01:44,  2.02it/s][Astep: 17
extend+tolist() time: 0.0012998580932617188

Evaluating:   8%|▊         | 18/228 [00:08<01:39,  2.12it/s][Astep: 18
extend+tolist() time: 0.001171112060546875

Evaluating:   8%|▊         | 19/228 [00:08<01:36,  2.16it/s][Astep: 19
extend+tolist() time: 0.0014133453369140625

Evaluating:   9%|▉         | 20/228 [00:09<01:33,  2.22it/s][Astep: 20
extend+tolist() time: 0.0007307529449462891

Evaluating:   9%|▉         | 21/228 [00:09<01:31,  2.27it/s][Astep: 21
extend+tolist() time: 0.0016207695007324219

Evaluating:  10%|▉         | 22/228 [00:09<01:30,  2.29it/s][Astep: 22
extend+tolist() time: 0.0007398128509521484

Evaluating:  10%|█         | 23/228 [00:10<01:26,  2.36it/s][Astep: 23
extend+tolist() time: 0.0010957717895507812

Evaluating:  11%|█         | 24/228 [00:10<01:26,  2.36it/s][Astep: 24
extend+tolist() time: 0.001104593276977539

Evaluating:  11%|█         | 25/228 [00:11<01:25,  2.36it/s][Astep: 25
extend+tolist() time: 0.0021529197692871094

Evaluating:  11%|█▏        | 26/228 [00:11<01:26,  2.34it/s][Astep: 26
extend+tolist() time: 0.0010852813720703125

Evaluating:  12%|█▏        | 27/228 [00:12<01:23,  2.39it/s][Astep: 27
extend+tolist() time: 0.0016427040100097656

Evaluating:  12%|█▏        | 28/228 [00:12<01:22,  2.42it/s][Astep: 28
extend+tolist() time: 0.0003304481506347656

Evaluating:  13%|█▎        | 29/228 [00:12<01:23,  2.39it/s][Astep: 29
extend+tolist() time: 0.0006952285766601562

Evaluating:  13%|█▎        | 30/228 [00:13<01:22,  2.39it/s][Astep: 30
extend+tolist() time: 0.001519918441772461

Evaluating:  14%|█▎        | 31/228 [00:13<01:23,  2.36it/s][Astep: 31
extend+tolist() time: 0.0005652904510498047

Evaluating:  14%|█▍        | 32/228 [00:14<01:21,  2.40it/s][Astep: 32
extend+tolist() time: 0.19042491912841797

Evaluating:  14%|█▍        | 33/228 [00:14<01:31,  2.13it/s][Astep: 33
extend+tolist() time: 0.0017452239990234375

Evaluating:  15%|█▍        | 34/228 [00:15<01:29,  2.17it/s][Astep: 34
extend+tolist() time: 0.0012004375457763672

Evaluating:  15%|█▌        | 35/228 [00:15<01:26,  2.23it/s][Astep: 35
extend+tolist() time: 0.0006663799285888672

Evaluating:  16%|█▌        | 36/228 [00:15<01:24,  2.27it/s][Astep: 36
extend+tolist() time: 0.0012018680572509766

Evaluating:  16%|█▌        | 37/228 [00:16<01:22,  2.32it/s][Astep: 37
extend+tolist() time: 0.0016279220581054688

Evaluating:  17%|█▋        | 38/228 [00:16<01:23,  2.27it/s][Astep: 38
extend+tolist() time: 0.0007426738739013672

Evaluating:  17%|█▋        | 39/228 [00:17<01:21,  2.31it/s][Astep: 39
extend+tolist() time: 0.0011038780212402344

Evaluating:  18%|█▊        | 40/228 [00:17<01:20,  2.34it/s][Astep: 40
extend+tolist() time: 0.0006699562072753906

Evaluating:  18%|█▊        | 41/228 [00:18<01:20,  2.31it/s][Astep: 41
extend+tolist() time: 0.0008461475372314453

Evaluating:  18%|█▊        | 42/228 [00:18<01:18,  2.37it/s][Astep: 42
extend+tolist() time: 0.0017330646514892578

Evaluating:  19%|█▉        | 43/228 [00:18<01:19,  2.32it/s][Astep: 43
extend+tolist() time: 0.0019359588623046875

Evaluating:  19%|█▉        | 44/228 [00:19<01:19,  2.30it/s][Astep: 44
extend+tolist() time: 0.00115966796875

Evaluating:  20%|█▉        | 45/228 [00:20<01:28,  2.07it/s][Astep: 45
extend+tolist() time: 0.0016546249389648438

Evaluating:  20%|██        | 46/228 [00:20<01:24,  2.14it/s][Astep: 46
extend+tolist() time: 0.00125885009765625

Evaluating:  21%|██        | 47/228 [00:20<01:23,  2.16it/s][Astep: 47
extend+tolist() time: 0.0016438961029052734

Evaluating:  21%|██        | 48/228 [00:21<01:21,  2.21it/s][Astep: 48
extend+tolist() time: 0.001596212387084961

Evaluating:  21%|██▏       | 49/228 [00:21<01:32,  1.94it/s][Astep: 49
extend+tolist() time: 0.0009531974792480469

Evaluating:  22%|██▏       | 50/228 [00:22<01:26,  2.06it/s][Astep: 50
extend+tolist() time: 0.0011868476867675781

Evaluating:  22%|██▏       | 51/228 [00:22<01:24,  2.09it/s][Astep: 51
extend+tolist() time: 0.0016775131225585938

Evaluating:  23%|██▎       | 52/228 [00:23<01:21,  2.16it/s][Astep: 52
extend+tolist() time: 0.0013608932495117188

Evaluating:  23%|██▎       | 53/228 [00:23<01:18,  2.22it/s][Astep: 53
extend+tolist() time: 0.0016567707061767578

Evaluating:  24%|██▎       | 54/228 [00:24<01:18,  2.23it/s][Astep: 54
extend+tolist() time: 0.0008175373077392578

Evaluating:  24%|██▍       | 55/228 [00:24<01:15,  2.29it/s][Astep: 55
extend+tolist() time: 0.0011751651763916016

Evaluating:  25%|██▍       | 56/228 [00:24<01:14,  2.30it/s][Astep: 56
extend+tolist() time: 0.0011763572692871094

Evaluating:  25%|██▌       | 57/228 [00:25<01:13,  2.33it/s][Astep: 57
extend+tolist() time: 0.0012776851654052734

Evaluating:  25%|██▌       | 58/228 [00:25<01:13,  2.33it/s][Astep: 58
extend+tolist() time: 0.0008411407470703125

Evaluating:  26%|██▌       | 59/228 [00:26<01:11,  2.37it/s][Astep: 59
extend+tolist() time: 0.0013816356658935547

Evaluating:  26%|██▋       | 60/228 [00:26<01:09,  2.42it/s][Astep: 60
extend+tolist() time: 0.0007414817810058594

Evaluating:  27%|██▋       | 61/228 [00:27<01:10,  2.38it/s][Astep: 61
extend+tolist() time: 0.0012786388397216797

Evaluating:  27%|██▋       | 62/228 [00:27<01:09,  2.40it/s][Astep: 62
extend+tolist() time: 0.0007829666137695312

Evaluating:  28%|██▊       | 63/228 [00:27<01:09,  2.39it/s][Astep: 63
extend+tolist() time: 0.0012469291687011719

Evaluating:  28%|██▊       | 64/228 [00:28<01:07,  2.42it/s][Astep: 64
extend+tolist() time: 0.0008058547973632812

Evaluating:  29%|██▊       | 65/228 [00:28<01:06,  2.45it/s][Astep: 65
extend+tolist() time: 0.21756744384765625

Evaluating:  29%|██▉       | 66/228 [00:29<01:18,  2.08it/s][Astep: 66
extend+tolist() time: 0.0011131763458251953

Evaluating:  29%|██▉       | 67/228 [00:29<01:14,  2.17it/s][Astep: 67
extend+tolist() time: 0.0008988380432128906

Evaluating:  30%|██▉       | 68/228 [00:30<01:11,  2.23it/s][Astep: 68
extend+tolist() time: 0.001065969467163086

Evaluating:  30%|███       | 69/228 [00:30<01:09,  2.30it/s][Astep: 69
extend+tolist() time: 0.0011181831359863281

Evaluating:  31%|███       | 70/228 [00:31<01:09,  2.28it/s][Astep: 70
extend+tolist() time: 0.0010867118835449219

Evaluating:  31%|███       | 71/228 [00:31<01:07,  2.31it/s][Astep: 71
extend+tolist() time: 0.0014014244079589844

Evaluating:  32%|███▏      | 72/228 [00:31<01:06,  2.34it/s][Astep: 72
extend+tolist() time: 0.0008027553558349609

Evaluating:  32%|███▏      | 73/228 [00:32<01:05,  2.36it/s][Astep: 73
extend+tolist() time: 0.0009415149688720703

Evaluating:  32%|███▏      | 74/228 [00:32<01:04,  2.41it/s][Astep: 74
extend+tolist() time: 0.0007336139678955078

Evaluating:  33%|███▎      | 75/228 [00:33<01:04,  2.39it/s][Astep: 75
extend+tolist() time: 0.0018088817596435547

Evaluating:  33%|███▎      | 76/228 [00:33<01:03,  2.39it/s][Astep: 76
extend+tolist() time: 0.0006563663482666016

Evaluating:  34%|███▍      | 77/228 [00:33<01:02,  2.42it/s][Astep: 77
extend+tolist() time: 0.0019047260284423828

Evaluating:  34%|███▍      | 78/228 [00:34<01:02,  2.39it/s][Astep: 78
extend+tolist() time: 0.0012319087982177734

Evaluating:  35%|███▍      | 79/228 [00:34<01:01,  2.44it/s][Astep: 79
extend+tolist() time: 0.0012464523315429688

Evaluating:  35%|███▌      | 80/228 [00:35<01:10,  2.11it/s][Astep: 80
extend+tolist() time: 0.0009281635284423828

Evaluating:  36%|███▌      | 81/228 [00:35<01:05,  2.23it/s][Astep: 81
extend+tolist() time: 0.0012984275817871094

Evaluating:  36%|███▌      | 82/228 [00:36<01:04,  2.27it/s][Astep: 82
extend+tolist() time: 0.0008466243743896484

Evaluating:  36%|███▋      | 83/228 [00:36<01:02,  2.33it/s][Astep: 83
extend+tolist() time: 0.0011408329010009766

Evaluating:  37%|███▋      | 84/228 [00:36<01:00,  2.38it/s][Astep: 84
extend+tolist() time: 0.001004934310913086

Evaluating:  37%|███▋      | 85/228 [00:37<01:00,  2.37it/s][Astep: 85
extend+tolist() time: 0.0013959407806396484

Evaluating:  38%|███▊      | 86/228 [00:37<00:58,  2.44it/s][Astep: 86
extend+tolist() time: 0.0012543201446533203

Evaluating:  38%|███▊      | 87/228 [00:38<01:07,  2.10it/s][Astep: 87
extend+tolist() time: 0.0009100437164306641

Evaluating:  39%|███▊      | 88/228 [00:38<01:03,  2.21it/s][Astep: 88
extend+tolist() time: 0.0011897087097167969

Evaluating:  39%|███▉      | 89/228 [00:39<01:02,  2.24it/s][Astep: 89
extend+tolist() time: 0.0007228851318359375

Evaluating:  39%|███▉      | 90/228 [00:39<01:00,  2.28it/s][Astep: 90
extend+tolist() time: 0.0013537406921386719

Evaluating:  40%|███▉      | 91/228 [00:40<01:00,  2.26it/s][Astep: 91
extend+tolist() time: 0.0007748603820800781

Evaluating:  40%|████      | 92/228 [00:40<00:59,  2.30it/s][Astep: 92
extend+tolist() time: 0.0012140274047851562

Evaluating:  41%|████      | 93/228 [00:40<00:57,  2.36it/s][Astep: 93
extend+tolist() time: 0.0009524822235107422

Evaluating:  41%|████      | 94/228 [00:41<00:56,  2.36it/s][Astep: 94
extend+tolist() time: 0.0011718273162841797

Evaluating:  42%|████▏     | 95/228 [00:41<00:55,  2.39it/s][Astep: 95
extend+tolist() time: 0.0011970996856689453

Evaluating:  42%|████▏     | 96/228 [00:42<00:56,  2.34it/s][Astep: 96
extend+tolist() time: 0.001333475112915039

Evaluating:  43%|████▎     | 97/228 [00:42<00:55,  2.37it/s][Astep: 97
extend+tolist() time: 0.0011484622955322266

Evaluating:  43%|████▎     | 98/228 [00:43<00:54,  2.40it/s][Astep: 98
extend+tolist() time: 0.0009107589721679688

Evaluating:  43%|████▎     | 99/228 [00:43<00:53,  2.40it/s][Astep: 99
extend+tolist() time: 0.0013270378112792969

Evaluating:  44%|████▍     | 100/228 [00:43<00:53,  2.41it/s][Astep: 100
extend+tolist() time: 0.001752614974975586

Evaluating:  44%|████▍     | 101/228 [00:44<00:53,  2.38it/s][Astep: 101
extend+tolist() time: 0.001241922378540039

Evaluating:  45%|████▍     | 102/228 [00:44<00:52,  2.40it/s][Astep: 102
extend+tolist() time: 0.0006985664367675781

Evaluating:  45%|████▌     | 103/228 [00:45<00:51,  2.43it/s][Astep: 103
extend+tolist() time: 0.0011904239654541016

Evaluating:  46%|████▌     | 104/228 [00:45<00:50,  2.43it/s][Astep: 104
extend+tolist() time: 0.0006728172302246094

Evaluating:  46%|████▌     | 105/228 [00:45<00:50,  2.44it/s][Astep: 105
extend+tolist() time: 0.0012514591217041016

Evaluating:  46%|████▋     | 106/228 [00:46<00:50,  2.41it/s][Astep: 106
extend+tolist() time: 0.0013058185577392578

Evaluating:  47%|████▋     | 107/228 [00:46<00:50,  2.40it/s][Astep: 107
extend+tolist() time: 0.0009872913360595703

Evaluating:  47%|████▋     | 108/228 [00:47<00:50,  2.40it/s][Astep: 108
extend+tolist() time: 0.0011715888977050781

Evaluating:  48%|████▊     | 109/228 [00:47<00:49,  2.42it/s][Astep: 109
extend+tolist() time: 0.0008471012115478516

Evaluating:  48%|████▊     | 110/228 [00:47<00:47,  2.46it/s][Astep: 110
extend+tolist() time: 0.000621795654296875

Evaluating:  49%|████▊     | 111/228 [00:48<00:48,  2.42it/s][Astep: 111
extend+tolist() time: 0.2484147548675537

Evaluating:  49%|████▉     | 112/228 [00:49<00:57,  2.03it/s][Astep: 112
extend+tolist() time: 0.0007932186126708984

Evaluating:  50%|████▉     | 113/228 [00:49<00:53,  2.14it/s][Astep: 113
extend+tolist() time: 0.0006747245788574219

Evaluating:  50%|█████     | 114/228 [00:49<00:51,  2.23it/s][Astep: 114
extend+tolist() time: 0.0014510154724121094

Evaluating:  50%|█████     | 115/228 [00:50<00:50,  2.24it/s][Astep: 115
extend+tolist() time: 0.0006418228149414062

Evaluating:  51%|█████     | 116/228 [00:50<00:48,  2.30it/s][Astep: 116
extend+tolist() time: 0.0012176036834716797

Evaluating:  51%|█████▏    | 117/228 [00:51<00:47,  2.34it/s][Astep: 117
extend+tolist() time: 0.0011832714080810547

Evaluating:  52%|█████▏    | 118/228 [00:51<00:47,  2.33it/s][Astep: 118
extend+tolist() time: 0.0005617141723632812

Evaluating:  52%|█████▏    | 119/228 [00:52<00:46,  2.34it/s][Astep: 119
extend+tolist() time: 0.0007023811340332031

Evaluating:  53%|█████▎    | 120/228 [00:52<00:46,  2.33it/s][Astep: 120
extend+tolist() time: 0.0011105537414550781

Evaluating:  53%|█████▎    | 121/228 [00:52<00:45,  2.37it/s][Astep: 121
extend+tolist() time: 0.0008685588836669922

Evaluating:  54%|█████▎    | 122/228 [00:53<00:44,  2.37it/s][Astep: 122
extend+tolist() time: 0.0010657310485839844

Evaluating:  54%|█████▍    | 123/228 [00:53<00:43,  2.43it/s][Astep: 123
extend+tolist() time: 0.0006892681121826172

Evaluating:  54%|█████▍    | 124/228 [00:54<00:42,  2.44it/s][Astep: 124
extend+tolist() time: 0.0009307861328125

Evaluating:  55%|█████▍    | 125/228 [00:54<00:42,  2.40it/s][Astep: 125
extend+tolist() time: 0.0009198188781738281

Evaluating:  55%|█████▌    | 126/228 [00:54<00:41,  2.44it/s][Astep: 126
extend+tolist() time: 0.002121448516845703

Evaluating:  56%|█████▌    | 127/228 [00:55<00:41,  2.43it/s][Astep: 127
extend+tolist() time: 0.0015044212341308594

Evaluating:  56%|█████▌    | 128/228 [00:55<00:40,  2.47it/s][Astep: 128
extend+tolist() time: 0.0012371540069580078

Evaluating:  57%|█████▋    | 129/228 [00:56<00:39,  2.50it/s][Astep: 129
extend+tolist() time: 0.0008342266082763672

Evaluating:  57%|█████▋    | 130/228 [00:56<00:39,  2.45it/s][Astep: 130
extend+tolist() time: 0.001512289047241211

Evaluating:  57%|█████▋    | 131/228 [00:56<00:39,  2.45it/s][Astep: 131
extend+tolist() time: 0.0005035400390625

Evaluating:  58%|█████▊    | 132/228 [00:57<00:46,  2.08it/s][Astep: 132
extend+tolist() time: 0.0016491413116455078

Evaluating:  58%|█████▊    | 133/228 [00:57<00:43,  2.18it/s][Astep: 133
extend+tolist() time: 0.0005114078521728516

Evaluating:  59%|█████▉    | 134/228 [00:58<00:42,  2.23it/s][Astep: 134
extend+tolist() time: 0.0014789104461669922

Evaluating:  59%|█████▉    | 135/228 [00:58<00:40,  2.29it/s][Astep: 135
extend+tolist() time: 0.0005049705505371094

Evaluating:  60%|█████▉    | 136/228 [00:59<00:38,  2.38it/s][Astep: 136
extend+tolist() time: 0.0013480186462402344

Evaluating:  60%|██████    | 137/228 [00:59<00:38,  2.36it/s][Astep: 137
extend+tolist() time: 0.0004258155822753906

Evaluating:  61%|██████    | 138/228 [01:00<00:37,  2.40it/s][Astep: 138
extend+tolist() time: 0.000812530517578125

Evaluating:  61%|██████    | 139/228 [01:00<00:37,  2.38it/s][Astep: 139
extend+tolist() time: 0.0005252361297607422

Evaluating:  61%|██████▏   | 140/228 [01:00<00:36,  2.41it/s][Astep: 140
extend+tolist() time: 0.0008473396301269531

Evaluating:  62%|██████▏   | 141/228 [01:01<00:35,  2.48it/s][Astep: 141
extend+tolist() time: 0.0008499622344970703

Evaluating:  62%|██████▏   | 142/228 [01:01<00:35,  2.46it/s][Astep: 142
extend+tolist() time: 0.001093149185180664

Evaluating:  63%|██████▎   | 143/228 [01:02<00:34,  2.49it/s][Astep: 143
extend+tolist() time: 0.00038361549377441406

Evaluating:  63%|██████▎   | 144/228 [01:02<00:40,  2.10it/s][Astep: 144
extend+tolist() time: 0.0007941722869873047

Evaluating:  64%|██████▎   | 145/228 [01:03<00:37,  2.22it/s][Astep: 145
extend+tolist() time: 0.0009849071502685547

Evaluating:  64%|██████▍   | 146/228 [01:03<00:35,  2.28it/s][Astep: 146
extend+tolist() time: 0.00042247772216796875

Evaluating:  64%|██████▍   | 147/228 [01:03<00:33,  2.39it/s][Astep: 147
extend+tolist() time: 0.0008108615875244141

Evaluating:  65%|██████▍   | 148/228 [01:04<00:32,  2.47it/s][Astep: 148
extend+tolist() time: 0.0011937618255615234

Evaluating:  65%|██████▌   | 149/228 [01:04<00:32,  2.45it/s][Astep: 149
extend+tolist() time: 0.0003898143768310547

Evaluating:  66%|██████▌   | 150/228 [01:05<00:31,  2.49it/s][Astep: 150
extend+tolist() time: 0.0009262561798095703

Evaluating:  66%|██████▌   | 151/228 [01:05<00:30,  2.51it/s][Astep: 151
extend+tolist() time: 0.0011000633239746094

Evaluating:  67%|██████▋   | 152/228 [01:05<00:30,  2.47it/s][Astep: 152
extend+tolist() time: 0.0009047985076904297

Evaluating:  67%|██████▋   | 153/228 [01:06<00:30,  2.46it/s][Astep: 153
extend+tolist() time: 0.0014624595642089844

Evaluating:  68%|██████▊   | 154/228 [01:06<00:30,  2.40it/s][Astep: 154
extend+tolist() time: 0.0020172595977783203

Evaluating:  68%|██████▊   | 155/228 [01:07<00:30,  2.38it/s][Astep: 155
extend+tolist() time: 0.0007178783416748047

Evaluating:  68%|██████▊   | 156/228 [01:07<00:30,  2.35it/s][Astep: 156
extend+tolist() time: 0.0005602836608886719

Evaluating:  69%|██████▉   | 157/228 [01:07<00:29,  2.40it/s][Astep: 157
extend+tolist() time: 0.00115203857421875

Evaluating:  69%|██████▉   | 158/228 [01:08<00:28,  2.45it/s][Astep: 158
extend+tolist() time: 0.0005145072937011719

Evaluating:  70%|██████▉   | 159/228 [01:08<00:28,  2.41it/s][Astep: 159
extend+tolist() time: 0.0007288455963134766

Evaluating:  70%|███████   | 160/228 [01:09<00:28,  2.41it/s][Astep: 160
extend+tolist() time: 0.0008504390716552734

Evaluating:  71%|███████   | 161/228 [01:09<00:28,  2.38it/s][Astep: 161
extend+tolist() time: 0.0008041858673095703

Evaluating:  71%|███████   | 162/228 [01:10<00:27,  2.40it/s][Astep: 162
extend+tolist() time: 0.0005247592926025391

Evaluating:  71%|███████▏  | 163/228 [01:10<00:26,  2.44it/s][Astep: 163
extend+tolist() time: 0.0004322528839111328

Evaluating:  72%|███████▏  | 164/228 [01:10<00:26,  2.45it/s][Astep: 164
extend+tolist() time: 0.0010523796081542969

Evaluating:  72%|███████▏  | 165/228 [01:11<00:25,  2.49it/s][Astep: 165
extend+tolist() time: 0.00046634674072265625

Evaluating:  73%|███████▎  | 166/228 [01:11<00:25,  2.47it/s][Astep: 166
extend+tolist() time: 0.0003876686096191406

Evaluating:  73%|███████▎  | 167/228 [01:12<00:24,  2.50it/s][Astep: 167
extend+tolist() time: 0.000579833984375

Evaluating:  74%|███████▎  | 168/228 [01:12<00:23,  2.53it/s][Astep: 168
extend+tolist() time: 0.0012347698211669922

Evaluating:  74%|███████▍  | 169/228 [01:12<00:24,  2.43it/s][Astep: 169
extend+tolist() time: 0.0003752708435058594

Evaluating:  75%|███████▍  | 170/228 [01:13<00:23,  2.45it/s][Astep: 170
extend+tolist() time: 0.0014188289642333984

Evaluating:  75%|███████▌  | 171/228 [01:13<00:23,  2.40it/s][Astep: 171
extend+tolist() time: 0.00030541419982910156

Evaluating:  75%|███████▌  | 172/228 [01:14<00:23,  2.42it/s][Astep: 172
extend+tolist() time: 0.0008411407470703125

Evaluating:  76%|███████▌  | 173/228 [01:14<00:22,  2.44it/s][Astep: 173
extend+tolist() time: 0.0016028881072998047

Evaluating:  76%|███████▋  | 174/228 [01:14<00:22,  2.41it/s][Astep: 174
extend+tolist() time: 0.0018494129180908203

Evaluating:  77%|███████▋  | 175/228 [01:15<00:22,  2.39it/s][Astep: 175
extend+tolist() time: 0.0008361339569091797

Evaluating:  77%|███████▋  | 176/228 [01:15<00:22,  2.35it/s][Astep: 176
extend+tolist() time: 0.0011522769927978516

Evaluating:  78%|███████▊  | 177/228 [01:16<00:21,  2.39it/s][Astep: 177
extend+tolist() time: 0.0006117820739746094

Evaluating:  78%|███████▊  | 178/228 [01:16<00:20,  2.42it/s][Astep: 178
extend+tolist() time: 0.001630544662475586

Evaluating:  79%|███████▊  | 179/228 [01:17<00:20,  2.38it/s][Astep: 179
extend+tolist() time: 0.00040078163146972656

Evaluating:  79%|███████▉  | 180/228 [01:17<00:19,  2.40it/s][Astep: 180
extend+tolist() time: 0.0003993511199951172

Evaluating:  79%|███████▉  | 181/228 [01:17<00:19,  2.36it/s][Astep: 181
extend+tolist() time: 0.0007197856903076172

Evaluating:  80%|███████▉  | 182/228 [01:18<00:19,  2.36it/s][Astep: 182
extend+tolist() time: 0.0012750625610351562

Evaluating:  80%|████████  | 183/228 [01:18<00:19,  2.31it/s][Astep: 183
extend+tolist() time: 0.0006659030914306641

Evaluating:  81%|████████  | 184/228 [01:19<00:18,  2.34it/s][Astep: 184
extend+tolist() time: 0.00048232078552246094

Evaluating:  81%|████████  | 185/228 [01:19<00:18,  2.37it/s][Astep: 185
extend+tolist() time: 0.0016200542449951172

Evaluating:  82%|████████▏ | 186/228 [01:20<00:17,  2.34it/s][Astep: 186
extend+tolist() time: 0.2885880470275879

Evaluating:  82%|████████▏ | 187/228 [01:20<00:20,  1.96it/s][Astep: 187
extend+tolist() time: 0.00045371055603027344

Evaluating:  82%|████████▏ | 188/228 [01:21<00:18,  2.11it/s][Astep: 188
extend+tolist() time: 0.0007259845733642578

Evaluating:  83%|████████▎ | 189/228 [01:21<00:17,  2.21it/s][Astep: 189
extend+tolist() time: 0.0007531642913818359

Evaluating:  83%|████████▎ | 190/228 [01:21<00:17,  2.23it/s][Astep: 190
extend+tolist() time: 0.0011892318725585938

Evaluating:  84%|████████▍ | 191/228 [01:22<00:16,  2.27it/s][Astep: 191
extend+tolist() time: 0.0011179447174072266

Evaluating:  84%|████████▍ | 192/228 [01:22<00:15,  2.27it/s][Astep: 192
extend+tolist() time: 0.00046372413635253906

Evaluating:  85%|████████▍ | 193/228 [01:23<00:15,  2.33it/s][Astep: 193
extend+tolist() time: 0.0014963150024414062

Evaluating:  85%|████████▌ | 194/228 [01:23<00:14,  2.37it/s][Astep: 194
extend+tolist() time: 0.0006418228149414062

Evaluating:  86%|████████▌ | 195/228 [01:24<00:14,  2.35it/s][Astep: 195
extend+tolist() time: 0.0005514621734619141

Evaluating:  86%|████████▌ | 196/228 [01:24<00:13,  2.38it/s][Astep: 196
extend+tolist() time: 0.001062631607055664

Evaluating:  86%|████████▋ | 197/228 [01:24<00:13,  2.36it/s][Astep: 197
extend+tolist() time: 0.0006716251373291016

Evaluating:  87%|████████▋ | 198/228 [01:25<00:12,  2.39it/s][Astep: 198
extend+tolist() time: 0.0006349086761474609

Evaluating:  87%|████████▋ | 199/228 [01:25<00:11,  2.43it/s][Astep: 199
extend+tolist() time: 0.0019502639770507812

Evaluating:  88%|████████▊ | 200/228 [01:26<00:11,  2.39it/s][Astep: 200
extend+tolist() time: 0.000690460205078125

Evaluating:  88%|████████▊ | 201/228 [01:26<00:11,  2.42it/s][Astep: 201
extend+tolist() time: 0.0009799003601074219

Evaluating:  89%|████████▊ | 202/228 [01:26<00:10,  2.39it/s][Astep: 202
extend+tolist() time: 0.0004031658172607422

Evaluating:  89%|████████▉ | 203/228 [01:27<00:10,  2.43it/s][Astep: 203
extend+tolist() time: 0.000492095947265625

Evaluating:  89%|████████▉ | 204/228 [01:27<00:09,  2.44it/s][Astep: 204
extend+tolist() time: 0.0003848075866699219

Evaluating:  90%|████████▉ | 205/228 [01:28<00:09,  2.44it/s][Astep: 205
extend+tolist() time: 0.0007944107055664062

Evaluating:  90%|█████████ | 206/228 [01:28<00:08,  2.45it/s][Astep: 206
extend+tolist() time: 0.0005753040313720703

Evaluating:  91%|█████████ | 207/228 [01:29<00:08,  2.41it/s][Astep: 207
extend+tolist() time: 0.0006012916564941406

Evaluating:  91%|█████████ | 208/228 [01:29<00:08,  2.43it/s][Astep: 208
extend+tolist() time: 0.0011725425720214844

Evaluating:  92%|█████████▏| 209/228 [01:29<00:07,  2.44it/s][Astep: 209
extend+tolist() time: 0.0005919933319091797

Evaluating:  92%|█████████▏| 210/228 [01:30<00:07,  2.46it/s][Astep: 210
extend+tolist() time: 0.0005834102630615234

Evaluating:  93%|█████████▎| 211/228 [01:30<00:06,  2.50it/s][Astep: 211
extend+tolist() time: 0.0015773773193359375

Evaluating:  93%|█████████▎| 212/228 [01:31<00:06,  2.45it/s][Astep: 212
extend+tolist() time: 0.0008597373962402344

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.48it/s][Astep: 213
extend+tolist() time: 0.0011646747589111328

Evaluating:  94%|█████████▍| 214/228 [01:31<00:05,  2.50it/s][Astep: 214
extend+tolist() time: 0.0008432865142822266

Evaluating:  94%|█████████▍| 215/228 [01:32<00:05,  2.50it/s][Astep: 215
extend+tolist() time: 0.0010521411895751953

Evaluating:  95%|█████████▍| 216/228 [01:32<00:04,  2.52it/s][Astep: 216
extend+tolist() time: 0.0005774497985839844

Evaluating:  95%|█████████▌| 217/228 [01:33<00:04,  2.48it/s][Astep: 217
extend+tolist() time: 0.0005476474761962891

Evaluating:  96%|█████████▌| 218/228 [01:33<00:03,  2.51it/s][Astep: 218
extend+tolist() time: 0.0014376640319824219

Evaluating:  96%|█████████▌| 219/228 [01:33<00:03,  2.53it/s][Astep: 219
extend+tolist() time: 0.00045800209045410156

Evaluating:  96%|█████████▋| 220/228 [01:34<00:03,  2.47it/s][Astep: 220
extend+tolist() time: 0.0003993511199951172

Evaluating:  97%|█████████▋| 221/228 [01:34<00:02,  2.48it/s][Astep: 221
extend+tolist() time: 0.0010578632354736328

Evaluating:  97%|█████████▋| 222/228 [01:35<00:02,  2.43it/s][Astep: 222
extend+tolist() time: 0.00045752525329589844

Evaluating:  98%|█████████▊| 223/228 [01:35<00:02,  2.05it/s][Astep: 223
extend+tolist() time: 0.0004055500030517578

Evaluating:  98%|█████████▊| 224/228 [01:36<00:01,  2.15it/s][Astep: 224
extend+tolist() time: 0.00038051605224609375

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.25it/s][Astep: 225
extend+tolist() time: 0.00045013427734375

Evaluating:  99%|█████████▉| 226/228 [01:36<00:00,  2.32it/s][Astep: 226
extend+tolist() time: 0.0009930133819580078

Evaluating: 100%|█████████▉| 227/228 [01:37<00:00,  2.34it/s][Astep: 227
extend+tolist() time: 0.0004949569702148438

Evaluating: 100%|██████████| 228/228 [01:37<00:00,  2.35it/s][A09/08/2023 22:12:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 22:12:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:12:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:12:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:12:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:12:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:12:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:12:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:12:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:12:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:12:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:12:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:12:56 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:12:57 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-051eda6d-25ff-489c-8054-d30342aa2da1-1-0.arrow
09/08/2023 22:12:57 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:12:57 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:12:57 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:40<00:00,  2.27it/s]
09/08/2023 22:12:57 - INFO - __main__ -   Step: 1440, Validation Metrics: {'pred_1_num': 9945, 'pred_-1_num': 825, 'pred_0_num': 31, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.8004814369039903, 'f1_micro': 0.8004814369039903, 'f1_macro': 0.4241610951201625, 'f1_weighted': 0.7582250656181615, 'f1_-1': 0.3538268506900878, 'f1_0': 0.03283582089552239, 'f1_1': 0.8858206137748773, 'precision_micro': 0.8004814369039903, 'precision_macro': 0.5644358536958157, 'precision_weighted': 0.7524995329072997, 'precision_-1': 0.5127272727272727, 'precision_0': 0.3548387096774194, 'precision_1': 0.8257415786827551, 'recall_micro': 0.8004814369039903, 'recall_macro': 0.41421913319580356, 'recall_weighted': 0.8004814369039903, 'recall_-1': 0.27011494252873564, 'recall_0': 0.017214397496087636, 'recall_1': 0.9553280595625873, 'roc_auc_micro': 0.896124338290197, 'roc_auc_macro': 0.7027741713376537, 'roc_auc_weighted': 0.6845455206274053, 'roc_auc_-1': 0.7157879160642262, 'roc_auc_0': 0.7160204992116753, 'roc_auc_1': 0.6765140987370597}
[2023-09-08 22:13:17,269] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1441/66600 [50:26<914:01:09, 50.50s/it]09/08/2023 22:13:17 - INFO - __main__ -   Step: 1441, LR: 1.4429841031418201e-05, Loss: 0.42583391070365906
[2023-09-08 22:13:37,231] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1442/66600 [50:46<748:11:36, 41.34s/it]09/08/2023 22:13:37 - INFO - __main__ -   Step: 1442, LR: 1.4439854800350483e-05, Loss: 0.3146109879016876
[2023-09-08 22:13:57,521] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1443/66600 [51:07<633:53:44, 35.02s/it]09/08/2023 22:13:57 - INFO - __main__ -   Step: 1443, LR: 1.4449868569282766e-05, Loss: 0.5239038467407227
[2023-09-08 22:14:17,913] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1444/66600 [51:27<554:26:32, 30.63s/it]09/08/2023 22:14:17 - INFO - __main__ -   Step: 1444, LR: 1.4459882338215048e-05, Loss: 0.4053433835506439
[2023-09-08 22:14:37,939] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1445/66600 [51:47<496:50:10, 27.45s/it]09/08/2023 22:14:37 - INFO - __main__ -   Step: 1445, LR: 1.446989610714733e-05, Loss: 0.4472895562648773
[2023-09-08 22:14:58,106] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1446/66600 [52:07<457:16:30, 25.27s/it]09/08/2023 22:14:58 - INFO - __main__ -   Step: 1446, LR: 1.4479909876079609e-05, Loss: 0.4252619445323944
[2023-09-08 22:15:18,395] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1447/66600 [52:27<430:14:55, 23.77s/it]09/08/2023 22:15:18 - INFO - __main__ -   Step: 1447, LR: 1.4489923645011892e-05, Loss: 0.35219132900238037
[2023-09-08 22:15:39,045] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1448/66600 [52:48<413:17:17, 22.84s/it]09/08/2023 22:15:39 - INFO - __main__ -   Step: 1448, LR: 1.4499937413944174e-05, Loss: 0.3803713619709015
[2023-09-08 22:16:00,119] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1449/66600 [53:09<403:42:26, 22.31s/it]09/08/2023 22:16:00 - INFO - __main__ -   Step: 1449, LR: 1.4509951182876456e-05, Loss: 0.4182726740837097
[2023-09-08 22:16:21,423] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1450/66600 [53:30<398:15:28, 22.01s/it]09/08/2023 22:16:21 - INFO - __main__ -   Step: 1450, LR: 1.4519964951808739e-05, Loss: 0.36274081468582153
[2023-09-08 22:16:41,592] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1451/66600 [53:51<388:16:25, 21.46s/it]09/08/2023 22:16:41 - INFO - __main__ -   Step: 1451, LR: 1.452997872074102e-05, Loss: 0.4377606511116028
[2023-09-08 22:17:01,786] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1452/66600 [54:11<381:25:03, 21.08s/it]09/08/2023 22:17:01 - INFO - __main__ -   Step: 1452, LR: 1.4539992489673302e-05, Loss: 0.5036789774894714
[2023-09-08 22:17:22,282] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1453/66600 [54:31<378:15:45, 20.90s/it]09/08/2023 22:17:22 - INFO - __main__ -   Step: 1453, LR: 1.4550006258605584e-05, Loss: 0.3993053436279297
[2023-09-08 22:17:42,575] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1454/66600 [54:52<374:56:53, 20.72s/it]09/08/2023 22:17:42 - INFO - __main__ -   Step: 1454, LR: 1.4560020027537867e-05, Loss: 0.3776249885559082
[2023-09-08 22:18:03,436] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1455/66600 [55:12<375:42:19, 20.76s/it]09/08/2023 22:18:03 - INFO - __main__ -   Step: 1455, LR: 1.4570033796470147e-05, Loss: 0.4431469440460205
[2023-09-08 22:18:24,460] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1456/66600 [55:34<377:07:19, 20.84s/it]09/08/2023 22:18:24 - INFO - __main__ -   Step: 1456, LR: 1.4580047565402429e-05, Loss: 0.4084034264087677
[2023-09-08 22:18:44,561] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1457/66600 [55:54<373:06:06, 20.62s/it]09/08/2023 22:18:44 - INFO - __main__ -   Step: 1457, LR: 1.459006133433471e-05, Loss: 0.5247479677200317
[2023-09-08 22:19:04,319] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1458/66600 [56:13<368:25:18, 20.36s/it]09/08/2023 22:19:04 - INFO - __main__ -   Step: 1458, LR: 1.4600075103266993e-05, Loss: 0.4622133672237396
[2023-09-08 22:19:24,819] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1459/66600 [56:34<369:10:33, 20.40s/it]09/08/2023 22:19:24 - INFO - __main__ -   Step: 1459, LR: 1.4610088872199275e-05, Loss: 0.4427168667316437
[2023-09-08 22:19:45,668] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1460/66600 [56:55<371:35:43, 20.54s/it]09/08/2023 22:19:45 - INFO - __main__ -   Step: 1460, LR: 1.4620102641131557e-05, Loss: 0.36368632316589355
09/08/2023 22:19:45 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0019254684448242188

Evaluating:   0%|          | 1/228 [00:00<01:48,  2.10it/s][Astep: 1
extend+tolist() time: 0.1614389419555664

Evaluating:   1%|          | 2/228 [00:01<02:23,  1.57it/s][Astep: 2
extend+tolist() time: 0.002190828323364258

Evaluating:   1%|▏         | 3/228 [00:01<02:01,  1.84it/s][Astep: 3
extend+tolist() time: 0.001875162124633789

Evaluating:   2%|▏         | 4/228 [00:02<01:53,  1.97it/s][Astep: 4
extend+tolist() time: 0.0014219284057617188

Evaluating:   2%|▏         | 5/228 [00:02<01:45,  2.12it/s][Astep: 5
extend+tolist() time: 0.0020236968994140625

Evaluating:   3%|▎         | 6/228 [00:02<01:44,  2.13it/s][Astep: 6
extend+tolist() time: 0.0018973350524902344

Evaluating:   3%|▎         | 7/228 [00:03<01:52,  1.96it/s][Astep: 7
extend+tolist() time: 0.0009839534759521484

Evaluating:   4%|▎         | 8/228 [00:04<01:47,  2.05it/s][Astep: 8
extend+tolist() time: 0.0011985301971435547

Evaluating:   4%|▍         | 9/228 [00:04<01:40,  2.17it/s][Astep: 9
extend+tolist() time: 0.0007913112640380859

Evaluating:   4%|▍         | 10/228 [00:04<01:37,  2.22it/s][Astep: 10
extend+tolist() time: 0.0012860298156738281

Evaluating:   5%|▍         | 11/228 [00:05<01:35,  2.28it/s][Astep: 11
extend+tolist() time: 0.0005841255187988281

Evaluating:   5%|▌         | 12/228 [00:05<01:31,  2.36it/s][Astep: 12
extend+tolist() time: 0.0011169910430908203

Evaluating:   6%|▌         | 13/228 [00:06<01:31,  2.36it/s][Astep: 13
extend+tolist() time: 0.0005900859832763672

Evaluating:   6%|▌         | 14/228 [00:06<01:28,  2.42it/s][Astep: 14
extend+tolist() time: 0.0005571842193603516

Evaluating:   7%|▋         | 15/228 [00:06<01:26,  2.45it/s][Astep: 15
extend+tolist() time: 0.0010530948638916016

Evaluating:   7%|▋         | 16/228 [00:07<01:25,  2.47it/s][Astep: 16
extend+tolist() time: 0.0006403923034667969

Evaluating:   7%|▋         | 17/228 [00:07<01:23,  2.51it/s][Astep: 17
extend+tolist() time: 0.0013515949249267578

Evaluating:   8%|▊         | 18/228 [00:08<01:25,  2.46it/s][Astep: 18
extend+tolist() time: 0.001196146011352539

Evaluating:   8%|▊         | 19/228 [00:08<01:24,  2.48it/s][Astep: 19
extend+tolist() time: 0.0015192031860351562

Evaluating:   9%|▉         | 20/228 [00:08<01:25,  2.45it/s][Astep: 20
extend+tolist() time: 0.0007758140563964844

Evaluating:   9%|▉         | 21/228 [00:09<01:24,  2.46it/s][Astep: 21
extend+tolist() time: 0.0006461143493652344

Evaluating:  10%|▉         | 22/228 [00:09<01:22,  2.50it/s][Astep: 22
extend+tolist() time: 0.0007703304290771484

Evaluating:  10%|█         | 23/228 [00:10<01:23,  2.46it/s][Astep: 23
extend+tolist() time: 0.0011606216430664062

Evaluating:  11%|█         | 24/228 [00:10<01:21,  2.51it/s][Astep: 24
extend+tolist() time: 0.0014920234680175781

Evaluating:  11%|█         | 25/228 [00:10<01:22,  2.46it/s][Astep: 25
extend+tolist() time: 0.0014853477478027344

Evaluating:  11%|█▏        | 26/228 [00:11<01:22,  2.43it/s][Astep: 26
extend+tolist() time: 0.001194000244140625

Evaluating:  12%|█▏        | 27/228 [00:11<01:20,  2.49it/s][Astep: 27
extend+tolist() time: 0.0016834735870361328

Evaluating:  12%|█▏        | 28/228 [00:12<01:23,  2.39it/s][Astep: 28
extend+tolist() time: 0.00037097930908203125

Evaluating:  13%|█▎        | 29/228 [00:12<01:30,  2.20it/s][Astep: 29
extend+tolist() time: 0.0007503032684326172

Evaluating:  13%|█▎        | 30/228 [00:13<01:28,  2.23it/s][Astep: 30
extend+tolist() time: 0.14997196197509766

Evaluating:  14%|█▎        | 31/228 [00:13<01:34,  2.08it/s][Astep: 31
extend+tolist() time: 0.001069784164428711

Evaluating:  14%|█▍        | 32/228 [00:14<01:31,  2.15it/s][Astep: 32
extend+tolist() time: 0.0010066032409667969

Evaluating:  14%|█▍        | 33/228 [00:14<01:27,  2.24it/s][Astep: 33
extend+tolist() time: 0.0017130374908447266

Evaluating:  15%|█▍        | 34/228 [00:14<01:26,  2.25it/s][Astep: 34
extend+tolist() time: 0.0012664794921875

Evaluating:  15%|█▌        | 35/228 [00:15<01:23,  2.31it/s][Astep: 35
extend+tolist() time: 0.0006468296051025391

Evaluating:  16%|█▌        | 36/228 [00:15<01:20,  2.38it/s][Astep: 36
extend+tolist() time: 0.0011820793151855469

Evaluating:  16%|█▌        | 37/228 [00:16<01:30,  2.11it/s][Astep: 37
extend+tolist() time: 0.0016324520111083984

Evaluating:  17%|█▋        | 38/228 [00:16<01:26,  2.19it/s][Astep: 38
extend+tolist() time: 0.0007936954498291016

Evaluating:  17%|█▋        | 39/228 [00:17<01:25,  2.22it/s][Astep: 39
extend+tolist() time: 0.0011272430419921875

Evaluating:  18%|█▊        | 40/228 [00:17<01:21,  2.32it/s][Astep: 40
extend+tolist() time: 0.0006606578826904297

Evaluating:  18%|█▊        | 41/228 [00:18<01:20,  2.33it/s][Astep: 41
extend+tolist() time: 0.0008668899536132812

Evaluating:  18%|█▊        | 42/228 [00:18<01:18,  2.37it/s][Astep: 42
extend+tolist() time: 0.0017137527465820312

Evaluating:  19%|█▉        | 43/228 [00:18<01:16,  2.40it/s][Astep: 43
extend+tolist() time: 0.0018754005432128906

Evaluating:  19%|█▉        | 44/228 [00:19<01:18,  2.33it/s][Astep: 44
extend+tolist() time: 0.0011281967163085938

Evaluating:  20%|█▉        | 45/228 [00:19<01:16,  2.40it/s][Astep: 45
extend+tolist() time: 0.0016703605651855469

Evaluating:  20%|██        | 46/228 [00:20<01:17,  2.35it/s][Astep: 46
extend+tolist() time: 0.0012657642364501953

Evaluating:  21%|██        | 47/228 [00:20<01:16,  2.36it/s][Astep: 47
extend+tolist() time: 0.0016210079193115234

Evaluating:  21%|██        | 48/228 [00:20<01:15,  2.40it/s][Astep: 48
extend+tolist() time: 0.0016283988952636719

Evaluating:  21%|██▏       | 49/228 [00:21<01:17,  2.32it/s][Astep: 49
extend+tolist() time: 0.0009410381317138672

Evaluating:  22%|██▏       | 50/228 [00:21<01:14,  2.37it/s][Astep: 50
extend+tolist() time: 0.001224517822265625

Evaluating:  22%|██▏       | 51/228 [00:22<01:16,  2.31it/s][Astep: 51
extend+tolist() time: 0.0017232894897460938

Evaluating:  23%|██▎       | 52/228 [00:22<01:14,  2.36it/s][Astep: 52
extend+tolist() time: 0.0014014244079589844

Evaluating:  23%|██▎       | 53/228 [00:23<01:15,  2.33it/s][Astep: 53
extend+tolist() time: 0.0017147064208984375

Evaluating:  24%|██▎       | 54/228 [00:23<01:14,  2.34it/s][Astep: 54
extend+tolist() time: 0.0008261203765869141

Evaluating:  24%|██▍       | 55/228 [00:23<01:12,  2.39it/s][Astep: 55
extend+tolist() time: 0.0012273788452148438

Evaluating:  25%|██▍       | 56/228 [00:24<01:13,  2.34it/s][Astep: 56
extend+tolist() time: 0.001867055892944336

Evaluating:  25%|██▌       | 57/228 [00:24<01:12,  2.37it/s][Astep: 57
extend+tolist() time: 0.001020193099975586

Evaluating:  25%|██▌       | 58/228 [00:25<01:14,  2.29it/s][Astep: 58
extend+tolist() time: 0.0009129047393798828

Evaluating:  26%|██▌       | 59/228 [00:25<01:11,  2.36it/s][Astep: 59
extend+tolist() time: 0.0016422271728515625

Evaluating:  26%|██▋       | 60/228 [00:26<01:11,  2.37it/s][Astep: 60
extend+tolist() time: 0.0007603168487548828

Evaluating:  27%|██▋       | 61/228 [00:26<01:18,  2.14it/s][Astep: 61
extend+tolist() time: 0.00128173828125

Evaluating:  27%|██▋       | 62/228 [00:27<01:14,  2.24it/s][Astep: 62
extend+tolist() time: 0.0008118152618408203

Evaluating:  28%|██▊       | 63/228 [00:27<01:13,  2.25it/s][Astep: 63
extend+tolist() time: 0.1638016700744629

Evaluating:  28%|██▊       | 64/228 [00:28<01:17,  2.11it/s][Astep: 64
extend+tolist() time: 0.001275777816772461

Evaluating:  29%|██▊       | 65/228 [00:28<01:15,  2.15it/s][Astep: 65
extend+tolist() time: 0.0008165836334228516

Evaluating:  29%|██▉       | 66/228 [00:28<01:11,  2.28it/s][Astep: 66
extend+tolist() time: 0.0011374950408935547

Evaluating:  29%|██▉       | 67/228 [00:29<01:09,  2.30it/s][Astep: 67
extend+tolist() time: 0.0009167194366455078

Evaluating:  30%|██▉       | 68/228 [00:29<01:08,  2.35it/s][Astep: 68
extend+tolist() time: 0.0010902881622314453

Evaluating:  30%|███       | 69/228 [00:30<01:05,  2.42it/s][Astep: 69
extend+tolist() time: 0.0015015602111816406

Evaluating:  31%|███       | 70/228 [00:30<01:06,  2.37it/s][Astep: 70
extend+tolist() time: 0.0010437965393066406

Evaluating:  31%|███       | 71/228 [00:31<01:14,  2.11it/s][Astep: 71
extend+tolist() time: 0.0014374256134033203

Evaluating:  32%|███▏      | 72/228 [00:31<01:11,  2.17it/s][Astep: 72
extend+tolist() time: 0.0008296966552734375

Evaluating:  32%|███▏      | 73/228 [00:31<01:07,  2.29it/s][Astep: 73
extend+tolist() time: 0.0009717941284179688

Evaluating:  32%|███▏      | 74/228 [00:32<01:06,  2.30it/s][Astep: 74
extend+tolist() time: 0.0007612705230712891

Evaluating:  33%|███▎      | 75/228 [00:32<01:04,  2.36it/s][Astep: 75
extend+tolist() time: 0.0018131732940673828

Evaluating:  33%|███▎      | 76/228 [00:33<01:03,  2.41it/s][Astep: 76
extend+tolist() time: 0.0006587505340576172

Evaluating:  34%|███▍      | 77/228 [00:33<01:04,  2.35it/s][Astep: 77
extend+tolist() time: 0.001905202865600586

Evaluating:  34%|███▍      | 78/228 [00:33<01:03,  2.38it/s][Astep: 78
extend+tolist() time: 0.0012583732604980469

Evaluating:  35%|███▍      | 79/228 [00:34<01:04,  2.32it/s][Astep: 79
extend+tolist() time: 0.0012807846069335938

Evaluating:  35%|███▌      | 80/228 [00:34<01:01,  2.40it/s][Astep: 80
extend+tolist() time: 0.0009241104125976562

Evaluating:  36%|███▌      | 81/228 [00:35<01:01,  2.40it/s][Astep: 81
extend+tolist() time: 0.0013022422790527344

Evaluating:  36%|███▌      | 82/228 [00:35<01:01,  2.39it/s][Astep: 82
extend+tolist() time: 0.0008692741394042969

Evaluating:  36%|███▋      | 83/228 [00:36<00:59,  2.45it/s][Astep: 83
extend+tolist() time: 0.0011348724365234375

Evaluating:  37%|███▋      | 84/228 [00:36<01:00,  2.38it/s][Astep: 84
extend+tolist() time: 0.0010192394256591797

Evaluating:  37%|███▋      | 85/228 [00:36<00:58,  2.44it/s][Astep: 85
extend+tolist() time: 0.0014345645904541016

Evaluating:  38%|███▊      | 86/228 [00:37<00:57,  2.46it/s][Astep: 86
extend+tolist() time: 0.001264810562133789

Evaluating:  38%|███▊      | 87/228 [00:37<00:58,  2.43it/s][Astep: 87
extend+tolist() time: 0.0009064674377441406

Evaluating:  39%|███▊      | 88/228 [00:38<00:56,  2.48it/s][Astep: 88
extend+tolist() time: 0.0012199878692626953

Evaluating:  39%|███▉      | 89/228 [00:38<00:57,  2.40it/s][Astep: 89
extend+tolist() time: 0.0007734298706054688

Evaluating:  39%|███▉      | 90/228 [00:38<00:55,  2.47it/s][Astep: 90
extend+tolist() time: 0.001367330551147461

Evaluating:  40%|███▉      | 91/228 [00:39<00:56,  2.42it/s][Astep: 91
extend+tolist() time: 0.0007796287536621094

Evaluating:  40%|████      | 92/228 [00:39<00:57,  2.38it/s][Astep: 92
extend+tolist() time: 0.0012524127960205078

Evaluating:  41%|████      | 93/228 [00:40<00:55,  2.42it/s][Astep: 93
extend+tolist() time: 0.0009877681732177734

Evaluating:  41%|████      | 94/228 [00:40<00:57,  2.32it/s][Astep: 94
extend+tolist() time: 0.0011975765228271484

Evaluating:  42%|████▏     | 95/228 [00:41<00:55,  2.38it/s][Astep: 95
extend+tolist() time: 0.001178741455078125

Evaluating:  42%|████▏     | 96/228 [00:41<00:57,  2.29it/s][Astep: 96
extend+tolist() time: 0.001409292221069336

Evaluating:  43%|████▎     | 97/228 [00:41<00:55,  2.35it/s][Astep: 97
extend+tolist() time: 0.0011861324310302734

Evaluating:  43%|████▎     | 98/228 [00:42<00:54,  2.37it/s][Astep: 98
extend+tolist() time: 0.0009291172027587891

Evaluating:  43%|████▎     | 99/228 [00:42<00:55,  2.32it/s][Astep: 99
extend+tolist() time: 0.0013344287872314453

Evaluating:  44%|████▍     | 100/228 [00:43<00:54,  2.37it/s][Astep: 100
extend+tolist() time: 0.0007405281066894531

Evaluating:  44%|████▍     | 101/228 [00:43<00:55,  2.30it/s][Astep: 101
extend+tolist() time: 0.001252889633178711

Evaluating:  45%|████▍     | 102/228 [00:44<00:53,  2.36it/s][Astep: 102
extend+tolist() time: 0.0007646083831787109

Evaluating:  45%|████▌     | 103/228 [00:44<00:53,  2.36it/s][Astep: 103
extend+tolist() time: 0.0011839866638183594

Evaluating:  46%|████▌     | 104/228 [00:44<00:52,  2.35it/s][Astep: 104
extend+tolist() time: 0.0007214546203613281

Evaluating:  46%|████▌     | 105/228 [00:45<01:01,  2.02it/s][Astep: 105
extend+tolist() time: 0.0012464523315429688

Evaluating:  46%|████▋     | 106/228 [00:45<00:56,  2.15it/s][Astep: 106
extend+tolist() time: 0.0013544559478759766

Evaluating:  47%|████▋     | 107/228 [00:46<00:54,  2.22it/s][Astep: 107
extend+tolist() time: 0.0007970333099365234

Evaluating:  47%|████▋     | 108/228 [00:46<00:53,  2.25it/s][Astep: 108
extend+tolist() time: 0.0012059211730957031

Evaluating:  48%|████▊     | 109/228 [00:47<00:50,  2.35it/s][Astep: 109
extend+tolist() time: 0.19414019584655762

Evaluating:  48%|████▊     | 110/228 [00:47<00:57,  2.05it/s][Astep: 110
extend+tolist() time: 0.0011072158813476562

Evaluating:  49%|████▊     | 111/228 [00:48<00:53,  2.20it/s][Astep: 111
extend+tolist() time: 0.001706838607788086

Evaluating:  49%|████▉     | 112/228 [00:48<00:52,  2.22it/s][Astep: 112
extend+tolist() time: 0.00042319297790527344

Evaluating:  50%|████▉     | 113/228 [00:49<00:49,  2.34it/s][Astep: 113
extend+tolist() time: 0.00070953369140625

Evaluating:  50%|█████     | 114/228 [00:49<00:47,  2.42it/s][Astep: 114
extend+tolist() time: 0.0015735626220703125

Evaluating:  50%|█████     | 115/228 [00:49<00:48,  2.34it/s][Astep: 115
extend+tolist() time: 0.0009677410125732422

Evaluating:  51%|█████     | 116/228 [00:50<00:54,  2.04it/s][Astep: 116
extend+tolist() time: 0.0007765293121337891

Evaluating:  51%|█████▏    | 117/228 [00:50<00:51,  2.14it/s][Astep: 117
extend+tolist() time: 0.0012650489807128906

Evaluating:  52%|█████▏    | 118/228 [00:51<00:48,  2.26it/s][Astep: 118
extend+tolist() time: 0.0005524158477783203

Evaluating:  52%|█████▏    | 119/228 [00:51<00:48,  2.25it/s][Astep: 119
extend+tolist() time: 0.0007195472717285156

Evaluating:  53%|█████▎    | 120/228 [00:52<00:46,  2.35it/s][Astep: 120
extend+tolist() time: 0.0010442733764648438

Evaluating:  53%|█████▎    | 121/228 [00:52<00:44,  2.38it/s][Astep: 121
extend+tolist() time: 0.0006380081176757812

Evaluating:  54%|█████▎    | 122/228 [00:52<00:44,  2.39it/s][Astep: 122
extend+tolist() time: 0.0011029243469238281

Evaluating:  54%|█████▍    | 123/228 [00:53<00:42,  2.47it/s][Astep: 123
extend+tolist() time: 0.0006177425384521484

Evaluating:  54%|█████▍    | 124/228 [00:53<00:43,  2.40it/s][Astep: 124
extend+tolist() time: 0.0012094974517822266

Evaluating:  55%|█████▍    | 125/228 [00:54<00:41,  2.47it/s][Astep: 125
extend+tolist() time: 0.0004253387451171875

Evaluating:  55%|█████▌    | 126/228 [00:54<00:40,  2.53it/s][Astep: 126
extend+tolist() time: 0.0016908645629882812

Evaluating:  56%|█████▌    | 127/228 [00:54<00:41,  2.46it/s][Astep: 127
extend+tolist() time: 0.0012731552124023438

Evaluating:  56%|█████▌    | 128/228 [00:55<00:40,  2.49it/s][Astep: 128
extend+tolist() time: 0.001455545425415039

Evaluating:  57%|█████▋    | 129/228 [00:55<00:40,  2.44it/s][Astep: 129
extend+tolist() time: 0.0007741451263427734

Evaluating:  57%|█████▋    | 130/228 [00:56<00:39,  2.50it/s][Astep: 130
extend+tolist() time: 0.0013585090637207031

Evaluating:  57%|█████▋    | 131/228 [00:56<00:38,  2.54it/s][Astep: 131
extend+tolist() time: 0.0005068778991699219

Evaluating:  58%|█████▊    | 132/228 [00:56<00:39,  2.46it/s][Astep: 132
extend+tolist() time: 0.0016186237335205078

Evaluating:  58%|█████▊    | 133/228 [00:57<00:38,  2.50it/s][Astep: 133
extend+tolist() time: 0.0005006790161132812

Evaluating:  59%|█████▉    | 134/228 [00:57<00:37,  2.49it/s][Astep: 134
extend+tolist() time: 0.0014200210571289062

Evaluating:  59%|█████▉    | 135/228 [00:58<00:37,  2.45it/s][Astep: 135
extend+tolist() time: 0.0005116462707519531

Evaluating:  60%|█████▉    | 136/228 [00:58<00:36,  2.52it/s][Astep: 136
extend+tolist() time: 0.0013146400451660156

Evaluating:  60%|██████    | 137/228 [00:58<00:37,  2.43it/s][Astep: 137
extend+tolist() time: 0.0004353523254394531

Evaluating:  61%|██████    | 138/228 [00:59<00:35,  2.50it/s][Astep: 138
extend+tolist() time: 0.0008106231689453125

Evaluating:  61%|██████    | 139/228 [00:59<00:35,  2.47it/s][Astep: 139
extend+tolist() time: 0.0005288124084472656

Evaluating:  61%|██████▏   | 140/228 [01:00<00:36,  2.44it/s][Astep: 140
extend+tolist() time: 0.0008487701416015625

Evaluating:  62%|██████▏   | 141/228 [01:00<00:35,  2.48it/s][Astep: 141
extend+tolist() time: 0.0008945465087890625

Evaluating:  62%|██████▏   | 142/228 [01:01<00:35,  2.40it/s][Astep: 142
extend+tolist() time: 0.0011029243469238281

Evaluating:  63%|██████▎   | 143/228 [01:01<00:34,  2.48it/s][Astep: 143
extend+tolist() time: 0.0003669261932373047

Evaluating:  63%|██████▎   | 144/228 [01:01<00:33,  2.49it/s][Astep: 144
extend+tolist() time: 0.0007824897766113281

Evaluating:  64%|██████▎   | 145/228 [01:02<00:33,  2.47it/s][Astep: 145
extend+tolist() time: 0.0009627342224121094

Evaluating:  64%|██████▍   | 146/228 [01:02<00:32,  2.55it/s][Astep: 146
extend+tolist() time: 0.0004284381866455078

Evaluating:  64%|██████▍   | 147/228 [01:03<00:33,  2.45it/s][Astep: 147
extend+tolist() time: 0.0008351802825927734

Evaluating:  65%|██████▍   | 148/228 [01:03<00:31,  2.51it/s][Astep: 148
extend+tolist() time: 0.0011646747589111328

Evaluating:  65%|██████▌   | 149/228 [01:03<00:31,  2.50it/s][Astep: 149
extend+tolist() time: 0.00040078163146972656

Evaluating:  66%|██████▌   | 150/228 [01:04<00:31,  2.47it/s][Astep: 150
extend+tolist() time: 0.0009615421295166016

Evaluating:  66%|██████▌   | 151/228 [01:04<00:30,  2.51it/s][Astep: 151
extend+tolist() time: 0.0011708736419677734

Evaluating:  67%|██████▋   | 152/228 [01:05<00:31,  2.41it/s][Astep: 152
extend+tolist() time: 0.0009179115295410156

Evaluating:  67%|██████▋   | 153/228 [01:05<00:30,  2.46it/s][Astep: 153
extend+tolist() time: 0.0014145374298095703

Evaluating:  68%|██████▊   | 154/228 [01:05<00:30,  2.44it/s][Astep: 154
extend+tolist() time: 0.002031564712524414

Evaluating:  68%|██████▊   | 155/228 [01:06<00:30,  2.38it/s][Astep: 155
extend+tolist() time: 0.0007114410400390625

Evaluating:  68%|██████▊   | 156/228 [01:06<00:29,  2.46it/s][Astep: 156
extend+tolist() time: 0.0005698204040527344

Evaluating:  69%|██████▉   | 157/228 [01:07<00:29,  2.39it/s][Astep: 157
extend+tolist() time: 0.0011556148529052734

Evaluating:  69%|██████▉   | 158/228 [01:07<00:28,  2.45it/s][Astep: 158
extend+tolist() time: 0.0005118846893310547

Evaluating:  70%|██████▉   | 159/228 [01:07<00:28,  2.45it/s][Astep: 159
extend+tolist() time: 0.0006966590881347656

Evaluating:  70%|███████   | 160/228 [01:08<00:27,  2.43it/s][Astep: 160
extend+tolist() time: 0.0008347034454345703

Evaluating:  71%|███████   | 161/228 [01:08<00:26,  2.49it/s][Astep: 161
extend+tolist() time: 0.0008261203765869141

Evaluating:  71%|███████   | 162/228 [01:09<00:27,  2.40it/s][Astep: 162
extend+tolist() time: 0.0005071163177490234

Evaluating:  71%|███████▏  | 163/228 [01:09<00:26,  2.47it/s][Astep: 163
extend+tolist() time: 0.00043010711669921875

Evaluating:  72%|███████▏  | 164/228 [01:09<00:25,  2.46it/s][Astep: 164
extend+tolist() time: 0.0010471343994140625

Evaluating:  72%|███████▏  | 165/228 [01:10<00:25,  2.45it/s][Astep: 165
extend+tolist() time: 0.00047779083251953125

Evaluating:  73%|███████▎  | 166/228 [01:10<00:24,  2.49it/s][Astep: 166
extend+tolist() time: 0.00060272216796875

Evaluating:  73%|███████▎  | 167/228 [01:11<00:25,  2.38it/s][Astep: 167
extend+tolist() time: 0.0005908012390136719

Evaluating:  74%|███████▎  | 168/228 [01:11<00:24,  2.44it/s][Astep: 168
extend+tolist() time: 0.0012080669403076172

Evaluating:  74%|███████▍  | 169/228 [01:12<00:24,  2.41it/s][Astep: 169
extend+tolist() time: 0.0003814697265625

Evaluating:  75%|███████▍  | 170/228 [01:12<00:23,  2.45it/s][Astep: 170
extend+tolist() time: 0.0013818740844726562

Evaluating:  75%|███████▌  | 171/228 [01:12<00:22,  2.49it/s][Astep: 171
extend+tolist() time: 0.0002956390380859375

Evaluating:  75%|███████▌  | 172/228 [01:13<00:23,  2.40it/s][Astep: 172
extend+tolist() time: 0.0008394718170166016

Evaluating:  76%|███████▌  | 173/228 [01:13<00:22,  2.46it/s][Astep: 173
extend+tolist() time: 0.0015714168548583984

Evaluating:  76%|███████▋  | 174/228 [01:14<00:22,  2.43it/s][Astep: 174
extend+tolist() time: 0.001811981201171875

Evaluating:  77%|███████▋  | 175/228 [01:14<00:21,  2.41it/s][Astep: 175
extend+tolist() time: 0.0008294582366943359

Evaluating:  77%|███████▋  | 176/228 [01:15<00:24,  2.09it/s][Astep: 176
extend+tolist() time: 0.0010149478912353516

Evaluating:  78%|███████▊  | 177/228 [01:15<00:23,  2.20it/s][Astep: 177
extend+tolist() time: 0.0006051063537597656

Evaluating:  78%|███████▊  | 178/228 [01:15<00:21,  2.28it/s][Astep: 178
extend+tolist() time: 0.0016031265258789062

Evaluating:  79%|███████▊  | 179/228 [01:16<00:21,  2.27it/s][Astep: 179
extend+tolist() time: 0.0004069805145263672

Evaluating:  79%|███████▉  | 180/228 [01:16<00:20,  2.37it/s][Astep: 180
extend+tolist() time: 0.0003821849822998047

Evaluating:  79%|███████▉  | 181/228 [01:17<00:19,  2.37it/s][Astep: 181
extend+tolist() time: 0.0006053447723388672

Evaluating:  80%|███████▉  | 182/228 [01:17<00:19,  2.41it/s][Astep: 182
extend+tolist() time: 0.001218557357788086

Evaluating:  80%|████████  | 183/228 [01:17<00:18,  2.44it/s][Astep: 183
extend+tolist() time: 0.0006592273712158203

Evaluating:  81%|████████  | 184/228 [01:18<00:18,  2.40it/s][Astep: 184
extend+tolist() time: 0.0004444122314453125

Evaluating:  81%|████████  | 185/228 [01:18<00:17,  2.46it/s][Astep: 185
extend+tolist() time: 0.251645565032959

Evaluating:  82%|████████▏ | 186/228 [01:19<00:20,  2.03it/s][Astep: 186
extend+tolist() time: 0.0014853477478027344

Evaluating:  82%|████████▏ | 187/228 [01:19<00:18,  2.17it/s][Astep: 187
extend+tolist() time: 0.0004303455352783203

Evaluating:  82%|████████▏ | 188/228 [01:20<00:17,  2.24it/s][Astep: 188
extend+tolist() time: 0.0007040500640869141

Evaluating:  83%|████████▎ | 189/228 [01:20<00:16,  2.31it/s][Astep: 189
extend+tolist() time: 0.0003452301025390625

Evaluating:  83%|████████▎ | 190/228 [01:21<00:16,  2.34it/s][Astep: 190
extend+tolist() time: 0.0011627674102783203

Evaluating:  84%|████████▍ | 191/228 [01:21<00:15,  2.33it/s][Astep: 191
extend+tolist() time: 0.001096487045288086

Evaluating:  84%|████████▍ | 192/228 [01:21<00:15,  2.40it/s][Astep: 192
extend+tolist() time: 0.0004436969757080078

Evaluating:  85%|████████▍ | 193/228 [01:22<00:14,  2.37it/s][Astep: 193
extend+tolist() time: 0.0014612674713134766

Evaluating:  85%|████████▌ | 194/228 [01:22<00:14,  2.37it/s][Astep: 194
extend+tolist() time: 0.000598907470703125

Evaluating:  86%|████████▌ | 195/228 [01:23<00:13,  2.38it/s][Astep: 195
extend+tolist() time: 0.0005443096160888672

Evaluating:  86%|████████▌ | 196/228 [01:23<00:15,  2.02it/s][Astep: 196
extend+tolist() time: 0.0010111331939697266

Evaluating:  86%|████████▋ | 197/228 [01:24<00:14,  2.11it/s][Astep: 197
extend+tolist() time: 0.0006830692291259766

Evaluating:  87%|████████▋ | 198/228 [01:24<00:13,  2.20it/s][Astep: 198
extend+tolist() time: 0.0006084442138671875

Evaluating:  87%|████████▋ | 199/228 [01:25<00:12,  2.29it/s][Astep: 199
extend+tolist() time: 0.0019259452819824219

Evaluating:  88%|████████▊ | 200/228 [01:25<00:12,  2.26it/s][Astep: 200
extend+tolist() time: 0.0007054805755615234

Evaluating:  88%|████████▊ | 201/228 [01:25<00:11,  2.35it/s][Astep: 201
extend+tolist() time: 0.0010018348693847656

Evaluating:  89%|████████▊ | 202/228 [01:26<00:11,  2.34it/s][Astep: 202
extend+tolist() time: 0.00038170814514160156

Evaluating:  89%|████████▉ | 203/228 [01:26<00:10,  2.39it/s][Astep: 203
extend+tolist() time: 0.0005025863647460938

Evaluating:  89%|████████▉ | 204/228 [01:27<00:10,  2.39it/s][Astep: 204
extend+tolist() time: 0.0004000663757324219

Evaluating:  90%|████████▉ | 205/228 [01:27<00:09,  2.39it/s][Astep: 205
extend+tolist() time: 0.0007274150848388672

Evaluating:  90%|█████████ | 206/228 [01:27<00:08,  2.45it/s][Astep: 206
extend+tolist() time: 0.0005953311920166016

Evaluating:  91%|█████████ | 207/228 [01:28<00:08,  2.41it/s][Astep: 207
extend+tolist() time: 0.0006155967712402344

Evaluating:  91%|█████████ | 208/228 [01:28<00:08,  2.42it/s][Astep: 208
extend+tolist() time: 0.0010967254638671875

Evaluating:  92%|█████████▏| 209/228 [01:29<00:07,  2.38it/s][Astep: 209
extend+tolist() time: 0.0005884170532226562

Evaluating:  92%|█████████▏| 210/228 [01:29<00:07,  2.33it/s][Astep: 210
extend+tolist() time: 0.0006010532379150391

Evaluating:  93%|█████████▎| 211/228 [01:30<00:07,  2.39it/s][Astep: 211
extend+tolist() time: 0.0017817020416259766

Evaluating:  93%|█████████▎| 212/228 [01:30<00:06,  2.31it/s][Astep: 212
extend+tolist() time: 0.0009140968322753906

Evaluating:  93%|█████████▎| 213/228 [01:30<00:06,  2.36it/s][Astep: 213
extend+tolist() time: 0.0011925697326660156

Evaluating:  94%|█████████▍| 214/228 [01:31<00:06,  2.31it/s][Astep: 214
extend+tolist() time: 0.0008630752563476562

Evaluating:  94%|█████████▍| 215/228 [01:31<00:05,  2.33it/s][Astep: 215
extend+tolist() time: 0.0010678768157958984

Evaluating:  95%|█████████▍| 216/228 [01:32<00:05,  2.34it/s][Astep: 216
extend+tolist() time: 0.0005686283111572266

Evaluating:  95%|█████████▌| 217/228 [01:32<00:04,  2.36it/s][Astep: 217
extend+tolist() time: 0.0005772113800048828

Evaluating:  96%|█████████▌| 218/228 [01:33<00:04,  2.41it/s][Astep: 218
extend+tolist() time: 0.0015177726745605469

Evaluating:  96%|█████████▌| 219/228 [01:33<00:03,  2.34it/s][Astep: 219
extend+tolist() time: 0.0004906654357910156

Evaluating:  96%|█████████▋| 220/228 [01:33<00:03,  2.37it/s][Astep: 220
extend+tolist() time: 0.00040459632873535156

Evaluating:  97%|█████████▋| 221/228 [01:34<00:02,  2.35it/s][Astep: 221
extend+tolist() time: 0.001043558120727539

Evaluating:  97%|█████████▋| 222/228 [01:34<00:02,  2.35it/s][Astep: 222
extend+tolist() time: 0.00041985511779785156

Evaluating:  98%|█████████▊| 223/228 [01:35<00:02,  2.40it/s][Astep: 223
extend+tolist() time: 0.0006318092346191406

Evaluating:  98%|█████████▊| 224/228 [01:35<00:01,  2.35it/s][Astep: 224
extend+tolist() time: 0.0003826618194580078

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.41it/s][Astep: 225
extend+tolist() time: 0.0004367828369140625

Evaluating:  99%|█████████▉| 226/228 [01:36<00:00,  2.37it/s][Astep: 226
extend+tolist() time: 0.0010366439819335938

Evaluating: 100%|█████████▉| 227/228 [01:36<00:00,  2.38it/s][Astep: 227
extend+tolist() time: 0.0005006790161132812

Evaluating: 100%|██████████| 228/228 [01:37<00:00,  2.33it/s][A09/08/2023 22:21:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 22:21:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:21:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:21:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:21:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:21:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:21:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:21:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:21:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:21:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:21:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:21:23 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:21:24 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:21:24 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:21:24 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:21:24 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:21:24 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:39<00:00,  2.30it/s]
09/08/2023 22:21:24 - INFO - __main__ -   Step: 1460, Validation Metrics: {'pred_1_num': 9580, 'pred_-1_num': 1184, 'pred_0_num': 37, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7916859550041663, 'f1_micro': 0.7916859550041662, 'f1_macro': 0.4404227276199784, 'f1_weighted': 0.7599146541900784, 'f1_-1': 0.3978181818181818, 'f1_0': 0.04437869822485207, 'f1_1': 0.8790713028169014, 'precision_micro': 0.7916859550041663, 'precision_macro': 0.567107830690816, 'precision_weighted': 0.754648035093413, 'precision_-1': 0.46199324324324326, 'precision_0': 0.40540540540540543, 'precision_1': 0.8339248434237996, 'recall_micro': 0.7916859550041663, 'recall_macro': 0.43405250421941527, 'recall_weighted': 0.7916859550041663, 'recall_-1': 0.3492975734355045, 'recall_0': 0.023474178403755867, 'recall_1': 0.9293857608189856, 'roc_auc_micro': 0.9068139631479942, 'roc_auc_macro': 0.7263839814737946, 'roc_auc_weighted': 0.7006060177870376, 'roc_auc_-1': 0.7643658799848707, 'roc_auc_0': 0.7278185723054899, 'roc_auc_1': 0.6869674921310234}
09/08/2023 22:21:38 - INFO - __main__ - Saving state to /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818
09/08/2023 22:21:38 - INFO - accelerate.accelerator - Saving current state to /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818
09/08/2023 22:21:38 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2023-09-08 22:21:38,822] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2023-09-08 22:21:38,830] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt...
[2023-09-08 22:21:38,830] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt...
[2023-09-08 22:21:38,830] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt
[2023-09-08 22:21:38,830] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt...
[2023-09-08 22:21:38,831] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt
[2023-09-08 22:21:38,831] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-09-08 22:21:38,844] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt.
[2023-09-08 22:21:38,844] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt.
[2023-09-08 22:21:38,844] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt.
[2023-09-08 22:21:38,846] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-09-08 22:21:38,849] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2023-09-08 22:21:38,849] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[2023-09-08 22:21:38,849] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-09-08 22:21:38,849] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2023-09-08 22:22:23,443] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[2023-09-08 22:22:23,443] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt
[2023-09-08 22:22:26,663] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2023-09-08 22:22:26,664] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2023-09-08 22:22:28,146] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-09-08 22:22:28,147] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2023-09-08 22:22:30,026] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[2023-09-08 22:22:30,026] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt
[2023-09-08 22:22:30,072] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 22:22:30,072] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 22:22:30,072] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 22:22:30,072] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/08/2023 22:22:30 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/pytorch_model
09/08/2023 22:22:30 - INFO - accelerate.checkpointing - Scheduler state saved in /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/scheduler.bin
09/08/2023 22:22:30 - INFO - accelerate.checkpointing - Random states saved in /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1460-best-f1_-1=0.3978181818181818/random_states_0.pkl
[2023-09-08 22:22:49,826] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1461/66600 [59:59<1259:46:07, 69.62s/it]09/08/2023 22:22:49 - INFO - __main__ -   Step: 1461, LR: 1.463011641006384e-05, Loss: 0.4265146255493164
[2023-09-08 22:23:10,622] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1462/66600 [1:00:20<994:42:29, 54.97s/it]09/08/2023 22:23:10 - INFO - __main__ -   Step: 1462, LR: 1.4640130178996122e-05, Loss: 0.37481003999710083
[2023-09-08 22:23:31,264] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1463/66600 [1:00:40<808:19:56, 44.68s/it]09/08/2023 22:23:31 - INFO - __main__ -   Step: 1463, LR: 1.4650143947928403e-05, Loss: 0.39599770307540894
[2023-09-08 22:23:52,139] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1464/66600 [1:01:01<679:07:56, 37.53s/it]09/08/2023 22:23:52 - INFO - __main__ -   Step: 1464, LR: 1.4660157716860686e-05, Loss: 0.42320457100868225
[2023-09-08 22:24:13,007] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1465/66600 [1:01:22<588:39:25, 32.53s/it]09/08/2023 22:24:13 - INFO - __main__ -   Step: 1465, LR: 1.4670171485792966e-05, Loss: 0.3828788697719574
[2023-09-08 22:24:33,401] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1466/66600 [1:01:42<522:44:57, 28.89s/it]09/08/2023 22:24:33 - INFO - __main__ -   Step: 1466, LR: 1.4680185254725248e-05, Loss: 0.4048807919025421
[2023-09-08 22:24:54,062] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1467/66600 [1:02:03<478:03:45, 26.42s/it]09/08/2023 22:24:54 - INFO - __main__ -   Step: 1467, LR: 1.469019902365753e-05, Loss: 0.4314844608306885
[2023-09-08 22:25:14,750] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1468/66600 [1:02:24<446:55:18, 24.70s/it]09/08/2023 22:25:14 - INFO - __main__ -   Step: 1468, LR: 1.4700212792589811e-05, Loss: 0.40786927938461304
[2023-09-08 22:25:35,511] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1469/66600 [1:02:45<425:31:16, 23.52s/it]09/08/2023 22:25:35 - INFO - __main__ -   Step: 1469, LR: 1.4710226561522094e-05, Loss: 0.37124359607696533
[2023-09-08 22:25:55,612] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1470/66600 [1:03:05<406:57:38, 22.49s/it]09/08/2023 22:25:55 - INFO - __main__ -   Step: 1470, LR: 1.4720240330454376e-05, Loss: 0.4584815502166748
[2023-09-08 22:26:16,384] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1471/66600 [1:03:25<397:36:20, 21.98s/it]09/08/2023 22:26:16 - INFO - __main__ -   Step: 1471, LR: 1.4730254099386658e-05, Loss: 0.3670068383216858
[2023-09-08 22:26:36,928] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1472/66600 [1:03:46<389:49:17, 21.55s/it]09/08/2023 22:26:36 - INFO - __main__ -   Step: 1472, LR: 1.4740267868318941e-05, Loss: 0.3844549059867859
[2023-09-08 22:26:58,200] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1473/66600 [1:04:07<388:19:08, 21.46s/it]09/08/2023 22:26:58 - INFO - __main__ -   Step: 1473, LR: 1.4750281637251223e-05, Loss: 0.4128558933734894
[2023-09-08 22:27:19,155] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1474/66600 [1:04:28<385:32:39, 21.31s/it]09/08/2023 22:27:19 - INFO - __main__ -   Step: 1474, LR: 1.4760295406183502e-05, Loss: 0.42620670795440674
[2023-09-08 22:27:39,666] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1475/66600 [1:04:49<381:11:23, 21.07s/it]09/08/2023 22:27:39 - INFO - __main__ -   Step: 1475, LR: 1.4770309175115784e-05, Loss: 0.34765684604644775
[2023-09-08 22:27:59,711] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1476/66600 [1:05:09<375:36:51, 20.76s/it]09/08/2023 22:27:59 - INFO - __main__ -   Step: 1476, LR: 1.4780322944048067e-05, Loss: 0.4410131573677063
[2023-09-08 22:28:20,831] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1477/66600 [1:05:30<377:32:37, 20.87s/it]09/08/2023 22:28:20 - INFO - __main__ -   Step: 1477, LR: 1.4790336712980349e-05, Loss: 0.504601001739502
[2023-09-08 22:28:41,782] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1478/66600 [1:05:51<377:58:25, 20.89s/it]09/08/2023 22:28:41 - INFO - __main__ -   Step: 1478, LR: 1.480035048191263e-05, Loss: 0.35820290446281433
[2023-09-08 22:29:02,382] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1479/66600 [1:06:11<376:21:58, 20.81s/it]09/08/2023 22:29:02 - INFO - __main__ -   Step: 1479, LR: 1.4810364250844912e-05, Loss: 0.42247679829597473
[2023-09-08 22:29:23,098] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1480/66600 [1:06:32<375:52:31, 20.78s/it]09/08/2023 22:29:23 - INFO - __main__ -   Step: 1480, LR: 1.4820378019777196e-05, Loss: 0.4159509241580963
09/08/2023 22:29:23 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.14997005462646484

Evaluating:   0%|          | 1/228 [00:00<02:22,  1.59it/s][Astep: 1
extend+tolist() time: 0.0015788078308105469

Evaluating:   1%|          | 2/228 [00:01<01:55,  1.96it/s][Astep: 2
extend+tolist() time: 0.0019969940185546875

Evaluating:   1%|▏         | 3/228 [00:01<01:44,  2.16it/s][Astep: 3
extend+tolist() time: 0.0018854141235351562

Evaluating:   2%|▏         | 4/228 [00:01<01:44,  2.15it/s][Astep: 4
extend+tolist() time: 0.0010018348693847656

Evaluating:   2%|▏         | 5/228 [00:02<01:37,  2.29it/s][Astep: 5
extend+tolist() time: 0.002118349075317383

Evaluating:   3%|▎         | 6/228 [00:02<01:35,  2.31it/s][Astep: 6
extend+tolist() time: 0.0019576549530029297

Evaluating:   3%|▎         | 7/228 [00:03<01:35,  2.30it/s][Astep: 7
extend+tolist() time: 0.0013279914855957031

Evaluating:   4%|▎         | 8/228 [00:03<01:32,  2.37it/s][Astep: 8
extend+tolist() time: 0.0007801055908203125

Evaluating:   4%|▍         | 9/228 [00:04<01:34,  2.33it/s][Astep: 9
extend+tolist() time: 0.001264810562133789

Evaluating:   4%|▍         | 10/228 [00:04<01:41,  2.15it/s][Astep: 10
extend+tolist() time: 0.0008769035339355469

Evaluating:   5%|▍         | 11/228 [00:05<01:39,  2.18it/s][Astep: 11
extend+tolist() time: 0.0009732246398925781

Evaluating:   5%|▌         | 12/228 [00:05<01:34,  2.29it/s][Astep: 12
extend+tolist() time: 0.0009415149688720703

Evaluating:   6%|▌         | 13/228 [00:05<01:34,  2.27it/s][Astep: 13
extend+tolist() time: 0.0006077289581298828

Evaluating:   6%|▌         | 14/228 [00:06<01:30,  2.35it/s][Astep: 14
extend+tolist() time: 0.0010187625885009766

Evaluating:   7%|▋         | 15/228 [00:06<01:27,  2.42it/s][Astep: 15
extend+tolist() time: 0.0005996227264404297

Evaluating:   7%|▋         | 16/228 [00:07<01:29,  2.36it/s][Astep: 16
extend+tolist() time: 0.0006265640258789062

Evaluating:   7%|▋         | 17/228 [00:07<01:26,  2.43it/s][Astep: 17
extend+tolist() time: 0.0009052753448486328

Evaluating:   8%|▊         | 18/228 [00:07<01:27,  2.39it/s][Astep: 18
extend+tolist() time: 0.001711130142211914

Evaluating:   8%|▊         | 19/228 [00:08<01:26,  2.43it/s][Astep: 19
extend+tolist() time: 0.0010027885437011719

Evaluating:   9%|▉         | 20/228 [00:08<01:24,  2.46it/s][Astep: 20
extend+tolist() time: 0.0012388229370117188

Evaluating:   9%|▉         | 21/228 [00:09<01:34,  2.20it/s][Astep: 21
extend+tolist() time: 0.0007002353668212891

Evaluating:  10%|▉         | 22/228 [00:09<01:44,  1.98it/s][Astep: 22
extend+tolist() time: 0.0011832714080810547

Evaluating:  10%|█         | 23/228 [00:10<01:41,  2.01it/s][Astep: 23
extend+tolist() time: 0.0007100105285644531

Evaluating:  11%|█         | 24/228 [00:10<01:35,  2.13it/s][Astep: 24
extend+tolist() time: 0.0016193389892578125

Evaluating:  11%|█         | 25/228 [00:11<01:34,  2.16it/s][Astep: 25
extend+tolist() time: 0.0018529891967773438

Evaluating:  11%|█▏        | 26/228 [00:11<01:29,  2.25it/s][Astep: 26
extend+tolist() time: 0.0007441043853759766

Evaluating:  12%|█▏        | 27/228 [00:12<01:29,  2.24it/s][Astep: 27
extend+tolist() time: 0.17341232299804688

Evaluating:  12%|█▏        | 28/228 [00:12<01:36,  2.07it/s][Astep: 28
extend+tolist() time: 0.00033783912658691406

Evaluating:  13%|█▎        | 29/228 [00:13<01:34,  2.11it/s][Astep: 29
extend+tolist() time: 0.0007100105285644531

Evaluating:  13%|█▎        | 30/228 [00:13<01:28,  2.25it/s][Astep: 30
extend+tolist() time: 0.001455545425415039

Evaluating:  14%|█▎        | 31/228 [00:13<01:25,  2.31it/s][Astep: 31
extend+tolist() time: 0.0005695819854736328

Evaluating:  14%|█▍        | 32/228 [00:14<01:24,  2.31it/s][Astep: 32
extend+tolist() time: 0.0013670921325683594

Evaluating:  14%|█▍        | 33/228 [00:14<01:22,  2.36it/s][Astep: 33
extend+tolist() time: 0.0016205310821533203

Evaluating:  15%|█▍        | 34/228 [00:15<01:24,  2.31it/s][Astep: 34
extend+tolist() time: 0.0008821487426757812

Evaluating:  15%|█▌        | 35/228 [00:15<01:20,  2.38it/s][Astep: 35
extend+tolist() time: 0.0011260509490966797

Evaluating:  16%|█▌        | 36/228 [00:15<01:19,  2.42it/s][Astep: 36
extend+tolist() time: 0.0007970333099365234

Evaluating:  16%|█▌        | 37/228 [00:16<01:20,  2.39it/s][Astep: 37
extend+tolist() time: 0.0017347335815429688

Evaluating:  17%|█▋        | 38/228 [00:16<01:18,  2.42it/s][Astep: 38
extend+tolist() time: 0.0007677078247070312

Evaluating:  17%|█▋        | 39/228 [00:17<01:20,  2.36it/s][Astep: 39
extend+tolist() time: 0.0007228851318359375

Evaluating:  18%|█▊        | 40/228 [00:17<01:17,  2.43it/s][Astep: 40
extend+tolist() time: 0.0006494522094726562

Evaluating:  18%|█▊        | 41/228 [00:17<01:16,  2.44it/s][Astep: 41
extend+tolist() time: 0.0013575553894042969

Evaluating:  18%|█▊        | 42/228 [00:18<01:16,  2.44it/s][Astep: 42
extend+tolist() time: 0.0015807151794433594

Evaluating:  19%|█▉        | 43/228 [00:18<01:15,  2.46it/s][Astep: 43
extend+tolist() time: 0.001844167709350586

Evaluating:  19%|█▉        | 44/228 [00:19<01:26,  2.12it/s][Astep: 44
extend+tolist() time: 0.0007817745208740234

Evaluating:  20%|█▉        | 45/228 [00:19<01:21,  2.25it/s][Astep: 45
extend+tolist() time: 0.0016896724700927734

Evaluating:  20%|██        | 46/228 [00:20<01:21,  2.23it/s][Astep: 46
extend+tolist() time: 0.0016503334045410156

Evaluating:  21%|██        | 47/228 [00:20<01:18,  2.31it/s][Astep: 47
extend+tolist() time: 0.0011148452758789062

Evaluating:  21%|██        | 48/228 [00:21<01:18,  2.30it/s][Astep: 48
extend+tolist() time: 0.0012028217315673828

Evaluating:  21%|██▏       | 49/228 [00:21<01:15,  2.37it/s][Astep: 49
extend+tolist() time: 0.0014035701751708984

Evaluating:  22%|██▏       | 50/228 [00:21<01:13,  2.43it/s][Astep: 50
extend+tolist() time: 0.0016906261444091797

Evaluating:  22%|██▏       | 51/228 [00:22<01:15,  2.35it/s][Astep: 51
extend+tolist() time: 0.0012307167053222656

Evaluating:  23%|██▎       | 52/228 [00:22<01:23,  2.10it/s][Astep: 52
extend+tolist() time: 0.0009922981262207031

Evaluating:  23%|██▎       | 53/228 [00:23<01:28,  1.98it/s][Astep: 53
extend+tolist() time: 0.0018262863159179688

Evaluating:  24%|██▎       | 54/228 [00:23<01:22,  2.11it/s][Astep: 54
extend+tolist() time: 0.0011861324310302734

Evaluating:  24%|██▍       | 55/228 [00:24<01:20,  2.16it/s][Astep: 55
extend+tolist() time: 0.0007996559143066406

Evaluating:  25%|██▍       | 56/228 [00:24<01:15,  2.28it/s][Astep: 56
extend+tolist() time: 0.0016548633575439453

Evaluating:  25%|██▌       | 57/228 [00:25<01:15,  2.27it/s][Astep: 57
extend+tolist() time: 0.0005872249603271484

Evaluating:  25%|██▌       | 58/228 [00:25<01:11,  2.38it/s][Astep: 58
extend+tolist() time: 0.16536903381347656

Evaluating:  26%|██▌       | 59/228 [00:26<01:17,  2.17it/s][Astep: 59
extend+tolist() time: 0.0009434223175048828

Evaluating:  26%|██▋       | 60/228 [00:26<01:15,  2.21it/s][Astep: 60
extend+tolist() time: 0.0007097721099853516

Evaluating:  27%|██▋       | 61/228 [00:26<01:12,  2.32it/s][Astep: 61
extend+tolist() time: 0.001291036605834961

Evaluating:  27%|██▋       | 62/228 [00:27<01:12,  2.29it/s][Astep: 62
extend+tolist() time: 0.0007963180541992188

Evaluating:  28%|██▊       | 63/228 [00:27<01:09,  2.38it/s][Astep: 63
extend+tolist() time: 0.0015668869018554688

Evaluating:  28%|██▊       | 64/228 [00:28<01:09,  2.35it/s][Astep: 64
extend+tolist() time: 0.0008432865142822266

Evaluating:  29%|██▊       | 65/228 [00:28<01:08,  2.39it/s][Astep: 65
extend+tolist() time: 0.0012133121490478516

Evaluating:  29%|██▉       | 66/228 [00:28<01:06,  2.45it/s][Astep: 66
extend+tolist() time: 0.0007781982421875

Evaluating:  29%|██▉       | 67/228 [00:29<01:07,  2.38it/s][Astep: 67
extend+tolist() time: 0.001340627670288086

Evaluating:  30%|██▉       | 68/228 [00:29<01:05,  2.43it/s][Astep: 68
extend+tolist() time: 0.0007245540618896484

Evaluating:  30%|███       | 69/228 [00:30<01:06,  2.39it/s][Astep: 69
extend+tolist() time: 0.0016202926635742188

Evaluating:  31%|███       | 70/228 [00:30<01:04,  2.44it/s][Astep: 70
extend+tolist() time: 0.0014617443084716797

Evaluating:  31%|███       | 71/228 [00:31<01:03,  2.46it/s][Astep: 71
extend+tolist() time: 0.0010030269622802734

Evaluating:  32%|███▏      | 72/228 [00:31<01:05,  2.38it/s][Astep: 72
extend+tolist() time: 0.0012214183807373047

Evaluating:  32%|███▏      | 73/228 [00:31<01:03,  2.44it/s][Astep: 73
extend+tolist() time: 0.0005362033843994141

Evaluating:  32%|███▏      | 74/228 [00:32<01:04,  2.38it/s][Astep: 74
extend+tolist() time: 0.0011522769927978516

Evaluating:  33%|███▎      | 75/228 [00:32<01:02,  2.43it/s][Astep: 75
extend+tolist() time: 0.0012803077697753906

Evaluating:  33%|███▎      | 76/228 [00:33<01:02,  2.45it/s][Astep: 76
extend+tolist() time: 0.0010914802551269531

Evaluating:  34%|███▍      | 77/228 [00:33<01:03,  2.40it/s][Astep: 77
extend+tolist() time: 0.0018100738525390625

Evaluating:  34%|███▍      | 78/228 [00:33<01:02,  2.39it/s][Astep: 78
extend+tolist() time: 0.0008647441864013672

Evaluating:  35%|███▍      | 79/228 [00:34<01:12,  2.05it/s][Astep: 79
extend+tolist() time: 0.0013310909271240234

Evaluating:  35%|███▌      | 80/228 [00:35<01:07,  2.18it/s][Astep: 80
extend+tolist() time: 0.0013060569763183594

Evaluating:  36%|███▌      | 81/228 [00:35<01:07,  2.18it/s][Astep: 81
extend+tolist() time: 0.0008525848388671875

Evaluating:  36%|███▌      | 82/228 [00:35<01:04,  2.28it/s][Astep: 82
extend+tolist() time: 0.0012624263763427734

Evaluating:  36%|███▋      | 83/228 [00:36<01:02,  2.33it/s][Astep: 83
extend+tolist() time: 0.0007162094116210938

Evaluating:  37%|███▋      | 84/228 [00:36<01:02,  2.32it/s][Astep: 84
extend+tolist() time: 0.001397848129272461

Evaluating:  37%|███▋      | 85/228 [00:37<01:00,  2.38it/s][Astep: 85
extend+tolist() time: 0.0009212493896484375

Evaluating:  38%|███▊      | 86/228 [00:37<01:01,  2.32it/s][Astep: 86
extend+tolist() time: 0.0013439655303955078

Evaluating:  38%|███▊      | 87/228 [00:37<00:59,  2.38it/s][Astep: 87
extend+tolist() time: 0.0009148120880126953

Evaluating:  39%|███▊      | 88/228 [00:38<00:59,  2.35it/s][Astep: 88
extend+tolist() time: 0.0012054443359375

Evaluating:  39%|███▉      | 89/228 [00:38<00:57,  2.42it/s][Astep: 89
extend+tolist() time: 0.0007064342498779297

Evaluating:  39%|███▉      | 90/228 [00:39<00:56,  2.46it/s][Astep: 90
extend+tolist() time: 0.0013561248779296875

Evaluating:  40%|███▉      | 91/228 [00:39<00:57,  2.37it/s][Astep: 91
extend+tolist() time: 0.0007715225219726562

Evaluating:  40%|████      | 92/228 [00:40<01:03,  2.15it/s][Astep: 92
extend+tolist() time: 0.0012271404266357422

Evaluating:  41%|████      | 93/228 [00:40<01:02,  2.16it/s][Astep: 93
extend+tolist() time: 0.0013458728790283203

Evaluating:  41%|████      | 94/228 [00:41<01:06,  2.00it/s][Astep: 94
extend+tolist() time: 0.0007212162017822266

Evaluating:  42%|████▏     | 95/228 [00:41<01:03,  2.09it/s][Astep: 95
extend+tolist() time: 0.0016002655029296875

Evaluating:  42%|████▏     | 96/228 [00:42<01:00,  2.20it/s][Astep: 96
extend+tolist() time: 0.0009591579437255859

Evaluating:  43%|████▎     | 97/228 [00:42<00:59,  2.20it/s][Astep: 97
extend+tolist() time: 0.0012552738189697266

Evaluating:  43%|████▎     | 98/228 [00:42<00:56,  2.30it/s][Astep: 98
extend+tolist() time: 0.0012547969818115234

Evaluating:  43%|████▎     | 99/228 [00:43<00:55,  2.33it/s][Astep: 99
extend+tolist() time: 0.0008988380432128906

Evaluating:  44%|████▍     | 100/228 [00:43<00:55,  2.32it/s][Astep: 100
extend+tolist() time: 0.0011763572692871094

Evaluating:  44%|████▍     | 101/228 [00:44<00:53,  2.39it/s][Astep: 101
extend+tolist() time: 0.0008077621459960938

Evaluating:  45%|████▍     | 102/228 [00:44<00:53,  2.34it/s][Astep: 102
extend+tolist() time: 0.0011000633239746094

Evaluating:  45%|████▌     | 103/228 [00:44<00:51,  2.41it/s][Astep: 103
extend+tolist() time: 0.19015169143676758

Evaluating:  46%|████▌     | 104/228 [00:45<00:58,  2.13it/s][Astep: 104
extend+tolist() time: 0.0011661052703857422

Evaluating:  46%|████▌     | 105/228 [00:45<00:54,  2.25it/s][Astep: 105
extend+tolist() time: 0.0008487701416015625

Evaluating:  46%|████▋     | 106/228 [00:46<00:52,  2.31it/s][Astep: 106
extend+tolist() time: 0.0017192363739013672

Evaluating:  47%|████▋     | 107/228 [00:46<00:53,  2.28it/s][Astep: 107
extend+tolist() time: 0.0011250972747802734

Evaluating:  47%|████▋     | 108/228 [00:47<00:51,  2.35it/s][Astep: 108
extend+tolist() time: 0.0008022785186767578

Evaluating:  48%|████▊     | 109/228 [00:47<00:51,  2.32it/s][Astep: 109
extend+tolist() time: 0.0012066364288330078

Evaluating:  48%|████▊     | 110/228 [00:48<00:49,  2.38it/s][Astep: 110
extend+tolist() time: 0.000629425048828125

Evaluating:  49%|████▊     | 111/228 [00:48<00:48,  2.39it/s][Astep: 111
extend+tolist() time: 0.0018489360809326172

Evaluating:  49%|████▉     | 112/228 [00:48<00:49,  2.32it/s][Astep: 112
extend+tolist() time: 0.00038909912109375

Evaluating:  50%|████▉     | 113/228 [00:49<00:47,  2.41it/s][Astep: 113
extend+tolist() time: 0.0011026859283447266

Evaluating:  50%|█████     | 114/228 [00:49<00:48,  2.36it/s][Astep: 114
extend+tolist() time: 0.001458883285522461

Evaluating:  50%|█████     | 115/228 [00:50<00:47,  2.40it/s][Astep: 115
extend+tolist() time: 0.0006859302520751953

Evaluating:  51%|█████     | 116/228 [00:50<00:47,  2.38it/s][Astep: 116
extend+tolist() time: 0.0008425712585449219

Evaluating:  51%|█████▏    | 117/228 [00:50<00:45,  2.43it/s][Astep: 117
extend+tolist() time: 0.0013499259948730469

Evaluating:  52%|█████▏    | 118/228 [00:51<00:44,  2.46it/s][Astep: 118
extend+tolist() time: 0.0005741119384765625

Evaluating:  52%|█████▏    | 119/228 [00:51<00:45,  2.40it/s][Astep: 119
extend+tolist() time: 0.0011203289031982422

Evaluating:  53%|█████▎    | 120/228 [00:52<00:43,  2.46it/s][Astep: 120
extend+tolist() time: 0.0006709098815917969

Evaluating:  53%|█████▎    | 121/228 [00:52<00:44,  2.42it/s][Astep: 121
extend+tolist() time: 0.0010387897491455078

Evaluating:  54%|█████▎    | 122/228 [00:53<00:43,  2.46it/s][Astep: 122
extend+tolist() time: 0.0006778240203857422

Evaluating:  54%|█████▍    | 123/228 [00:53<00:42,  2.49it/s][Astep: 123
extend+tolist() time: 0.0006382465362548828

Evaluating:  54%|█████▍    | 124/228 [00:53<00:43,  2.41it/s][Astep: 124
extend+tolist() time: 0.0012989044189453125

Evaluating:  55%|█████▍    | 125/228 [00:54<00:42,  2.45it/s][Astep: 125
extend+tolist() time: 0.0004487037658691406

Evaluating:  55%|█████▌    | 126/228 [00:54<00:42,  2.39it/s][Astep: 126
extend+tolist() time: 0.0017242431640625

Evaluating:  56%|█████▌    | 127/228 [00:55<00:42,  2.39it/s][Astep: 127
extend+tolist() time: 0.0016775131225585938

Evaluating:  56%|█████▌    | 128/228 [00:55<00:42,  2.38it/s][Astep: 128
extend+tolist() time: 0.0007426738739013672

Evaluating:  57%|█████▋    | 129/228 [00:55<00:41,  2.37it/s][Astep: 129
extend+tolist() time: 0.0012390613555908203

Evaluating:  57%|█████▋    | 130/228 [00:56<00:46,  2.11it/s][Astep: 130
extend+tolist() time: 0.00090789794921875

Evaluating:  57%|█████▋    | 131/228 [00:56<00:44,  2.19it/s][Astep: 131
extend+tolist() time: 0.0008549690246582031

Evaluating:  58%|█████▊    | 132/228 [00:57<00:41,  2.33it/s][Astep: 132
extend+tolist() time: 0.001064300537109375

Evaluating:  58%|█████▊    | 133/228 [00:57<00:41,  2.30it/s][Astep: 133
extend+tolist() time: 0.0009076595306396484

Evaluating:  59%|█████▉    | 134/228 [00:58<00:39,  2.40it/s][Astep: 134
extend+tolist() time: 0.0011205673217773438

Evaluating:  59%|█████▉    | 135/228 [00:58<00:38,  2.41it/s][Astep: 135
extend+tolist() time: 0.0005030632019042969

Evaluating:  60%|█████▉    | 136/228 [00:58<00:38,  2.40it/s][Astep: 136
extend+tolist() time: 0.0014290809631347656

Evaluating:  60%|██████    | 137/228 [00:59<00:36,  2.47it/s][Astep: 137
extend+tolist() time: 0.0004382133483886719

Evaluating:  61%|██████    | 138/228 [00:59<00:37,  2.43it/s][Astep: 138
extend+tolist() time: 0.0011913776397705078

Evaluating:  61%|██████    | 139/228 [01:00<00:35,  2.50it/s][Astep: 139
extend+tolist() time: 0.0005254745483398438

Evaluating:  61%|██████▏   | 140/228 [01:00<00:34,  2.56it/s][Astep: 140
extend+tolist() time: 0.0008647441864013672

Evaluating:  62%|██████▏   | 141/228 [01:00<00:35,  2.48it/s][Astep: 141
extend+tolist() time: 0.0013120174407958984

Evaluating:  62%|██████▏   | 142/228 [01:01<00:33,  2.53it/s][Astep: 142
extend+tolist() time: 0.0008909702301025391

Evaluating:  63%|██████▎   | 143/228 [01:01<00:33,  2.53it/s][Astep: 143
extend+tolist() time: 0.00037932395935058594

Evaluating:  63%|██████▎   | 144/228 [01:02<00:32,  2.56it/s][Astep: 144
extend+tolist() time: 0.001241445541381836

Evaluating:  64%|██████▎   | 145/228 [01:02<00:32,  2.59it/s][Astep: 145
extend+tolist() time: 0.0005471706390380859

Evaluating:  64%|██████▍   | 146/228 [01:02<00:32,  2.53it/s][Astep: 146
extend+tolist() time: 0.0004334449768066406

Evaluating:  64%|██████▍   | 147/228 [01:03<00:31,  2.59it/s][Astep: 147
extend+tolist() time: 0.0012042522430419922

Evaluating:  65%|██████▍   | 148/228 [01:03<00:30,  2.59it/s][Astep: 148
extend+tolist() time: 0.0007398128509521484

Evaluating:  65%|██████▌   | 149/228 [01:04<00:30,  2.56it/s][Astep: 149
extend+tolist() time: 0.00039076805114746094

Evaluating:  66%|██████▌   | 150/228 [01:04<00:29,  2.61it/s][Astep: 150
extend+tolist() time: 0.0013773441314697266

Evaluating:  66%|██████▌   | 151/228 [01:04<00:30,  2.52it/s][Astep: 151
extend+tolist() time: 0.0006575584411621094

Evaluating:  67%|██████▋   | 152/228 [01:05<00:29,  2.56it/s][Astep: 152
extend+tolist() time: 0.0012943744659423828

Evaluating:  67%|██████▋   | 153/228 [01:05<00:29,  2.58it/s][Astep: 153
extend+tolist() time: 0.0010097026824951172

Evaluating:  68%|██████▊   | 154/228 [01:06<00:29,  2.49it/s][Astep: 154
extend+tolist() time: 0.002127408981323242

Evaluating:  68%|██████▊   | 155/228 [01:06<00:33,  2.16it/s][Astep: 155
extend+tolist() time: 0.0010881423950195312

Evaluating:  68%|██████▊   | 156/228 [01:07<00:35,  2.01it/s][Astep: 156
extend+tolist() time: 0.0005710124969482422

Evaluating:  69%|██████▉   | 157/228 [01:07<00:33,  2.15it/s][Astep: 157
extend+tolist() time: 0.0007338523864746094

Evaluating:  69%|██████▉   | 158/228 [01:08<00:32,  2.18it/s][Astep: 158
extend+tolist() time: 0.0005071163177490234

Evaluating:  70%|██████▉   | 159/228 [01:08<00:30,  2.28it/s][Astep: 159
extend+tolist() time: 0.0011935234069824219

Evaluating:  70%|███████   | 160/228 [01:08<00:29,  2.28it/s][Astep: 160
extend+tolist() time: 0.00039696693420410156

Evaluating:  71%|███████   | 161/228 [01:09<00:28,  2.36it/s][Astep: 161
extend+tolist() time: 0.0008234977722167969

Evaluating:  71%|███████   | 162/228 [01:09<00:27,  2.41it/s][Astep: 162
extend+tolist() time: 0.00095367431640625

Evaluating:  71%|███████▏  | 163/228 [01:10<00:27,  2.37it/s][Astep: 163
extend+tolist() time: 0.0004215240478515625

Evaluating:  72%|███████▏  | 164/228 [01:10<00:26,  2.44it/s][Astep: 164
extend+tolist() time: 0.0006084442138671875

Evaluating:  72%|███████▏  | 165/228 [01:10<00:26,  2.40it/s][Astep: 165
extend+tolist() time: 0.0004825592041015625

Evaluating:  73%|███████▎  | 166/228 [01:11<00:25,  2.46it/s][Astep: 166
extend+tolist() time: 0.0008485317230224609

Evaluating:  73%|███████▎  | 167/228 [01:11<00:24,  2.51it/s][Astep: 167
extend+tolist() time: 0.0005931854248046875

Evaluating:  74%|███████▎  | 168/228 [01:12<00:24,  2.40it/s][Astep: 168
extend+tolist() time: 0.0016438961029052734

Evaluating:  74%|███████▍  | 169/228 [01:12<00:24,  2.44it/s][Astep: 169
extend+tolist() time: 0.0003943443298339844

Evaluating:  75%|███████▍  | 170/228 [01:12<00:23,  2.42it/s][Astep: 170
extend+tolist() time: 0.0009427070617675781

Evaluating:  75%|███████▌  | 171/228 [01:13<00:23,  2.44it/s][Astep: 171
extend+tolist() time: 0.00029587745666503906

Evaluating:  75%|███████▌  | 172/228 [01:13<00:22,  2.50it/s][Astep: 172
extend+tolist() time: 0.00135040283203125

Evaluating:  76%|███████▌  | 173/228 [01:14<00:23,  2.38it/s][Astep: 173
extend+tolist() time: 0.0011568069458007812

Evaluating:  76%|███████▋  | 174/228 [01:14<00:22,  2.43it/s][Astep: 174
extend+tolist() time: 0.26288533210754395

Evaluating:  77%|███████▋  | 175/228 [01:15<00:26,  1.97it/s][Astep: 175
extend+tolist() time: 0.0012345314025878906

Evaluating:  77%|███████▋  | 176/228 [01:15<00:24,  2.10it/s][Astep: 176
extend+tolist() time: 0.0006427764892578125

Evaluating:  78%|███████▊  | 177/228 [01:16<00:24,  2.11it/s][Astep: 177
extend+tolist() time: 0.0009260177612304688

Evaluating:  78%|███████▊  | 178/228 [01:16<00:22,  2.23it/s][Astep: 178
extend+tolist() time: 0.0012364387512207031

Evaluating:  79%|███████▊  | 179/228 [01:17<00:22,  2.21it/s][Astep: 179
extend+tolist() time: 0.0008170604705810547

Evaluating:  79%|███████▉  | 180/228 [01:17<00:21,  2.27it/s][Astep: 180
extend+tolist() time: 0.0003857612609863281

Evaluating:  79%|███████▉  | 181/228 [01:17<00:20,  2.35it/s][Astep: 181
extend+tolist() time: 0.0005948543548583984

Evaluating:  80%|███████▉  | 182/228 [01:18<00:20,  2.29it/s][Astep: 182
extend+tolist() time: 0.001161336898803711

Evaluating:  80%|████████  | 183/228 [01:18<00:19,  2.35it/s][Astep: 183
extend+tolist() time: 0.0006556510925292969

Evaluating:  81%|████████  | 184/228 [01:19<00:19,  2.29it/s][Astep: 184
extend+tolist() time: 0.00046372413635253906

Evaluating:  81%|████████  | 185/228 [01:19<00:18,  2.37it/s][Astep: 185
extend+tolist() time: 0.0015375614166259766

Evaluating:  82%|████████▏ | 186/228 [01:19<00:17,  2.38it/s][Astep: 186
extend+tolist() time: 0.0010268688201904297

Evaluating:  82%|████████▏ | 187/228 [01:20<00:17,  2.35it/s][Astep: 187
extend+tolist() time: 0.0008561611175537109

Evaluating:  82%|████████▏ | 188/228 [01:20<00:16,  2.45it/s][Astep: 188
extend+tolist() time: 0.0007421970367431641

Evaluating:  83%|████████▎ | 189/228 [01:21<00:16,  2.40it/s][Astep: 189
extend+tolist() time: 0.0003733634948730469

Evaluating:  83%|████████▎ | 190/228 [01:21<00:15,  2.48it/s][Astep: 190
extend+tolist() time: 0.0016210079193115234

Evaluating:  84%|████████▍ | 191/228 [01:21<00:14,  2.48it/s][Astep: 191
extend+tolist() time: 0.0007009506225585938

Evaluating:  84%|████████▍ | 192/228 [01:22<00:14,  2.45it/s][Astep: 192
extend+tolist() time: 0.0004303455352783203

Evaluating:  85%|████████▍ | 193/228 [01:22<00:13,  2.51it/s][Astep: 193
extend+tolist() time: 0.0014765262603759766

Evaluating:  85%|████████▌ | 194/228 [01:23<00:14,  2.42it/s][Astep: 194
extend+tolist() time: 0.0006282329559326172

Evaluating:  86%|████████▌ | 195/228 [01:23<00:13,  2.49it/s][Astep: 195
extend+tolist() time: 0.0009202957153320312

Evaluating:  86%|████████▌ | 196/228 [01:23<00:12,  2.53it/s][Astep: 196
extend+tolist() time: 0.0005955696105957031

Evaluating:  86%|████████▋ | 197/228 [01:24<00:12,  2.48it/s][Astep: 197
extend+tolist() time: 0.0006697177886962891

Evaluating:  87%|████████▋ | 198/228 [01:24<00:11,  2.53it/s][Astep: 198
extend+tolist() time: 0.001039743423461914

Evaluating:  87%|████████▋ | 199/228 [01:25<00:11,  2.46it/s][Astep: 199
extend+tolist() time: 0.0017352104187011719

Evaluating:  88%|████████▊ | 200/228 [01:25<00:11,  2.48it/s][Astep: 200
extend+tolist() time: 0.0006997585296630859

Evaluating:  88%|████████▊ | 201/228 [01:26<00:10,  2.52it/s][Astep: 201
extend+tolist() time: 0.0006237030029296875

Evaluating:  89%|████████▊ | 202/228 [01:26<00:10,  2.47it/s][Astep: 202
extend+tolist() time: 0.0003902912139892578

Evaluating:  89%|████████▉ | 203/228 [01:26<00:09,  2.53it/s][Astep: 203
extend+tolist() time: 0.0009763240814208984

Evaluating:  89%|████████▉ | 204/228 [01:27<00:09,  2.44it/s][Astep: 204
extend+tolist() time: 0.0004017353057861328

Evaluating:  90%|████████▉ | 205/228 [01:27<00:09,  2.49it/s][Astep: 205
extend+tolist() time: 0.0002987384796142578

Evaluating:  90%|█████████ | 206/228 [01:28<00:08,  2.51it/s][Astep: 206
extend+tolist() time: 0.00058746337890625

Evaluating:  91%|█████████ | 207/228 [01:28<00:08,  2.42it/s][Astep: 207
extend+tolist() time: 0.0010411739349365234

Evaluating:  91%|█████████ | 208/228 [01:28<00:08,  2.47it/s][Astep: 208
extend+tolist() time: 0.0006997585296630859

Evaluating:  92%|█████████▏| 209/228 [01:29<00:07,  2.39it/s][Astep: 209
extend+tolist() time: 0.0005922317504882812

Evaluating:  92%|█████████▏| 210/228 [01:29<00:07,  2.44it/s][Astep: 210
extend+tolist() time: 0.001009225845336914

Evaluating:  93%|█████████▎| 211/228 [01:30<00:06,  2.48it/s][Astep: 211
extend+tolist() time: 0.0011196136474609375

Evaluating:  93%|█████████▎| 212/228 [01:30<00:06,  2.41it/s][Astep: 212
extend+tolist() time: 0.0013089179992675781

Evaluating:  93%|█████████▎| 213/228 [01:30<00:06,  2.44it/s][Astep: 213
extend+tolist() time: 0.0007350444793701172

Evaluating:  94%|█████████▍| 214/228 [01:31<00:05,  2.37it/s][Astep: 214
extend+tolist() time: 0.0012187957763671875

Evaluating:  94%|█████████▍| 215/228 [01:31<00:05,  2.41it/s][Astep: 215
extend+tolist() time: 0.0006422996520996094

Evaluating:  95%|█████████▍| 216/228 [01:32<00:04,  2.42it/s][Astep: 216
extend+tolist() time: 0.0005590915679931641

Evaluating:  95%|█████████▌| 217/228 [01:32<00:05,  2.03it/s][Astep: 217
extend+tolist() time: 0.0009412765502929688

Evaluating:  96%|█████████▌| 218/228 [01:33<00:04,  2.12it/s][Astep: 218
extend+tolist() time: 0.000997781753540039

Evaluating:  96%|█████████▌| 219/228 [01:33<00:04,  2.21it/s][Astep: 219
extend+tolist() time: 0.0004949569702148438

Evaluating:  96%|█████████▋| 220/228 [01:34<00:03,  2.31it/s][Astep: 220
extend+tolist() time: 0.0008015632629394531

Evaluating:  97%|█████████▋| 221/228 [01:34<00:03,  2.29it/s][Astep: 221
extend+tolist() time: 0.0006432533264160156

Evaluating:  97%|█████████▋| 222/228 [01:34<00:02,  2.38it/s][Astep: 222
extend+tolist() time: 0.00042319297790527344

Evaluating:  98%|█████████▊| 223/228 [01:35<00:02,  2.40it/s][Astep: 223
extend+tolist() time: 0.00038242340087890625

Evaluating:  98%|█████████▊| 224/228 [01:35<00:01,  2.44it/s][Astep: 224
extend+tolist() time: 0.0007808208465576172

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.50it/s][Astep: 225
extend+tolist() time: 0.00040984153747558594

Evaluating:  99%|█████████▉| 226/228 [01:36<00:00,  2.41it/s][Astep: 226
extend+tolist() time: 0.0005335807800292969

Evaluating: 100%|█████████▉| 227/228 [01:36<00:00,  2.47it/s][Astep: 227
extend+tolist() time: 0.0004901885986328125

Evaluating: 100%|██████████| 228/228 [01:37<00:00,  2.38it/s][A09/08/2023 22:31:00 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 22:31:01 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:31:01 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:31:01 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:31:01 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:31:01 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:31:01 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:31:01 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:31:01 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:31:01 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:31:01 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:31:01 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:31:01 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:31:02 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:31:02 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:31:02 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:31:02 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:39<00:00,  2.29it/s]
09/08/2023 22:31:02 - INFO - __main__ -   Step: 1480, Validation Metrics: {'pred_1_num': 9863, 'pred_-1_num': 897, 'pred_0_num': 41, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7987223405240256, 'f1_micro': 0.7987223405240256, 'f1_macro': 0.4327013722397545, 'f1_weighted': 0.7595426759850556, 'f1_-1': 0.3670320747056436, 'f1_0': 0.047058823529411764, 'f1_1': 0.8840132184842082, 'precision_micro': 0.7987223405240256, 'precision_macro': 0.5737929636748547, 'precision_weighted': 0.7545016102434909, 'precision_-1': 0.5039018952062431, 'precision_0': 0.3902439024390244, 'precision_1': 0.8272330933792964, 'recall_micro': 0.7987223405240256, 'recall_macro': 0.42094499526490853, 'recall_weighted': 0.7987223405240256, 'recall_-1': 0.2886334610472541, 'recall_0': 0.025039123630672927, 'recall_1': 0.9491624011167985, 'roc_auc_micro': 0.8979767922951787, 'roc_auc_macro': 0.7051165821037214, 'roc_auc_weighted': 0.683248816698352, 'roc_auc_-1': 0.7212518522667319, 'roc_auc_0': 0.7205448571945131, 'roc_auc_1': 0.6735530368499192}
[2023-09-08 22:31:23,639] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1481/66600 [1:08:33<917:13:47, 50.71s/it]09/08/2023 22:31:23 - INFO - __main__ -   Step: 1481, LR: 1.4830391788709477e-05, Loss: 0.407327800989151
[2023-09-08 22:31:44,382] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1482/66600 [1:08:53<754:36:44, 41.72s/it]09/08/2023 22:31:44 - INFO - __main__ -   Step: 1482, LR: 1.4840405557641759e-05, Loss: 0.461689829826355
[2023-09-08 22:32:05,585] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1483/66600 [1:09:15<643:16:41, 35.56s/it]09/08/2023 22:32:05 - INFO - __main__ -   Step: 1483, LR: 1.4850419326574042e-05, Loss: 0.37706053256988525
[2023-09-08 22:32:26,165] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1484/66600 [1:09:35<561:57:46, 31.07s/it]09/08/2023 22:32:26 - INFO - __main__ -   Step: 1484, LR: 1.4860433095506322e-05, Loss: 0.3939276933670044
[2023-09-08 22:32:46,466] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1485/66600 [1:09:56<503:31:26, 27.84s/it]09/08/2023 22:32:46 - INFO - __main__ -   Step: 1485, LR: 1.4870446864438604e-05, Loss: 0.4286673367023468
[2023-09-08 22:33:07,411] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1486/66600 [1:10:16<466:07:03, 25.77s/it]09/08/2023 22:33:07 - INFO - __main__ -   Step: 1486, LR: 1.4880460633370885e-05, Loss: 0.3931483328342438
[2023-09-08 22:33:28,034] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1487/66600 [1:10:37<438:10:29, 24.23s/it]09/08/2023 22:33:28 - INFO - __main__ -   Step: 1487, LR: 1.4890474402303168e-05, Loss: 0.3710830807685852
[2023-09-08 22:33:48,882] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1488/66600 [1:10:58<419:50:30, 23.21s/it]09/08/2023 22:33:48 - INFO - __main__ -   Step: 1488, LR: 1.490048817123545e-05, Loss: 0.41095709800720215
[2023-09-08 22:34:09,204] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1489/66600 [1:11:18<404:08:52, 22.35s/it]09/08/2023 22:34:09 - INFO - __main__ -   Step: 1489, LR: 1.4910501940167732e-05, Loss: 0.39494597911834717
[2023-09-08 22:34:29,427] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1490/66600 [1:11:38<392:37:39, 21.71s/it]09/08/2023 22:34:29 - INFO - __main__ -   Step: 1490, LR: 1.4920515709100015e-05, Loss: 0.41295069456100464
[2023-09-08 22:34:50,494] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1491/66600 [1:12:00<389:08:18, 21.52s/it]09/08/2023 22:34:50 - INFO - __main__ -   Step: 1491, LR: 1.4930529478032297e-05, Loss: 0.39352941513061523
[2023-09-08 22:35:11,265] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1492/66600 [1:12:20<385:05:27, 21.29s/it]09/08/2023 22:35:11 - INFO - __main__ -   Step: 1492, LR: 1.4940543246964578e-05, Loss: 0.3942604660987854
[2023-09-08 22:35:31,675] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1493/66600 [1:12:41<380:17:32, 21.03s/it]09/08/2023 22:35:31 - INFO - __main__ -   Step: 1493, LR: 1.495055701589686e-05, Loss: 0.4376680552959442
[2023-09-08 22:35:52,528] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1494/66600 [1:13:02<379:20:28, 20.98s/it]09/08/2023 22:35:52 - INFO - __main__ -   Step: 1494, LR: 1.496057078482914e-05, Loss: 0.4332398474216461
[2023-09-08 22:36:13,419] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1495/66600 [1:13:22<378:52:28, 20.95s/it]09/08/2023 22:36:13 - INFO - __main__ -   Step: 1495, LR: 1.4970584553761423e-05, Loss: 0.4352821111679077
[2023-09-08 22:36:34,698] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1496/66600 [1:13:44<380:39:13, 21.05s/it]09/08/2023 22:36:34 - INFO - __main__ -   Step: 1496, LR: 1.4980598322693705e-05, Loss: 0.4121682345867157
[2023-09-08 22:36:56,298] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1497/66600 [1:14:05<383:38:30, 21.21s/it]09/08/2023 22:36:56 - INFO - __main__ -   Step: 1497, LR: 1.4990612091625986e-05, Loss: 0.35838401317596436
[2023-09-08 22:37:16,762] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1498/66600 [1:14:26<379:33:43, 20.99s/it]09/08/2023 22:37:16 - INFO - __main__ -   Step: 1498, LR: 1.500062586055827e-05, Loss: 0.42550474405288696
[2023-09-08 22:37:37,525] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1499/66600 [1:14:47<378:19:56, 20.92s/it]09/08/2023 22:37:37 - INFO - __main__ -   Step: 1499, LR: 1.5010639629490551e-05, Loss: 0.369838684797287
[2023-09-08 22:37:58,705] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1500/66600 [1:15:08<379:43:53, 21.00s/it]09/08/2023 22:37:58 - INFO - __main__ -   Step: 1500, LR: 1.5020653398422833e-05, Loss: 0.44129708409309387
09/08/2023 22:37:58 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0024497509002685547

Evaluating:   0%|          | 1/228 [00:00<01:48,  2.09it/s][Astep: 1
extend+tolist() time: 0.0010540485382080078

Evaluating:   1%|          | 2/228 [00:00<01:44,  2.17it/s][Astep: 2
extend+tolist() time: 0.002232789993286133

Evaluating:   1%|▏         | 3/228 [00:01<01:39,  2.27it/s][Astep: 3
extend+tolist() time: 0.0019452571868896484

Evaluating:   2%|▏         | 4/228 [00:01<01:39,  2.25it/s][Astep: 4
extend+tolist() time: 0.0013966560363769531

Evaluating:   2%|▏         | 5/228 [00:02<01:36,  2.31it/s][Astep: 5
extend+tolist() time: 0.001953125

Evaluating:   3%|▎         | 6/228 [00:02<01:34,  2.35it/s][Astep: 6
extend+tolist() time: 0.001440286636352539

Evaluating:   3%|▎         | 7/228 [00:03<01:37,  2.27it/s][Astep: 7
extend+tolist() time: 0.0014147758483886719

Evaluating:   4%|▎         | 8/228 [00:03<01:34,  2.32it/s][Astep: 8
extend+tolist() time: 0.0011515617370605469

Evaluating:   4%|▍         | 9/228 [00:03<01:36,  2.28it/s][Astep: 9
extend+tolist() time: 0.0007679462432861328

Evaluating:   4%|▍         | 10/228 [00:04<01:32,  2.35it/s][Astep: 10
extend+tolist() time: 0.0012505054473876953

Evaluating:   5%|▍         | 11/228 [00:04<01:31,  2.36it/s][Astep: 11
extend+tolist() time: 0.00055694580078125

Evaluating:   5%|▌         | 12/228 [00:05<01:31,  2.35it/s][Astep: 12
extend+tolist() time: 0.0006556510925292969

Evaluating:   6%|▌         | 13/228 [00:05<01:28,  2.42it/s][Astep: 13
extend+tolist() time: 0.0010325908660888672

Evaluating:   6%|▌         | 14/228 [00:06<01:30,  2.36it/s][Astep: 14
extend+tolist() time: 0.0005409717559814453

Evaluating:   7%|▋         | 15/228 [00:06<01:27,  2.42it/s][Astep: 15
extend+tolist() time: 0.0005879402160644531

Evaluating:   7%|▋         | 16/228 [00:06<01:28,  2.39it/s][Astep: 16
extend+tolist() time: 0.15022754669189453

Evaluating:   7%|▋         | 17/228 [00:07<01:37,  2.17it/s][Astep: 17
extend+tolist() time: 0.0009019374847412109

Evaluating:   8%|▊         | 18/228 [00:07<01:34,  2.21it/s][Astep: 18
extend+tolist() time: 0.0011057853698730469

Evaluating:   8%|▊         | 19/228 [00:08<01:31,  2.29it/s][Astep: 19
extend+tolist() time: 0.0013442039489746094

Evaluating:   9%|▉         | 20/228 [00:08<01:27,  2.38it/s][Astep: 20
extend+tolist() time: 0.0007255077362060547

Evaluating:   9%|▉         | 21/228 [00:09<01:28,  2.34it/s][Astep: 21
extend+tolist() time: 0.0006434917449951172

Evaluating:  10%|▉         | 22/228 [00:09<01:25,  2.42it/s][Astep: 22
extend+tolist() time: 0.0007712841033935547

Evaluating:  10%|█         | 23/228 [00:10<01:34,  2.16it/s][Astep: 23
extend+tolist() time: 0.0011899471282958984

Evaluating:  11%|█         | 24/228 [00:10<01:29,  2.29it/s][Astep: 24
extend+tolist() time: 0.0014905929565429688

Evaluating:  11%|█         | 25/228 [00:10<01:25,  2.37it/s][Astep: 25
extend+tolist() time: 0.0018055438995361328

Evaluating:  11%|█▏        | 26/228 [00:11<01:34,  2.14it/s][Astep: 26
extend+tolist() time: 0.0007319450378417969

Evaluating:  12%|█▏        | 27/228 [00:11<01:38,  2.04it/s][Astep: 27
extend+tolist() time: 0.0017027854919433594

Evaluating:  12%|█▏        | 28/228 [00:12<01:34,  2.12it/s][Astep: 28
extend+tolist() time: 0.0003466606140136719

Evaluating:  13%|█▎        | 29/228 [00:12<01:28,  2.24it/s][Astep: 29
extend+tolist() time: 0.0007038116455078125

Evaluating:  13%|█▎        | 30/228 [00:13<01:28,  2.23it/s][Astep: 30
extend+tolist() time: 0.0011012554168701172

Evaluating:  14%|█▎        | 31/228 [00:13<01:25,  2.30it/s][Astep: 31
extend+tolist() time: 0.0010800361633300781

Evaluating:  14%|█▍        | 32/228 [00:14<01:24,  2.31it/s][Astep: 32
extend+tolist() time: 0.0010223388671875

Evaluating:  14%|█▍        | 33/228 [00:14<01:22,  2.36it/s][Astep: 33
extend+tolist() time: 0.0017480850219726562

Evaluating:  15%|█▍        | 34/228 [00:14<01:20,  2.41it/s][Astep: 34
extend+tolist() time: 0.0012538433074951172

Evaluating:  15%|█▌        | 35/228 [00:15<01:21,  2.36it/s][Astep: 35
extend+tolist() time: 0.0006415843963623047

Evaluating:  16%|█▌        | 36/228 [00:15<01:18,  2.44it/s][Astep: 36
extend+tolist() time: 0.0007715225219726562

Evaluating:  16%|█▌        | 37/228 [00:16<01:19,  2.41it/s][Astep: 37
extend+tolist() time: 0.0017240047454833984

Evaluating:  17%|█▋        | 38/228 [00:16<01:18,  2.41it/s][Astep: 38
extend+tolist() time: 0.0011105537414550781

Evaluating:  17%|█▋        | 39/228 [00:16<01:16,  2.47it/s][Astep: 39
extend+tolist() time: 0.0007269382476806641

Evaluating:  18%|█▊        | 40/228 [00:17<01:18,  2.40it/s][Astep: 40
extend+tolist() time: 0.0010571479797363281

Evaluating:  18%|█▊        | 41/228 [00:17<01:15,  2.46it/s][Astep: 41
extend+tolist() time: 0.0008764266967773438

Evaluating:  18%|█▊        | 42/228 [00:18<01:16,  2.43it/s][Astep: 42
extend+tolist() time: 0.0016241073608398438

Evaluating:  19%|█▉        | 43/228 [00:18<01:15,  2.44it/s][Astep: 43
extend+tolist() time: 0.0018546581268310547

Evaluating:  19%|█▉        | 44/228 [00:18<01:14,  2.46it/s][Astep: 44
extend+tolist() time: 0.0007293224334716797

Evaluating:  20%|█▉        | 45/228 [00:19<01:16,  2.40it/s][Astep: 45
extend+tolist() time: 0.0016982555389404297

Evaluating:  20%|██        | 46/228 [00:19<01:14,  2.44it/s][Astep: 46
extend+tolist() time: 0.0016701221466064453

Evaluating:  21%|██        | 47/228 [00:20<01:15,  2.39it/s][Astep: 47
extend+tolist() time: 0.15542173385620117

Evaluating:  21%|██        | 48/228 [00:20<01:22,  2.19it/s][Astep: 48
extend+tolist() time: 0.0016322135925292969

Evaluating:  21%|██▏       | 49/228 [00:21<01:20,  2.22it/s][Astep: 49
extend+tolist() time: 0.0009176731109619141

Evaluating:  22%|██▏       | 50/228 [00:21<01:17,  2.29it/s][Astep: 50
extend+tolist() time: 0.0016064643859863281

Evaluating:  22%|██▏       | 51/228 [00:21<01:15,  2.35it/s][Astep: 51
extend+tolist() time: 0.001546621322631836

Evaluating:  23%|██▎       | 52/228 [00:22<01:16,  2.30it/s][Astep: 52
extend+tolist() time: 0.0013647079467773438

Evaluating:  23%|██▎       | 53/228 [00:22<01:21,  2.14it/s][Astep: 53
extend+tolist() time: 0.0016541481018066406

Evaluating:  24%|██▎       | 54/228 [00:23<01:20,  2.16it/s][Astep: 54
extend+tolist() time: 0.0008258819580078125

Evaluating:  24%|██▍       | 55/228 [00:23<01:16,  2.27it/s][Astep: 55
extend+tolist() time: 0.0012409687042236328

Evaluating:  25%|██▍       | 56/228 [00:24<01:25,  2.02it/s][Astep: 56
extend+tolist() time: 0.0011589527130126953

Evaluating:  25%|██▌       | 57/228 [00:24<01:19,  2.15it/s][Astep: 57
extend+tolist() time: 0.001058816909790039

Evaluating:  25%|██▌       | 58/228 [00:25<01:26,  1.97it/s][Astep: 58
extend+tolist() time: 0.0008580684661865234

Evaluating:  26%|██▌       | 59/228 [00:25<01:19,  2.12it/s][Astep: 59
extend+tolist() time: 0.0013535022735595703

Evaluating:  26%|██▋       | 60/228 [00:26<01:18,  2.15it/s][Astep: 60
extend+tolist() time: 0.0007317066192626953

Evaluating:  27%|██▋       | 61/228 [00:26<01:13,  2.28it/s][Astep: 61
extend+tolist() time: 0.0012323856353759766

Evaluating:  27%|██▋       | 62/228 [00:27<01:10,  2.35it/s][Astep: 62
extend+tolist() time: 0.0007882118225097656

Evaluating:  28%|██▊       | 63/228 [00:27<01:11,  2.31it/s][Astep: 63
extend+tolist() time: 0.0012311935424804688

Evaluating:  28%|██▊       | 64/228 [00:27<01:09,  2.37it/s][Astep: 64
extend+tolist() time: 0.0011355876922607422

Evaluating:  29%|██▊       | 65/228 [00:28<01:10,  2.32it/s][Astep: 65
extend+tolist() time: 0.0008020401000976562

Evaluating:  29%|██▉       | 66/228 [00:28<01:07,  2.41it/s][Astep: 66
extend+tolist() time: 0.0011601448059082031

Evaluating:  29%|██▉       | 67/228 [00:29<01:05,  2.48it/s][Astep: 67
extend+tolist() time: 0.0008962154388427734

Evaluating:  30%|██▉       | 68/228 [00:29<01:06,  2.40it/s][Astep: 68
extend+tolist() time: 0.0010688304901123047

Evaluating:  30%|███       | 69/228 [00:29<01:04,  2.47it/s][Astep: 69
extend+tolist() time: 0.0011196136474609375

Evaluating:  31%|███       | 70/228 [00:30<01:06,  2.38it/s][Astep: 70
extend+tolist() time: 0.001514434814453125

Evaluating:  31%|███       | 71/228 [00:30<01:04,  2.43it/s][Astep: 71
extend+tolist() time: 0.001569986343383789

Evaluating:  32%|███▏      | 72/228 [00:31<01:03,  2.44it/s][Astep: 72
extend+tolist() time: 0.0007565021514892578

Evaluating:  32%|███▏      | 73/228 [00:31<01:03,  2.44it/s][Astep: 73
extend+tolist() time: 0.0005047321319580078

Evaluating:  32%|███▏      | 74/228 [00:31<01:01,  2.50it/s][Astep: 74
extend+tolist() time: 0.0011992454528808594

Evaluating:  33%|███▎      | 75/228 [00:32<01:01,  2.47it/s][Astep: 75
extend+tolist() time: 0.0016126632690429688

Evaluating:  33%|███▎      | 76/228 [00:32<01:01,  2.48it/s][Astep: 76
extend+tolist() time: 0.0006437301635742188

Evaluating:  34%|███▍      | 77/228 [00:33<00:59,  2.52it/s][Astep: 77
extend+tolist() time: 0.0018644332885742188

Evaluating:  34%|███▍      | 78/228 [00:33<01:02,  2.41it/s][Astep: 78
extend+tolist() time: 0.0012166500091552734

Evaluating:  35%|███▍      | 79/228 [00:33<01:00,  2.47it/s][Astep: 79
extend+tolist() time: 0.0008819103240966797

Evaluating:  35%|███▌      | 80/228 [00:34<01:00,  2.44it/s][Astep: 80
extend+tolist() time: 0.0013539791107177734

Evaluating:  36%|███▌      | 81/228 [00:34<00:58,  2.50it/s][Astep: 81
extend+tolist() time: 0.0008475780487060547

Evaluating:  36%|███▌      | 82/228 [00:35<00:57,  2.52it/s][Astep: 82
extend+tolist() time: 0.001283407211303711

Evaluating:  36%|███▋      | 83/228 [00:35<00:59,  2.44it/s][Astep: 83
extend+tolist() time: 0.0006883144378662109

Evaluating:  37%|███▋      | 84/228 [00:35<00:57,  2.51it/s][Astep: 84
extend+tolist() time: 0.0013761520385742188

Evaluating:  37%|███▋      | 85/228 [00:36<00:58,  2.46it/s][Astep: 85
extend+tolist() time: 0.0012364387512207031

Evaluating:  38%|███▊      | 86/228 [00:36<00:57,  2.48it/s][Astep: 86
extend+tolist() time: 0.17246580123901367

Evaluating:  38%|███▊      | 87/228 [00:37<01:03,  2.24it/s][Astep: 87
extend+tolist() time: 0.0013265609741210938

Evaluating:  39%|███▊      | 88/228 [00:37<01:00,  2.32it/s][Astep: 88
extend+tolist() time: 0.0007314682006835938

Evaluating:  39%|███▉      | 89/228 [00:38<00:57,  2.41it/s][Astep: 89
extend+tolist() time: 0.0010843276977539062

Evaluating:  39%|███▉      | 90/228 [00:38<00:57,  2.38it/s][Astep: 90
extend+tolist() time: 0.0012767314910888672

Evaluating:  40%|███▉      | 91/228 [00:38<00:55,  2.45it/s][Astep: 91
extend+tolist() time: 0.0007448196411132812

Evaluating:  40%|████      | 92/228 [00:39<00:55,  2.47it/s][Astep: 92
extend+tolist() time: 0.0011551380157470703

Evaluating:  41%|████      | 93/228 [00:39<00:54,  2.46it/s][Astep: 93
extend+tolist() time: 0.0009882450103759766

Evaluating:  41%|████      | 94/228 [00:40<00:53,  2.49it/s][Astep: 94
extend+tolist() time: 0.001176595687866211

Evaluating:  42%|████▏     | 95/228 [00:40<01:01,  2.15it/s][Astep: 95
extend+tolist() time: 0.0011701583862304688

Evaluating:  42%|████▏     | 96/228 [00:41<00:58,  2.25it/s][Astep: 96
extend+tolist() time: 0.0008993148803710938

Evaluating:  43%|████▎     | 97/228 [00:41<00:57,  2.26it/s][Astep: 97
extend+tolist() time: 0.0012099742889404297

Evaluating:  43%|████▎     | 98/228 [00:41<00:55,  2.36it/s][Astep: 98
extend+tolist() time: 0.0008974075317382812

Evaluating:  43%|████▎     | 99/228 [00:42<00:54,  2.38it/s][Astep: 99
extend+tolist() time: 0.0013356208801269531

Evaluating:  44%|████▍     | 100/228 [00:42<00:59,  2.14it/s][Astep: 100
extend+tolist() time: 0.0007100105285644531

Evaluating:  44%|████▍     | 101/228 [00:43<01:04,  1.96it/s][Astep: 101
extend+tolist() time: 0.0012483596801757812

Evaluating:  45%|████▍     | 102/228 [00:43<00:59,  2.13it/s][Astep: 102
extend+tolist() time: 0.000728607177734375

Evaluating:  45%|████▌     | 103/228 [00:44<00:55,  2.27it/s][Astep: 103
extend+tolist() time: 0.001188039779663086

Evaluating:  46%|████▌     | 104/228 [00:44<00:54,  2.28it/s][Astep: 104
extend+tolist() time: 0.0007011890411376953

Evaluating:  46%|████▌     | 105/228 [00:45<00:51,  2.39it/s][Astep: 105
extend+tolist() time: 0.001291513442993164

Evaluating:  46%|████▋     | 106/228 [00:45<00:51,  2.38it/s][Astep: 106
extend+tolist() time: 0.0017468929290771484

Evaluating:  47%|████▋     | 107/228 [00:45<00:50,  2.40it/s][Astep: 107
extend+tolist() time: 0.0007765293121337891

Evaluating:  47%|████▋     | 108/228 [00:46<00:49,  2.45it/s][Astep: 108
extend+tolist() time: 0.001252889633178711

Evaluating:  48%|████▊     | 109/228 [00:46<00:49,  2.40it/s][Astep: 109
extend+tolist() time: 0.0008285045623779297

Evaluating:  48%|████▊     | 110/228 [00:47<00:47,  2.47it/s][Astep: 110
extend+tolist() time: 0.0006086826324462891

Evaluating:  49%|████▊     | 111/228 [00:47<00:47,  2.44it/s][Astep: 111
extend+tolist() time: 0.00183868408203125

Evaluating:  49%|████▉     | 112/228 [00:47<00:47,  2.44it/s][Astep: 112
extend+tolist() time: 0.0007367134094238281

Evaluating:  50%|████▉     | 113/228 [00:48<00:46,  2.48it/s][Astep: 113
extend+tolist() time: 0.0006852149963378906

Evaluating:  50%|█████     | 114/228 [00:48<00:46,  2.45it/s][Astep: 114
extend+tolist() time: 0.001535177230834961

Evaluating:  50%|█████     | 115/228 [00:49<00:45,  2.50it/s][Astep: 115
extend+tolist() time: 0.0006613731384277344

Evaluating:  51%|█████     | 116/228 [00:49<00:45,  2.45it/s][Astep: 116
extend+tolist() time: 0.0012199878692626953

Evaluating:  51%|█████▏    | 117/228 [00:49<00:44,  2.49it/s][Astep: 117
extend+tolist() time: 0.0008234977722167969

Evaluating:  52%|█████▏    | 118/228 [00:50<00:44,  2.50it/s][Astep: 118
extend+tolist() time: 0.0009539127349853516

Evaluating:  52%|█████▏    | 119/228 [00:50<00:44,  2.45it/s][Astep: 119
extend+tolist() time: 0.000682830810546875

Evaluating:  53%|█████▎    | 120/228 [00:51<00:42,  2.52it/s][Astep: 120
extend+tolist() time: 0.0006020069122314453

Evaluating:  53%|█████▎    | 121/228 [00:51<00:42,  2.49it/s][Astep: 121
extend+tolist() time: 0.0010294914245605469

Evaluating:  54%|█████▎    | 122/228 [00:51<00:42,  2.52it/s][Astep: 122
extend+tolist() time: 0.0006718635559082031

Evaluating:  54%|█████▍    | 123/228 [00:52<00:41,  2.54it/s][Astep: 123
extend+tolist() time: 0.0009958744049072266

Evaluating:  54%|█████▍    | 124/228 [00:52<00:41,  2.48it/s][Astep: 124
extend+tolist() time: 0.0008056163787841797

Evaluating:  55%|█████▍    | 125/228 [00:53<00:40,  2.54it/s][Astep: 125
extend+tolist() time: 0.00044345855712890625

Evaluating:  55%|█████▌    | 126/228 [00:53<00:40,  2.51it/s][Astep: 126
extend+tolist() time: 0.0017528533935546875

Evaluating:  56%|█████▌    | 127/228 [00:53<00:40,  2.47it/s][Astep: 127
extend+tolist() time: 0.0018448829650878906

Evaluating:  56%|█████▌    | 128/228 [00:54<00:40,  2.46it/s][Astep: 128
extend+tolist() time: 0.0010509490966796875

Evaluating:  57%|█████▋    | 129/228 [00:54<00:40,  2.42it/s][Astep: 129
extend+tolist() time: 0.0007731914520263672

Evaluating:  57%|█████▋    | 130/228 [00:55<00:39,  2.50it/s][Astep: 130
extend+tolist() time: 0.0012965202331542969

Evaluating:  57%|█████▋    | 131/228 [00:55<00:39,  2.46it/s][Astep: 131
extend+tolist() time: 0.00046133995056152344

Evaluating:  58%|█████▊    | 132/228 [00:56<00:39,  2.41it/s][Astep: 132
extend+tolist() time: 0.0014388561248779297

Evaluating:  58%|█████▊    | 133/228 [00:56<00:38,  2.45it/s][Astep: 133
extend+tolist() time: 0.0004546642303466797

Evaluating:  59%|█████▉    | 134/228 [00:56<00:39,  2.37it/s][Astep: 134
extend+tolist() time: 0.0009579658508300781

Evaluating:  59%|█████▉    | 135/228 [00:57<00:38,  2.40it/s][Astep: 135
extend+tolist() time: 0.0009257793426513672

Evaluating:  60%|█████▉    | 136/228 [00:57<00:38,  2.37it/s][Astep: 136
extend+tolist() time: 0.0008056163787841797

Evaluating:  60%|██████    | 137/228 [00:58<00:38,  2.39it/s][Astep: 137
extend+tolist() time: 0.00044608116149902344

Evaluating:  61%|██████    | 138/228 [00:58<00:36,  2.44it/s][Astep: 138
extend+tolist() time: 0.001287221908569336

Evaluating:  61%|██████    | 139/228 [00:58<00:37,  2.37it/s][Astep: 139
extend+tolist() time: 0.000522613525390625

Evaluating:  61%|██████▏   | 140/228 [00:59<00:36,  2.43it/s][Astep: 140
extend+tolist() time: 0.001470327377319336

Evaluating:  62%|██████▏   | 141/228 [00:59<00:36,  2.35it/s][Astep: 141
extend+tolist() time: 0.0008511543273925781

Evaluating:  62%|██████▏   | 142/228 [01:00<00:35,  2.42it/s][Astep: 142
extend+tolist() time: 0.0006287097930908203

Evaluating:  63%|██████▎   | 143/228 [01:00<00:34,  2.48it/s][Astep: 143
extend+tolist() time: 0.0008244514465332031

Evaluating:  63%|██████▎   | 144/228 [01:01<00:35,  2.39it/s][Astep: 144
extend+tolist() time: 0.24386334419250488

Evaluating:  64%|██████▎   | 145/228 [01:01<00:40,  2.07it/s][Astep: 145
extend+tolist() time: 0.0005266666412353516

Evaluating:  64%|██████▍   | 146/228 [01:02<00:38,  2.13it/s][Astep: 146
extend+tolist() time: 0.00043392181396484375

Evaluating:  64%|██████▍   | 147/228 [01:02<00:35,  2.25it/s][Astep: 147
extend+tolist() time: 0.0008044242858886719

Evaluating:  65%|██████▍   | 148/228 [01:02<00:35,  2.24it/s][Astep: 148
extend+tolist() time: 0.0011239051818847656

Evaluating:  65%|██████▌   | 149/228 [01:03<00:33,  2.34it/s][Astep: 149
extend+tolist() time: 0.00041794776916503906

Evaluating:  66%|██████▌   | 150/228 [01:03<00:33,  2.36it/s][Astep: 150
extend+tolist() time: 0.0009262561798095703

Evaluating:  66%|██████▌   | 151/228 [01:04<00:32,  2.36it/s][Astep: 151
extend+tolist() time: 0.001104593276977539

Evaluating:  67%|██████▋   | 152/228 [01:04<00:31,  2.42it/s][Astep: 152
extend+tolist() time: 0.0008826255798339844

Evaluating:  67%|██████▋   | 153/228 [01:05<00:31,  2.35it/s][Astep: 153
extend+tolist() time: 0.0014102458953857422

Evaluating:  68%|██████▊   | 154/228 [01:05<00:30,  2.40it/s][Astep: 154
extend+tolist() time: 0.002067089080810547

Evaluating:  68%|██████▊   | 155/228 [01:05<00:31,  2.33it/s][Astep: 155
extend+tolist() time: 0.0006930828094482422

Evaluating:  68%|██████▊   | 156/228 [01:06<00:30,  2.37it/s][Astep: 156
extend+tolist() time: 0.0005893707275390625

Evaluating:  69%|██████▉   | 157/228 [01:06<00:34,  2.07it/s][Astep: 157
extend+tolist() time: 0.0011353492736816406

Evaluating:  69%|██████▉   | 158/228 [01:07<00:32,  2.18it/s][Astep: 158
extend+tolist() time: 0.0005099773406982422

Evaluating:  70%|██████▉   | 159/228 [01:07<00:30,  2.29it/s][Astep: 159
extend+tolist() time: 0.0007452964782714844

Evaluating:  70%|███████   | 160/228 [01:08<00:29,  2.27it/s][Astep: 160
extend+tolist() time: 0.0008113384246826172

Evaluating:  71%|███████   | 161/228 [01:08<00:28,  2.35it/s][Astep: 161
extend+tolist() time: 0.0008363723754882812

Evaluating:  71%|███████   | 162/228 [01:08<00:28,  2.32it/s][Astep: 162
extend+tolist() time: 0.0005218982696533203

Evaluating:  71%|███████▏  | 163/228 [01:09<00:27,  2.39it/s][Astep: 163
extend+tolist() time: 0.0008666515350341797

Evaluating:  72%|███████▏  | 164/228 [01:09<00:26,  2.45it/s][Astep: 164
extend+tolist() time: 0.0006036758422851562

Evaluating:  72%|███████▏  | 165/228 [01:10<00:26,  2.37it/s][Astep: 165
extend+tolist() time: 0.0005064010620117188

Evaluating:  73%|███████▎  | 166/228 [01:10<00:25,  2.42it/s][Astep: 166
extend+tolist() time: 0.00041937828063964844

Evaluating:  73%|███████▎  | 167/228 [01:11<00:25,  2.36it/s][Astep: 167
extend+tolist() time: 0.0011739730834960938

Evaluating:  74%|███████▎  | 168/228 [01:11<00:24,  2.41it/s][Astep: 168
extend+tolist() time: 0.0012447834014892578

Evaluating:  74%|███████▍  | 169/228 [01:11<00:24,  2.38it/s][Astep: 169
extend+tolist() time: 0.00037384033203125

Evaluating:  75%|███████▍  | 170/228 [01:12<00:28,  2.03it/s][Astep: 170
extend+tolist() time: 0.0014204978942871094

Evaluating:  75%|███████▌  | 171/228 [01:12<00:26,  2.13it/s][Astep: 171
extend+tolist() time: 0.0003173351287841797

Evaluating:  75%|███████▌  | 172/228 [01:13<00:28,  1.94it/s][Astep: 172
extend+tolist() time: 0.000843048095703125

Evaluating:  76%|███████▌  | 173/228 [01:14<00:26,  2.04it/s][Astep: 173
extend+tolist() time: 0.0016222000122070312

Evaluating:  76%|███████▋  | 174/228 [01:14<00:25,  2.14it/s][Astep: 174
extend+tolist() time: 0.0018665790557861328

Evaluating:  77%|███████▋  | 175/228 [01:14<00:23,  2.22it/s][Astep: 175
extend+tolist() time: 0.0008435249328613281

Evaluating:  77%|███████▋  | 176/228 [01:15<00:23,  2.21it/s][Astep: 176
extend+tolist() time: 0.001077413558959961

Evaluating:  78%|███████▊  | 177/228 [01:15<00:22,  2.30it/s][Astep: 177
extend+tolist() time: 0.0006222724914550781

Evaluating:  78%|███████▊  | 178/228 [01:16<00:21,  2.28it/s][Astep: 178
extend+tolist() time: 0.0016570091247558594

Evaluating:  79%|███████▊  | 179/228 [01:16<00:20,  2.34it/s][Astep: 179
extend+tolist() time: 0.00042510032653808594

Evaluating:  79%|███████▉  | 180/228 [01:16<00:20,  2.38it/s][Astep: 180
extend+tolist() time: 0.0003936290740966797

Evaluating:  79%|███████▉  | 181/228 [01:17<00:19,  2.40it/s][Astep: 181
extend+tolist() time: 0.0006463527679443359

Evaluating:  80%|███████▉  | 182/228 [01:17<00:18,  2.45it/s][Astep: 182
extend+tolist() time: 0.0012538433074951172

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.37it/s][Astep: 183
extend+tolist() time: 0.0006587505340576172

Evaluating:  81%|████████  | 184/228 [01:18<00:18,  2.42it/s][Astep: 184
extend+tolist() time: 0.00047397613525390625

Evaluating:  81%|████████  | 185/228 [01:18<00:17,  2.43it/s][Astep: 185
extend+tolist() time: 0.001546621322631836

Evaluating:  82%|████████▏ | 186/228 [01:19<00:17,  2.41it/s][Astep: 186
extend+tolist() time: 0.001416921615600586

Evaluating:  82%|████████▏ | 187/228 [01:19<00:16,  2.46it/s][Astep: 187
extend+tolist() time: 0.000453948974609375

Evaluating:  82%|████████▏ | 188/228 [01:20<00:16,  2.40it/s][Astep: 188
extend+tolist() time: 0.0007297992706298828

Evaluating:  83%|████████▎ | 189/228 [01:20<00:15,  2.45it/s][Astep: 189
extend+tolist() time: 0.000370025634765625

Evaluating:  83%|████████▎ | 190/228 [01:21<00:15,  2.44it/s][Astep: 190
extend+tolist() time: 0.0016851425170898438

Evaluating:  84%|████████▍ | 191/228 [01:21<00:15,  2.39it/s][Astep: 191
extend+tolist() time: 0.0007011890411376953

Evaluating:  84%|████████▍ | 192/228 [01:21<00:14,  2.45it/s][Astep: 192
extend+tolist() time: 0.0008194446563720703

Evaluating:  85%|████████▍ | 193/228 [01:22<00:14,  2.40it/s][Astep: 193
extend+tolist() time: 0.0010797977447509766

Evaluating:  85%|████████▌ | 194/228 [01:22<00:13,  2.44it/s][Astep: 194
extend+tolist() time: 0.001012563705444336

Evaluating:  86%|████████▌ | 195/228 [01:23<00:13,  2.44it/s][Astep: 195
extend+tolist() time: 0.0005352497100830078

Evaluating:  86%|████████▌ | 196/228 [01:23<00:13,  2.43it/s][Astep: 196
extend+tolist() time: 0.0005867481231689453

Evaluating:  86%|████████▋ | 197/228 [01:23<00:12,  2.48it/s][Astep: 197
extend+tolist() time: 0.0010762214660644531

Evaluating:  87%|████████▋ | 198/228 [01:24<00:12,  2.42it/s][Astep: 198
extend+tolist() time: 0.0006098747253417969

Evaluating:  87%|████████▋ | 199/228 [01:24<00:11,  2.48it/s][Astep: 199
extend+tolist() time: 0.0019423961639404297

Evaluating:  88%|████████▊ | 200/228 [01:25<00:11,  2.45it/s][Astep: 200
extend+tolist() time: 0.0006909370422363281

Evaluating:  88%|████████▊ | 201/228 [01:25<00:11,  2.43it/s][Astep: 201
extend+tolist() time: 0.0006132125854492188

Evaluating:  89%|████████▊ | 202/228 [01:25<00:10,  2.49it/s][Astep: 202
extend+tolist() time: 0.0007915496826171875

Evaluating:  89%|████████▉ | 203/228 [01:26<00:10,  2.43it/s][Astep: 203
extend+tolist() time: 0.0004999637603759766

Evaluating:  89%|████████▉ | 204/228 [01:26<00:09,  2.48it/s][Astep: 204
extend+tolist() time: 0.0004100799560546875

Evaluating:  90%|████████▉ | 205/228 [01:27<00:09,  2.48it/s][Astep: 205
extend+tolist() time: 0.00030159950256347656

Evaluating:  90%|█████████ | 206/228 [01:27<00:08,  2.48it/s][Astep: 206
extend+tolist() time: 0.0005929470062255859

Evaluating:  91%|█████████ | 207/228 [01:27<00:08,  2.52it/s][Astep: 207
extend+tolist() time: 0.0010535717010498047

Evaluating:  91%|█████████ | 208/228 [01:28<00:08,  2.44it/s][Astep: 208
extend+tolist() time: 0.0006978511810302734

Evaluating:  92%|█████████▏| 209/228 [01:28<00:07,  2.49it/s][Astep: 209
extend+tolist() time: 0.0005950927734375

Evaluating:  92%|█████████▏| 210/228 [01:29<00:07,  2.49it/s][Astep: 210
extend+tolist() time: 0.0010404586791992188

Evaluating:  93%|█████████▎| 211/228 [01:29<00:06,  2.48it/s][Astep: 211
extend+tolist() time: 0.0011196136474609375

Evaluating:  93%|█████████▎| 212/228 [01:29<00:06,  2.50it/s][Astep: 212
extend+tolist() time: 0.001306772232055664

Evaluating:  93%|█████████▎| 213/228 [01:30<00:06,  2.42it/s][Astep: 213
extend+tolist() time: 0.0007543563842773438

Evaluating:  94%|█████████▍| 214/228 [01:30<00:05,  2.47it/s][Astep: 214
extend+tolist() time: 0.0013096332550048828

Evaluating:  94%|█████████▍| 215/228 [01:31<00:05,  2.45it/s][Astep: 215
extend+tolist() time: 0.0006783008575439453

Evaluating:  95%|█████████▍| 216/228 [01:31<00:04,  2.44it/s][Astep: 216
extend+tolist() time: 0.0005621910095214844

Evaluating:  95%|█████████▌| 217/228 [01:32<00:04,  2.47it/s][Astep: 217
extend+tolist() time: 0.0010156631469726562

Evaluating:  96%|█████████▌| 218/228 [01:32<00:04,  2.39it/s][Astep: 218
extend+tolist() time: 0.0010612010955810547

Evaluating:  96%|█████████▌| 219/228 [01:32<00:03,  2.42it/s][Astep: 219
extend+tolist() time: 0.0009186267852783203

Evaluating:  96%|█████████▋| 220/228 [01:33<00:03,  2.40it/s][Astep: 220
extend+tolist() time: 0.0003974437713623047

Evaluating:  97%|█████████▋| 221/228 [01:33<00:02,  2.37it/s][Astep: 221
extend+tolist() time: 0.0006508827209472656

Evaluating:  97%|█████████▋| 222/228 [01:34<00:02,  2.42it/s][Astep: 222
extend+tolist() time: 0.0004355907440185547

Evaluating:  98%|█████████▊| 223/228 [01:34<00:02,  2.35it/s][Astep: 223
extend+tolist() time: 0.0008497238159179688

Evaluating:  98%|█████████▊| 224/228 [01:34<00:01,  2.39it/s][Astep: 224
extend+tolist() time: 0.00037598609924316406

Evaluating:  99%|█████████▊| 225/228 [01:35<00:01,  2.35it/s][Astep: 225
extend+tolist() time: 0.0004253387451171875

Evaluating:  99%|█████████▉| 226/228 [01:35<00:00,  2.40it/s][Astep: 226
extend+tolist() time: 0.0008091926574707031

Evaluating: 100%|█████████▉| 227/228 [01:36<00:00,  2.40it/s][Astep: 227
extend+tolist() time: 0.0009331703186035156

Evaluating: 100%|██████████| 228/228 [01:36<00:00,  2.36it/s][A09/08/2023 22:39:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 22:39:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:39:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:39:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:39:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:39:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:39:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:39:36 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:39:36 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:39:36 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:39:36 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:39:36 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:39:36 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:39:36 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:39:36 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:39:36 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:39:37 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:38<00:00,  2.32it/s]
09/08/2023 22:39:37 - INFO - __main__ -   Step: 1500, Validation Metrics: {'pred_1_num': 9655, 'pred_-1_num': 922, 'pred_0_num': 224, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7877048421442459, 'f1_micro': 0.7877048421442459, 'f1_macro': 0.45377726272130586, 'f1_weighted': 0.7577392512984611, 'f1_-1': 0.35610932475884244, 'f1_0': 0.12746234067207415, 'f1_1': 0.8777601227330009, 'precision_micro': 0.7877048421442459, 'precision_macro': 0.5185449650826673, 'precision_weighted': 0.7444454217467137, 'precision_-1': 0.4804772234273319, 'precision_0': 0.24553571428571427, 'precision_1': 0.8296219575349559, 'recall_micro': 0.7877048421442459, 'recall_macro': 0.43359569321752245, 'recall_weighted': 0.7877048421442459, 'recall_-1': 0.2828863346104725, 'recall_0': 0.08607198748043818, 'recall_1': 0.9318287575616566, 'roc_auc_micro': 0.9001411848445316, 'roc_auc_macro': 0.7107073507114047, 'roc_auc_weighted': 0.6885955311643408, 'roc_auc_-1': 0.7397859287885985, 'roc_auc_0': 0.715031512964159, 'roc_auc_1': 0.6773046103814567}
[2023-09-08 22:39:57,927] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1501/66600 [1:17:07<912:34:39, 50.47s/it]09/08/2023 22:39:57 - INFO - __main__ -   Step: 1501, LR: 1.5030667167355116e-05, Loss: 0.43746882677078247
[2023-09-08 22:40:18,315] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1502/66600 [1:17:27<749:23:39, 41.44s/it]09/08/2023 22:40:18 - INFO - __main__ -   Step: 1502, LR: 1.5040680936287398e-05, Loss: 0.4396837055683136
[2023-09-08 22:40:38,806] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1503/66600 [1:17:48<635:43:30, 35.16s/it]09/08/2023 22:40:38 - INFO - __main__ -   Step: 1503, LR: 1.5050694705219677e-05, Loss: 0.44224071502685547
[2023-09-08 22:40:59,959] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1504/66600 [1:18:09<559:44:59, 30.96s/it]09/08/2023 22:40:59 - INFO - __main__ -   Step: 1504, LR: 1.5060708474151959e-05, Loss: 0.41770273447036743
[2023-09-08 22:41:21,037] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1505/66600 [1:18:30<506:09:33, 27.99s/it]09/08/2023 22:41:21 - INFO - __main__ -   Step: 1505, LR: 1.507072224308424e-05, Loss: 0.40996789932250977
[2023-09-08 22:41:42,015] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1506/66600 [1:18:51<468:05:59, 25.89s/it]09/08/2023 22:41:42 - INFO - __main__ -   Step: 1506, LR: 1.5080736012016524e-05, Loss: 0.39289844036102295
[2023-09-08 22:42:02,125] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1507/66600 [1:19:11<436:45:12, 24.15s/it]09/08/2023 22:42:02 - INFO - __main__ -   Step: 1507, LR: 1.5090749780948806e-05, Loss: 0.366240918636322
[2023-09-08 22:42:21,904] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1508/66600 [1:19:31<413:00:36, 22.84s/it]09/08/2023 22:42:21 - INFO - __main__ -   Step: 1508, LR: 1.5100763549881087e-05, Loss: 0.3879525363445282
[2023-09-08 22:42:42,687] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1509/66600 [1:19:52<401:50:00, 22.22s/it]09/08/2023 22:42:42 - INFO - __main__ -   Step: 1509, LR: 1.511077731881337e-05, Loss: 0.38802751898765564
[2023-09-08 22:43:03,447] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1510/66600 [1:20:12<393:53:09, 21.79s/it]09/08/2023 22:43:03 - INFO - __main__ -   Step: 1510, LR: 1.5120791087745652e-05, Loss: 0.3971850872039795
[2023-09-08 22:43:24,417] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1511/66600 [1:20:33<389:27:34, 21.54s/it]09/08/2023 22:43:24 - INFO - __main__ -   Step: 1511, LR: 1.5130804856677934e-05, Loss: 0.42269167304039
[2023-09-08 22:43:45,592] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1512/66600 [1:20:55<387:28:13, 21.43s/it]09/08/2023 22:43:45 - INFO - __main__ -   Step: 1512, LR: 1.5140818625610217e-05, Loss: 0.35919737815856934
[2023-09-08 22:44:07,393] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1513/66600 [1:21:16<389:28:13, 21.54s/it]09/08/2023 22:44:07 - INFO - __main__ -   Step: 1513, LR: 1.5150832394542497e-05, Loss: 0.3811693787574768
[2023-09-08 22:44:28,482] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1514/66600 [1:21:38<387:00:32, 21.41s/it]09/08/2023 22:44:28 - INFO - __main__ -   Step: 1514, LR: 1.5160846163474779e-05, Loss: 0.35683563351631165
[2023-09-08 22:44:48,973] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1515/66600 [1:21:58<382:02:20, 21.13s/it]09/08/2023 22:44:48 - INFO - __main__ -   Step: 1515, LR: 1.517085993240706e-05, Loss: 0.385995090007782
[2023-09-08 22:45:09,432] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1516/66600 [1:22:18<378:23:13, 20.93s/it]09/08/2023 22:45:09 - INFO - __main__ -   Step: 1516, LR: 1.5180873701339343e-05, Loss: 0.4206908345222473
[2023-09-08 22:45:30,138] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1517/66600 [1:22:39<377:10:06, 20.86s/it]09/08/2023 22:45:30 - INFO - __main__ -   Step: 1517, LR: 1.5190887470271625e-05, Loss: 0.44644224643707275
[2023-09-08 22:45:51,494] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1518/66600 [1:23:01<379:50:23, 21.01s/it]09/08/2023 22:45:51 - INFO - __main__ -   Step: 1518, LR: 1.5200901239203907e-05, Loss: 0.48527371883392334
[2023-09-08 22:46:12,268] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1519/66600 [1:23:21<378:32:43, 20.94s/it]09/08/2023 22:46:12 - INFO - __main__ -   Step: 1519, LR: 1.5210915008136188e-05, Loss: 0.41475343704223633
[2023-09-08 22:46:32,697] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1520/66600 [1:23:42<375:46:25, 20.79s/it]09/08/2023 22:46:32 - INFO - __main__ -   Step: 1520, LR: 1.5220928777068472e-05, Loss: 0.36997029185295105
09/08/2023 22:46:32 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.002820730209350586

Evaluating:   0%|          | 1/228 [00:00<01:50,  2.06it/s][Astep: 1
extend+tolist() time: 0.0015707015991210938

Evaluating:   1%|          | 2/228 [00:00<01:40,  2.26it/s][Astep: 2
extend+tolist() time: 0.0021283626556396484

Evaluating:   1%|▏         | 3/228 [00:01<01:40,  2.23it/s][Astep: 3
extend+tolist() time: 0.001478433609008789

Evaluating:   2%|▏         | 4/228 [00:01<01:38,  2.28it/s][Astep: 4
extend+tolist() time: 0.0017223358154296875

Evaluating:   2%|▏         | 5/228 [00:02<01:36,  2.30it/s][Astep: 5
extend+tolist() time: 0.002128124237060547

Evaluating:   3%|▎         | 6/228 [00:02<01:34,  2.35it/s][Astep: 6
extend+tolist() time: 0.0019769668579101562

Evaluating:   3%|▎         | 7/228 [00:03<01:35,  2.32it/s][Astep: 7
extend+tolist() time: 0.001020669937133789

Evaluating:   4%|▎         | 8/228 [00:03<01:44,  2.10it/s][Astep: 8
extend+tolist() time: 0.0012581348419189453

Evaluating:   4%|▍         | 9/228 [00:04<01:41,  2.16it/s][Astep: 9
extend+tolist() time: 0.00086212158203125

Evaluating:   4%|▍         | 10/228 [00:04<01:36,  2.27it/s][Astep: 10
extend+tolist() time: 0.0013232231140136719

Evaluating:   5%|▍         | 11/228 [00:04<01:34,  2.30it/s][Astep: 11
extend+tolist() time: 0.000545501708984375

Evaluating:   5%|▌         | 12/228 [00:05<01:33,  2.32it/s][Astep: 12
extend+tolist() time: 0.0010869503021240234

Evaluating:   6%|▌         | 13/228 [00:05<01:30,  2.39it/s][Astep: 13
extend+tolist() time: 0.0005953311920166016

Evaluating:   6%|▌         | 14/228 [00:06<01:30,  2.36it/s][Astep: 14
extend+tolist() time: 0.0005626678466796875

Evaluating:   7%|▋         | 15/228 [00:06<01:37,  2.18it/s][Astep: 15
extend+tolist() time: 0.1357283592224121

Evaluating:   7%|▋         | 16/228 [00:07<01:43,  2.05it/s][Astep: 16
extend+tolist() time: 0.0006496906280517578

Evaluating:   7%|▋         | 17/228 [00:07<01:39,  2.13it/s][Astep: 17
extend+tolist() time: 0.0012753009796142578

Evaluating:   8%|▊         | 18/228 [00:08<01:35,  2.19it/s][Astep: 18
extend+tolist() time: 0.0015087127685546875

Evaluating:   8%|▊         | 19/228 [00:08<01:32,  2.26it/s][Astep: 19
extend+tolist() time: 0.0010058879852294922

Evaluating:   9%|▉         | 20/228 [00:08<01:30,  2.30it/s][Astep: 20
extend+tolist() time: 0.0011982917785644531

Evaluating:   9%|▉         | 21/228 [00:09<01:29,  2.31it/s][Astep: 21
extend+tolist() time: 0.0006701946258544922

Evaluating:  10%|▉         | 22/228 [00:09<01:26,  2.38it/s][Astep: 22
extend+tolist() time: 0.0011889934539794922

Evaluating:  10%|█         | 23/228 [00:10<01:27,  2.34it/s][Astep: 23
extend+tolist() time: 0.000720977783203125

Evaluating:  11%|█         | 24/228 [00:10<01:25,  2.39it/s][Astep: 24
extend+tolist() time: 0.0015931129455566406

Evaluating:  11%|█         | 25/228 [00:10<01:25,  2.38it/s][Astep: 25
extend+tolist() time: 0.001878499984741211

Evaluating:  11%|█▏        | 26/228 [00:11<01:26,  2.33it/s][Astep: 26
extend+tolist() time: 0.0007615089416503906

Evaluating:  12%|█▏        | 27/228 [00:11<01:25,  2.36it/s][Astep: 27
extend+tolist() time: 0.0017359256744384766

Evaluating:  12%|█▏        | 28/228 [00:12<01:28,  2.27it/s][Astep: 28
extend+tolist() time: 0.00035071372985839844

Evaluating:  13%|█▎        | 29/228 [00:12<01:24,  2.35it/s][Astep: 29
extend+tolist() time: 0.001356363296508789

Evaluating:  13%|█▎        | 30/228 [00:13<01:23,  2.37it/s][Astep: 30
extend+tolist() time: 0.0014929771423339844

Evaluating:  14%|█▎        | 31/228 [00:13<01:23,  2.37it/s][Astep: 31
extend+tolist() time: 0.0006041526794433594

Evaluating:  14%|█▍        | 32/228 [00:13<01:21,  2.40it/s][Astep: 32
extend+tolist() time: 0.0014772415161132812

Evaluating:  14%|█▍        | 33/228 [00:14<01:22,  2.35it/s][Astep: 33
extend+tolist() time: 0.0013136863708496094

Evaluating:  15%|█▍        | 34/228 [00:14<01:22,  2.36it/s][Astep: 34
extend+tolist() time: 0.0013477802276611328

Evaluating:  15%|█▌        | 35/228 [00:15<01:23,  2.31it/s][Astep: 35
extend+tolist() time: 0.0006823539733886719

Evaluating:  16%|█▌        | 36/228 [00:15<01:20,  2.37it/s][Astep: 36
extend+tolist() time: 0.0012714862823486328

Evaluating:  16%|█▌        | 37/228 [00:16<01:20,  2.38it/s][Astep: 37
extend+tolist() time: 0.0016868114471435547

Evaluating:  17%|█▋        | 38/228 [00:16<01:21,  2.33it/s][Astep: 38
extend+tolist() time: 0.0007727146148681641

Evaluating:  17%|█▋        | 39/228 [00:16<01:20,  2.34it/s][Astep: 39
extend+tolist() time: 0.0012099742889404297

Evaluating:  18%|█▊        | 40/228 [00:17<01:20,  2.33it/s][Astep: 40
extend+tolist() time: 0.0006396770477294922

Evaluating:  18%|█▊        | 41/228 [00:17<01:28,  2.11it/s][Astep: 41
extend+tolist() time: 0.0013208389282226562

Evaluating:  18%|█▊        | 42/228 [00:18<01:26,  2.16it/s][Astep: 42
extend+tolist() time: 0.0012264251708984375

Evaluating:  19%|█▉        | 43/228 [00:18<01:23,  2.23it/s][Astep: 43
extend+tolist() time: 0.002019643783569336

Evaluating:  19%|█▉        | 44/228 [00:19<01:23,  2.21it/s][Astep: 44
extend+tolist() time: 0.001157999038696289

Evaluating:  20%|█▉        | 45/228 [00:19<01:20,  2.26it/s][Astep: 45
extend+tolist() time: 0.0017888545989990234

Evaluating:  20%|██        | 46/228 [00:20<01:20,  2.27it/s][Astep: 46
extend+tolist() time: 0.0012593269348144531

Evaluating:  21%|██        | 47/228 [00:20<01:27,  2.07it/s][Astep: 47
extend+tolist() time: 0.18067574501037598

Evaluating:  21%|██        | 48/228 [00:21<01:33,  1.92it/s][Astep: 48
extend+tolist() time: 0.0016632080078125

Evaluating:  21%|██▏       | 49/228 [00:21<01:27,  2.04it/s][Astep: 49
extend+tolist() time: 0.001271963119506836

Evaluating:  22%|██▏       | 50/228 [00:22<01:23,  2.12it/s][Astep: 50
extend+tolist() time: 0.0015730857849121094

Evaluating:  22%|██▏       | 51/228 [00:22<01:21,  2.16it/s][Astep: 51
extend+tolist() time: 0.0012054443359375

Evaluating:  23%|██▎       | 52/228 [00:23<01:18,  2.23it/s][Astep: 52
extend+tolist() time: 0.0010094642639160156

Evaluating:  23%|██▎       | 53/228 [00:23<01:18,  2.24it/s][Astep: 53
extend+tolist() time: 0.0017578601837158203

Evaluating:  24%|██▎       | 54/228 [00:23<01:15,  2.30it/s][Astep: 54
extend+tolist() time: 0.0011916160583496094

Evaluating:  24%|██▍       | 55/228 [00:24<01:15,  2.30it/s][Astep: 55
extend+tolist() time: 0.0007982254028320312

Evaluating:  25%|██▍       | 56/228 [00:24<01:13,  2.33it/s][Astep: 56
extend+tolist() time: 0.001623392105102539

Evaluating:  25%|██▌       | 57/228 [00:25<01:12,  2.34it/s][Astep: 57
extend+tolist() time: 0.0005879402160644531

Evaluating:  25%|██▌       | 58/228 [00:25<01:12,  2.35it/s][Astep: 58
extend+tolist() time: 0.0012331008911132812

Evaluating:  26%|██▌       | 59/228 [00:25<01:10,  2.40it/s][Astep: 59
extend+tolist() time: 0.0009181499481201172

Evaluating:  26%|██▋       | 60/228 [00:26<01:11,  2.34it/s][Astep: 60
extend+tolist() time: 0.0012013912200927734

Evaluating:  27%|██▋       | 61/228 [00:26<01:10,  2.36it/s][Astep: 61
extend+tolist() time: 0.0008492469787597656

Evaluating:  27%|██▋       | 62/228 [00:27<01:10,  2.37it/s][Astep: 62
extend+tolist() time: 0.0012395381927490234

Evaluating:  28%|██▊       | 63/228 [00:27<01:10,  2.34it/s][Astep: 63
extend+tolist() time: 0.0008106231689453125

Evaluating:  28%|██▊       | 64/228 [00:28<01:09,  2.35it/s][Astep: 64
extend+tolist() time: 0.0012636184692382812

Evaluating:  29%|██▊       | 65/228 [00:28<01:10,  2.32it/s][Astep: 65
extend+tolist() time: 0.0008180141448974609

Evaluating:  29%|██▉       | 66/228 [00:28<01:08,  2.38it/s][Astep: 66
extend+tolist() time: 0.0012936592102050781

Evaluating:  29%|██▉       | 67/228 [00:29<01:09,  2.33it/s][Astep: 67
extend+tolist() time: 0.0012822151184082031

Evaluating:  30%|██▉       | 68/228 [00:29<01:08,  2.34it/s][Astep: 68
extend+tolist() time: 0.0007071495056152344

Evaluating:  30%|███       | 69/228 [00:30<01:07,  2.37it/s][Astep: 69
extend+tolist() time: 0.0015692710876464844

Evaluating:  31%|███       | 70/228 [00:30<01:07,  2.33it/s][Astep: 70
extend+tolist() time: 0.0010666847229003906

Evaluating:  31%|███       | 71/228 [00:31<01:06,  2.37it/s][Astep: 71
extend+tolist() time: 0.0014994144439697266

Evaluating:  32%|███▏      | 72/228 [00:31<01:07,  2.31it/s][Astep: 72
extend+tolist() time: 0.0007717609405517578

Evaluating:  32%|███▏      | 73/228 [00:31<01:06,  2.35it/s][Astep: 73
extend+tolist() time: 0.0005693435668945312

Evaluating:  32%|███▏      | 74/228 [00:32<01:05,  2.36it/s][Astep: 74
extend+tolist() time: 0.0007550716400146484

Evaluating:  33%|███▎      | 75/228 [00:32<01:05,  2.35it/s][Astep: 75
extend+tolist() time: 0.0017900466918945312

Evaluating:  33%|███▎      | 76/228 [00:33<01:04,  2.36it/s][Astep: 76
extend+tolist() time: 0.001031637191772461

Evaluating:  34%|███▍      | 77/228 [00:33<01:12,  2.08it/s][Astep: 77
extend+tolist() time: 0.0014786720275878906

Evaluating:  34%|███▍      | 78/228 [00:34<01:09,  2.14it/s][Astep: 78
extend+tolist() time: 0.0008699893951416016

Evaluating:  35%|███▍      | 79/228 [00:34<01:08,  2.16it/s][Astep: 79
extend+tolist() time: 0.001329660415649414

Evaluating:  35%|███▌      | 80/228 [00:35<01:05,  2.24it/s][Astep: 80
extend+tolist() time: 0.0009438991546630859

Evaluating:  36%|███▌      | 81/228 [00:35<01:05,  2.25it/s][Astep: 81
extend+tolist() time: 0.0012767314910888672

Evaluating:  36%|███▌      | 82/228 [00:35<01:02,  2.33it/s][Astep: 82
extend+tolist() time: 0.0008654594421386719

Evaluating:  36%|███▋      | 83/228 [00:36<01:01,  2.35it/s][Astep: 83
extend+tolist() time: 0.0011513233184814453

Evaluating:  37%|███▋      | 84/228 [00:36<01:08,  2.09it/s][Astep: 84
extend+tolist() time: 0.0009739398956298828

Evaluating:  37%|███▋      | 85/228 [00:37<01:06,  2.15it/s][Astep: 85
extend+tolist() time: 0.23422741889953613

Evaluating:  38%|███▊      | 86/228 [00:38<01:14,  1.90it/s][Astep: 86
extend+tolist() time: 0.0013713836669921875

Evaluating:  38%|███▊      | 87/228 [00:38<01:10,  2.00it/s][Astep: 87
extend+tolist() time: 0.0008759498596191406

Evaluating:  39%|███▊      | 88/228 [00:38<01:06,  2.12it/s][Astep: 88
extend+tolist() time: 0.0011305809020996094

Evaluating:  39%|███▉      | 89/228 [00:39<01:03,  2.19it/s][Astep: 89
extend+tolist() time: 0.0007123947143554688

Evaluating:  39%|███▉      | 90/228 [00:39<01:01,  2.24it/s][Astep: 90
extend+tolist() time: 0.0013484954833984375

Evaluating:  40%|███▉      | 91/228 [00:40<00:59,  2.31it/s][Astep: 91
extend+tolist() time: 0.0011143684387207031

Evaluating:  40%|████      | 92/228 [00:40<00:59,  2.30it/s][Astep: 92
extend+tolist() time: 0.0007848739624023438

Evaluating:  41%|████      | 93/228 [00:41<00:57,  2.34it/s][Astep: 93
extend+tolist() time: 0.0014431476593017578

Evaluating:  41%|████      | 94/228 [00:41<00:57,  2.35it/s][Astep: 94
extend+tolist() time: 0.0007517337799072266

Evaluating:  42%|████▏     | 95/228 [00:41<00:56,  2.34it/s][Astep: 95
extend+tolist() time: 0.001642465591430664

Evaluating:  42%|████▏     | 96/228 [00:42<00:56,  2.34it/s][Astep: 96
extend+tolist() time: 0.0012903213500976562

Evaluating:  43%|████▎     | 97/228 [00:42<00:56,  2.31it/s][Astep: 97
extend+tolist() time: 0.0008313655853271484

Evaluating:  43%|████▎     | 98/228 [00:43<00:55,  2.36it/s][Astep: 98
extend+tolist() time: 0.0015912055969238281

Evaluating:  43%|████▎     | 99/228 [00:43<00:54,  2.35it/s][Astep: 99
extend+tolist() time: 0.0008869171142578125

Evaluating:  44%|████▍     | 100/228 [00:43<00:53,  2.39it/s][Astep: 100
extend+tolist() time: 0.0011944770812988281

Evaluating:  44%|████▍     | 101/228 [00:44<00:52,  2.42it/s][Astep: 101
extend+tolist() time: 0.0008063316345214844

Evaluating:  45%|████▍     | 102/228 [00:44<00:52,  2.41it/s][Astep: 102
extend+tolist() time: 0.0011701583862304688

Evaluating:  45%|████▌     | 103/228 [00:45<00:50,  2.47it/s][Astep: 103
extend+tolist() time: 0.0010175704956054688

Evaluating:  46%|████▌     | 104/228 [00:45<00:51,  2.42it/s][Astep: 104
extend+tolist() time: 0.0010833740234375

Evaluating:  46%|████▌     | 105/228 [00:46<00:50,  2.44it/s][Astep: 105
extend+tolist() time: 0.0008158683776855469

Evaluating:  46%|████▋     | 106/228 [00:46<00:50,  2.44it/s][Astep: 106
extend+tolist() time: 0.0017726421356201172

Evaluating:  47%|████▋     | 107/228 [00:46<00:51,  2.36it/s][Astep: 107
extend+tolist() time: 0.0007684230804443359

Evaluating:  47%|████▋     | 108/228 [00:47<00:50,  2.39it/s][Astep: 108
extend+tolist() time: 0.0008020401000976562

Evaluating:  48%|████▊     | 109/228 [00:47<00:50,  2.35it/s][Astep: 109
extend+tolist() time: 0.0012922286987304688

Evaluating:  48%|████▊     | 110/228 [00:48<00:50,  2.36it/s][Astep: 110
extend+tolist() time: 0.0006196498870849609

Evaluating:  49%|████▊     | 111/228 [00:48<00:49,  2.37it/s][Astep: 111
extend+tolist() time: 0.0018274784088134766

Evaluating:  49%|████▉     | 112/228 [00:49<00:50,  2.30it/s][Astep: 112
extend+tolist() time: 0.00039124488830566406

Evaluating:  50%|████▉     | 113/228 [00:49<00:49,  2.34it/s][Astep: 113
extend+tolist() time: 0.0006964206695556641

Evaluating:  50%|█████     | 114/228 [00:49<00:49,  2.32it/s][Astep: 114
extend+tolist() time: 0.0011029243469238281

Evaluating:  50%|█████     | 115/228 [00:50<00:48,  2.34it/s][Astep: 115
extend+tolist() time: 0.0011157989501953125

Evaluating:  51%|█████     | 116/228 [00:50<00:48,  2.33it/s][Astep: 116
extend+tolist() time: 0.0008323192596435547

Evaluating:  51%|█████▏    | 117/228 [00:51<00:47,  2.36it/s][Astep: 117
extend+tolist() time: 0.0012881755828857422

Evaluating:  52%|█████▏    | 118/228 [00:51<00:46,  2.37it/s][Astep: 118
extend+tolist() time: 0.0005609989166259766

Evaluating:  52%|█████▏    | 119/228 [00:52<00:46,  2.35it/s][Astep: 119
extend+tolist() time: 0.0007150173187255859

Evaluating:  53%|█████▎    | 120/228 [00:52<00:44,  2.40it/s][Astep: 120
extend+tolist() time: 0.0010881423950195312

Evaluating:  53%|█████▎    | 121/228 [00:52<00:44,  2.38it/s][Astep: 121
extend+tolist() time: 0.0006375312805175781

Evaluating:  54%|█████▎    | 122/228 [00:53<00:44,  2.41it/s][Astep: 122
extend+tolist() time: 0.0011034011840820312

Evaluating:  54%|█████▍    | 123/228 [00:53<00:43,  2.42it/s][Astep: 123
extend+tolist() time: 0.0006093978881835938

Evaluating:  54%|█████▍    | 124/228 [00:54<00:43,  2.40it/s][Astep: 124
extend+tolist() time: 0.0012428760528564453

Evaluating:  55%|█████▍    | 125/228 [00:54<00:42,  2.44it/s][Astep: 125
extend+tolist() time: 0.0004360675811767578

Evaluating:  55%|█████▌    | 126/228 [00:55<00:49,  2.05it/s][Astep: 126
extend+tolist() time: 0.0017063617706298828

Evaluating:  56%|█████▌    | 127/228 [00:55<00:47,  2.14it/s][Astep: 127
extend+tolist() time: 0.0016431808471679688

Evaluating:  56%|█████▌    | 128/228 [00:56<00:46,  2.15it/s][Astep: 128
extend+tolist() time: 0.0007464885711669922

Evaluating:  57%|█████▋    | 129/228 [00:56<00:43,  2.26it/s][Astep: 129
extend+tolist() time: 0.0007700920104980469

Evaluating:  57%|█████▋    | 130/228 [00:56<00:43,  2.28it/s][Astep: 130
extend+tolist() time: 0.0008924007415771484

Evaluating:  57%|█████▋    | 131/228 [00:57<00:41,  2.32it/s][Astep: 131
extend+tolist() time: 0.00046539306640625

Evaluating:  58%|█████▊    | 132/228 [00:57<00:40,  2.36it/s][Astep: 132
extend+tolist() time: 0.0015461444854736328

Evaluating:  58%|█████▊    | 133/228 [00:58<00:40,  2.33it/s][Astep: 133
extend+tolist() time: 0.0004379749298095703

Evaluating:  59%|█████▉    | 134/228 [00:58<00:39,  2.41it/s][Astep: 134
extend+tolist() time: 0.0014061927795410156

Evaluating:  59%|█████▉    | 135/228 [00:58<00:39,  2.36it/s][Astep: 135
extend+tolist() time: 0.0005068778991699219

Evaluating:  60%|█████▉    | 136/228 [00:59<00:38,  2.38it/s][Astep: 136
extend+tolist() time: 0.0013475418090820312

Evaluating:  60%|██████    | 137/228 [00:59<00:43,  2.08it/s][Astep: 137
extend+tolist() time: 0.0004341602325439453

Evaluating:  61%|██████    | 138/228 [01:00<00:41,  2.18it/s][Astep: 138
extend+tolist() time: 0.0008566379547119141

Evaluating:  61%|██████    | 139/228 [01:00<00:39,  2.24it/s][Astep: 139
extend+tolist() time: 0.0009937286376953125

Evaluating:  61%|██████▏   | 140/228 [01:01<00:38,  2.26it/s][Astep: 140
extend+tolist() time: 0.0008895397186279297

Evaluating:  62%|██████▏   | 141/228 [01:01<00:37,  2.32it/s][Astep: 141
extend+tolist() time: 0.0013279914855957031

Evaluating:  62%|██████▏   | 142/228 [01:02<00:37,  2.28it/s][Astep: 142
extend+tolist() time: 0.2350320816040039

Evaluating:  63%|██████▎   | 143/228 [01:02<00:48,  1.77it/s][Astep: 143
extend+tolist() time: 0.0003707408905029297

Evaluating:  63%|██████▎   | 144/228 [01:03<00:43,  1.94it/s][Astep: 144
extend+tolist() time: 0.0011563301086425781

Evaluating:  64%|██████▎   | 145/228 [01:03<00:39,  2.08it/s][Astep: 145
extend+tolist() time: 0.0005424022674560547

Evaluating:  64%|██████▍   | 146/228 [01:04<00:37,  2.16it/s][Astep: 146
extend+tolist() time: 0.0004284381866455078

Evaluating:  64%|██████▍   | 147/228 [01:04<00:35,  2.28it/s][Astep: 147
extend+tolist() time: 0.0011548995971679688

Evaluating:  65%|██████▍   | 148/228 [01:04<00:35,  2.28it/s][Astep: 148
extend+tolist() time: 0.0007336139678955078

Evaluating:  65%|██████▌   | 149/228 [01:05<00:33,  2.34it/s][Astep: 149
extend+tolist() time: 0.00038552284240722656

Evaluating:  66%|██████▌   | 150/228 [01:05<00:32,  2.39it/s][Astep: 150
extend+tolist() time: 0.0013842582702636719

Evaluating:  66%|██████▌   | 151/228 [01:06<00:33,  2.28it/s][Astep: 151
extend+tolist() time: 0.0006635189056396484

Evaluating:  67%|██████▋   | 152/228 [01:06<00:32,  2.34it/s][Astep: 152
extend+tolist() time: 0.001329183578491211

Evaluating:  67%|██████▋   | 153/228 [01:07<00:32,  2.29it/s][Astep: 153
extend+tolist() time: 0.0010635852813720703

Evaluating:  68%|██████▊   | 154/228 [01:07<00:31,  2.33it/s][Astep: 154
extend+tolist() time: 0.0023415088653564453

Evaluating:  68%|██████▊   | 155/228 [01:07<00:31,  2.30it/s][Astep: 155
extend+tolist() time: 0.0010614395141601562

Evaluating:  68%|██████▊   | 156/228 [01:08<00:30,  2.33it/s][Astep: 156
extend+tolist() time: 0.0005669593811035156

Evaluating:  69%|██████▉   | 157/228 [01:08<00:30,  2.32it/s][Astep: 157
extend+tolist() time: 0.0007090568542480469

Evaluating:  69%|██████▉   | 158/228 [01:09<00:30,  2.30it/s][Astep: 158
extend+tolist() time: 0.0009434223175048828

Evaluating:  70%|██████▉   | 159/228 [01:09<00:29,  2.35it/s][Astep: 159
extend+tolist() time: 0.0007619857788085938

Evaluating:  70%|███████   | 160/228 [01:10<00:29,  2.33it/s][Astep: 160
extend+tolist() time: 0.00040340423583984375

Evaluating:  71%|███████   | 161/228 [01:10<00:28,  2.37it/s][Astep: 161
extend+tolist() time: 0.0012421607971191406

Evaluating:  71%|███████   | 162/228 [01:10<00:27,  2.39it/s][Astep: 162
extend+tolist() time: 0.0005221366882324219

Evaluating:  71%|███████▏  | 163/228 [01:11<00:27,  2.38it/s][Astep: 163
extend+tolist() time: 0.000400543212890625

Evaluating:  72%|███████▏  | 164/228 [01:11<00:26,  2.43it/s][Astep: 164
extend+tolist() time: 0.0005972385406494141

Evaluating:  72%|███████▏  | 165/228 [01:12<00:26,  2.40it/s][Astep: 165
extend+tolist() time: 0.0009129047393798828

Evaluating:  73%|███████▎  | 166/228 [01:12<00:25,  2.45it/s][Astep: 166
extend+tolist() time: 0.0003952980041503906

Evaluating:  73%|███████▎  | 167/228 [01:12<00:24,  2.47it/s][Astep: 167
extend+tolist() time: 0.0005884170532226562

Evaluating:  74%|███████▎  | 168/228 [01:13<00:24,  2.43it/s][Astep: 168
extend+tolist() time: 0.0016474723815917969

Evaluating:  74%|███████▍  | 169/228 [01:13<00:23,  2.46it/s][Astep: 169
extend+tolist() time: 0.000377655029296875

Evaluating:  75%|███████▍  | 170/228 [01:14<00:23,  2.42it/s][Astep: 170
extend+tolist() time: 0.0009484291076660156

Evaluating:  75%|███████▌  | 171/228 [01:14<00:23,  2.45it/s][Astep: 171
extend+tolist() time: 0.0007462501525878906

Evaluating:  75%|███████▌  | 172/228 [01:15<00:22,  2.45it/s][Astep: 172
extend+tolist() time: 0.000823974609375

Evaluating:  76%|███████▌  | 173/228 [01:15<00:22,  2.41it/s][Astep: 173
extend+tolist() time: 0.0015921592712402344

Evaluating:  76%|███████▋  | 174/228 [01:15<00:22,  2.36it/s][Astep: 174
extend+tolist() time: 0.0014734268188476562

Evaluating:  77%|███████▋  | 175/228 [01:16<00:22,  2.32it/s][Astep: 175
extend+tolist() time: 0.0012602806091308594

Evaluating:  77%|███████▋  | 176/228 [01:16<00:21,  2.38it/s][Astep: 176
extend+tolist() time: 0.0006496906280517578

Evaluating:  78%|███████▊  | 177/228 [01:17<00:21,  2.37it/s][Astep: 177
extend+tolist() time: 0.0010156631469726562

Evaluating:  78%|███████▊  | 178/228 [01:17<00:20,  2.40it/s][Astep: 178
extend+tolist() time: 0.0012531280517578125

Evaluating:  79%|███████▊  | 179/228 [01:17<00:20,  2.40it/s][Astep: 179
extend+tolist() time: 0.00040912628173828125

Evaluating:  79%|███████▉  | 180/228 [01:18<00:20,  2.37it/s][Astep: 180
extend+tolist() time: 0.0008337497711181641

Evaluating:  79%|███████▉  | 181/228 [01:18<00:19,  2.43it/s][Astep: 181
extend+tolist() time: 0.0006318092346191406

Evaluating:  80%|███████▉  | 182/228 [01:19<00:19,  2.40it/s][Astep: 182
extend+tolist() time: 0.0007686614990234375

Evaluating:  80%|████████  | 183/228 [01:19<00:18,  2.42it/s][Astep: 183
extend+tolist() time: 0.001085519790649414

Evaluating:  81%|████████  | 184/228 [01:20<00:17,  2.46it/s][Astep: 184
extend+tolist() time: 0.00046753883361816406

Evaluating:  81%|████████  | 185/228 [01:20<00:17,  2.42it/s][Astep: 185
extend+tolist() time: 0.0014743804931640625

Evaluating:  82%|████████▏ | 186/228 [01:20<00:17,  2.45it/s][Astep: 186
extend+tolist() time: 0.0010759830474853516

Evaluating:  82%|████████▏ | 187/228 [01:21<00:17,  2.40it/s][Astep: 187
extend+tolist() time: 0.0004642009735107422

Evaluating:  82%|████████▏ | 188/228 [01:21<00:16,  2.44it/s][Astep: 188
extend+tolist() time: 0.0011849403381347656

Evaluating:  83%|████████▎ | 189/228 [01:22<00:15,  2.45it/s][Astep: 189
extend+tolist() time: 0.0003476142883300781

Evaluating:  83%|████████▎ | 190/228 [01:22<00:15,  2.42it/s][Astep: 190
extend+tolist() time: 0.0015423297882080078

Evaluating:  84%|████████▍ | 191/228 [01:22<00:15,  2.47it/s][Astep: 191
extend+tolist() time: 0.0007607936859130859

Evaluating:  84%|████████▍ | 192/228 [01:23<00:14,  2.45it/s][Astep: 192
extend+tolist() time: 0.0004439353942871094

Evaluating:  85%|████████▍ | 193/228 [01:23<00:14,  2.48it/s][Astep: 193
extend+tolist() time: 0.0014584064483642578

Evaluating:  85%|████████▌ | 194/228 [01:24<00:13,  2.49it/s][Astep: 194
extend+tolist() time: 0.0006053447723388672

Evaluating:  86%|████████▌ | 195/228 [01:24<00:13,  2.46it/s][Astep: 195
extend+tolist() time: 0.0005197525024414062

Evaluating:  86%|████████▌ | 196/228 [01:24<00:13,  2.46it/s][Astep: 196
extend+tolist() time: 0.0010576248168945312

Evaluating:  86%|████████▋ | 197/228 [01:25<00:12,  2.45it/s][Astep: 197
extend+tolist() time: 0.0006668567657470703

Evaluating:  87%|████████▋ | 198/228 [01:25<00:12,  2.45it/s][Astep: 198
extend+tolist() time: 0.0006425380706787109

Evaluating:  87%|████████▋ | 199/228 [01:26<00:11,  2.45it/s][Astep: 199
extend+tolist() time: 0.002016782760620117

Evaluating:  88%|████████▊ | 200/228 [01:26<00:11,  2.35it/s][Astep: 200
extend+tolist() time: 0.0011043548583984375

Evaluating:  88%|████████▊ | 201/228 [01:27<00:11,  2.39it/s][Astep: 201
extend+tolist() time: 0.0006422996520996094

Evaluating:  89%|████████▊ | 202/228 [01:27<00:11,  2.33it/s][Astep: 202
extend+tolist() time: 0.0004019737243652344

Evaluating:  89%|████████▉ | 203/228 [01:27<00:10,  2.38it/s][Astep: 203
extend+tolist() time: 0.0007774829864501953

Evaluating:  89%|████████▉ | 204/228 [01:28<00:10,  2.36it/s][Astep: 204
extend+tolist() time: 0.0008685588836669922

Evaluating:  90%|████████▉ | 205/228 [01:28<00:09,  2.38it/s][Astep: 205
extend+tolist() time: 0.00029969215393066406

Evaluating:  90%|█████████ | 206/228 [01:29<00:09,  2.39it/s][Astep: 206
extend+tolist() time: 0.0006058216094970703

Evaluating:  91%|█████████ | 207/228 [01:29<00:08,  2.35it/s][Astep: 207
extend+tolist() time: 0.0006296634674072266

Evaluating:  91%|█████████ | 208/228 [01:29<00:08,  2.41it/s][Astep: 208
extend+tolist() time: 0.0012123584747314453

Evaluating:  92%|█████████▏| 209/228 [01:30<00:07,  2.38it/s][Astep: 209
extend+tolist() time: 0.0006022453308105469

Evaluating:  92%|█████████▏| 210/228 [01:30<00:07,  2.41it/s][Astep: 210
extend+tolist() time: 0.0005903244018554688

Evaluating:  93%|█████████▎| 211/228 [01:31<00:06,  2.43it/s][Astep: 211
extend+tolist() time: 0.002458333969116211

Evaluating:  93%|█████████▎| 212/228 [01:31<00:06,  2.36it/s][Astep: 212
extend+tolist() time: 0.0009248256683349609

Evaluating:  93%|█████████▎| 213/228 [01:32<00:07,  1.92it/s][Astep: 213
extend+tolist() time: 0.0011353492736816406

Evaluating:  94%|█████████▍| 214/228 [01:32<00:06,  2.06it/s][Astep: 214
extend+tolist() time: 0.0008594989776611328

Evaluating:  94%|█████████▍| 215/228 [01:33<00:05,  2.17it/s][Astep: 215
extend+tolist() time: 0.001077890396118164

Evaluating:  95%|█████████▍| 216/228 [01:33<00:05,  2.21it/s][Astep: 216
extend+tolist() time: 0.0005667209625244141

Evaluating:  95%|█████████▌| 217/228 [01:34<00:04,  2.31it/s][Astep: 217
extend+tolist() time: 0.0005748271942138672

Evaluating:  96%|█████████▌| 218/228 [01:34<00:04,  2.32it/s][Astep: 218
extend+tolist() time: 0.001458883285522461

Evaluating:  96%|█████████▌| 219/228 [01:34<00:03,  2.35it/s][Astep: 219
extend+tolist() time: 0.0005159378051757812

Evaluating:  96%|█████████▋| 220/228 [01:35<00:03,  2.36it/s][Astep: 220
extend+tolist() time: 0.00040459632873535156

Evaluating:  97%|█████████▋| 221/228 [01:35<00:03,  2.33it/s][Astep: 221
extend+tolist() time: 0.0010333061218261719

Evaluating:  97%|█████████▋| 222/228 [01:36<00:02,  2.39it/s][Astep: 222
extend+tolist() time: 0.0004374980926513672

Evaluating:  98%|█████████▊| 223/228 [01:36<00:02,  2.37it/s][Astep: 223
extend+tolist() time: 0.00040721893310546875

Evaluating:  98%|█████████▊| 224/228 [01:36<00:01,  2.40it/s][Astep: 224
extend+tolist() time: 0.0003695487976074219

Evaluating:  99%|█████████▊| 225/228 [01:37<00:01,  2.44it/s][Astep: 225
extend+tolist() time: 0.0004253387451171875

Evaluating:  99%|█████████▉| 226/228 [01:37<00:00,  2.41it/s][Astep: 226
extend+tolist() time: 0.0009849071502685547

Evaluating: 100%|█████████▉| 227/228 [01:38<00:00,  2.48it/s][Astep: 227
extend+tolist() time: 0.0004825592041015625

Evaluating: 100%|██████████| 228/228 [01:38<00:00,  2.38it/s][A09/08/2023 22:48:11 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 22:48:11 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:48:11 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:48:11 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:48:11 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:48:11 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:48:11 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:48:13 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:48:13 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:48:13 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:48:13 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:41<00:00,  2.26it/s]
09/08/2023 22:48:13 - INFO - __main__ -   Step: 1520, Validation Metrics: {'pred_1_num': 9983, 'pred_-1_num': 782, 'pred_0_num': 36, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7986297565040275, 'f1_micro': 0.7986297565040275, 'f1_macro': 0.41818068647762335, 'f1_weighted': 0.754911823351954, 'f1_-1': 0.3339011925042589, 'f1_0': 0.035555555555555556, 'f1_1': 0.8850853113730556, 'precision_micro': 0.7986297565040275, 'precision_macro': 0.5527374086387323, 'precision_weighted': 0.7478630859014282, 'precision_-1': 0.5012787723785166, 'precision_0': 0.3333333333333333, 'precision_1': 0.8236001202043474, 'recall_micro': 0.7986297565040275, 'recall_macro': 0.40853000628995323, 'recall_weighted': 0.7986297565040275, 'recall_-1': 0.2503192848020434, 'recall_0': 0.018779342723004695, 'recall_1': 0.9564913913448115, 'roc_auc_micro': 0.9120493554687287, 'roc_auc_macro': 0.7352148942301565, 'roc_auc_weighted': 0.7098377557663134, 'roc_auc_-1': 0.7755333110681019, 'roc_auc_0': 0.7340410852791969, 'roc_auc_1': 0.6960702863431708}
[2023-09-08 22:48:34,127] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1521/66600 [1:25:43<921:34:54, 50.98s/it]09/08/2023 22:48:34 - INFO - __main__ -   Step: 1521, LR: 1.5230942546000753e-05, Loss: 0.3961490988731384
[2023-09-08 22:48:54,696] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1522/66600 [1:26:04<756:38:39, 41.86s/it]09/08/2023 22:48:54 - INFO - __main__ -   Step: 1522, LR: 1.5240956314933033e-05, Loss: 0.42501652240753174
[2023-09-08 22:49:14,997] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1523/66600 [1:26:24<639:44:13, 35.39s/it]09/08/2023 22:49:14 - INFO - __main__ -   Step: 1523, LR: 1.5250970083865315e-05, Loss: 0.4764448404312134
[2023-09-08 22:49:35,441] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1524/66600 [1:26:44<558:40:31, 30.91s/it]09/08/2023 22:49:35 - INFO - __main__ -   Step: 1524, LR: 1.5260983852797598e-05, Loss: 0.4241793155670166
[2023-09-08 22:49:56,377] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1525/66600 [1:27:05<504:36:20, 27.92s/it]09/08/2023 22:49:56 - INFO - __main__ -   Step: 1525, LR: 1.527099762172988e-05, Loss: 0.3548082113265991
[2023-09-08 22:50:17,218] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1526/66600 [1:27:26<466:14:07, 25.79s/it]09/08/2023 22:50:17 - INFO - __main__ -   Step: 1526, LR: 1.528101139066216e-05, Loss: 0.40517276525497437
[2023-09-08 22:50:37,717] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1527/66600 [1:27:47<437:31:01, 24.20s/it]09/08/2023 22:50:37 - INFO - __main__ -   Step: 1527, LR: 1.5291025159594443e-05, Loss: 0.4538268744945526
[2023-09-08 22:50:58,222] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1528/66600 [1:28:07<417:26:59, 23.09s/it]09/08/2023 22:50:58 - INFO - __main__ -   Step: 1528, LR: 1.5301038928526724e-05, Loss: 0.4151878356933594
[2023-09-08 22:51:18,541] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1529/66600 [1:28:28<402:23:23, 22.26s/it]09/08/2023 22:51:18 - INFO - __main__ -   Step: 1529, LR: 1.531105269745901e-05, Loss: 0.4215177893638611
[2023-09-08 22:51:39,544] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1530/66600 [1:28:49<395:33:33, 21.88s/it]09/08/2023 22:51:39 - INFO - __main__ -   Step: 1530, LR: 1.532106646639129e-05, Loss: 0.38169199228286743
[2023-09-08 22:52:00,407] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1531/66600 [1:29:09<390:00:58, 21.58s/it]09/08/2023 22:52:00 - INFO - __main__ -   Step: 1531, LR: 1.5331080235323573e-05, Loss: 0.3674432635307312
[2023-09-08 22:52:21,022] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1532/66600 [1:29:30<384:47:20, 21.29s/it]09/08/2023 22:52:21 - INFO - __main__ -   Step: 1532, LR: 1.534109400425585e-05, Loss: 0.3802645802497864
[2023-09-08 22:52:40,955] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1533/66600 [1:29:50<377:25:39, 20.88s/it]09/08/2023 22:52:40 - INFO - __main__ -   Step: 1533, LR: 1.5351107773188136e-05, Loss: 0.4295574128627777
[2023-09-08 22:53:02,082] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1534/66600 [1:30:11<378:45:08, 20.96s/it]09/08/2023 22:53:02 - INFO - __main__ -   Step: 1534, LR: 1.5361121542120417e-05, Loss: 0.42097944021224976
[2023-09-08 22:53:22,514] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1535/66600 [1:30:32<375:54:09, 20.80s/it]09/08/2023 22:53:22 - INFO - __main__ -   Step: 1535, LR: 1.53711353110527e-05, Loss: 0.39847898483276367
[2023-09-08 22:53:43,440] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1536/66600 [1:30:52<376:35:27, 20.84s/it]09/08/2023 22:53:43 - INFO - __main__ -   Step: 1536, LR: 1.538114907998498e-05, Loss: 0.42718055844306946
[2023-09-08 22:54:04,305] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1537/66600 [1:31:13<376:44:19, 20.85s/it]09/08/2023 22:54:04 - INFO - __main__ -   Step: 1537, LR: 1.5391162848917262e-05, Loss: 0.3780999481678009
[2023-09-08 22:54:24,721] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1538/66600 [1:31:34<374:24:21, 20.72s/it]09/08/2023 22:54:24 - INFO - __main__ -   Step: 1538, LR: 1.5401176617849544e-05, Loss: 0.4477979242801666
[2023-09-08 22:54:46,107] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1539/66600 [1:31:55<378:01:46, 20.92s/it]09/08/2023 22:54:46 - INFO - __main__ -   Step: 1539, LR: 1.5411190386781825e-05, Loss: 0.4191994071006775
[2023-09-08 22:55:07,445] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1540/66600 [1:32:16<380:18:02, 21.04s/it]09/08/2023 22:55:07 - INFO - __main__ -   Step: 1540, LR: 1.542120415571411e-05, Loss: 0.3881164491176605
09/08/2023 22:55:07 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0029380321502685547

Evaluating:   0%|          | 1/228 [00:00<01:57,  1.92it/s][Astep: 1
extend+tolist() time: 0.0010945796966552734

Evaluating:   1%|          | 2/228 [00:00<01:46,  2.11it/s][Astep: 2
extend+tolist() time: 0.0021817684173583984

Evaluating:   1%|▏         | 3/228 [00:01<01:42,  2.19it/s][Astep: 3
extend+tolist() time: 0.0019659996032714844

Evaluating:   2%|▏         | 4/228 [00:01<01:43,  2.16it/s][Astep: 4
extend+tolist() time: 0.0014500617980957031

Evaluating:   2%|▏         | 5/228 [00:02<01:39,  2.25it/s][Astep: 5
extend+tolist() time: 0.0015821456909179688

Evaluating:   3%|▎         | 6/228 [00:02<01:40,  2.22it/s][Astep: 6
extend+tolist() time: 0.17646145820617676

Evaluating:   3%|▎         | 7/228 [00:03<01:50,  2.00it/s][Astep: 7
extend+tolist() time: 0.0009849071502685547

Evaluating:   4%|▎         | 8/228 [00:03<01:46,  2.07it/s][Astep: 8
extend+tolist() time: 0.0011303424835205078

Evaluating:   4%|▍         | 9/228 [00:04<01:41,  2.17it/s][Astep: 9
extend+tolist() time: 0.0008122920989990234

Evaluating:   4%|▍         | 10/228 [00:04<01:47,  2.02it/s][Astep: 10
extend+tolist() time: 0.0012764930725097656

Evaluating:   5%|▍         | 11/228 [00:05<01:41,  2.13it/s][Astep: 11
extend+tolist() time: 0.0005686283111572266

Evaluating:   5%|▌         | 12/228 [00:05<01:38,  2.19it/s][Astep: 12
extend+tolist() time: 0.0010609626770019531

Evaluating:   6%|▌         | 13/228 [00:06<01:36,  2.23it/s][Astep: 13
extend+tolist() time: 0.0005717277526855469

Evaluating:   6%|▌         | 14/228 [00:06<01:32,  2.31it/s][Astep: 14
extend+tolist() time: 0.0005557537078857422

Evaluating:   7%|▋         | 15/228 [00:06<01:32,  2.30it/s][Astep: 15
extend+tolist() time: 0.0010461807250976562

Evaluating:   7%|▋         | 16/228 [00:07<01:29,  2.37it/s][Astep: 16
extend+tolist() time: 0.0006136894226074219

Evaluating:   7%|▋         | 17/228 [00:07<01:30,  2.34it/s][Astep: 17
extend+tolist() time: 0.0012652873992919922

Evaluating:   8%|▊         | 18/228 [00:08<01:29,  2.36it/s][Astep: 18
extend+tolist() time: 0.0011448860168457031

Evaluating:   8%|▊         | 19/228 [00:08<01:27,  2.39it/s][Astep: 19
extend+tolist() time: 0.00142669677734375

Evaluating:   9%|▉         | 20/228 [00:08<01:29,  2.31it/s][Astep: 20
extend+tolist() time: 0.0011060237884521484

Evaluating:   9%|▉         | 21/228 [00:09<01:26,  2.39it/s][Astep: 21
extend+tolist() time: 0.00066375732421875

Evaluating:  10%|▉         | 22/228 [00:09<01:26,  2.38it/s][Astep: 22
extend+tolist() time: 0.0007252693176269531

Evaluating:  10%|█         | 23/228 [00:10<01:24,  2.42it/s][Astep: 23
extend+tolist() time: 0.0011582374572753906

Evaluating:  11%|█         | 24/228 [00:10<01:22,  2.47it/s][Astep: 24
extend+tolist() time: 0.0015017986297607422

Evaluating:  11%|█         | 25/228 [00:11<01:30,  2.23it/s][Astep: 25
extend+tolist() time: 0.0018320083618164062

Evaluating:  11%|█▏        | 26/228 [00:11<01:27,  2.30it/s][Astep: 26
extend+tolist() time: 0.0007295608520507812

Evaluating:  12%|█▏        | 27/228 [00:11<01:27,  2.29it/s][Astep: 27
extend+tolist() time: 0.0017261505126953125

Evaluating:  12%|█▏        | 28/228 [00:12<01:25,  2.35it/s][Astep: 28
extend+tolist() time: 0.00034928321838378906

Evaluating:  13%|█▎        | 29/228 [00:12<01:24,  2.36it/s][Astep: 29
extend+tolist() time: 0.0006821155548095703

Evaluating:  13%|█▎        | 30/228 [00:13<01:22,  2.41it/s][Astep: 30
extend+tolist() time: 0.0014963150024414062

Evaluating:  14%|█▎        | 31/228 [00:13<01:20,  2.44it/s][Astep: 31
extend+tolist() time: 0.0009291172027587891

Evaluating:  14%|█▍        | 32/228 [00:14<01:21,  2.39it/s][Astep: 32
extend+tolist() time: 0.0009596347808837891

Evaluating:  14%|█▍        | 33/228 [00:14<01:20,  2.44it/s][Astep: 33
extend+tolist() time: 0.0016551017761230469

Evaluating:  15%|█▍        | 34/228 [00:14<01:21,  2.39it/s][Astep: 34
extend+tolist() time: 0.001207113265991211

Evaluating:  15%|█▌        | 35/228 [00:15<01:19,  2.44it/s][Astep: 35
extend+tolist() time: 0.0007472038269042969

Evaluating:  16%|█▌        | 36/228 [00:15<01:16,  2.51it/s][Astep: 36
extend+tolist() time: 0.0007815361022949219

Evaluating:  16%|█▌        | 37/228 [00:16<01:18,  2.43it/s][Astep: 37
extend+tolist() time: 0.0017862319946289062

Evaluating:  17%|█▋        | 38/228 [00:16<01:16,  2.47it/s][Astep: 38
extend+tolist() time: 0.1660175323486328

Evaluating:  17%|█▋        | 39/228 [00:17<01:37,  1.93it/s][Astep: 39
extend+tolist() time: 0.0007047653198242188

Evaluating:  18%|█▊        | 40/228 [00:17<01:29,  2.11it/s][Astep: 40
extend+tolist() time: 0.0010123252868652344

Evaluating:  18%|█▊        | 41/228 [00:18<01:26,  2.17it/s][Astep: 41
extend+tolist() time: 0.0008511543273925781

Evaluating:  18%|█▊        | 42/228 [00:18<01:21,  2.28it/s][Astep: 42
extend+tolist() time: 0.0016112327575683594

Evaluating:  19%|█▉        | 43/228 [00:19<01:32,  2.01it/s][Astep: 43
extend+tolist() time: 0.001834869384765625

Evaluating:  19%|█▉        | 44/228 [00:19<01:26,  2.14it/s][Astep: 44
extend+tolist() time: 0.0010933876037597656

Evaluating:  20%|█▉        | 45/228 [00:19<01:23,  2.20it/s][Astep: 45
extend+tolist() time: 0.0015811920166015625

Evaluating:  20%|██        | 46/228 [00:20<01:20,  2.27it/s][Astep: 46
extend+tolist() time: 0.00122833251953125

Evaluating:  21%|██        | 47/228 [00:20<01:17,  2.34it/s][Astep: 47
extend+tolist() time: 0.0015702247619628906

Evaluating:  21%|██        | 48/228 [00:21<01:18,  2.29it/s][Astep: 48
extend+tolist() time: 0.0016036033630371094

Evaluating:  21%|██▏       | 49/228 [00:21<01:16,  2.35it/s][Astep: 49
extend+tolist() time: 0.0012917518615722656

Evaluating:  22%|██▏       | 50/228 [00:21<01:16,  2.34it/s][Astep: 50
extend+tolist() time: 0.0011920928955078125

Evaluating:  22%|██▏       | 51/228 [00:22<01:14,  2.37it/s][Astep: 51
extend+tolist() time: 0.0016667842864990234

Evaluating:  23%|██▎       | 52/228 [00:22<01:12,  2.43it/s][Astep: 52
extend+tolist() time: 0.0013365745544433594

Evaluating:  23%|██▎       | 53/228 [00:23<01:14,  2.36it/s][Astep: 53
extend+tolist() time: 0.00170135498046875

Evaluating:  24%|██▎       | 54/228 [00:23<01:12,  2.41it/s][Astep: 54
extend+tolist() time: 0.0008025169372558594

Evaluating:  24%|██▍       | 55/228 [00:24<01:21,  2.12it/s][Astep: 55
extend+tolist() time: 0.001195669174194336

Evaluating:  25%|██▍       | 56/228 [00:24<01:16,  2.25it/s][Astep: 56
extend+tolist() time: 0.001168966293334961

Evaluating:  25%|██▌       | 57/228 [00:25<01:15,  2.26it/s][Astep: 57
extend+tolist() time: 0.001035451889038086

Evaluating:  25%|██▌       | 58/228 [00:25<01:12,  2.34it/s][Astep: 58
extend+tolist() time: 0.0008594989776611328

Evaluating:  26%|██▌       | 59/228 [00:25<01:10,  2.41it/s][Astep: 59
extend+tolist() time: 0.0013346672058105469

Evaluating:  26%|██▋       | 60/228 [00:26<01:10,  2.37it/s][Astep: 60
extend+tolist() time: 0.0007197856903076172

Evaluating:  27%|██▋       | 61/228 [00:26<01:08,  2.44it/s][Astep: 61
extend+tolist() time: 0.0012314319610595703

Evaluating:  27%|██▋       | 62/228 [00:27<01:08,  2.42it/s][Astep: 62
extend+tolist() time: 0.0007691383361816406

Evaluating:  28%|██▊       | 63/228 [00:27<01:07,  2.46it/s][Astep: 63
extend+tolist() time: 0.001218557357788086

Evaluating:  28%|██▊       | 64/228 [00:27<01:05,  2.51it/s][Astep: 64
extend+tolist() time: 0.001146554946899414

Evaluating:  29%|██▊       | 65/228 [00:28<01:07,  2.42it/s][Astep: 65
extend+tolist() time: 0.0007846355438232422

Evaluating:  29%|██▉       | 66/228 [00:28<01:05,  2.47it/s][Astep: 66
extend+tolist() time: 0.0011553764343261719

Evaluating:  29%|██▉       | 67/228 [00:29<01:05,  2.45it/s][Astep: 67
extend+tolist() time: 0.0008943080902099609

Evaluating:  30%|██▉       | 68/228 [00:29<01:04,  2.48it/s][Astep: 68
extend+tolist() time: 0.001062631607055664

Evaluating:  30%|███       | 69/228 [00:29<01:02,  2.54it/s][Astep: 69
extend+tolist() time: 0.0011060237884521484

Evaluating:  31%|███       | 70/228 [00:30<01:04,  2.45it/s][Astep: 70
extend+tolist() time: 0.0015044212341308594

Evaluating:  31%|███       | 71/228 [00:30<01:02,  2.49it/s][Astep: 71
extend+tolist() time: 0.001323699951171875

Evaluating:  32%|███▏      | 72/228 [00:31<01:03,  2.45it/s][Astep: 72
extend+tolist() time: 0.0007450580596923828

Evaluating:  32%|███▏      | 73/228 [00:31<01:02,  2.49it/s][Astep: 73
extend+tolist() time: 0.0005288124084472656

Evaluating:  32%|███▏      | 74/228 [00:32<01:10,  2.18it/s][Astep: 74
extend+tolist() time: 0.20775675773620605

Evaluating:  33%|███▎      | 75/228 [00:32<01:16,  2.00it/s][Astep: 75
extend+tolist() time: 0.0016875267028808594

Evaluating:  33%|███▎      | 76/228 [00:33<01:14,  2.03it/s][Astep: 76
extend+tolist() time: 0.0006430149078369141

Evaluating:  34%|███▍      | 77/228 [00:33<01:09,  2.16it/s][Astep: 77
extend+tolist() time: 0.001779794692993164

Evaluating:  34%|███▍      | 78/228 [00:34<01:15,  1.98it/s][Astep: 78
extend+tolist() time: 0.0011751651763916016

Evaluating:  35%|███▍      | 79/228 [00:34<01:10,  2.11it/s][Astep: 79
extend+tolist() time: 0.0012187957763671875

Evaluating:  35%|███▌      | 80/228 [00:34<01:06,  2.21it/s][Astep: 80
extend+tolist() time: 0.0009071826934814453

Evaluating:  36%|███▌      | 81/228 [00:35<01:06,  2.22it/s][Astep: 81
extend+tolist() time: 0.0012011528015136719

Evaluating:  36%|███▌      | 82/228 [00:35<01:03,  2.32it/s][Astep: 82
extend+tolist() time: 0.0008232593536376953

Evaluating:  36%|███▋      | 83/228 [00:36<01:02,  2.33it/s][Astep: 83
extend+tolist() time: 0.001146078109741211

Evaluating:  37%|███▋      | 84/228 [00:36<01:00,  2.37it/s][Astep: 84
extend+tolist() time: 0.0010128021240234375

Evaluating:  37%|███▋      | 85/228 [00:36<00:58,  2.43it/s][Astep: 85
extend+tolist() time: 0.001355886459350586

Evaluating:  38%|███▊      | 86/228 [00:37<00:59,  2.39it/s][Astep: 86
extend+tolist() time: 0.0012192726135253906

Evaluating:  38%|███▊      | 87/228 [00:37<00:57,  2.44it/s][Astep: 87
extend+tolist() time: 0.0008611679077148438

Evaluating:  39%|███▊      | 88/228 [00:38<00:57,  2.42it/s][Astep: 88
extend+tolist() time: 0.0011625289916992188

Evaluating:  39%|███▉      | 89/228 [00:38<00:56,  2.44it/s][Astep: 89
extend+tolist() time: 0.0007731914520263672

Evaluating:  39%|███▉      | 90/228 [00:39<00:55,  2.49it/s][Astep: 90
extend+tolist() time: 0.0013492107391357422

Evaluating:  40%|███▉      | 91/228 [00:39<00:56,  2.43it/s][Astep: 91
extend+tolist() time: 0.0007483959197998047

Evaluating:  40%|████      | 92/228 [00:39<00:54,  2.48it/s][Astep: 92
extend+tolist() time: 0.0012178421020507812

Evaluating:  41%|████      | 93/228 [00:40<00:55,  2.43it/s][Astep: 93
extend+tolist() time: 0.0009593963623046875

Evaluating:  41%|████      | 94/228 [00:40<00:55,  2.43it/s][Astep: 94
extend+tolist() time: 0.0011332035064697266

Evaluating:  42%|████▏     | 95/228 [00:41<00:53,  2.48it/s][Astep: 95
extend+tolist() time: 0.0015232563018798828

Evaluating:  42%|████▏     | 96/228 [00:41<00:55,  2.38it/s][Astep: 96
extend+tolist() time: 0.0011036396026611328

Evaluating:  43%|████▎     | 97/228 [00:42<01:04,  2.04it/s][Astep: 97
extend+tolist() time: 0.001224517822265625

Evaluating:  43%|████▎     | 98/228 [00:42<01:00,  2.15it/s][Astep: 98
extend+tolist() time: 0.00089263916015625

Evaluating:  43%|████▎     | 99/228 [00:42<00:57,  2.24it/s][Astep: 99
extend+tolist() time: 0.0012905597686767578

Evaluating:  44%|████▍     | 100/228 [00:43<00:57,  2.24it/s][Astep: 100
extend+tolist() time: 0.0007202625274658203

Evaluating:  44%|████▍     | 101/228 [00:43<00:54,  2.32it/s][Astep: 101
extend+tolist() time: 0.0012536048889160156

Evaluating:  45%|████▍     | 102/228 [00:44<00:54,  2.33it/s][Astep: 102
extend+tolist() time: 0.0007092952728271484

Evaluating:  45%|████▌     | 103/228 [00:44<00:52,  2.37it/s][Astep: 103
extend+tolist() time: 0.001178741455078125

Evaluating:  46%|████▌     | 104/228 [00:45<00:51,  2.43it/s][Astep: 104
extend+tolist() time: 0.0006949901580810547

Evaluating:  46%|████▌     | 105/228 [00:45<00:51,  2.38it/s][Astep: 105
extend+tolist() time: 0.001230001449584961

Evaluating:  46%|████▋     | 106/228 [00:45<00:50,  2.43it/s][Astep: 106
extend+tolist() time: 0.0016891956329345703

Evaluating:  47%|████▋     | 107/228 [00:46<00:51,  2.37it/s][Astep: 107
extend+tolist() time: 0.0007627010345458984

Evaluating:  47%|████▋     | 108/228 [00:46<00:50,  2.40it/s][Astep: 108
extend+tolist() time: 0.0012030601501464844

Evaluating:  48%|████▊     | 109/228 [00:47<00:48,  2.45it/s][Astep: 109
extend+tolist() time: 0.0008215904235839844

Evaluating:  48%|████▊     | 110/228 [00:47<00:49,  2.37it/s][Astep: 110
extend+tolist() time: 0.0010254383087158203

Evaluating:  49%|████▊     | 111/228 [00:47<00:48,  2.42it/s][Astep: 111
extend+tolist() time: 0.0013880729675292969

Evaluating:  49%|████▉     | 112/228 [00:48<00:49,  2.36it/s][Astep: 112
extend+tolist() time: 0.0008730888366699219

Evaluating:  50%|████▉     | 113/228 [00:48<00:48,  2.39it/s][Astep: 113
extend+tolist() time: 0.00069427490234375

Evaluating:  50%|█████     | 114/228 [00:49<00:46,  2.43it/s][Astep: 114
extend+tolist() time: 0.0015251636505126953

Evaluating:  50%|█████     | 115/228 [00:49<00:47,  2.36it/s][Astep: 115
extend+tolist() time: 0.0006468296051025391

Evaluating:  51%|█████     | 116/228 [00:50<00:46,  2.41it/s][Astep: 116
extend+tolist() time: 0.0012650489807128906

Evaluating:  51%|█████▏    | 117/228 [00:50<00:46,  2.38it/s][Astep: 117
extend+tolist() time: 0.0008685588836669922

Evaluating:  52%|█████▏    | 118/228 [00:50<00:46,  2.38it/s][Astep: 118
extend+tolist() time: 0.001245260238647461

Evaluating:  52%|█████▏    | 119/228 [00:51<00:45,  2.42it/s][Astep: 119
extend+tolist() time: 0.0007152557373046875

Evaluating:  53%|█████▎    | 120/228 [00:51<00:45,  2.39it/s][Astep: 120
extend+tolist() time: 0.000640869140625

Evaluating:  53%|█████▎    | 121/228 [00:52<00:44,  2.41it/s][Astep: 121
extend+tolist() time: 0.0011096000671386719

Evaluating:  54%|█████▎    | 122/228 [00:52<00:45,  2.35it/s][Astep: 122
extend+tolist() time: 0.0006847381591796875

Evaluating:  54%|█████▍    | 123/228 [00:53<00:50,  2.06it/s][Astep: 123
extend+tolist() time: 0.25411272048950195

Evaluating:  54%|█████▍    | 124/228 [00:53<00:56,  1.83it/s][Astep: 124
extend+tolist() time: 0.0008122920989990234

Evaluating:  55%|█████▍    | 125/228 [00:54<00:52,  1.97it/s][Astep: 125
extend+tolist() time: 0.0007824897766113281

Evaluating:  55%|█████▌    | 126/228 [00:54<00:49,  2.06it/s][Astep: 126
extend+tolist() time: 0.0016379356384277344

Evaluating:  56%|█████▌    | 127/228 [00:55<00:47,  2.15it/s][Astep: 127
extend+tolist() time: 0.0012922286987304688

Evaluating:  56%|█████▌    | 128/228 [00:55<00:46,  2.15it/s][Astep: 128
extend+tolist() time: 0.0011641979217529297

Evaluating:  57%|█████▋    | 129/228 [00:56<00:49,  2.00it/s][Astep: 129
extend+tolist() time: 0.0007817745208740234

Evaluating:  57%|█████▋    | 130/228 [00:56<00:47,  2.06it/s][Astep: 130
extend+tolist() time: 0.0012950897216796875

Evaluating:  57%|█████▋    | 131/228 [00:57<00:44,  2.16it/s][Astep: 131
extend+tolist() time: 0.00044798851013183594

Evaluating:  58%|█████▊    | 132/228 [00:57<00:43,  2.22it/s][Astep: 132
extend+tolist() time: 0.001445770263671875

Evaluating:  58%|█████▊    | 133/228 [00:57<00:41,  2.27it/s][Astep: 133
extend+tolist() time: 0.0004265308380126953

Evaluating:  59%|█████▉    | 134/228 [00:58<00:40,  2.34it/s][Astep: 134
extend+tolist() time: 0.0013573169708251953

Evaluating:  59%|█████▉    | 135/228 [00:58<00:40,  2.30it/s][Astep: 135
extend+tolist() time: 0.00041747093200683594

Evaluating:  60%|█████▉    | 136/228 [00:59<00:38,  2.38it/s][Astep: 136
extend+tolist() time: 0.0011844635009765625

Evaluating:  60%|██████    | 137/228 [00:59<00:38,  2.36it/s][Astep: 137
extend+tolist() time: 0.0003972053527832031

Evaluating:  61%|██████    | 138/228 [01:00<00:37,  2.39it/s][Astep: 138
extend+tolist() time: 0.0006799697875976562

Evaluating:  61%|██████    | 139/228 [01:00<00:36,  2.44it/s][Astep: 139
extend+tolist() time: 0.0009274482727050781

Evaluating:  61%|██████▏   | 140/228 [01:00<00:36,  2.40it/s][Astep: 140
extend+tolist() time: 0.0008831024169921875

Evaluating:  62%|██████▏   | 141/228 [01:01<00:35,  2.46it/s][Astep: 141
extend+tolist() time: 0.0012450218200683594

Evaluating:  62%|██████▏   | 142/228 [01:01<00:35,  2.43it/s][Astep: 142
extend+tolist() time: 0.0006155967712402344

Evaluating:  63%|██████▎   | 143/228 [01:02<00:34,  2.46it/s][Astep: 143
extend+tolist() time: 0.0003552436828613281

Evaluating:  63%|██████▎   | 144/228 [01:02<00:33,  2.50it/s][Astep: 144
extend+tolist() time: 0.0008072853088378906

Evaluating:  64%|██████▎   | 145/228 [01:02<00:34,  2.41it/s][Astep: 145
extend+tolist() time: 0.0009539127349853516

Evaluating:  64%|██████▍   | 146/228 [01:03<00:33,  2.46it/s][Astep: 146
extend+tolist() time: 0.00045609474182128906

Evaluating:  64%|██████▍   | 147/228 [01:03<00:33,  2.43it/s][Astep: 147
extend+tolist() time: 0.0008058547973632812

Evaluating:  65%|██████▍   | 148/228 [01:04<00:32,  2.45it/s][Astep: 148
extend+tolist() time: 0.0012104511260986328

Evaluating:  65%|██████▌   | 149/228 [01:04<00:31,  2.49it/s][Astep: 149
extend+tolist() time: 0.00039505958557128906

Evaluating:  66%|██████▌   | 150/228 [01:04<00:32,  2.41it/s][Astep: 150
extend+tolist() time: 0.0009179115295410156

Evaluating:  66%|██████▌   | 151/228 [01:05<00:31,  2.43it/s][Astep: 151
extend+tolist() time: 0.0010752677917480469

Evaluating:  67%|██████▋   | 152/228 [01:05<00:31,  2.38it/s][Astep: 152
extend+tolist() time: 0.0009012222290039062

Evaluating:  67%|██████▋   | 153/228 [01:06<00:31,  2.42it/s][Astep: 153
extend+tolist() time: 0.0016524791717529297

Evaluating:  68%|██████▊   | 154/228 [01:06<00:31,  2.37it/s][Astep: 154
extend+tolist() time: 0.0020470619201660156

Evaluating:  68%|██████▊   | 155/228 [01:07<00:30,  2.37it/s][Astep: 155
extend+tolist() time: 0.0006840229034423828

Evaluating:  68%|██████▊   | 156/228 [01:07<00:29,  2.43it/s][Astep: 156
extend+tolist() time: 0.000629425048828125

Evaluating:  69%|██████▉   | 157/228 [01:07<00:29,  2.40it/s][Astep: 157
extend+tolist() time: 0.0011205673217773438

Evaluating:  69%|██████▉   | 158/228 [01:08<00:28,  2.46it/s][Astep: 158
extend+tolist() time: 0.0005209445953369141

Evaluating:  70%|██████▉   | 159/228 [01:08<00:28,  2.44it/s][Astep: 159
extend+tolist() time: 0.000751495361328125

Evaluating:  70%|███████   | 160/228 [01:09<00:27,  2.46it/s][Astep: 160
extend+tolist() time: 0.0008111000061035156

Evaluating:  71%|███████   | 161/228 [01:09<00:26,  2.51it/s][Astep: 161
extend+tolist() time: 0.0008559226989746094

Evaluating:  71%|███████   | 162/228 [01:10<00:30,  2.15it/s][Astep: 162
extend+tolist() time: 0.0005142688751220703

Evaluating:  71%|███████▏  | 163/228 [01:10<00:28,  2.27it/s][Astep: 163
extend+tolist() time: 0.0008318424224853516

Evaluating:  72%|███████▏  | 164/228 [01:10<00:27,  2.29it/s][Astep: 164
extend+tolist() time: 0.0006024837493896484

Evaluating:  72%|███████▏  | 165/228 [01:11<00:26,  2.34it/s][Astep: 165
extend+tolist() time: 0.0006549358367919922

Evaluating:  73%|███████▎  | 166/228 [01:11<00:26,  2.37it/s][Astep: 166
extend+tolist() time: 0.0004515647888183594

Evaluating:  73%|███████▎  | 167/228 [01:12<00:25,  2.40it/s][Astep: 167
extend+tolist() time: 0.0012090206146240234

Evaluating:  74%|███████▎  | 168/228 [01:12<00:24,  2.48it/s][Astep: 168
extend+tolist() time: 0.001234292984008789

Evaluating:  74%|███████▍  | 169/228 [01:12<00:24,  2.42it/s][Astep: 169
extend+tolist() time: 0.0003941059112548828

Evaluating:  75%|███████▍  | 170/228 [01:13<00:23,  2.47it/s][Astep: 170
extend+tolist() time: 0.0013766288757324219

Evaluating:  75%|███████▌  | 171/228 [01:13<00:22,  2.52it/s][Astep: 171
extend+tolist() time: 0.000316619873046875

Evaluating:  75%|███████▌  | 172/228 [01:14<00:22,  2.46it/s][Astep: 172
extend+tolist() time: 0.0008141994476318359

Evaluating:  76%|███████▌  | 173/228 [01:14<00:21,  2.52it/s][Astep: 173
extend+tolist() time: 0.0016319751739501953

Evaluating:  76%|███████▋  | 174/228 [01:14<00:22,  2.45it/s][Astep: 174
extend+tolist() time: 0.0018393993377685547

Evaluating:  77%|███████▋  | 175/228 [01:15<00:21,  2.43it/s][Astep: 175
extend+tolist() time: 0.0008175373077392578

Evaluating:  77%|███████▋  | 176/228 [01:15<00:20,  2.49it/s][Astep: 176
extend+tolist() time: 0.0010533332824707031

Evaluating:  78%|███████▊  | 177/228 [01:16<00:21,  2.42it/s][Astep: 177
extend+tolist() time: 0.0005664825439453125

Evaluating:  78%|███████▊  | 178/228 [01:16<00:20,  2.49it/s][Astep: 178
extend+tolist() time: 0.001669168472290039

Evaluating:  79%|███████▊  | 179/228 [01:16<00:20,  2.41it/s][Astep: 179
extend+tolist() time: 0.0004210472106933594

Evaluating:  79%|███████▉  | 180/228 [01:17<00:19,  2.44it/s][Astep: 180
extend+tolist() time: 0.0003819465637207031

Evaluating:  79%|███████▉  | 181/228 [01:17<00:18,  2.50it/s][Astep: 181
extend+tolist() time: 0.0006232261657714844

Evaluating:  80%|███████▉  | 182/228 [01:18<00:18,  2.43it/s][Astep: 182
extend+tolist() time: 0.0012061595916748047

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.48it/s][Astep: 183
extend+tolist() time: 0.0006697177886962891

Evaluating:  81%|████████  | 184/228 [01:18<00:18,  2.43it/s][Astep: 184
extend+tolist() time: 0.00047206878662109375

Evaluating:  81%|████████  | 185/228 [01:19<00:17,  2.46it/s][Astep: 185
extend+tolist() time: 0.0015208721160888672

Evaluating:  82%|████████▏ | 186/228 [01:19<00:16,  2.49it/s][Astep: 186
extend+tolist() time: 0.0014071464538574219

Evaluating:  82%|████████▏ | 187/228 [01:20<00:17,  2.40it/s][Astep: 187
extend+tolist() time: 0.00045871734619140625

Evaluating:  82%|████████▏ | 188/228 [01:20<00:16,  2.46it/s][Astep: 188
extend+tolist() time: 0.000720977783203125

Evaluating:  83%|████████▎ | 189/228 [01:20<00:16,  2.43it/s][Astep: 189
extend+tolist() time: 0.0003514289855957031

Evaluating:  83%|████████▎ | 190/228 [01:21<00:15,  2.45it/s][Astep: 190
extend+tolist() time: 0.00206756591796875

Evaluating:  84%|████████▍ | 191/228 [01:21<00:15,  2.45it/s][Astep: 191
extend+tolist() time: 0.0007381439208984375

Evaluating:  84%|████████▍ | 192/228 [01:22<00:14,  2.41it/s][Astep: 192
extend+tolist() time: 0.0008139610290527344

Evaluating:  85%|████████▍ | 193/228 [01:22<00:14,  2.47it/s][Astep: 193
extend+tolist() time: 0.0010380744934082031

Evaluating:  85%|████████▌ | 194/228 [01:23<00:14,  2.42it/s][Astep: 194
extend+tolist() time: 0.0010037422180175781

Evaluating:  86%|████████▌ | 195/228 [01:23<00:13,  2.45it/s][Astep: 195
extend+tolist() time: 0.0005311965942382812

Evaluating:  86%|████████▌ | 196/228 [01:23<00:12,  2.52it/s][Astep: 196
extend+tolist() time: 0.0006234645843505859

Evaluating:  86%|████████▋ | 197/228 [01:24<00:12,  2.44it/s][Astep: 197
extend+tolist() time: 0.0010538101196289062

Evaluating:  87%|████████▋ | 198/228 [01:24<00:11,  2.51it/s][Astep: 198
extend+tolist() time: 0.0006322860717773438

Evaluating:  87%|████████▋ | 199/228 [01:25<00:11,  2.47it/s][Astep: 199
extend+tolist() time: 0.0018873214721679688

Evaluating:  88%|████████▊ | 200/228 [01:25<00:11,  2.46it/s][Astep: 200
extend+tolist() time: 0.0007026195526123047

Evaluating:  88%|████████▊ | 201/228 [01:25<00:10,  2.52it/s][Astep: 201
extend+tolist() time: 0.0006237030029296875

Evaluating:  89%|████████▊ | 202/228 [01:26<00:10,  2.44it/s][Astep: 202
extend+tolist() time: 0.0008225440979003906

Evaluating:  89%|████████▉ | 203/228 [01:26<00:09,  2.50it/s][Astep: 203
extend+tolist() time: 0.0005071163177490234

Evaluating:  89%|████████▉ | 204/228 [01:27<00:09,  2.47it/s][Astep: 204
extend+tolist() time: 0.0004055500030517578

Evaluating:  90%|████████▉ | 205/228 [01:27<00:09,  2.50it/s][Astep: 205
extend+tolist() time: 0.0002961158752441406

Evaluating:  90%|█████████ | 206/228 [01:27<00:08,  2.56it/s][Astep: 206
extend+tolist() time: 0.0006079673767089844

Evaluating:  91%|█████████ | 207/228 [01:28<00:08,  2.46it/s][Astep: 207
extend+tolist() time: 0.00107574462890625

Evaluating:  91%|█████████ | 208/228 [01:28<00:07,  2.51it/s][Astep: 208
extend+tolist() time: 0.0007116794586181641

Evaluating:  92%|█████████▏| 209/228 [01:29<00:09,  2.04it/s][Astep: 209
extend+tolist() time: 0.0006146430969238281

Evaluating:  92%|█████████▏| 210/228 [01:29<00:08,  2.19it/s][Astep: 210
extend+tolist() time: 0.2830467224121094

Evaluating:  93%|█████████▎| 211/228 [01:30<00:09,  1.87it/s][Astep: 211
extend+tolist() time: 0.0015397071838378906

Evaluating:  93%|█████████▎| 212/228 [01:30<00:07,  2.01it/s][Astep: 212
extend+tolist() time: 0.0009288787841796875

Evaluating:  93%|█████████▎| 213/228 [01:31<00:07,  2.07it/s][Astep: 213
extend+tolist() time: 0.00107574462890625

Evaluating:  94%|█████████▍| 214/228 [01:31<00:06,  2.19it/s][Astep: 214
extend+tolist() time: 0.0008585453033447266

Evaluating:  94%|█████████▍| 215/228 [01:32<00:05,  2.21it/s][Astep: 215
extend+tolist() time: 0.0010461807250976562

Evaluating:  95%|█████████▍| 216/228 [01:32<00:05,  2.28it/s][Astep: 216
extend+tolist() time: 0.0005800724029541016

Evaluating:  95%|█████████▌| 217/228 [01:33<00:05,  1.94it/s][Astep: 217
extend+tolist() time: 0.000579833984375

Evaluating:  96%|█████████▌| 218/228 [01:33<00:04,  2.10it/s][Astep: 218
extend+tolist() time: 0.0014657974243164062

Evaluating:  96%|█████████▌| 219/228 [01:34<00:04,  2.20it/s][Astep: 219
extend+tolist() time: 0.0005109310150146484

Evaluating:  96%|█████████▋| 220/228 [01:34<00:03,  2.26it/s][Astep: 220
extend+tolist() time: 0.0004208087921142578

Evaluating:  97%|█████████▋| 221/228 [01:34<00:02,  2.36it/s][Astep: 221
extend+tolist() time: 0.0010769367218017578

Evaluating:  97%|█████████▋| 222/228 [01:35<00:02,  2.31it/s][Astep: 222
extend+tolist() time: 0.0004582405090332031

Evaluating:  98%|█████████▊| 223/228 [01:35<00:02,  2.39it/s][Astep: 223
extend+tolist() time: 0.0004241466522216797

Evaluating:  98%|█████████▊| 224/228 [01:36<00:01,  2.41it/s][Astep: 224
extend+tolist() time: 0.00039958953857421875

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.40it/s][Astep: 225
extend+tolist() time: 0.0004596710205078125

Evaluating:  99%|█████████▉| 226/228 [01:36<00:00,  2.45it/s][Astep: 226
extend+tolist() time: 0.0009903907775878906

Evaluating: 100%|█████████▉| 227/228 [01:37<00:00,  2.40it/s][Astep: 227
extend+tolist() time: 0.0004868507385253906

Evaluating: 100%|██████████| 228/228 [01:37<00:00,  2.41it/s][A09/08/2023 22:56:45 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 22:56:45 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:56:45 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:56:45 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:56:45 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 22:56:45 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:56:45 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:56:46 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:56:46 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 22:56:46 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:56:46 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:56:46 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:56:46 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 22:56:46 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:56:46 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:56:46 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 22:56:47 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:39<00:00,  2.29it/s]
09/08/2023 22:56:47 - INFO - __main__ -   Step: 1540, Validation Metrics: {'pred_1_num': 9289, 'pred_-1_num': 1213, 'pred_0_num': 299, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7709471345245811, 'f1_micro': 0.7709471345245811, 'f1_macro': 0.46019480540341906, 'f1_weighted': 0.751465318933796, 'f1_-1': 0.36703850305865415, 'f1_0': 0.1471215351812367, 'f1_1': 0.8664243779703663, 'precision_micro': 0.7709471345245811, 'precision_macro': 0.49510642107360275, 'precision_weighted': 0.7384357023768567, 'precision_-1': 0.42044517724649627, 'precision_0': 0.23076923076923078, 'precision_1': 0.8341048552050813, 'recall_micro': 0.7709471345245811, 'recall_macro': 0.4450003945363161, 'recall_weighted': 0.7709471345245811, 'recall_-1': 0.32567049808429116, 'recall_0': 0.107981220657277, 'recall_1': 0.9013494648673802, 'roc_auc_micro': 0.8857867937197261, 'roc_auc_macro': 0.7161472603196262, 'roc_auc_weighted': 0.6819784925053617, 'roc_auc_-1': 0.7577792091140858, 'roc_auc_0': 0.7257468909765092, 'roc_auc_1': 0.6649156808682833}
[2023-09-08 22:57:07,605] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1541/66600 [1:34:17<917:39:54, 50.78s/it]09/08/2023 22:57:07 - INFO - __main__ -   Step: 1541, LR: 1.5431217924646392e-05, Loss: 0.4311280846595764
[2023-09-08 22:57:27,759] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1542/66600 [1:34:37<751:37:17, 41.59s/it]09/08/2023 22:57:27 - INFO - __main__ -   Step: 1542, LR: 1.544123169357867e-05, Loss: 0.43110567331314087
[2023-09-08 22:57:48,400] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1543/66600 [1:34:57<638:01:51, 35.31s/it]09/08/2023 22:57:48 - INFO - __main__ -   Step: 1543, LR: 1.5451245462510952e-05, Loss: 0.5360026955604553
[2023-09-08 22:58:08,905] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1544/66600 [1:35:18<557:46:46, 30.87s/it]09/08/2023 22:58:08 - INFO - __main__ -   Step: 1544, LR: 1.5461259231443237e-05, Loss: 0.47287407517433167
[2023-09-08 22:58:29,584] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1545/66600 [1:35:39<502:32:38, 27.81s/it]09/08/2023 22:58:29 - INFO - __main__ -   Step: 1545, LR: 1.547127300037552e-05, Loss: 0.3267114460468292
[2023-09-08 22:58:50,481] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1546/66600 [1:36:00<465:03:47, 25.74s/it]09/08/2023 22:58:50 - INFO - __main__ -   Step: 1546, LR: 1.54812867693078e-05, Loss: 0.37514883279800415
[2023-09-08 22:59:11,468] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1547/66600 [1:36:21<439:18:37, 24.31s/it]09/08/2023 22:59:11 - INFO - __main__ -   Step: 1547, LR: 1.549130053824008e-05, Loss: 0.3826705515384674
[2023-09-08 22:59:32,026] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1548/66600 [1:36:41<418:57:31, 23.19s/it]09/08/2023 22:59:32 - INFO - __main__ -   Step: 1548, LR: 1.5501314307172363e-05, Loss: 0.4021414816379547
[2023-09-08 22:59:52,372] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1549/66600 [1:37:01<403:33:43, 22.33s/it]09/08/2023 22:59:52 - INFO - __main__ -   Step: 1549, LR: 1.5511328076104645e-05, Loss: 0.3970046937465668
[2023-09-08 23:00:13,386] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1550/66600 [1:37:22<396:23:48, 21.94s/it]09/08/2023 23:00:13 - INFO - __main__ -   Step: 1550, LR: 1.5521341845036926e-05, Loss: 0.3799781799316406
[2023-09-08 23:00:34,314] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1551/66600 [1:37:43<390:55:19, 21.63s/it]09/08/2023 23:00:34 - INFO - __main__ -   Step: 1551, LR: 1.5531355613969208e-05, Loss: 0.4054678678512573
[2023-09-08 23:00:55,724] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1552/66600 [1:38:05<389:41:53, 21.57s/it]09/08/2023 23:00:55 - INFO - __main__ -   Step: 1552, LR: 1.554136938290149e-05, Loss: 0.365195095539093
[2023-09-08 23:01:16,830] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1553/66600 [1:38:26<387:11:38, 21.43s/it]09/08/2023 23:01:16 - INFO - __main__ -   Step: 1553, LR: 1.555138315183377e-05, Loss: 0.47189146280288696
[2023-09-08 23:01:37,554] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1554/66600 [1:38:47<383:21:48, 21.22s/it]09/08/2023 23:01:37 - INFO - __main__ -   Step: 1554, LR: 1.5561396920766053e-05, Loss: 0.4419873356819153
[2023-09-08 23:01:58,910] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1555/66600 [1:39:08<384:06:20, 21.26s/it]09/08/2023 23:01:58 - INFO - __main__ -   Step: 1555, LR: 1.5571410689698338e-05, Loss: 0.42356017231941223
[2023-09-08 23:02:19,968] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1556/66600 [1:39:29<383:00:52, 21.20s/it]09/08/2023 23:02:19 - INFO - __main__ -   Step: 1556, LR: 1.558142445863062e-05, Loss: 0.39222803711891174
[2023-09-08 23:02:40,494] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1557/66600 [1:39:50<379:21:37, 21.00s/it]09/08/2023 23:02:40 - INFO - __main__ -   Step: 1557, LR: 1.55914382275629e-05, Loss: 0.5009456872940063
[2023-09-08 23:03:01,283] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1558/66600 [1:40:10<378:13:37, 20.93s/it]09/08/2023 23:03:01 - INFO - __main__ -   Step: 1558, LR: 1.5601451996495183e-05, Loss: 0.39496463537216187
[2023-09-08 23:03:21,526] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1559/66600 [1:40:31<374:28:29, 20.73s/it]09/08/2023 23:03:21 - INFO - __main__ -   Step: 1559, LR: 1.5611465765427464e-05, Loss: 0.42052921652793884
[2023-09-08 23:03:41,783] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1560/66600 [1:40:51<371:55:16, 20.59s/it]09/08/2023 23:03:41 - INFO - __main__ -   Step: 1560, LR: 1.5621479534359746e-05, Loss: 0.38183334469795227
09/08/2023 23:03:41 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0024793148040771484

Evaluating:   0%|          | 1/228 [00:00<01:57,  1.94it/s][Astep: 1
extend+tolist() time: 0.0010859966278076172

Evaluating:   1%|          | 2/228 [00:00<01:45,  2.14it/s][Astep: 2
extend+tolist() time: 0.0021805763244628906

Evaluating:   1%|▏         | 3/228 [00:01<01:39,  2.25it/s][Astep: 3
extend+tolist() time: 0.0019898414611816406

Evaluating:   2%|▏         | 4/228 [00:01<01:50,  2.02it/s][Astep: 4
extend+tolist() time: 0.0015025138854980469

Evaluating:   2%|▏         | 5/228 [00:02<01:42,  2.17it/s][Astep: 5
extend+tolist() time: 0.0020208358764648438

Evaluating:   3%|▎         | 6/228 [00:02<01:38,  2.25it/s][Astep: 6
extend+tolist() time: 0.0018646717071533203

Evaluating:   3%|▎         | 7/228 [00:03<01:38,  2.25it/s][Astep: 7
extend+tolist() time: 0.0009591579437255859

Evaluating:   4%|▎         | 8/228 [00:03<01:34,  2.33it/s][Astep: 8
extend+tolist() time: 0.0012009143829345703

Evaluating:   4%|▍         | 9/228 [00:04<01:33,  2.34it/s][Astep: 9
extend+tolist() time: 0.0007905960083007812

Evaluating:   4%|▍         | 10/228 [00:04<01:30,  2.40it/s][Astep: 10
extend+tolist() time: 0.0012638568878173828

Evaluating:   5%|▍         | 11/228 [00:04<01:28,  2.44it/s][Astep: 11
extend+tolist() time: 0.0005600452423095703

Evaluating:   5%|▌         | 12/228 [00:05<01:29,  2.42it/s][Astep: 12
extend+tolist() time: 0.000659942626953125

Evaluating:   6%|▌         | 13/228 [00:05<01:27,  2.46it/s][Astep: 13
extend+tolist() time: 0.00103759765625

Evaluating:   6%|▌         | 14/228 [00:06<01:28,  2.41it/s][Astep: 14
extend+tolist() time: 0.0005447864532470703

Evaluating:   7%|▋         | 15/228 [00:06<01:26,  2.45it/s][Astep: 15
extend+tolist() time: 0.0005965232849121094

Evaluating:   7%|▋         | 16/228 [00:06<01:25,  2.48it/s][Astep: 16
extend+tolist() time: 0.001064300537109375

Evaluating:   7%|▋         | 17/228 [00:07<01:26,  2.43it/s][Astep: 17
extend+tolist() time: 0.0008647441864013672

Evaluating:   8%|▊         | 18/228 [00:07<01:37,  2.16it/s][Astep: 18
extend+tolist() time: 0.18988823890686035

Evaluating:   8%|▊         | 19/228 [00:08<01:47,  1.95it/s][Astep: 19
extend+tolist() time: 0.0017232894897460938

Evaluating:   9%|▉         | 20/228 [00:08<01:42,  2.03it/s][Astep: 20
extend+tolist() time: 0.0007550716400146484

Evaluating:   9%|▉         | 21/228 [00:09<01:37,  2.12it/s][Astep: 21
extend+tolist() time: 0.0010645389556884766

Evaluating:  10%|▉         | 22/228 [00:09<01:33,  2.21it/s][Astep: 22
extend+tolist() time: 0.0007479190826416016

Evaluating:  10%|█         | 23/228 [00:10<01:32,  2.22it/s][Astep: 23
extend+tolist() time: 0.0010867118835449219

Evaluating:  11%|█         | 24/228 [00:10<01:28,  2.29it/s][Astep: 24
extend+tolist() time: 0.001489400863647461

Evaluating:  11%|█         | 25/228 [00:11<01:29,  2.26it/s][Astep: 25
extend+tolist() time: 0.0018072128295898438

Evaluating:  11%|█▏        | 26/228 [00:11<01:28,  2.29it/s][Astep: 26
extend+tolist() time: 0.0007669925689697266

Evaluating:  12%|█▏        | 27/228 [00:12<01:37,  2.07it/s][Astep: 27
extend+tolist() time: 0.0017724037170410156

Evaluating:  12%|█▏        | 28/228 [00:12<01:32,  2.16it/s][Astep: 28
extend+tolist() time: 0.0003376007080078125

Evaluating:  13%|█▎        | 29/228 [00:12<01:28,  2.26it/s][Astep: 29
extend+tolist() time: 0.0010700225830078125

Evaluating:  13%|█▎        | 30/228 [00:13<01:27,  2.27it/s][Astep: 30
extend+tolist() time: 0.0010838508605957031

Evaluating:  14%|█▎        | 31/228 [00:13<01:24,  2.33it/s][Astep: 31
extend+tolist() time: 0.001035451889038086

Evaluating:  14%|█▍        | 32/228 [00:14<01:24,  2.32it/s][Astep: 32
extend+tolist() time: 0.0009789466857910156

Evaluating:  14%|█▍        | 33/228 [00:14<01:23,  2.35it/s][Astep: 33
extend+tolist() time: 0.0017642974853515625

Evaluating:  15%|█▍        | 34/228 [00:15<01:33,  2.08it/s][Astep: 34
extend+tolist() time: 0.001256704330444336

Evaluating:  15%|█▌        | 35/228 [00:15<01:28,  2.19it/s][Astep: 35
extend+tolist() time: 0.0006616115570068359

Evaluating:  16%|█▌        | 36/228 [00:15<01:23,  2.30it/s][Astep: 36
extend+tolist() time: 0.0011413097381591797

Evaluating:  16%|█▌        | 37/228 [00:16<01:23,  2.30it/s][Astep: 37
extend+tolist() time: 0.001241445541381836

Evaluating:  17%|█▋        | 38/228 [00:16<01:21,  2.34it/s][Astep: 38
extend+tolist() time: 0.0012445449829101562

Evaluating:  17%|█▋        | 39/228 [00:17<01:21,  2.31it/s][Astep: 39
extend+tolist() time: 0.0007450580596923828

Evaluating:  18%|█▊        | 40/228 [00:17<01:19,  2.36it/s][Astep: 40
extend+tolist() time: 0.0012865066528320312

Evaluating:  18%|█▊        | 41/228 [00:18<01:19,  2.35it/s][Astep: 41
extend+tolist() time: 0.0008571147918701172

Evaluating:  18%|█▊        | 42/228 [00:18<01:17,  2.40it/s][Astep: 42
extend+tolist() time: 0.0015902519226074219

Evaluating:  19%|█▉        | 43/228 [00:18<01:16,  2.42it/s][Astep: 43
extend+tolist() time: 0.0018169879913330078

Evaluating:  19%|█▉        | 44/228 [00:19<01:17,  2.36it/s][Astep: 44
extend+tolist() time: 0.0007579326629638672

Evaluating:  20%|█▉        | 45/228 [00:19<01:16,  2.40it/s][Astep: 45
extend+tolist() time: 0.0016353130340576172

Evaluating:  20%|██        | 46/228 [00:20<01:17,  2.35it/s][Astep: 46
extend+tolist() time: 0.0015559196472167969

Evaluating:  21%|██        | 47/228 [00:20<01:15,  2.38it/s][Astep: 47
extend+tolist() time: 0.0014865398406982422

Evaluating:  21%|██        | 48/228 [00:21<01:14,  2.40it/s][Astep: 48
extend+tolist() time: 0.1650686264038086

Evaluating:  21%|██▏       | 49/228 [00:21<01:31,  1.96it/s][Astep: 49
extend+tolist() time: 0.0009520053863525391

Evaluating:  22%|██▏       | 50/228 [00:22<01:26,  2.06it/s][Astep: 50
extend+tolist() time: 0.0015826225280761719

Evaluating:  22%|██▏       | 51/228 [00:22<01:21,  2.16it/s][Astep: 51
extend+tolist() time: 0.0015285015106201172

Evaluating:  23%|██▎       | 52/228 [00:22<01:18,  2.24it/s][Astep: 52
extend+tolist() time: 0.0013320446014404297

Evaluating:  23%|██▎       | 53/228 [00:23<01:17,  2.25it/s][Astep: 53
extend+tolist() time: 0.001645803451538086

Evaluating:  24%|██▎       | 54/228 [00:23<01:15,  2.30it/s][Astep: 54
extend+tolist() time: 0.0008156299591064453

Evaluating:  24%|██▍       | 55/228 [00:24<01:15,  2.29it/s][Astep: 55
extend+tolist() time: 0.001138925552368164

Evaluating:  25%|██▍       | 56/228 [00:24<01:13,  2.35it/s][Astep: 56
extend+tolist() time: 0.0014841556549072266

Evaluating:  25%|██▌       | 57/228 [00:25<01:11,  2.38it/s][Astep: 57
extend+tolist() time: 0.0005681514739990234

Evaluating:  25%|██▌       | 58/228 [00:25<01:20,  2.11it/s][Astep: 58
extend+tolist() time: 0.0008709430694580078

Evaluating:  26%|██▌       | 59/228 [00:26<01:16,  2.22it/s][Astep: 59
extend+tolist() time: 0.0013871192932128906

Evaluating:  26%|██▋       | 60/228 [00:26<01:15,  2.23it/s][Astep: 60
extend+tolist() time: 0.0007188320159912109

Evaluating:  27%|██▋       | 61/228 [00:26<01:11,  2.32it/s][Astep: 61
extend+tolist() time: 0.0012524127960205078

Evaluating:  27%|██▋       | 62/228 [00:27<01:12,  2.30it/s][Astep: 62
extend+tolist() time: 0.0011262893676757812

Evaluating:  28%|██▊       | 63/228 [00:27<01:09,  2.37it/s][Astep: 63
extend+tolist() time: 0.0008089542388916016

Evaluating:  28%|██▊       | 64/228 [00:28<01:07,  2.43it/s][Astep: 64
extend+tolist() time: 0.0012042522430419922

Evaluating:  29%|██▊       | 65/228 [00:28<01:08,  2.37it/s][Astep: 65
extend+tolist() time: 0.0008301734924316406

Evaluating:  29%|██▉       | 66/228 [00:28<01:07,  2.41it/s][Astep: 66
extend+tolist() time: 0.001169443130493164

Evaluating:  29%|██▉       | 67/228 [00:29<01:16,  2.11it/s][Astep: 67
extend+tolist() time: 0.0009179115295410156

Evaluating:  30%|██▉       | 68/228 [00:29<01:12,  2.21it/s][Astep: 68
extend+tolist() time: 0.0011439323425292969

Evaluating:  30%|███       | 69/228 [00:30<01:12,  2.21it/s][Astep: 69
extend+tolist() time: 0.0010943412780761719

Evaluating:  31%|███       | 70/228 [00:30<01:09,  2.28it/s][Astep: 70
extend+tolist() time: 0.0016846656799316406

Evaluating:  31%|███       | 71/228 [00:31<01:08,  2.29it/s][Astep: 71
extend+tolist() time: 0.0013110637664794922

Evaluating:  32%|███▏      | 72/228 [00:31<01:07,  2.33it/s][Astep: 72
extend+tolist() time: 0.0007910728454589844

Evaluating:  32%|███▏      | 73/228 [00:32<01:04,  2.39it/s][Astep: 73
extend+tolist() time: 0.0005548000335693359

Evaluating:  32%|███▏      | 74/228 [00:32<01:05,  2.35it/s][Astep: 74
extend+tolist() time: 0.0012187957763671875

Evaluating:  33%|███▎      | 75/228 [00:32<01:03,  2.42it/s][Astep: 75
extend+tolist() time: 0.0016393661499023438

Evaluating:  33%|███▎      | 76/228 [00:33<01:03,  2.38it/s][Astep: 76
extend+tolist() time: 0.0006492137908935547

Evaluating:  34%|███▍      | 77/228 [00:33<01:01,  2.44it/s][Astep: 77
extend+tolist() time: 0.0018148422241210938

Evaluating:  34%|███▍      | 78/228 [00:34<01:01,  2.44it/s][Astep: 78
extend+tolist() time: 0.0012202262878417969

Evaluating:  35%|███▍      | 79/228 [00:34<01:03,  2.35it/s][Astep: 79
extend+tolist() time: 0.0008757114410400391

Evaluating:  35%|███▌      | 80/228 [00:35<01:01,  2.40it/s][Astep: 80
extend+tolist() time: 0.0013120174407958984

Evaluating:  36%|███▌      | 81/228 [00:35<01:03,  2.33it/s][Astep: 81
extend+tolist() time: 0.0008320808410644531

Evaluating:  36%|███▌      | 82/228 [00:35<01:01,  2.39it/s][Astep: 82
extend+tolist() time: 0.0012323856353759766

Evaluating:  36%|███▋      | 83/228 [00:36<00:59,  2.44it/s][Astep: 83
extend+tolist() time: 0.0007035732269287109

Evaluating:  37%|███▋      | 84/228 [00:36<01:00,  2.37it/s][Astep: 84
extend+tolist() time: 0.0014493465423583984

Evaluating:  37%|███▋      | 85/228 [00:37<00:59,  2.41it/s][Astep: 85
extend+tolist() time: 0.001247406005859375

Evaluating:  38%|███▊      | 86/228 [00:37<01:00,  2.35it/s][Astep: 86
extend+tolist() time: 0.0008389949798583984

Evaluating:  38%|███▊      | 87/228 [00:37<00:58,  2.41it/s][Astep: 87
extend+tolist() time: 0.0013167858123779297

Evaluating:  39%|███▊      | 88/228 [00:38<01:08,  2.05it/s][Astep: 88
extend+tolist() time: 0.0007116794586181641

Evaluating:  39%|███▉      | 89/228 [00:38<01:03,  2.19it/s][Astep: 89
extend+tolist() time: 0.1717994213104248

Evaluating:  39%|███▉      | 90/228 [00:39<01:07,  2.04it/s][Astep: 90
extend+tolist() time: 0.0009348392486572266

Evaluating:  40%|███▉      | 91/228 [00:39<01:03,  2.17it/s][Astep: 91
extend+tolist() time: 0.0007340908050537109

Evaluating:  40%|████      | 92/228 [00:40<00:59,  2.27it/s][Astep: 92
extend+tolist() time: 0.0011413097381591797

Evaluating:  41%|████      | 93/228 [00:40<00:59,  2.25it/s][Astep: 93
extend+tolist() time: 0.0009844303131103516

Evaluating:  41%|████      | 94/228 [00:41<00:58,  2.31it/s][Astep: 94
extend+tolist() time: 0.001176595687866211

Evaluating:  42%|████▏     | 95/228 [00:41<00:58,  2.27it/s][Astep: 95
extend+tolist() time: 0.0015125274658203125

Evaluating:  42%|████▏     | 96/228 [00:42<00:56,  2.32it/s][Astep: 96
extend+tolist() time: 0.0009129047393798828

Evaluating:  43%|████▎     | 97/228 [00:42<00:56,  2.31it/s][Astep: 97
extend+tolist() time: 0.0012123584747314453

Evaluating:  43%|████▎     | 98/228 [00:42<00:54,  2.37it/s][Astep: 98
extend+tolist() time: 0.0008752346038818359

Evaluating:  43%|████▎     | 99/228 [00:43<00:53,  2.42it/s][Astep: 99
extend+tolist() time: 0.0013544559478759766

Evaluating:  44%|████▍     | 100/228 [00:43<00:54,  2.34it/s][Astep: 100
extend+tolist() time: 0.0007283687591552734

Evaluating:  44%|████▍     | 101/228 [00:44<00:53,  2.40it/s][Astep: 101
extend+tolist() time: 0.0012400150299072266

Evaluating:  45%|████▍     | 102/228 [00:44<00:54,  2.33it/s][Astep: 102
extend+tolist() time: 0.0007166862487792969

Evaluating:  45%|████▌     | 103/228 [00:45<00:59,  2.11it/s][Astep: 103
extend+tolist() time: 0.0011827945709228516

Evaluating:  46%|████▌     | 104/228 [00:45<00:57,  2.14it/s][Astep: 104
extend+tolist() time: 0.0006940364837646484

Evaluating:  46%|████▌     | 105/228 [00:46<00:54,  2.24it/s][Astep: 105
extend+tolist() time: 0.0012352466583251953

Evaluating:  46%|████▋     | 106/228 [00:46<00:52,  2.32it/s][Astep: 106
extend+tolist() time: 0.0017306804656982422

Evaluating:  47%|████▋     | 107/228 [00:46<00:53,  2.25it/s][Astep: 107
extend+tolist() time: 0.0008063316345214844

Evaluating:  47%|████▋     | 108/228 [00:47<00:51,  2.32it/s][Astep: 108
extend+tolist() time: 0.001222848892211914

Evaluating:  48%|████▊     | 109/228 [00:47<00:52,  2.28it/s][Astep: 109
extend+tolist() time: 0.0008728504180908203

Evaluating:  48%|████▊     | 110/228 [00:48<00:50,  2.35it/s][Astep: 110
extend+tolist() time: 0.001054525375366211

Evaluating:  49%|████▊     | 111/228 [00:48<00:49,  2.34it/s][Astep: 111
extend+tolist() time: 0.0014050006866455078

Evaluating:  49%|████▉     | 112/228 [00:48<00:49,  2.35it/s][Astep: 112
extend+tolist() time: 0.0009012222290039062

Evaluating:  50%|████▉     | 113/228 [00:49<00:55,  2.07it/s][Astep: 113
extend+tolist() time: 0.0006844997406005859

Evaluating:  50%|█████     | 114/228 [00:49<00:51,  2.20it/s][Astep: 114
extend+tolist() time: 0.001569509506225586

Evaluating:  50%|█████     | 115/228 [00:50<00:49,  2.28it/s][Astep: 115
extend+tolist() time: 0.0006582736968994141

Evaluating:  51%|█████     | 116/228 [00:50<00:49,  2.25it/s][Astep: 116
extend+tolist() time: 0.0012531280517578125

Evaluating:  51%|█████▏    | 117/228 [00:51<00:47,  2.32it/s][Astep: 117
extend+tolist() time: 0.0008320808410644531

Evaluating:  52%|█████▏    | 118/228 [00:51<00:48,  2.27it/s][Astep: 118
extend+tolist() time: 0.001024007797241211

Evaluating:  52%|█████▏    | 119/228 [00:52<00:46,  2.35it/s][Astep: 119
extend+tolist() time: 0.0007007122039794922

Evaluating:  53%|█████▎    | 120/228 [00:52<00:44,  2.40it/s][Astep: 120
extend+tolist() time: 0.0006105899810791016

Evaluating:  53%|█████▎    | 121/228 [00:52<00:45,  2.35it/s][Astep: 121
extend+tolist() time: 0.0006289482116699219

Evaluating:  54%|█████▎    | 122/228 [00:53<00:43,  2.42it/s][Astep: 122
extend+tolist() time: 0.0006806850433349609

Evaluating:  54%|█████▍    | 123/228 [00:53<00:44,  2.37it/s][Astep: 123
extend+tolist() time: 0.0010852813720703125

Evaluating:  54%|█████▍    | 124/228 [00:54<00:42,  2.43it/s][Astep: 124
extend+tolist() time: 0.0007884502410888672

Evaluating:  55%|█████▍    | 125/228 [00:54<00:41,  2.49it/s][Astep: 125
extend+tolist() time: 0.0004184246063232422

Evaluating:  55%|█████▌    | 126/228 [00:54<00:41,  2.43it/s][Astep: 126
extend+tolist() time: 0.001748800277709961

Evaluating:  56%|█████▌    | 127/228 [00:55<00:40,  2.47it/s][Astep: 127
extend+tolist() time: 0.0016186237335205078

Evaluating:  56%|█████▌    | 128/228 [00:55<00:42,  2.38it/s][Astep: 128
extend+tolist() time: 0.0010619163513183594

Evaluating:  57%|█████▋    | 129/228 [00:56<00:40,  2.45it/s][Astep: 129
extend+tolist() time: 0.0007727146148681641

Evaluating:  57%|█████▋    | 130/228 [00:56<00:39,  2.48it/s][Astep: 130
extend+tolist() time: 0.0013699531555175781

Evaluating:  57%|█████▋    | 131/228 [00:57<00:40,  2.38it/s][Astep: 131
extend+tolist() time: 0.000461578369140625

Evaluating:  58%|█████▊    | 132/228 [00:57<00:38,  2.46it/s][Astep: 132
extend+tolist() time: 0.0014569759368896484

Evaluating:  58%|█████▊    | 133/228 [00:57<00:39,  2.40it/s][Astep: 133
extend+tolist() time: 0.0004391670227050781

Evaluating:  59%|█████▉    | 134/228 [00:58<00:37,  2.48it/s][Astep: 134
extend+tolist() time: 0.0013284683227539062

Evaluating:  59%|█████▉    | 135/228 [00:58<00:37,  2.50it/s][Astep: 135
extend+tolist() time: 0.0004241466522216797

Evaluating:  60%|█████▉    | 136/228 [00:59<00:37,  2.44it/s][Astep: 136
extend+tolist() time: 0.0008184909820556641

Evaluating:  60%|██████    | 137/228 [00:59<00:36,  2.47it/s][Astep: 137
extend+tolist() time: 0.00037550926208496094

Evaluating:  61%|██████    | 138/228 [00:59<00:37,  2.42it/s][Astep: 138
extend+tolist() time: 0.0012445449829101562

Evaluating:  61%|██████    | 139/228 [01:00<00:35,  2.48it/s][Astep: 139
extend+tolist() time: 0.0004856586456298828

Evaluating:  61%|██████▏   | 140/228 [01:00<00:34,  2.53it/s][Astep: 140
extend+tolist() time: 0.0012264251708984375

Evaluating:  62%|██████▏   | 141/228 [01:01<00:35,  2.45it/s][Astep: 141
extend+tolist() time: 0.0008573532104492188

Evaluating:  62%|██████▏   | 142/228 [01:01<00:34,  2.51it/s][Astep: 142
extend+tolist() time: 0.0006384849548339844

Evaluating:  63%|██████▎   | 143/228 [01:01<00:34,  2.46it/s][Astep: 143
extend+tolist() time: 0.0007932186126708984

Evaluating:  63%|██████▎   | 144/228 [01:02<00:33,  2.53it/s][Astep: 144
extend+tolist() time: 0.0008120536804199219

Evaluating:  64%|██████▎   | 145/228 [01:02<00:32,  2.56it/s][Astep: 145
extend+tolist() time: 0.0005114078521728516

Evaluating:  64%|██████▍   | 146/228 [01:03<00:36,  2.23it/s][Astep: 146
extend+tolist() time: 0.0008478164672851562

Evaluating:  64%|██████▍   | 147/228 [01:03<00:34,  2.35it/s][Astep: 147
extend+tolist() time: 0.0008134841918945312

Evaluating:  65%|██████▍   | 148/228 [01:04<00:34,  2.33it/s][Astep: 148
extend+tolist() time: 0.0007545948028564453

Evaluating:  65%|██████▌   | 149/228 [01:04<00:32,  2.42it/s][Astep: 149
extend+tolist() time: 0.001116037368774414

Evaluating:  66%|██████▌   | 150/228 [01:04<00:32,  2.43it/s][Astep: 150
extend+tolist() time: 0.0009021759033203125

Evaluating:  66%|██████▌   | 151/228 [01:05<00:31,  2.43it/s][Astep: 151
extend+tolist() time: 0.0006630420684814453

Evaluating:  67%|██████▋   | 152/228 [01:05<00:30,  2.50it/s][Astep: 152
extend+tolist() time: 0.2236788272857666

Evaluating:  67%|██████▋   | 153/228 [01:06<00:35,  2.10it/s][Astep: 153
extend+tolist() time: 0.0014369487762451172

Evaluating:  68%|██████▊   | 154/228 [01:06<00:33,  2.23it/s][Astep: 154
extend+tolist() time: 0.0018968582153320312

Evaluating:  68%|██████▊   | 155/228 [01:07<00:32,  2.22it/s][Astep: 155
extend+tolist() time: 0.0006802082061767578

Evaluating:  68%|██████▊   | 156/228 [01:07<00:31,  2.31it/s][Astep: 156
extend+tolist() time: 0.0005652904510498047

Evaluating:  69%|██████▉   | 157/228 [01:07<00:30,  2.32it/s][Astep: 157
extend+tolist() time: 0.0010666847229003906

Evaluating:  69%|██████▉   | 158/228 [01:08<00:28,  2.41it/s][Astep: 158
extend+tolist() time: 0.0005002021789550781

Evaluating:  70%|██████▉   | 159/228 [01:08<00:27,  2.49it/s][Astep: 159
extend+tolist() time: 0.0011031627655029297

Evaluating:  70%|███████   | 160/228 [01:09<00:28,  2.42it/s][Astep: 160
extend+tolist() time: 0.0003955364227294922

Evaluating:  71%|███████   | 161/228 [01:09<00:26,  2.50it/s][Astep: 161
extend+tolist() time: 0.0008256435394287109

Evaluating:  71%|███████   | 162/228 [01:09<00:26,  2.53it/s][Astep: 162
extend+tolist() time: 0.0005211830139160156

Evaluating:  71%|███████▏  | 163/228 [01:10<00:26,  2.45it/s][Astep: 163
extend+tolist() time: 0.0009045600891113281

Evaluating:  72%|███████▏  | 164/228 [01:10<00:25,  2.52it/s][Astep: 164
extend+tolist() time: 0.0005843639373779297

Evaluating:  72%|███████▏  | 165/228 [01:11<00:25,  2.45it/s][Astep: 165
extend+tolist() time: 0.0004935264587402344

Evaluating:  73%|███████▎  | 166/228 [01:11<00:24,  2.51it/s][Astep: 166
extend+tolist() time: 0.00039196014404296875

Evaluating:  73%|███████▎  | 167/228 [01:11<00:23,  2.55it/s][Astep: 167
extend+tolist() time: 0.0010464191436767578

Evaluating:  74%|███████▎  | 168/228 [01:12<00:24,  2.45it/s][Astep: 168
extend+tolist() time: 0.0012378692626953125

Evaluating:  74%|███████▍  | 169/228 [01:12<00:23,  2.48it/s][Astep: 169
extend+tolist() time: 0.0003886222839355469

Evaluating:  75%|███████▍  | 170/228 [01:13<00:23,  2.42it/s][Astep: 170
extend+tolist() time: 0.0014333724975585938

Evaluating:  75%|███████▌  | 171/228 [01:13<00:23,  2.47it/s][Astep: 171
extend+tolist() time: 0.0003037452697753906

Evaluating:  75%|███████▌  | 172/228 [01:13<00:22,  2.52it/s][Astep: 172
extend+tolist() time: 0.00121307373046875

Evaluating:  76%|███████▌  | 173/228 [01:14<00:22,  2.43it/s][Astep: 173
extend+tolist() time: 0.0013277530670166016

Evaluating:  76%|███████▋  | 174/228 [01:14<00:26,  2.06it/s][Astep: 174
extend+tolist() time: 0.001939535140991211

Evaluating:  77%|███████▋  | 175/228 [01:15<00:24,  2.13it/s][Astep: 175
extend+tolist() time: 0.0008337497711181641

Evaluating:  77%|███████▋  | 176/228 [01:15<00:23,  2.24it/s][Astep: 176
extend+tolist() time: 0.001046895980834961

Evaluating:  78%|███████▊  | 177/228 [01:16<00:22,  2.23it/s][Astep: 177
extend+tolist() time: 0.0006060600280761719

Evaluating:  78%|███████▊  | 178/228 [01:16<00:21,  2.32it/s][Astep: 178
extend+tolist() time: 0.0016105175018310547

Evaluating:  79%|███████▊  | 179/228 [01:17<00:21,  2.27it/s][Astep: 179
extend+tolist() time: 0.00041794776916503906

Evaluating:  79%|███████▉  | 180/228 [01:17<00:20,  2.36it/s][Astep: 180
extend+tolist() time: 0.00040268898010253906

Evaluating:  79%|███████▉  | 181/228 [01:17<00:19,  2.43it/s][Astep: 181
extend+tolist() time: 0.0005948543548583984

Evaluating:  80%|███████▉  | 182/228 [01:18<00:19,  2.36it/s][Astep: 182
extend+tolist() time: 0.0007545948028564453

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.43it/s][Astep: 183
extend+tolist() time: 0.0006554126739501953

Evaluating:  81%|████████  | 184/228 [01:19<00:18,  2.37it/s][Astep: 184
extend+tolist() time: 0.0004551410675048828

Evaluating:  81%|████████  | 185/228 [01:19<00:17,  2.45it/s][Astep: 185
extend+tolist() time: 0.001092672348022461

Evaluating:  82%|████████▏ | 186/228 [01:19<00:16,  2.49it/s][Astep: 186
extend+tolist() time: 0.0014729499816894531

Evaluating:  82%|████████▏ | 187/228 [01:20<00:17,  2.41it/s][Astep: 187
extend+tolist() time: 0.00045990943908691406

Evaluating:  82%|████████▏ | 188/228 [01:20<00:18,  2.13it/s][Astep: 188
extend+tolist() time: 0.0007109642028808594

Evaluating:  83%|████████▎ | 189/228 [01:21<00:17,  2.18it/s][Astep: 189
extend+tolist() time: 0.0003688335418701172

Evaluating:  83%|████████▎ | 190/228 [01:21<00:16,  2.30it/s][Astep: 190
extend+tolist() time: 0.0016489028930664062

Evaluating:  84%|████████▍ | 191/228 [01:22<00:16,  2.27it/s][Astep: 191
extend+tolist() time: 0.0006933212280273438

Evaluating:  84%|████████▍ | 192/228 [01:22<00:15,  2.37it/s][Astep: 192
extend+tolist() time: 0.00043511390686035156

Evaluating:  85%|████████▍ | 193/228 [01:23<00:14,  2.44it/s][Astep: 193
extend+tolist() time: 0.0010538101196289062

Evaluating:  85%|████████▌ | 194/228 [01:23<00:14,  2.39it/s][Astep: 194
extend+tolist() time: 0.0010373592376708984

Evaluating:  86%|████████▌ | 195/228 [01:23<00:13,  2.46it/s][Astep: 195
extend+tolist() time: 0.00054931640625

Evaluating:  86%|████████▌ | 196/228 [01:24<00:13,  2.41it/s][Astep: 196
extend+tolist() time: 0.0005970001220703125

Evaluating:  86%|████████▋ | 197/228 [01:24<00:12,  2.48it/s][Astep: 197
extend+tolist() time: 0.0010924339294433594

Evaluating:  87%|████████▋ | 198/228 [01:25<00:11,  2.52it/s][Astep: 198
extend+tolist() time: 0.0006024837493896484

Evaluating:  87%|████████▋ | 199/228 [01:25<00:11,  2.44it/s][Astep: 199
extend+tolist() time: 0.001867055892944336

Evaluating:  88%|████████▊ | 200/228 [01:25<00:11,  2.45it/s][Astep: 200
extend+tolist() time: 0.0007183551788330078

Evaluating:  88%|████████▊ | 201/228 [01:26<00:11,  2.39it/s][Astep: 201
extend+tolist() time: 0.0006225109100341797

Evaluating:  89%|████████▊ | 202/228 [01:26<00:10,  2.45it/s][Astep: 202
extend+tolist() time: 0.0008180141448974609

Evaluating:  89%|████████▉ | 203/228 [01:27<00:09,  2.50it/s][Astep: 203
extend+tolist() time: 0.0004985332489013672

Evaluating:  89%|████████▉ | 204/228 [01:27<00:09,  2.42it/s][Astep: 204
extend+tolist() time: 0.00039076805114746094

Evaluating:  90%|████████▉ | 205/228 [01:27<00:09,  2.47it/s][Astep: 205
extend+tolist() time: 0.0003097057342529297

Evaluating:  90%|█████████ | 206/228 [01:28<00:09,  2.41it/s][Astep: 206
extend+tolist() time: 0.0010197162628173828

Evaluating:  91%|█████████ | 207/228 [01:28<00:08,  2.46it/s][Astep: 207
extend+tolist() time: 0.0006062984466552734

Evaluating:  91%|█████████ | 208/228 [01:29<00:07,  2.50it/s][Astep: 208
extend+tolist() time: 0.0006885528564453125

Evaluating:  92%|█████████▏| 209/228 [01:29<00:07,  2.42it/s][Astep: 209
extend+tolist() time: 0.0010204315185546875

Evaluating:  92%|█████████▏| 210/228 [01:29<00:07,  2.47it/s][Astep: 210
extend+tolist() time: 0.0006127357482910156

Evaluating:  93%|█████████▎| 211/228 [01:30<00:07,  2.39it/s][Astep: 211
extend+tolist() time: 0.0010836124420166016

Evaluating:  93%|█████████▎| 212/228 [01:30<00:06,  2.43it/s][Astep: 212
extend+tolist() time: 0.0009105205535888672

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.45it/s][Astep: 213
extend+tolist() time: 0.0007529258728027344

Evaluating:  94%|█████████▍| 214/228 [01:31<00:05,  2.38it/s][Astep: 214
extend+tolist() time: 0.001268148422241211

Evaluating:  94%|█████████▍| 215/228 [01:32<00:05,  2.42it/s][Astep: 215
extend+tolist() time: 0.000682830810546875

Evaluating:  95%|█████████▍| 216/228 [01:32<00:05,  2.36it/s][Astep: 216
extend+tolist() time: 0.0009517669677734375

Evaluating:  95%|█████████▌| 217/228 [01:32<00:04,  2.42it/s][Astep: 217
extend+tolist() time: 0.0005686283111572266

Evaluating:  96%|█████████▌| 218/228 [01:33<00:04,  2.47it/s][Astep: 218
extend+tolist() time: 0.0010421276092529297

Evaluating:  96%|█████████▌| 219/228 [01:33<00:03,  2.39it/s][Astep: 219
extend+tolist() time: 0.0009164810180664062

Evaluating:  96%|█████████▋| 220/228 [01:34<00:03,  2.45it/s][Astep: 220
extend+tolist() time: 0.000408172607421875

Evaluating:  97%|█████████▋| 221/228 [01:34<00:02,  2.39it/s][Astep: 221
extend+tolist() time: 0.0006604194641113281

Evaluating:  97%|█████████▋| 222/228 [01:34<00:02,  2.44it/s][Astep: 222
extend+tolist() time: 0.0006768703460693359

Evaluating:  98%|█████████▊| 223/228 [01:35<00:02,  2.44it/s][Astep: 223
extend+tolist() time: 0.0008184909820556641

Evaluating:  98%|█████████▊| 224/228 [01:35<00:01,  2.43it/s][Astep: 224
extend+tolist() time: 0.0003762245178222656

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.47it/s][Astep: 225
extend+tolist() time: 0.00041556358337402344

Evaluating:  99%|█████████▉| 226/228 [01:36<00:00,  2.39it/s][Astep: 226
extend+tolist() time: 0.0005290508270263672

Evaluating: 100%|█████████▉| 227/228 [01:36<00:00,  2.43it/s][Astep: 227
extend+tolist() time: 0.0009467601776123047

Evaluating: 100%|██████████| 228/228 [01:37<00:00,  2.31it/s][A09/08/2023 23:05:19 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 23:05:19 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:05:19 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:05:19 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:05:19 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:05:20 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:05:20 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:05:20 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:05:20 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:05:20 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:05:20 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:05:20 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:05:20 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:05:21 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-2019464f-ba68-4783-80ee-63a1a0cd426f-1-0.arrow
09/08/2023 23:05:21 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:05:21 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:05:21 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:39<00:00,  2.28it/s]
09/08/2023 23:05:21 - INFO - __main__ -   Step: 1560, Validation Metrics: {'pred_1_num': 10209, 'pred_-1_num': 574, 'pred_0_num': 18, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7998333487640034, 'f1_micro': 0.7998333487640034, 'f1_macro': 0.3951151463331346, 'f1_weighted': 0.7470008407623344, 'f1_-1': 0.2775700934579439, 'f1_0': 0.021308980213089804, 'f1_1': 0.8864663653283701, 'precision_micro': 0.7998333487640034, 'precision_macro': 0.5742489897647113, 'precision_weighted': 0.7477891113385488, 'precision_-1': 0.5174216027874564, 'precision_0': 0.3888888888888889, 'precision_1': 0.8164364776177883, 'recall_micro': 0.7998333487640034, 'recall_macro': 0.3900822764953862, 'recall_weighted': 0.7998333487640034, 'recall_-1': 0.1896551724137931, 'recall_0': 0.010954616588419406, 'recall_1': 0.969637040483946, 'roc_auc_micro': 0.9156097536326456, 'roc_auc_macro': 0.7471573866753224, 'roc_auc_weighted': 0.7211527649055142, 'roc_auc_-1': 0.8012786604351677, 'roc_auc_0': 0.7346405292169822, 'roc_auc_1': 0.7055529703738173}
[2023-09-08 23:05:42,119] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1561/66600 [1:42:51<912:33:14, 50.51s/it]09/08/2023 23:05:42 - INFO - __main__ -   Step: 1561, LR: 1.5631493303292027e-05, Loss: 0.44008103013038635
[2023-09-08 23:06:02,971] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1562/66600 [1:43:12<751:47:30, 41.61s/it]09/08/2023 23:06:02 - INFO - __main__ -   Step: 1562, LR: 1.564150707222431e-05, Loss: 0.4205745458602905
[2023-09-08 23:06:24,006] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1563/66600 [1:43:33<640:15:03, 35.44s/it]09/08/2023 23:06:24 - INFO - __main__ -   Step: 1563, LR: 1.565152084115659e-05, Loss: 0.37510666251182556
[2023-09-08 23:06:44,738] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1564/66600 [1:43:54<560:31:48, 31.03s/it]09/08/2023 23:06:44 - INFO - __main__ -   Step: 1564, LR: 1.5661534610088872e-05, Loss: 0.43953821063041687
[2023-09-08 23:07:05,347] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1565/66600 [1:44:14<504:03:26, 27.90s/it]09/08/2023 23:07:05 - INFO - __main__ -   Step: 1565, LR: 1.5671548379021154e-05, Loss: 0.45216792821884155
[2023-09-08 23:07:26,327] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1566/66600 [1:44:35<466:32:13, 25.83s/it]09/08/2023 23:07:26 - INFO - __main__ -   Step: 1566, LR: 1.568156214795344e-05, Loss: 0.3647436201572418
[2023-09-08 23:07:46,980] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1567/66600 [1:44:56<438:29:31, 24.27s/it]09/08/2023 23:07:46 - INFO - __main__ -   Step: 1567, LR: 1.569157591688572e-05, Loss: 0.37987640500068665
[2023-09-08 23:08:08,004] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1568/66600 [1:45:17<420:52:37, 23.30s/it]09/08/2023 23:08:08 - INFO - __main__ -   Step: 1568, LR: 1.5701589685818002e-05, Loss: 0.40001484751701355
[2023-09-08 23:08:29,052] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1569/66600 [1:45:38<408:40:29, 22.62s/it]09/08/2023 23:08:29 - INFO - __main__ -   Step: 1569, LR: 1.5711603454750284e-05, Loss: 0.4498703181743622
[2023-09-08 23:08:50,490] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1570/66600 [1:46:00<402:14:47, 22.27s/it]09/08/2023 23:08:50 - INFO - __main__ -   Step: 1570, LR: 1.5721617223682565e-05, Loss: 0.5101794004440308
[2023-09-08 23:09:11,922] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1571/66600 [1:46:21<397:42:35, 22.02s/it]09/08/2023 23:09:11 - INFO - __main__ -   Step: 1571, LR: 1.5731630992614847e-05, Loss: 0.39666223526000977
[2023-09-08 23:09:32,996] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1572/66600 [1:46:42<392:35:19, 21.73s/it]09/08/2023 23:09:32 - INFO - __main__ -   Step: 1572, LR: 1.574164476154713e-05, Loss: 0.4288374185562134
[2023-09-08 23:09:53,278] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1573/66600 [1:47:02<384:42:57, 21.30s/it]09/08/2023 23:09:53 - INFO - __main__ -   Step: 1573, LR: 1.575165853047941e-05, Loss: 0.44679129123687744
[2023-09-08 23:10:14,073] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1574/66600 [1:47:23<381:58:48, 21.15s/it]09/08/2023 23:10:14 - INFO - __main__ -   Step: 1574, LR: 1.576167229941169e-05, Loss: 0.4306938052177429
[2023-09-08 23:10:34,764] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1575/66600 [1:47:44<379:30:15, 21.01s/it]09/08/2023 23:10:34 - INFO - __main__ -   Step: 1575, LR: 1.5771686068343973e-05, Loss: 0.4229389429092407
[2023-09-08 23:10:56,448] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1576/66600 [1:48:05<383:08:47, 21.21s/it]09/08/2023 23:10:56 - INFO - __main__ -   Step: 1576, LR: 1.5781699837276255e-05, Loss: 0.43201518058776855
[2023-09-08 23:11:17,144] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1577/66600 [1:48:26<380:20:25, 21.06s/it]09/08/2023 23:11:17 - INFO - __main__ -   Step: 1577, LR: 1.579171360620854e-05, Loss: 0.5066834688186646
[2023-09-08 23:11:37,779] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1578/66600 [1:48:47<378:02:50, 20.93s/it]09/08/2023 23:11:37 - INFO - __main__ -   Step: 1578, LR: 1.580172737514082e-05, Loss: 0.3976482152938843
[2023-09-08 23:11:58,323] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1579/66600 [1:49:07<375:56:29, 20.81s/it]09/08/2023 23:11:58 - INFO - __main__ -   Step: 1579, LR: 1.5811741144073103e-05, Loss: 0.46695783734321594
[2023-09-08 23:12:19,074] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1580/66600 [1:49:28<375:35:25, 20.80s/it]09/08/2023 23:12:19 - INFO - __main__ -   Step: 1580, LR: 1.582175491300538e-05, Loss: 0.4072190523147583
09/08/2023 23:12:19 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.002870321273803711

Evaluating:   0%|          | 1/228 [00:00<01:46,  2.14it/s][Astep: 1
extend+tolist() time: 0.0015609264373779297

Evaluating:   1%|          | 2/228 [00:00<01:38,  2.30it/s][Astep: 2
extend+tolist() time: 0.1299130916595459

Evaluating:   1%|▏         | 3/228 [00:01<01:48,  2.08it/s][Astep: 3
extend+tolist() time: 0.0018236637115478516

Evaluating:   2%|▏         | 4/228 [00:01<01:42,  2.18it/s][Astep: 4
extend+tolist() time: 0.0009717941284179688

Evaluating:   2%|▏         | 5/228 [00:02<01:36,  2.31it/s][Astep: 5
extend+tolist() time: 0.002347230911254883

Evaluating:   3%|▎         | 6/228 [00:02<01:35,  2.32it/s][Astep: 6
extend+tolist() time: 0.002002716064453125

Evaluating:   3%|▎         | 7/228 [00:03<01:33,  2.36it/s][Astep: 7
extend+tolist() time: 0.0013298988342285156

Evaluating:   4%|▎         | 8/228 [00:03<01:40,  2.18it/s][Astep: 8
extend+tolist() time: 0.0007624626159667969

Evaluating:   4%|▍         | 9/228 [00:04<01:37,  2.25it/s][Astep: 9
extend+tolist() time: 0.0012073516845703125

Evaluating:   4%|▍         | 10/228 [00:04<01:33,  2.34it/s][Astep: 10
extend+tolist() time: 0.0012288093566894531

Evaluating:   5%|▍         | 11/228 [00:04<01:32,  2.35it/s][Astep: 11
extend+tolist() time: 0.0005609989166259766

Evaluating:   5%|▌         | 12/228 [00:05<01:29,  2.43it/s][Astep: 12
extend+tolist() time: 0.0006475448608398438

Evaluating:   6%|▌         | 13/228 [00:05<01:26,  2.47it/s][Astep: 13
extend+tolist() time: 0.0010311603546142578

Evaluating:   6%|▌         | 14/228 [00:06<01:28,  2.43it/s][Astep: 14
extend+tolist() time: 0.0005440711975097656

Evaluating:   7%|▋         | 15/228 [00:06<01:26,  2.48it/s][Astep: 15
extend+tolist() time: 0.0006134510040283203

Evaluating:   7%|▋         | 16/228 [00:06<01:28,  2.40it/s][Astep: 16
extend+tolist() time: 0.0010876655578613281

Evaluating:   7%|▋         | 17/228 [00:07<01:36,  2.18it/s][Astep: 17
extend+tolist() time: 0.0008745193481445312

Evaluating:   8%|▊         | 18/228 [00:07<01:35,  2.20it/s][Astep: 18
extend+tolist() time: 0.001577138900756836

Evaluating:   8%|▊         | 19/228 [00:08<01:32,  2.26it/s][Astep: 19
extend+tolist() time: 0.0013375282287597656

Evaluating:   9%|▉         | 20/228 [00:08<01:30,  2.31it/s][Astep: 20
extend+tolist() time: 0.0007402896881103516

Evaluating:   9%|▉         | 21/228 [00:09<01:30,  2.28it/s][Astep: 21
extend+tolist() time: 0.0006492137908935547

Evaluating:  10%|▉         | 22/228 [00:09<01:27,  2.34it/s][Astep: 22
extend+tolist() time: 0.0012443065643310547

Evaluating:  10%|█         | 23/228 [00:09<01:29,  2.30it/s][Astep: 23
extend+tolist() time: 0.0006778240203857422

Evaluating:  11%|█         | 24/228 [00:10<01:26,  2.35it/s][Astep: 24
extend+tolist() time: 0.0015521049499511719

Evaluating:  11%|█         | 25/228 [00:10<01:28,  2.29it/s][Astep: 25
extend+tolist() time: 0.0018138885498046875

Evaluating:  11%|█▏        | 26/228 [00:11<01:26,  2.34it/s][Astep: 26
extend+tolist() time: 0.0007145404815673828

Evaluating:  12%|█▏        | 27/228 [00:11<01:23,  2.40it/s][Astep: 27
extend+tolist() time: 0.0013000965118408203

Evaluating:  12%|█▏        | 28/228 [00:12<01:31,  2.19it/s][Astep: 28
extend+tolist() time: 0.0007724761962890625

Evaluating:  13%|█▎        | 29/228 [00:12<01:26,  2.31it/s][Astep: 29
extend+tolist() time: 0.0007030963897705078

Evaluating:  13%|█▎        | 30/228 [00:13<01:26,  2.29it/s][Astep: 30
extend+tolist() time: 0.0014772415161132812

Evaluating:  14%|█▎        | 31/228 [00:13<01:23,  2.36it/s][Astep: 31
extend+tolist() time: 0.0008292198181152344

Evaluating:  14%|█▍        | 32/228 [00:13<01:23,  2.36it/s][Astep: 32
extend+tolist() time: 0.14299678802490234

Evaluating:  14%|█▍        | 33/228 [00:14<01:29,  2.18it/s][Astep: 33
extend+tolist() time: 0.0017139911651611328

Evaluating:  15%|█▍        | 34/228 [00:14<01:26,  2.26it/s][Astep: 34
extend+tolist() time: 0.0008769035339355469

Evaluating:  15%|█▌        | 35/228 [00:15<01:25,  2.25it/s][Astep: 35
extend+tolist() time: 0.0010609626770019531

Evaluating:  16%|█▌        | 36/228 [00:15<01:21,  2.34it/s][Astep: 36
extend+tolist() time: 0.000759124755859375

Evaluating:  16%|█▌        | 37/228 [00:16<01:22,  2.32it/s][Astep: 37
extend+tolist() time: 0.0016589164733886719

Evaluating:  17%|█▋        | 38/228 [00:16<01:20,  2.36it/s][Astep: 38
extend+tolist() time: 0.001089334487915039

Evaluating:  17%|█▋        | 39/228 [00:17<01:29,  2.11it/s][Astep: 39
extend+tolist() time: 0.0007145404815673828

Evaluating:  18%|█▊        | 40/228 [00:17<01:24,  2.23it/s][Astep: 40
extend+tolist() time: 0.0010294914245605469

Evaluating:  18%|█▊        | 41/228 [00:17<01:22,  2.28it/s][Astep: 41
extend+tolist() time: 0.0008339881896972656

Evaluating:  18%|█▊        | 42/228 [00:18<01:21,  2.28it/s][Astep: 42
extend+tolist() time: 0.0016565322875976562

Evaluating:  19%|█▉        | 43/228 [00:18<01:19,  2.32it/s][Astep: 43
extend+tolist() time: 0.0018260478973388672

Evaluating:  19%|█▉        | 44/228 [00:19<01:21,  2.24it/s][Astep: 44
extend+tolist() time: 0.0007197856903076172

Evaluating:  20%|█▉        | 45/228 [00:19<01:18,  2.32it/s][Astep: 45
extend+tolist() time: 0.0017039775848388672

Evaluating:  20%|██        | 46/228 [00:20<01:20,  2.27it/s][Astep: 46
extend+tolist() time: 0.0015971660614013672

Evaluating:  21%|██        | 47/228 [00:20<01:17,  2.33it/s][Astep: 47
extend+tolist() time: 0.0014700889587402344

Evaluating:  21%|██        | 48/228 [00:20<01:15,  2.38it/s][Astep: 48
extend+tolist() time: 0.0011661052703857422

Evaluating:  21%|██▏       | 49/228 [00:21<01:23,  2.13it/s][Astep: 49
extend+tolist() time: 0.0013458728790283203

Evaluating:  22%|██▏       | 50/228 [00:21<01:19,  2.24it/s][Astep: 50
extend+tolist() time: 0.0015630722045898438

Evaluating:  22%|██▏       | 51/228 [00:22<01:20,  2.21it/s][Astep: 51
extend+tolist() time: 0.0015549659729003906

Evaluating:  23%|██▎       | 52/228 [00:22<01:17,  2.28it/s][Astep: 52
extend+tolist() time: 0.0010128021240234375

Evaluating:  23%|██▎       | 53/228 [00:23<01:18,  2.24it/s][Astep: 53
extend+tolist() time: 0.0017938613891601562

Evaluating:  24%|██▎       | 54/228 [00:23<01:15,  2.29it/s][Astep: 54
extend+tolist() time: 0.0012078285217285156

Evaluating:  24%|██▍       | 55/228 [00:24<01:16,  2.26it/s][Astep: 55
extend+tolist() time: 0.00079345703125

Evaluating:  25%|██▍       | 56/228 [00:24<01:13,  2.34it/s][Astep: 56
extend+tolist() time: 0.0016632080078125

Evaluating:  25%|██▌       | 57/228 [00:24<01:12,  2.37it/s][Astep: 57
extend+tolist() time: 0.0005970001220703125

Evaluating:  25%|██▌       | 58/228 [00:25<01:13,  2.33it/s][Astep: 58
extend+tolist() time: 0.0013375282287597656

Evaluating:  26%|██▌       | 59/228 [00:25<01:20,  2.09it/s][Astep: 59
extend+tolist() time: 0.0009310245513916016

Evaluating:  26%|██▋       | 60/228 [00:26<01:18,  2.13it/s][Astep: 60
extend+tolist() time: 0.0011734962463378906

Evaluating:  27%|██▋       | 61/228 [00:26<01:14,  2.24it/s][Astep: 61
extend+tolist() time: 0.0008568763732910156

Evaluating:  27%|██▋       | 62/228 [00:27<01:14,  2.22it/s][Astep: 62
extend+tolist() time: 0.0012106895446777344

Evaluating:  28%|██▊       | 63/228 [00:27<01:11,  2.31it/s][Astep: 63
extend+tolist() time: 0.0008111000061035156

Evaluating:  28%|██▊       | 64/228 [00:27<01:08,  2.38it/s][Astep: 64
extend+tolist() time: 0.000812530517578125

Evaluating:  29%|██▊       | 65/228 [00:28<01:09,  2.33it/s][Astep: 65
extend+tolist() time: 0.0012781620025634766

Evaluating:  29%|██▉       | 66/228 [00:28<01:07,  2.38it/s][Astep: 66
extend+tolist() time: 0.1846480369567871

Evaluating:  29%|██▉       | 67/228 [00:29<01:17,  2.07it/s][Astep: 67
extend+tolist() time: 0.0014247894287109375

Evaluating:  30%|██▉       | 68/228 [00:29<01:12,  2.19it/s][Astep: 68
extend+tolist() time: 0.0006780624389648438

Evaluating:  30%|███       | 69/228 [00:30<01:11,  2.22it/s][Astep: 69
extend+tolist() time: 0.0014739036560058594

Evaluating:  31%|███       | 70/228 [00:30<01:08,  2.29it/s][Astep: 70
extend+tolist() time: 0.0014100074768066406

Evaluating:  31%|███       | 71/228 [00:31<01:08,  2.31it/s][Astep: 71
extend+tolist() time: 0.0009620189666748047

Evaluating:  32%|███▏      | 72/228 [00:31<01:06,  2.34it/s][Astep: 72
extend+tolist() time: 0.0011813640594482422

Evaluating:  32%|███▏      | 73/228 [00:31<01:04,  2.40it/s][Astep: 73
extend+tolist() time: 0.0005271434783935547

Evaluating:  32%|███▏      | 74/228 [00:32<01:12,  2.12it/s][Astep: 74
extend+tolist() time: 0.001168966293334961

Evaluating:  33%|███▎      | 75/228 [00:32<01:08,  2.23it/s][Astep: 75
extend+tolist() time: 0.0016281604766845703

Evaluating:  33%|███▎      | 76/228 [00:33<01:09,  2.20it/s][Astep: 76
extend+tolist() time: 0.0006546974182128906

Evaluating:  34%|███▍      | 77/228 [00:33<01:05,  2.30it/s][Astep: 77
extend+tolist() time: 0.0018813610076904297

Evaluating:  34%|███▍      | 78/228 [00:34<01:06,  2.25it/s][Astep: 78
extend+tolist() time: 0.0011947154998779297

Evaluating:  35%|███▍      | 79/228 [00:34<01:03,  2.34it/s][Astep: 79
extend+tolist() time: 0.000904083251953125

Evaluating:  35%|███▌      | 80/228 [00:35<01:01,  2.40it/s][Astep: 80
extend+tolist() time: 0.0013532638549804688

Evaluating:  36%|███▌      | 81/228 [00:35<01:02,  2.36it/s][Astep: 81
extend+tolist() time: 0.0008380413055419922

Evaluating:  36%|███▌      | 82/228 [00:35<01:00,  2.43it/s][Astep: 82
extend+tolist() time: 0.0012378692626953125

Evaluating:  36%|███▋      | 83/228 [00:36<01:01,  2.37it/s][Astep: 83
extend+tolist() time: 0.0006766319274902344

Evaluating:  37%|███▋      | 84/228 [00:36<00:59,  2.44it/s][Astep: 84
extend+tolist() time: 0.0014355182647705078

Evaluating:  37%|███▋      | 85/228 [00:37<00:57,  2.48it/s][Astep: 85
extend+tolist() time: 0.0009071826934814453

Evaluating:  38%|███▊      | 86/228 [00:37<00:59,  2.40it/s][Astep: 86
extend+tolist() time: 0.0013153553009033203

Evaluating:  38%|███▊      | 87/228 [00:38<01:06,  2.12it/s][Astep: 87
extend+tolist() time: 0.001271963119506836

Evaluating:  39%|███▊      | 88/228 [00:38<01:04,  2.17it/s][Astep: 88
extend+tolist() time: 0.0007302761077880859

Evaluating:  39%|███▉      | 89/228 [00:38<01:00,  2.28it/s][Astep: 89
extend+tolist() time: 0.0011370182037353516

Evaluating:  39%|███▉      | 90/228 [00:39<01:01,  2.26it/s][Astep: 90
extend+tolist() time: 0.0009763240814208984

Evaluating:  40%|███▉      | 91/228 [00:39<00:58,  2.33it/s][Astep: 91
extend+tolist() time: 0.0011904239654541016

Evaluating:  40%|████      | 92/228 [00:40<00:57,  2.39it/s][Astep: 92
extend+tolist() time: 0.000804901123046875

Evaluating:  41%|████      | 93/228 [00:40<00:57,  2.34it/s][Astep: 93
extend+tolist() time: 0.0014002323150634766

Evaluating:  41%|████      | 94/228 [00:41<00:56,  2.39it/s][Astep: 94
extend+tolist() time: 0.0007483959197998047

Evaluating:  42%|████▏     | 95/228 [00:41<00:56,  2.34it/s][Astep: 95
extend+tolist() time: 0.0015761852264404297

Evaluating:  42%|████▏     | 96/228 [00:41<00:55,  2.38it/s][Astep: 96
extend+tolist() time: 0.0012767314910888672

Evaluating:  43%|████▎     | 97/228 [00:42<00:55,  2.37it/s][Astep: 97
extend+tolist() time: 0.0008852481842041016

Evaluating:  43%|████▎     | 98/228 [00:42<00:54,  2.39it/s][Astep: 98
extend+tolist() time: 0.0012850761413574219

Evaluating:  43%|████▎     | 99/228 [00:43<00:53,  2.42it/s][Astep: 99
extend+tolist() time: 0.0009024143218994141

Evaluating:  44%|████▍     | 100/228 [00:43<00:54,  2.37it/s][Astep: 100
extend+tolist() time: 0.001203775405883789

Evaluating:  44%|████▍     | 101/228 [00:43<00:52,  2.41it/s][Astep: 101
extend+tolist() time: 0.0008232593536376953

Evaluating:  45%|████▍     | 102/228 [00:44<00:53,  2.35it/s][Astep: 102
extend+tolist() time: 0.0011763572692871094

Evaluating:  45%|████▌     | 103/228 [00:44<00:51,  2.41it/s][Astep: 103
extend+tolist() time: 0.0008077621459960938

Evaluating:  46%|████▌     | 104/228 [00:45<01:00,  2.05it/s][Astep: 104
extend+tolist() time: 0.0011372566223144531

Evaluating:  46%|████▌     | 105/228 [00:45<00:56,  2.16it/s][Astep: 105
extend+tolist() time: 0.0008087158203125

Evaluating:  46%|████▋     | 106/228 [00:46<00:54,  2.25it/s][Astep: 106
extend+tolist() time: 0.0018076896667480469

Evaluating:  47%|████▋     | 107/228 [00:46<00:54,  2.22it/s][Astep: 107
extend+tolist() time: 0.0011506080627441406

Evaluating:  47%|████▋     | 108/228 [00:47<00:52,  2.30it/s][Astep: 108
extend+tolist() time: 0.0008287429809570312

Evaluating:  48%|████▊     | 109/228 [00:47<00:52,  2.26it/s][Astep: 109
extend+tolist() time: 0.001264333724975586

Evaluating:  48%|████▊     | 110/228 [00:47<00:50,  2.34it/s][Astep: 110
extend+tolist() time: 0.0008766651153564453

Evaluating:  49%|████▊     | 111/228 [00:48<00:51,  2.29it/s][Astep: 111
extend+tolist() time: 0.1922159194946289

Evaluating:  49%|████▉     | 112/228 [00:49<00:57,  2.03it/s][Astep: 112
extend+tolist() time: 0.0003960132598876953

Evaluating:  50%|████▉     | 113/228 [00:49<00:55,  2.08it/s][Astep: 113
extend+tolist() time: 0.0011157989501953125

Evaluating:  50%|█████     | 114/228 [00:49<00:52,  2.18it/s][Astep: 114
extend+tolist() time: 0.0014400482177734375

Evaluating:  50%|█████     | 115/228 [00:50<00:50,  2.23it/s][Astep: 115
extend+tolist() time: 0.0006272792816162109

Evaluating:  51%|█████     | 116/228 [00:50<00:50,  2.21it/s][Astep: 116
extend+tolist() time: 0.0011966228485107422

Evaluating:  51%|█████▏    | 117/228 [00:51<00:48,  2.30it/s][Astep: 117
extend+tolist() time: 0.0008022785186767578

Evaluating:  52%|█████▏    | 118/228 [00:51<00:48,  2.26it/s][Astep: 118
extend+tolist() time: 0.0008702278137207031

Evaluating:  52%|█████▏    | 119/228 [00:52<00:46,  2.34it/s][Astep: 119
extend+tolist() time: 0.0009453296661376953

Evaluating:  53%|█████▎    | 120/228 [00:52<00:46,  2.30it/s][Astep: 120
extend+tolist() time: 0.0006437301635742188

Evaluating:  53%|█████▎    | 121/228 [00:52<00:44,  2.38it/s][Astep: 121
extend+tolist() time: 0.0011415481567382812

Evaluating:  54%|█████▎    | 122/228 [00:53<00:43,  2.44it/s][Astep: 122
extend+tolist() time: 0.0006501674652099609

Evaluating:  54%|█████▍    | 123/228 [00:53<00:49,  2.13it/s][Astep: 123
extend+tolist() time: 0.001010894775390625

Evaluating:  54%|█████▍    | 124/228 [00:54<00:46,  2.25it/s][Astep: 124
extend+tolist() time: 0.0008029937744140625

Evaluating:  55%|█████▍    | 125/228 [00:54<00:46,  2.23it/s][Astep: 125
extend+tolist() time: 0.00043082237243652344

Evaluating:  55%|█████▌    | 126/228 [00:55<00:43,  2.34it/s][Astep: 126
extend+tolist() time: 0.0020380020141601562

Evaluating:  56%|█████▌    | 127/228 [00:55<00:43,  2.31it/s][Astep: 127
extend+tolist() time: 0.0016896724700927734

Evaluating:  56%|█████▌    | 128/228 [00:55<00:42,  2.36it/s][Astep: 128
extend+tolist() time: 0.0007364749908447266

Evaluating:  57%|█████▋    | 129/228 [00:56<00:40,  2.43it/s][Astep: 129
extend+tolist() time: 0.0007576942443847656

Evaluating:  57%|█████▋    | 130/228 [00:56<00:41,  2.36it/s][Astep: 130
extend+tolist() time: 0.0013039112091064453

Evaluating:  57%|█████▋    | 131/228 [00:57<00:40,  2.42it/s][Astep: 131
extend+tolist() time: 0.000453948974609375

Evaluating:  58%|█████▊    | 132/228 [00:57<00:40,  2.36it/s][Astep: 132
extend+tolist() time: 0.0014693737030029297

Evaluating:  58%|█████▊    | 133/228 [00:57<00:39,  2.41it/s][Astep: 133
extend+tolist() time: 0.00041937828063964844

Evaluating:  59%|█████▉    | 134/228 [00:58<00:38,  2.46it/s][Astep: 134
extend+tolist() time: 0.0009636878967285156

Evaluating:  59%|█████▉    | 135/228 [00:58<00:39,  2.37it/s][Astep: 135
extend+tolist() time: 0.0009126663208007812

Evaluating:  60%|█████▉    | 136/228 [00:59<00:37,  2.44it/s][Astep: 136
extend+tolist() time: 0.0008294582366943359

Evaluating:  60%|██████    | 137/228 [00:59<00:38,  2.36it/s][Astep: 137
extend+tolist() time: 0.00038433074951171875

Evaluating:  61%|██████    | 138/228 [01:00<00:37,  2.43it/s][Astep: 138
extend+tolist() time: 0.0012102127075195312

Evaluating:  61%|██████    | 139/228 [01:00<00:35,  2.47it/s][Astep: 139
extend+tolist() time: 0.0004551410675048828

Evaluating:  61%|██████▏   | 140/228 [01:00<00:36,  2.40it/s][Astep: 140
extend+tolist() time: 0.001138448715209961

Evaluating:  62%|██████▏   | 141/228 [01:01<00:35,  2.45it/s][Astep: 141
extend+tolist() time: 0.0007596015930175781

Evaluating:  62%|██████▏   | 142/228 [01:01<00:36,  2.38it/s][Astep: 142
extend+tolist() time: 0.0005614757537841797

Evaluating:  63%|██████▎   | 143/228 [01:02<00:34,  2.45it/s][Astep: 143
extend+tolist() time: 0.0007991790771484375

Evaluating:  63%|██████▎   | 144/228 [01:02<00:40,  2.07it/s][Astep: 144
extend+tolist() time: 0.0006818771362304688

Evaluating:  64%|██████▎   | 145/228 [01:03<00:37,  2.21it/s][Astep: 145
extend+tolist() time: 0.0005211830139160156

Evaluating:  64%|██████▍   | 146/228 [01:03<00:35,  2.32it/s][Astep: 146
extend+tolist() time: 0.00042176246643066406

Evaluating:  64%|██████▍   | 147/228 [01:03<00:35,  2.29it/s][Astep: 147
extend+tolist() time: 0.0012578964233398438

Evaluating:  65%|██████▍   | 148/228 [01:04<00:33,  2.37it/s][Astep: 148
extend+tolist() time: 0.0007128715515136719

Evaluating:  65%|██████▌   | 149/228 [01:04<00:34,  2.32it/s][Astep: 149
extend+tolist() time: 0.0003867149353027344

Evaluating:  66%|██████▌   | 150/228 [01:05<00:32,  2.41it/s][Astep: 150
extend+tolist() time: 0.0013384819030761719

Evaluating:  66%|██████▌   | 151/228 [01:05<00:31,  2.46it/s][Astep: 151
extend+tolist() time: 0.0006666183471679688

Evaluating:  67%|██████▋   | 152/228 [01:06<00:31,  2.39it/s][Astep: 152
extend+tolist() time: 0.0013096332550048828

Evaluating:  67%|██████▋   | 153/228 [01:06<00:30,  2.44it/s][Astep: 153
extend+tolist() time: 0.0010333061218261719

Evaluating:  68%|██████▊   | 154/228 [01:06<00:31,  2.37it/s][Astep: 154
extend+tolist() time: 0.0021097660064697266

Evaluating:  68%|██████▊   | 155/228 [01:07<00:30,  2.39it/s][Astep: 155
extend+tolist() time: 0.0012705326080322266

Evaluating:  68%|██████▊   | 156/228 [01:07<00:30,  2.35it/s][Astep: 156
extend+tolist() time: 0.0005624294281005859

Evaluating:  69%|██████▉   | 157/228 [01:08<00:29,  2.42it/s][Astep: 157
extend+tolist() time: 0.0007243156433105469

Evaluating:  69%|██████▉   | 158/228 [01:08<00:28,  2.46it/s][Astep: 158
extend+tolist() time: 0.000934600830078125

Evaluating:  70%|██████▉   | 159/228 [01:08<00:29,  2.38it/s][Astep: 159
extend+tolist() time: 0.0007331371307373047

Evaluating:  70%|███████   | 160/228 [01:09<00:28,  2.43it/s][Astep: 160
extend+tolist() time: 0.0004076957702636719

Evaluating:  71%|███████   | 161/228 [01:09<00:28,  2.37it/s][Astep: 161
extend+tolist() time: 0.0012466907501220703

Evaluating:  71%|███████   | 162/228 [01:10<00:27,  2.42it/s][Astep: 162
extend+tolist() time: 0.0005204677581787109

Evaluating:  71%|███████▏  | 163/228 [01:10<00:26,  2.47it/s][Astep: 163
extend+tolist() time: 0.0004138946533203125

Evaluating:  72%|███████▏  | 164/228 [01:11<00:26,  2.40it/s][Astep: 164
extend+tolist() time: 0.0005829334259033203

Evaluating:  72%|███████▏  | 165/228 [01:11<00:25,  2.45it/s][Astep: 165
extend+tolist() time: 0.0009434223175048828

Evaluating:  73%|███████▎  | 166/228 [01:11<00:26,  2.37it/s][Astep: 166
extend+tolist() time: 0.00038504600524902344

Evaluating:  73%|███████▎  | 167/228 [01:12<00:25,  2.42it/s][Astep: 167
extend+tolist() time: 0.0005807876586914062

Evaluating:  74%|███████▎  | 168/228 [01:12<00:24,  2.45it/s][Astep: 168
extend+tolist() time: 0.0016138553619384766

Evaluating:  74%|███████▍  | 169/228 [01:13<00:25,  2.35it/s][Astep: 169
extend+tolist() time: 0.00037384033203125

Evaluating:  75%|███████▍  | 170/228 [01:13<00:24,  2.40it/s][Astep: 170
extend+tolist() time: 0.0009484291076660156

Evaluating:  75%|███████▌  | 171/228 [01:13<00:24,  2.33it/s][Astep: 171
extend+tolist() time: 0.0007240772247314453

Evaluating:  75%|███████▌  | 172/228 [01:14<00:23,  2.39it/s][Astep: 172
extend+tolist() time: 0.0008544921875

Evaluating:  76%|███████▌  | 173/228 [01:14<00:22,  2.41it/s][Astep: 173
extend+tolist() time: 0.0015931129455566406

Evaluating:  76%|███████▋  | 174/228 [01:15<00:22,  2.35it/s][Astep: 174
extend+tolist() time: 0.0014643669128417969

Evaluating:  77%|███████▋  | 175/228 [01:15<00:26,  1.99it/s][Astep: 175
extend+tolist() time: 0.0007991790771484375

Evaluating:  77%|███████▋  | 176/228 [01:16<00:24,  2.12it/s][Astep: 176
extend+tolist() time: 0.0006442070007324219

Evaluating:  78%|███████▊  | 177/228 [01:16<00:22,  2.23it/s][Astep: 177
extend+tolist() time: 0.0010492801666259766

Evaluating:  78%|███████▊  | 178/228 [01:17<00:22,  2.23it/s][Astep: 178
extend+tolist() time: 0.0012276172637939453

Evaluating:  79%|███████▊  | 179/228 [01:17<00:21,  2.30it/s][Astep: 179
extend+tolist() time: 0.0004215240478515625

Evaluating:  79%|███████▉  | 180/228 [01:17<00:20,  2.29it/s][Astep: 180
extend+tolist() time: 0.0008294582366943359

Evaluating:  79%|███████▉  | 181/228 [01:18<00:19,  2.39it/s][Astep: 181
extend+tolist() time: 0.0006120204925537109

Evaluating:  80%|███████▉  | 182/228 [01:18<00:18,  2.44it/s][Astep: 182
extend+tolist() time: 0.0007879734039306641

Evaluating:  80%|████████  | 183/228 [01:19<00:18,  2.38it/s][Astep: 183
extend+tolist() time: 0.0011241436004638672

Evaluating:  81%|████████  | 184/228 [01:19<00:18,  2.43it/s][Astep: 184
extend+tolist() time: 0.00047779083251953125

Evaluating:  81%|████████  | 185/228 [01:20<00:18,  2.37it/s][Astep: 185
extend+tolist() time: 0.0015180110931396484

Evaluating:  82%|████████▏ | 186/228 [01:20<00:17,  2.40it/s][Astep: 186
extend+tolist() time: 0.0010421276092529297

Evaluating:  82%|████████▏ | 187/228 [01:20<00:16,  2.43it/s][Astep: 187
extend+tolist() time: 0.0004458427429199219

Evaluating:  82%|████████▏ | 188/228 [01:21<00:16,  2.38it/s][Astep: 188
extend+tolist() time: 0.0011415481567382812

Evaluating:  83%|████████▎ | 189/228 [01:21<00:16,  2.43it/s][Astep: 189
extend+tolist() time: 0.0003783702850341797

Evaluating:  83%|████████▎ | 190/228 [01:22<00:15,  2.38it/s][Astep: 190
extend+tolist() time: 0.22281622886657715

Evaluating:  84%|████████▍ | 191/228 [01:22<00:17,  2.08it/s][Astep: 191
extend+tolist() time: 0.0007123947143554688

Evaluating:  84%|████████▍ | 192/228 [01:23<00:16,  2.14it/s][Astep: 192
extend+tolist() time: 0.000446319580078125

Evaluating:  85%|████████▍ | 193/228 [01:23<00:15,  2.25it/s][Astep: 193
extend+tolist() time: 0.0013027191162109375

Evaluating:  85%|████████▌ | 194/228 [01:23<00:14,  2.27it/s][Astep: 194
extend+tolist() time: 0.00061798095703125

Evaluating:  86%|████████▌ | 195/228 [01:24<00:14,  2.34it/s][Astep: 195
extend+tolist() time: 0.0010192394256591797

Evaluating:  86%|████████▌ | 196/228 [01:24<00:13,  2.42it/s][Astep: 196
extend+tolist() time: 0.000621795654296875

Evaluating:  86%|████████▋ | 197/228 [01:25<00:13,  2.34it/s][Astep: 197
extend+tolist() time: 0.000640869140625

Evaluating:  87%|████████▋ | 198/228 [01:25<00:12,  2.42it/s][Astep: 198
extend+tolist() time: 0.0006093978881835938

Evaluating:  87%|████████▋ | 199/228 [01:26<00:12,  2.37it/s][Astep: 199
extend+tolist() time: 0.0018725395202636719

Evaluating:  88%|████████▊ | 200/228 [01:26<00:11,  2.38it/s][Astep: 200
extend+tolist() time: 0.0007240772247314453

Evaluating:  88%|████████▊ | 201/228 [01:26<00:11,  2.45it/s][Astep: 201
extend+tolist() time: 0.0006318092346191406

Evaluating:  89%|████████▊ | 202/228 [01:27<00:10,  2.37it/s][Astep: 202
extend+tolist() time: 0.0008537769317626953

Evaluating:  89%|████████▉ | 203/228 [01:27<00:10,  2.45it/s][Astep: 203
extend+tolist() time: 0.0005259513854980469

Evaluating:  89%|████████▉ | 204/228 [01:28<00:10,  2.39it/s][Astep: 204
extend+tolist() time: 0.00038814544677734375

Evaluating:  90%|████████▉ | 205/228 [01:28<00:09,  2.46it/s][Astep: 205
extend+tolist() time: 0.0003249645233154297

Evaluating:  90%|█████████ | 206/228 [01:28<00:08,  2.52it/s][Astep: 206
extend+tolist() time: 0.0005991458892822266

Evaluating:  91%|█████████ | 207/228 [01:29<00:08,  2.44it/s][Astep: 207
extend+tolist() time: 0.0010602474212646484

Evaluating:  91%|█████████ | 208/228 [01:29<00:08,  2.49it/s][Astep: 208
extend+tolist() time: 0.0007152557373046875

Evaluating:  92%|█████████▏| 209/228 [01:30<00:09,  2.09it/s][Astep: 209
extend+tolist() time: 0.0005929470062255859

Evaluating:  92%|█████████▏| 210/228 [01:30<00:08,  2.23it/s][Astep: 210
extend+tolist() time: 0.0010449886322021484

Evaluating:  93%|█████████▎| 211/228 [01:31<00:07,  2.23it/s][Astep: 211
extend+tolist() time: 0.0011165142059326172

Evaluating:  93%|█████████▎| 212/228 [01:31<00:06,  2.30it/s][Astep: 212
extend+tolist() time: 0.001340627670288086

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.37it/s][Astep: 213
extend+tolist() time: 0.0007338523864746094

Evaluating:  94%|█████████▍| 214/228 [01:32<00:06,  2.32it/s][Astep: 214
extend+tolist() time: 0.0012159347534179688

Evaluating:  94%|█████████▍| 215/228 [01:32<00:05,  2.38it/s][Astep: 215
extend+tolist() time: 0.0006573200225830078

Evaluating:  95%|█████████▍| 216/228 [01:33<00:05,  2.33it/s][Astep: 216
extend+tolist() time: 0.0005655288696289062

Evaluating:  95%|█████████▌| 217/228 [01:33<00:04,  2.40it/s][Astep: 217
extend+tolist() time: 0.0009675025939941406

Evaluating:  96%|█████████▌| 218/228 [01:34<00:04,  2.45it/s][Astep: 218
extend+tolist() time: 0.0010128021240234375

Evaluating:  96%|█████████▌| 219/228 [01:34<00:03,  2.37it/s][Astep: 219
extend+tolist() time: 0.0008897781372070312

Evaluating:  96%|█████████▋| 220/228 [01:34<00:03,  2.44it/s][Astep: 220
extend+tolist() time: 0.00040602684020996094

Evaluating:  97%|█████████▋| 221/228 [01:35<00:02,  2.38it/s][Astep: 221
extend+tolist() time: 0.0006442070007324219

Evaluating:  97%|█████████▋| 222/228 [01:35<00:02,  2.43it/s][Astep: 222
extend+tolist() time: 0.0004093647003173828

Evaluating:  98%|█████████▊| 223/228 [01:36<00:02,  2.45it/s][Astep: 223
extend+tolist() time: 0.0008575916290283203

Evaluating:  98%|█████████▊| 224/228 [01:36<00:01,  2.39it/s][Astep: 224
extend+tolist() time: 0.000377655029296875

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.42it/s][Astep: 225
extend+tolist() time: 0.00041866302490234375

Evaluating:  99%|█████████▉| 226/228 [01:37<00:00,  2.35it/s][Astep: 226
extend+tolist() time: 0.0005557537078857422

Evaluating: 100%|█████████▉| 227/228 [01:37<00:00,  2.38it/s][Astep: 227
extend+tolist() time: 0.0009315013885498047

Evaluating: 100%|██████████| 228/228 [01:38<00:00,  2.30it/s][A09/08/2023 23:13:57 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 23:13:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:13:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:13:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:13:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:13:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:13:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:13:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:13:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:13:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:13:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:13:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:13:58 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:13:59 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:13:59 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:13:59 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:13:59 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:40<00:00,  2.27it/s]
09/08/2023 23:13:59 - INFO - __main__ -   Step: 1580, Validation Metrics: {'pred_1_num': 10152, 'pred_-1_num': 588, 'pred_0_num': 61, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.8002962688639941, 'f1_micro': 0.8002962688639941, 'f1_macro': 0.40751416890755654, 'f1_weighted': 0.7507342704709482, 'f1_-1': 0.2896935933147632, 'f1_0': 0.04571428571428572, 'f1_1': 0.8871346276936207, 'precision_micro': 0.8002962688639941, 'precision_macro': 0.5373520876784617, 'precision_weighted': 0.744370853458606, 'precision_-1': 0.5306122448979592, 'precision_0': 0.26229508196721313, 'precision_1': 0.8191489361702128, 'recall_micro': 0.8002962688639941, 'recall_macro': 0.39723318340116287, 'recall_weighted': 0.8002962688639941, 'recall_-1': 0.19923371647509577, 'recall_0': 0.025039123630672927, 'recall_1': 0.9674267100977199, 'roc_auc_micro': 0.911308541874031, 'roc_auc_macro': 0.7409250397368604, 'roc_auc_weighted': 0.7115288226621378, 'roc_auc_-1': 0.8003646104517974, 'roc_auc_0': 0.7283132964288387, 'roc_auc_1': 0.6940972123299451}
[2023-09-08 23:14:19,346] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1581/66600 [1:51:28<914:34:19, 50.64s/it]09/08/2023 23:14:19 - INFO - __main__ -   Step: 1581, LR: 1.5831768681937666e-05, Loss: 0.41984009742736816
[2023-09-08 23:14:39,464] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1582/66600 [1:51:49<749:11:39, 41.48s/it]09/08/2023 23:14:39 - INFO - __main__ -   Step: 1582, LR: 1.5841782450869948e-05, Loss: 0.4224705100059509
[2023-09-08 23:15:00,114] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1583/66600 [1:52:09<636:18:57, 35.23s/it]09/08/2023 23:15:00 - INFO - __main__ -   Step: 1583, LR: 1.585179621980223e-05, Loss: 0.4311107397079468
[2023-09-08 23:15:21,166] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1584/66600 [1:52:30<559:28:08, 30.98s/it]09/08/2023 23:15:21 - INFO - __main__ -   Step: 1584, LR: 1.586180998873451e-05, Loss: 0.390632688999176
[2023-09-08 23:15:42,099] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1585/66600 [1:52:51<505:02:08, 27.96s/it]09/08/2023 23:15:42 - INFO - __main__ -   Step: 1585, LR: 1.5871823757666793e-05, Loss: 0.46426448225975037
[2023-09-08 23:16:03,042] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1586/66600 [1:53:12<466:59:20, 25.86s/it]09/08/2023 23:16:03 - INFO - __main__ -   Step: 1586, LR: 1.5881837526599074e-05, Loss: 0.4047761559486389
[2023-09-08 23:16:25,052] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1587/66600 [1:53:34<446:07:50, 24.70s/it]09/08/2023 23:16:25 - INFO - __main__ -   Step: 1587, LR: 1.5891851295531356e-05, Loss: 0.34399330615997314
[2023-09-08 23:16:46,452] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1588/66600 [1:53:56<428:13:21, 23.71s/it]09/08/2023 23:16:46 - INFO - __main__ -   Step: 1588, LR: 1.590186506446364e-05, Loss: 0.36613234877586365
[2023-09-08 23:17:07,966] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1589/66600 [1:54:17<416:18:15, 23.05s/it]09/08/2023 23:17:07 - INFO - __main__ -   Step: 1589, LR: 1.5911878833395923e-05, Loss: 0.3704702854156494
[2023-09-08 23:17:29,487] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1590/66600 [1:54:39<408:00:06, 22.59s/it]09/08/2023 23:17:29 - INFO - __main__ -   Step: 1590, LR: 1.59218926023282e-05, Loss: 0.39064353704452515
[2023-09-08 23:17:50,249] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1591/66600 [1:54:59<398:04:25, 22.04s/it]09/08/2023 23:17:50 - INFO - __main__ -   Step: 1591, LR: 1.5931906371260482e-05, Loss: 0.466891884803772
[2023-09-08 23:18:11,523] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1592/66600 [1:55:21<393:53:51, 21.81s/it]09/08/2023 23:18:11 - INFO - __main__ -   Step: 1592, LR: 1.5941920140192767e-05, Loss: 0.3571236729621887
[2023-09-08 23:18:31,710] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1593/66600 [1:55:41<385:04:35, 21.33s/it]09/08/2023 23:18:31 - INFO - __main__ -   Step: 1593, LR: 1.595193390912505e-05, Loss: 0.4145551919937134
[2023-09-08 23:18:52,252] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1594/66600 [1:56:01<380:49:50, 21.09s/it]09/08/2023 23:18:52 - INFO - __main__ -   Step: 1594, LR: 1.596194767805733e-05, Loss: 0.37382596731185913
[2023-09-08 23:19:13,066] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1595/66600 [1:56:22<379:19:43, 21.01s/it]09/08/2023 23:19:13 - INFO - __main__ -   Step: 1595, LR: 1.5971961446989612e-05, Loss: 0.4735957384109497
[2023-09-08 23:19:33,430] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1596/66600 [1:56:42<375:50:26, 20.81s/it]09/08/2023 23:19:33 - INFO - __main__ -   Step: 1596, LR: 1.5981975215921894e-05, Loss: 0.41200196743011475
[2023-09-08 23:19:54,115] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1597/66600 [1:57:03<375:07:58, 20.78s/it]09/08/2023 23:19:54 - INFO - __main__ -   Step: 1597, LR: 1.5991988984854175e-05, Loss: 0.45659688115119934
[2023-09-08 23:20:14,939] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1598/66600 [1:57:24<375:23:10, 20.79s/it]09/08/2023 23:20:14 - INFO - __main__ -   Step: 1598, LR: 1.6002002753786457e-05, Loss: 0.45582157373428345
[2023-09-08 23:20:35,647] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1599/66600 [1:57:45<374:56:06, 20.77s/it]09/08/2023 23:20:35 - INFO - __main__ -   Step: 1599, LR: 1.601201652271874e-05, Loss: 0.4988732933998108
[2023-09-08 23:20:56,661] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1600/66600 [1:58:06<376:16:39, 20.84s/it]09/08/2023 23:20:56 - INFO - __main__ -   Step: 1600, LR: 1.602203029165102e-05, Loss: 0.42721039056777954
09/08/2023 23:20:56 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0028607845306396484

Evaluating:   0%|          | 1/228 [00:00<01:58,  1.92it/s][Astep: 1
extend+tolist() time: 0.0015575885772705078

Evaluating:   1%|          | 2/228 [00:00<01:44,  2.17it/s][Astep: 2
extend+tolist() time: 0.002062082290649414

Evaluating:   1%|▏         | 3/228 [00:01<01:40,  2.23it/s][Astep: 3
extend+tolist() time: 0.0014119148254394531

Evaluating:   2%|▏         | 4/228 [00:01<01:41,  2.21it/s][Astep: 4
extend+tolist() time: 0.0018239021301269531

Evaluating:   2%|▏         | 5/228 [00:02<01:37,  2.29it/s][Astep: 5
extend+tolist() time: 0.1514132022857666

Evaluating:   3%|▎         | 6/228 [00:02<01:50,  2.01it/s][Astep: 6
extend+tolist() time: 0.0020198822021484375

Evaluating:   3%|▎         | 7/228 [00:03<01:46,  2.08it/s][Astep: 7
extend+tolist() time: 0.0013129711151123047

Evaluating:   4%|▎         | 8/228 [00:03<01:42,  2.14it/s][Astep: 8
extend+tolist() time: 0.0007865428924560547

Evaluating:   4%|▍         | 9/228 [00:04<01:40,  2.18it/s][Astep: 9
extend+tolist() time: 0.0012469291687011719

Evaluating:   4%|▍         | 10/228 [00:04<01:38,  2.21it/s][Astep: 10
extend+tolist() time: 0.0008723735809326172

Evaluating:   5%|▍         | 11/228 [00:05<01:37,  2.23it/s][Astep: 11
extend+tolist() time: 0.0010101795196533203

Evaluating:   5%|▌         | 12/228 [00:05<01:35,  2.27it/s][Astep: 12
extend+tolist() time: 0.0006797313690185547

Evaluating:   6%|▌         | 13/228 [00:05<01:35,  2.25it/s][Astep: 13
extend+tolist() time: 0.0009891986846923828

Evaluating:   6%|▌         | 14/228 [00:06<01:32,  2.31it/s][Astep: 14
extend+tolist() time: 0.0005612373352050781

Evaluating:   7%|▋         | 15/228 [00:06<01:32,  2.31it/s][Astep: 15
extend+tolist() time: 0.0006394386291503906

Evaluating:   7%|▋         | 16/228 [00:07<01:31,  2.32it/s][Astep: 16
extend+tolist() time: 0.001112222671508789

Evaluating:   7%|▋         | 17/228 [00:07<01:31,  2.31it/s][Astep: 17
extend+tolist() time: 0.0008997917175292969

Evaluating:   8%|▊         | 18/228 [00:08<01:39,  2.11it/s][Astep: 18
extend+tolist() time: 0.0016200542449951172

Evaluating:   8%|▊         | 19/228 [00:08<01:36,  2.16it/s][Astep: 19
extend+tolist() time: 0.00135040283203125

Evaluating:   9%|▉         | 20/228 [00:09<01:34,  2.20it/s][Astep: 20
extend+tolist() time: 0.0007550716400146484

Evaluating:   9%|▉         | 21/228 [00:09<01:41,  2.04it/s][Astep: 21
extend+tolist() time: 0.0006721019744873047

Evaluating:  10%|▉         | 22/228 [00:10<01:36,  2.14it/s][Astep: 22
extend+tolist() time: 0.001247406005859375

Evaluating:  10%|█         | 23/228 [00:10<01:30,  2.25it/s][Astep: 23
extend+tolist() time: 0.0006990432739257812

Evaluating:  11%|█         | 24/228 [00:10<01:28,  2.29it/s][Astep: 24
extend+tolist() time: 0.0015730857849121094

Evaluating:  11%|█         | 25/228 [00:11<01:27,  2.31it/s][Astep: 25
extend+tolist() time: 0.0018548965454101562

Evaluating:  11%|█▏        | 26/228 [00:11<01:27,  2.31it/s][Astep: 26
extend+tolist() time: 0.0007297992706298828

Evaluating:  12%|█▏        | 27/228 [00:12<01:25,  2.34it/s][Astep: 27
extend+tolist() time: 0.0017163753509521484

Evaluating:  12%|█▏        | 28/228 [00:12<01:23,  2.39it/s][Astep: 28
extend+tolist() time: 0.0005955696105957031

Evaluating:  13%|█▎        | 29/228 [00:12<01:22,  2.41it/s][Astep: 29
extend+tolist() time: 0.0010933876037597656

Evaluating:  13%|█▎        | 30/228 [00:13<01:19,  2.48it/s][Astep: 30
extend+tolist() time: 0.0014374256134033203

Evaluating:  14%|█▎        | 31/228 [00:13<01:20,  2.44it/s][Astep: 31
extend+tolist() time: 0.0005717277526855469

Evaluating:  14%|█▍        | 32/228 [00:14<01:20,  2.45it/s][Astep: 32
extend+tolist() time: 0.001386404037475586

Evaluating:  14%|█▍        | 33/228 [00:14<01:18,  2.48it/s][Astep: 33
extend+tolist() time: 0.001447916030883789

Evaluating:  15%|█▍        | 34/228 [00:14<01:20,  2.42it/s][Astep: 34
extend+tolist() time: 0.001276254653930664

Evaluating:  15%|█▌        | 35/228 [00:15<01:18,  2.46it/s][Astep: 35
extend+tolist() time: 0.0006814002990722656

Evaluating:  16%|█▌        | 36/228 [00:15<01:18,  2.44it/s][Astep: 36
extend+tolist() time: 0.17955327033996582

Evaluating:  16%|█▌        | 37/228 [00:16<01:38,  1.94it/s][Astep: 37
extend+tolist() time: 0.0017404556274414062

Evaluating:  17%|█▋        | 38/228 [00:16<01:33,  2.03it/s][Astep: 38
extend+tolist() time: 0.0007879734039306641

Evaluating:  17%|█▋        | 39/228 [00:17<01:27,  2.15it/s][Astep: 39
extend+tolist() time: 0.0010678768157958984

Evaluating:  18%|█▊        | 40/228 [00:17<01:25,  2.20it/s][Astep: 40
extend+tolist() time: 0.0006234645843505859

Evaluating:  18%|█▊        | 41/228 [00:18<01:23,  2.24it/s][Astep: 41
extend+tolist() time: 0.0012753009796142578

Evaluating:  18%|█▊        | 42/228 [00:18<01:21,  2.28it/s][Astep: 42
extend+tolist() time: 0.0015878677368164062

Evaluating:  19%|█▉        | 43/228 [00:19<01:21,  2.27it/s][Astep: 43
extend+tolist() time: 0.0018715858459472656

Evaluating:  19%|█▉        | 44/228 [00:19<01:19,  2.30it/s][Astep: 44
extend+tolist() time: 0.0007309913635253906

Evaluating:  20%|█▉        | 45/228 [00:19<01:19,  2.31it/s][Astep: 45
extend+tolist() time: 0.001680135726928711

Evaluating:  20%|██        | 46/228 [00:20<01:19,  2.30it/s][Astep: 46
extend+tolist() time: 0.0016088485717773438

Evaluating:  21%|██        | 47/228 [00:20<01:18,  2.29it/s][Astep: 47
extend+tolist() time: 0.001458883285522461

Evaluating:  21%|██        | 48/228 [00:21<01:18,  2.29it/s][Astep: 48
extend+tolist() time: 0.0011990070343017578

Evaluating:  21%|██▏       | 49/228 [00:21<01:27,  2.04it/s][Astep: 49
extend+tolist() time: 0.0014429092407226562

Evaluating:  22%|██▏       | 50/228 [00:22<01:23,  2.12it/s][Astep: 50
extend+tolist() time: 0.001584768295288086

Evaluating:  22%|██▏       | 51/228 [00:22<01:20,  2.19it/s][Astep: 51
extend+tolist() time: 0.0015816688537597656

Evaluating:  23%|██▎       | 52/228 [00:23<01:28,  2.00it/s][Astep: 52
extend+tolist() time: 0.0009942054748535156

Evaluating:  23%|██▎       | 53/228 [00:23<01:23,  2.10it/s][Astep: 53
extend+tolist() time: 0.0017631053924560547

Evaluating:  24%|██▎       | 54/228 [00:24<01:21,  2.13it/s][Astep: 54
extend+tolist() time: 0.0011761188507080078

Evaluating:  24%|██▍       | 55/228 [00:24<01:17,  2.22it/s][Astep: 55
extend+tolist() time: 0.0008144378662109375

Evaluating:  25%|██▍       | 56/228 [00:25<01:16,  2.26it/s][Astep: 56
extend+tolist() time: 0.001590728759765625

Evaluating:  25%|██▌       | 57/228 [00:25<01:15,  2.27it/s][Astep: 57
extend+tolist() time: 0.0005793571472167969

Evaluating:  25%|██▌       | 58/228 [00:25<01:14,  2.30it/s][Astep: 58
extend+tolist() time: 0.0012869834899902344

Evaluating:  26%|██▌       | 59/228 [00:26<01:13,  2.31it/s][Astep: 59
extend+tolist() time: 0.0009768009185791016

Evaluating:  26%|██▋       | 60/228 [00:26<01:11,  2.36it/s][Astep: 60
extend+tolist() time: 0.0014710426330566406

Evaluating:  27%|██▋       | 61/228 [00:27<01:11,  2.34it/s][Astep: 61
extend+tolist() time: 0.0008299350738525391

Evaluating:  27%|██▋       | 62/228 [00:27<01:09,  2.39it/s][Astep: 62
extend+tolist() time: 0.0012476444244384766

Evaluating:  28%|██▊       | 63/228 [00:28<01:09,  2.37it/s][Astep: 63
extend+tolist() time: 0.0008203983306884766

Evaluating:  28%|██▊       | 64/228 [00:28<01:09,  2.36it/s][Astep: 64
extend+tolist() time: 0.0012583732604980469

Evaluating:  29%|██▊       | 65/228 [00:28<01:08,  2.38it/s][Astep: 65
extend+tolist() time: 0.0008058547973632812

Evaluating:  29%|██▉       | 66/228 [00:29<01:09,  2.33it/s][Astep: 66
extend+tolist() time: 0.0011532306671142578

Evaluating:  29%|██▉       | 67/228 [00:29<01:08,  2.36it/s][Astep: 67
extend+tolist() time: 0.0012793540954589844

Evaluating:  30%|██▉       | 68/228 [00:30<01:08,  2.35it/s][Astep: 68
extend+tolist() time: 0.0007047653198242188

Evaluating:  30%|███       | 69/228 [00:30<01:07,  2.35it/s][Astep: 69
extend+tolist() time: 0.0014884471893310547

Evaluating:  31%|███       | 70/228 [00:30<01:07,  2.34it/s][Astep: 70
extend+tolist() time: 0.0010612010955810547

Evaluating:  31%|███       | 71/228 [00:31<01:15,  2.09it/s][Astep: 71
extend+tolist() time: 0.16644716262817383

Evaluating:  32%|███▏      | 72/228 [00:32<01:20,  1.94it/s][Astep: 72
extend+tolist() time: 0.0012378692626953125

Evaluating:  32%|███▏      | 73/228 [00:32<01:15,  2.05it/s][Astep: 73
extend+tolist() time: 0.0005333423614501953

Evaluating:  32%|███▏      | 74/228 [00:33<01:11,  2.14it/s][Astep: 74
extend+tolist() time: 0.0010640621185302734

Evaluating:  33%|███▎      | 75/228 [00:33<01:09,  2.20it/s][Astep: 75
extend+tolist() time: 0.001253366470336914

Evaluating:  33%|███▎      | 76/228 [00:33<01:07,  2.27it/s][Astep: 76
extend+tolist() time: 0.0011324882507324219

Evaluating:  34%|███▍      | 77/228 [00:34<01:07,  2.25it/s][Astep: 77
extend+tolist() time: 0.0018236637115478516

Evaluating:  34%|███▍      | 78/228 [00:34<01:05,  2.28it/s][Astep: 78
extend+tolist() time: 0.0008807182312011719

Evaluating:  35%|███▍      | 79/228 [00:35<01:04,  2.29it/s][Astep: 79
extend+tolist() time: 0.0008738040924072266

Evaluating:  35%|███▌      | 80/228 [00:35<01:04,  2.30it/s][Astep: 80
extend+tolist() time: 0.0013608932495117188

Evaluating:  36%|███▌      | 81/228 [00:36<01:03,  2.31it/s][Astep: 81
extend+tolist() time: 0.0008590221405029297

Evaluating:  36%|███▌      | 82/228 [00:36<01:03,  2.31it/s][Astep: 82
extend+tolist() time: 0.0012717247009277344

Evaluating:  36%|███▋      | 83/228 [00:36<01:01,  2.37it/s][Astep: 83
extend+tolist() time: 0.0007290840148925781

Evaluating:  37%|███▋      | 84/228 [00:37<01:01,  2.36it/s][Astep: 84
extend+tolist() time: 0.0014271736145019531

Evaluating:  37%|███▋      | 85/228 [00:37<01:01,  2.34it/s][Astep: 85
extend+tolist() time: 0.000888824462890625

Evaluating:  38%|███▊      | 86/228 [00:38<01:00,  2.33it/s][Astep: 86
extend+tolist() time: 0.0013165473937988281

Evaluating:  38%|███▊      | 87/228 [00:38<01:00,  2.33it/s][Astep: 87
extend+tolist() time: 0.0012476444244384766

Evaluating:  39%|███▊      | 88/228 [00:39<01:07,  2.07it/s][Astep: 88
extend+tolist() time: 0.0007085800170898438

Evaluating:  39%|███▉      | 89/228 [00:39<01:04,  2.16it/s][Astep: 89
extend+tolist() time: 0.0011742115020751953

Evaluating:  39%|███▉      | 90/228 [00:40<01:01,  2.25it/s][Astep: 90
extend+tolist() time: 0.00095367431640625

Evaluating:  40%|███▉      | 91/228 [00:40<01:00,  2.26it/s][Astep: 91
extend+tolist() time: 0.0011742115020751953

Evaluating:  40%|████      | 92/228 [00:40<00:57,  2.35it/s][Astep: 92
extend+tolist() time: 0.0008265972137451172

Evaluating:  41%|████      | 93/228 [00:41<01:05,  2.06it/s][Astep: 93
extend+tolist() time: 0.0014183521270751953

Evaluating:  41%|████      | 94/228 [00:41<01:01,  2.17it/s][Astep: 94
extend+tolist() time: 0.0007402896881103516

Evaluating:  42%|████▏     | 95/228 [00:42<01:00,  2.22it/s][Astep: 95
extend+tolist() time: 0.0015709400177001953

Evaluating:  42%|████▏     | 96/228 [00:42<00:59,  2.23it/s][Astep: 96
extend+tolist() time: 0.0012993812561035156

Evaluating:  43%|████▎     | 97/228 [00:43<00:57,  2.26it/s][Astep: 97
extend+tolist() time: 0.000820159912109375

Evaluating:  43%|████▎     | 98/228 [00:43<00:56,  2.29it/s][Astep: 98
extend+tolist() time: 0.0013229846954345703

Evaluating:  43%|████▎     | 99/228 [00:43<00:54,  2.36it/s][Astep: 99
extend+tolist() time: 0.0009109973907470703

Evaluating:  44%|████▍     | 100/228 [00:44<00:54,  2.35it/s][Astep: 100
extend+tolist() time: 0.0011353492736816406

Evaluating:  44%|████▍     | 101/228 [00:44<00:53,  2.38it/s][Astep: 101
extend+tolist() time: 0.0007798671722412109

Evaluating:  45%|████▍     | 102/228 [00:45<00:52,  2.39it/s][Astep: 102
extend+tolist() time: 0.0011544227600097656

Evaluating:  45%|████▌     | 103/228 [00:45<00:51,  2.40it/s][Astep: 103
extend+tolist() time: 0.0007953643798828125

Evaluating:  46%|████▌     | 104/228 [00:46<00:50,  2.44it/s][Astep: 104
extend+tolist() time: 0.0013713836669921875

Evaluating:  46%|████▌     | 105/228 [00:46<00:51,  2.39it/s][Astep: 105
extend+tolist() time: 0.0008106231689453125

Evaluating:  46%|████▋     | 106/228 [00:46<00:49,  2.45it/s][Astep: 106
extend+tolist() time: 0.0018222332000732422

Evaluating:  47%|████▋     | 107/228 [00:47<00:50,  2.40it/s][Astep: 107
extend+tolist() time: 0.0007665157318115234

Evaluating:  47%|████▋     | 108/228 [00:47<00:49,  2.40it/s][Astep: 108
extend+tolist() time: 0.0007863044738769531

Evaluating:  48%|████▊     | 109/228 [00:48<00:48,  2.46it/s][Astep: 109
extend+tolist() time: 0.0015709400177001953

Evaluating:  48%|████▊     | 110/228 [00:48<00:48,  2.43it/s][Astep: 110
extend+tolist() time: 0.0006313323974609375

Evaluating:  49%|████▊     | 111/228 [00:48<00:47,  2.48it/s][Astep: 111
extend+tolist() time: 0.0018167495727539062

Evaluating:  49%|████▉     | 112/228 [00:49<00:47,  2.43it/s][Astep: 112
extend+tolist() time: 0.00038313865661621094

Evaluating:  50%|████▉     | 113/228 [00:49<00:46,  2.45it/s][Astep: 113
extend+tolist() time: 0.0006990432739257812

Evaluating:  50%|█████     | 114/228 [00:50<00:45,  2.48it/s][Astep: 114
extend+tolist() time: 0.0011355876922607422

Evaluating:  50%|█████     | 115/228 [00:50<00:46,  2.42it/s][Astep: 115
extend+tolist() time: 0.0011203289031982422

Evaluating:  51%|█████     | 116/228 [00:51<00:53,  2.10it/s][Astep: 116
extend+tolist() time: 0.0008037090301513672

Evaluating:  51%|█████▏    | 117/228 [00:51<00:51,  2.16it/s][Astep: 117
extend+tolist() time: 0.0012645721435546875

Evaluating:  52%|█████▏    | 118/228 [00:52<00:48,  2.28it/s][Astep: 118
extend+tolist() time: 0.0005650520324707031

Evaluating:  52%|█████▏    | 119/228 [00:52<00:47,  2.32it/s][Astep: 119
extend+tolist() time: 0.0006995201110839844

Evaluating:  53%|█████▎    | 120/228 [00:52<00:46,  2.34it/s][Astep: 120
extend+tolist() time: 0.1867821216583252

Evaluating:  53%|█████▎    | 121/228 [00:53<00:50,  2.12it/s][Astep: 121
extend+tolist() time: 0.0006413459777832031

Evaluating:  54%|█████▎    | 122/228 [00:53<00:48,  2.21it/s][Astep: 122
extend+tolist() time: 0.0006594657897949219

Evaluating:  54%|█████▍    | 123/228 [00:54<00:45,  2.32it/s][Astep: 123
extend+tolist() time: 0.0006353855133056641

Evaluating:  54%|█████▍    | 124/228 [00:54<00:44,  2.32it/s][Astep: 124
extend+tolist() time: 0.0012464523315429688

Evaluating:  55%|█████▍    | 125/228 [00:55<00:42,  2.40it/s][Astep: 125
extend+tolist() time: 0.00040411949157714844

Evaluating:  55%|█████▌    | 126/228 [00:55<00:42,  2.42it/s][Astep: 126
extend+tolist() time: 0.0016827583312988281

Evaluating:  56%|█████▌    | 127/228 [00:55<00:42,  2.39it/s][Astep: 127
extend+tolist() time: 0.0016508102416992188

Evaluating:  56%|█████▌    | 128/228 [00:56<00:41,  2.43it/s][Astep: 128
extend+tolist() time: 0.0007529258728027344

Evaluating:  57%|█████▋    | 129/228 [00:56<00:41,  2.38it/s][Astep: 129
extend+tolist() time: 0.0011641979217529297

Evaluating:  57%|█████▋    | 130/228 [00:57<00:40,  2.45it/s][Astep: 130
extend+tolist() time: 0.0009024143218994141

Evaluating:  57%|█████▋    | 131/228 [00:57<00:39,  2.43it/s][Astep: 131
extend+tolist() time: 0.0004451274871826172

Evaluating:  58%|█████▊    | 132/228 [00:57<00:39,  2.45it/s][Astep: 132
extend+tolist() time: 0.0010533332824707031

Evaluating:  58%|█████▊    | 133/228 [00:58<00:38,  2.48it/s][Astep: 133
extend+tolist() time: 0.0009093284606933594

Evaluating:  59%|█████▉    | 134/228 [00:58<00:38,  2.42it/s][Astep: 134
extend+tolist() time: 0.0009429454803466797

Evaluating:  59%|█████▉    | 135/228 [00:59<00:37,  2.47it/s][Astep: 135
extend+tolist() time: 0.0008225440979003906

Evaluating:  60%|█████▉    | 136/228 [00:59<00:37,  2.48it/s][Astep: 136
extend+tolist() time: 0.0007863044738769531

Evaluating:  60%|██████    | 137/228 [00:59<00:36,  2.47it/s][Astep: 137
extend+tolist() time: 0.0003788471221923828

Evaluating:  61%|██████    | 138/228 [01:00<00:35,  2.54it/s][Astep: 138
extend+tolist() time: 0.001399993896484375

Evaluating:  61%|██████    | 139/228 [01:00<00:36,  2.46it/s][Astep: 139
extend+tolist() time: 0.00044655799865722656

Evaluating:  61%|██████▏   | 140/228 [01:01<00:34,  2.53it/s][Astep: 140
extend+tolist() time: 0.0007455348968505859

Evaluating:  62%|██████▏   | 141/228 [01:01<00:34,  2.50it/s][Astep: 141
extend+tolist() time: 0.0012102127075195312

Evaluating:  62%|██████▏   | 142/228 [01:01<00:34,  2.50it/s][Astep: 142
extend+tolist() time: 0.0005362033843994141

Evaluating:  63%|██████▎   | 143/228 [01:02<00:33,  2.56it/s][Astep: 143
extend+tolist() time: 0.00034332275390625

Evaluating:  63%|██████▎   | 144/228 [01:02<00:33,  2.53it/s][Astep: 144
extend+tolist() time: 0.0011379718780517578

Evaluating:  64%|██████▎   | 145/228 [01:03<00:33,  2.50it/s][Astep: 145
extend+tolist() time: 0.0005338191986083984

Evaluating:  64%|██████▍   | 146/228 [01:03<00:37,  2.18it/s][Astep: 146
extend+tolist() time: 0.00040721893310546875

Evaluating:  64%|██████▍   | 147/228 [01:04<00:35,  2.27it/s][Astep: 147
extend+tolist() time: 0.0012176036834716797

Evaluating:  65%|██████▍   | 148/228 [01:04<00:34,  2.35it/s][Astep: 148
extend+tolist() time: 0.0007557868957519531

Evaluating:  65%|██████▌   | 149/228 [01:04<00:33,  2.37it/s][Astep: 149
extend+tolist() time: 0.000396728515625

Evaluating:  66%|██████▌   | 150/228 [01:05<00:31,  2.46it/s][Astep: 150
extend+tolist() time: 0.0013713836669921875

Evaluating:  66%|██████▌   | 151/228 [01:05<00:31,  2.45it/s][Astep: 151
extend+tolist() time: 0.0006613731384277344

Evaluating:  67%|██████▋   | 152/228 [01:06<00:30,  2.47it/s][Astep: 152
extend+tolist() time: 0.001291036605834961

Evaluating:  67%|██████▋   | 153/228 [01:06<00:29,  2.53it/s][Astep: 153
extend+tolist() time: 0.0010449886322021484

Evaluating:  68%|██████▊   | 154/228 [01:06<00:31,  2.38it/s][Astep: 154
extend+tolist() time: 0.001986265182495117

Evaluating:  68%|██████▊   | 155/228 [01:07<00:30,  2.41it/s][Astep: 155
extend+tolist() time: 0.0010640621185302734

Evaluating:  68%|██████▊   | 156/228 [01:07<00:34,  2.09it/s][Astep: 156
extend+tolist() time: 0.0005297660827636719

Evaluating:  69%|██████▉   | 157/228 [01:08<00:31,  2.24it/s][Astep: 157
extend+tolist() time: 0.0007679462432861328

Evaluating:  69%|██████▉   | 158/228 [01:08<00:30,  2.30it/s][Astep: 158
extend+tolist() time: 0.0009033679962158203

Evaluating:  70%|██████▉   | 159/228 [01:09<00:29,  2.34it/s][Astep: 159
extend+tolist() time: 0.0006899833679199219

Evaluating:  70%|███████   | 160/228 [01:09<00:28,  2.37it/s][Astep: 160
extend+tolist() time: 0.00040984153747558594

Evaluating:  71%|███████   | 161/228 [01:09<00:28,  2.39it/s][Astep: 161
extend+tolist() time: 0.0012371540069580078

Evaluating:  71%|███████   | 162/228 [01:10<00:26,  2.46it/s][Astep: 162
extend+tolist() time: 0.0005154609680175781

Evaluating:  71%|███████▏  | 163/228 [01:10<00:26,  2.46it/s][Astep: 163
extend+tolist() time: 0.00042128562927246094

Evaluating:  72%|███████▏  | 164/228 [01:11<00:25,  2.49it/s][Astep: 164
extend+tolist() time: 0.0005984306335449219

Evaluating:  72%|███████▏  | 165/228 [01:11<00:24,  2.54it/s][Astep: 165
extend+tolist() time: 0.0009424686431884766

Evaluating:  73%|███████▎  | 166/228 [01:11<00:25,  2.43it/s][Astep: 166
extend+tolist() time: 0.0004010200500488281

Evaluating:  73%|███████▎  | 167/228 [01:12<00:24,  2.51it/s][Astep: 167
extend+tolist() time: 0.0005855560302734375

Evaluating:  74%|███████▎  | 168/228 [01:12<00:24,  2.50it/s][Astep: 168
extend+tolist() time: 0.0016567707061767578

Evaluating:  74%|███████▍  | 169/228 [01:13<00:23,  2.48it/s][Astep: 169
extend+tolist() time: 0.0003726482391357422

Evaluating:  75%|███████▍  | 170/228 [01:13<00:22,  2.53it/s][Astep: 170
extend+tolist() time: 0.0009489059448242188

Evaluating:  75%|███████▌  | 171/228 [01:13<00:23,  2.45it/s][Astep: 171
extend+tolist() time: 0.0002892017364501953

Evaluating:  75%|███████▌  | 172/228 [01:14<00:22,  2.51it/s][Astep: 172
extend+tolist() time: 0.0012946128845214844

Evaluating:  76%|███████▌  | 173/228 [01:14<00:22,  2.46it/s][Astep: 173
extend+tolist() time: 0.0015091896057128906

Evaluating:  76%|███████▋  | 174/228 [01:15<00:22,  2.43it/s][Astep: 174
extend+tolist() time: 0.0014858245849609375

Evaluating:  77%|███████▋  | 175/228 [01:15<00:21,  2.44it/s][Astep: 175
extend+tolist() time: 0.0012662410736083984

Evaluating:  77%|███████▋  | 176/228 [01:16<00:21,  2.38it/s][Astep: 176
extend+tolist() time: 0.0006527900695800781

Evaluating:  78%|███████▊  | 177/228 [01:16<00:20,  2.46it/s][Astep: 177
extend+tolist() time: 0.0009775161743164062

Evaluating:  78%|███████▊  | 178/228 [01:16<00:20,  2.45it/s][Astep: 178
extend+tolist() time: 0.0012392997741699219

Evaluating:  79%|███████▊  | 179/228 [01:17<00:20,  2.45it/s][Astep: 179
extend+tolist() time: 0.00045752525329589844

Evaluating:  79%|███████▉  | 180/228 [01:17<00:19,  2.52it/s][Astep: 180
extend+tolist() time: 0.0012011528015136719

Evaluating:  79%|███████▉  | 181/228 [01:18<00:19,  2.46it/s][Astep: 181
extend+tolist() time: 0.0006115436553955078

Evaluating:  80%|███████▉  | 182/228 [01:18<00:18,  2.52it/s][Astep: 182
extend+tolist() time: 0.000766754150390625

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.45it/s][Astep: 183
extend+tolist() time: 0.0010857582092285156

Evaluating:  81%|████████  | 184/228 [01:19<00:18,  2.44it/s][Astep: 184
extend+tolist() time: 0.00047278404235839844

Evaluating:  81%|████████  | 185/228 [01:19<00:17,  2.49it/s][Astep: 185
extend+tolist() time: 0.0015153884887695312

Evaluating:  82%|████████▏ | 186/228 [01:20<00:17,  2.38it/s][Astep: 186
extend+tolist() time: 0.001058816909790039

Evaluating:  82%|████████▏ | 187/228 [01:20<00:16,  2.42it/s][Astep: 187
extend+tolist() time: 0.0004513263702392578

Evaluating:  82%|████████▏ | 188/228 [01:20<00:16,  2.42it/s][Astep: 188
extend+tolist() time: 0.0012116432189941406

Evaluating:  83%|████████▎ | 189/228 [01:21<00:16,  2.42it/s][Astep: 189
extend+tolist() time: 0.0003886222839355469

Evaluating:  83%|████████▎ | 190/228 [01:21<00:15,  2.47it/s][Astep: 190
extend+tolist() time: 0.0015642642974853516

Evaluating:  84%|████████▍ | 191/228 [01:22<00:15,  2.38it/s][Astep: 191
extend+tolist() time: 0.0007023811340332031

Evaluating:  84%|████████▍ | 192/228 [01:22<00:14,  2.45it/s][Astep: 192
extend+tolist() time: 0.0004608631134033203

Evaluating:  85%|████████▍ | 193/228 [01:22<00:14,  2.44it/s][Astep: 193
extend+tolist() time: 0.001489877700805664

Evaluating:  85%|████████▌ | 194/228 [01:23<00:14,  2.43it/s][Astep: 194
extend+tolist() time: 0.0006160736083984375

Evaluating:  86%|████████▌ | 195/228 [01:23<00:13,  2.45it/s][Astep: 195
extend+tolist() time: 0.0005357265472412109

Evaluating:  86%|████████▌ | 196/228 [01:24<00:15,  2.06it/s][Astep: 196
extend+tolist() time: 0.0010230541229248047

Evaluating:  86%|████████▋ | 197/228 [01:24<00:14,  2.18it/s][Astep: 197
extend+tolist() time: 0.0006420612335205078

Evaluating:  87%|████████▋ | 198/228 [01:25<00:13,  2.23it/s][Astep: 198
extend+tolist() time: 0.0006096363067626953

Evaluating:  87%|████████▋ | 199/228 [01:25<00:12,  2.30it/s][Astep: 199
extend+tolist() time: 0.0021657943725585938

Evaluating:  88%|████████▊ | 200/228 [01:26<00:12,  2.25it/s][Astep: 200
extend+tolist() time: 0.0007157325744628906

Evaluating:  88%|████████▊ | 201/228 [01:26<00:11,  2.33it/s][Astep: 201
extend+tolist() time: 0.0005996227264404297

Evaluating:  89%|████████▊ | 202/228 [01:26<00:11,  2.35it/s][Astep: 202
extend+tolist() time: 0.00042247772216796875

Evaluating:  89%|████████▉ | 203/228 [01:27<00:10,  2.35it/s][Astep: 203
extend+tolist() time: 0.0004930496215820312

Evaluating:  89%|████████▉ | 204/228 [01:27<00:09,  2.42it/s][Astep: 204
extend+tolist() time: 0.00038743019104003906

Evaluating:  90%|████████▉ | 205/228 [01:28<00:09,  2.36it/s][Astep: 205
extend+tolist() time: 0.0007662773132324219

Evaluating:  90%|█████████ | 206/228 [01:28<00:09,  2.42it/s][Astep: 206
extend+tolist() time: 0.0005915164947509766

Evaluating:  91%|█████████ | 207/228 [01:29<00:10,  2.02it/s][Astep: 207
extend+tolist() time: 0.0006058216094970703

Evaluating:  91%|█████████ | 208/228 [01:29<00:09,  2.16it/s][Astep: 208
extend+tolist() time: 0.0010519027709960938

Evaluating:  92%|█████████▏| 209/228 [01:30<00:08,  2.19it/s][Astep: 209
extend+tolist() time: 0.0005698204040527344

Evaluating:  92%|█████████▏| 210/228 [01:30<00:08,  2.24it/s][Astep: 210
extend+tolist() time: 0.0009217262268066406

Evaluating:  93%|█████████▎| 211/228 [01:30<00:07,  2.31it/s][Astep: 211
extend+tolist() time: 0.0010628700256347656

Evaluating:  93%|█████████▎| 212/228 [01:31<00:07,  2.28it/s][Astep: 212
extend+tolist() time: 0.0012352466583251953

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.36it/s][Astep: 213
extend+tolist() time: 0.0007305145263671875

Evaluating:  94%|█████████▍| 214/228 [01:32<00:05,  2.37it/s][Astep: 214
extend+tolist() time: 0.001219034194946289

Evaluating:  94%|█████████▍| 215/228 [01:32<00:05,  2.38it/s][Astep: 215
extend+tolist() time: 0.0006411075592041016

Evaluating:  95%|█████████▍| 216/228 [01:33<00:05,  2.38it/s][Astep: 216
extend+tolist() time: 0.0005631446838378906

Evaluating:  95%|█████████▌| 217/228 [01:33<00:04,  2.39it/s][Astep: 217
extend+tolist() time: 0.0009324550628662109

Evaluating:  96%|█████████▌| 218/228 [01:33<00:04,  2.44it/s][Astep: 218
extend+tolist() time: 0.001257181167602539

Evaluating:  96%|█████████▌| 219/228 [01:34<00:03,  2.39it/s][Astep: 219
extend+tolist() time: 0.000484466552734375

Evaluating:  96%|█████████▋| 220/228 [01:34<00:03,  2.46it/s][Astep: 220
extend+tolist() time: 0.000823974609375

Evaluating:  97%|█████████▋| 221/228 [01:35<00:02,  2.45it/s][Astep: 221
extend+tolist() time: 0.0006480216979980469

Evaluating:  97%|█████████▋| 222/228 [01:35<00:02,  2.45it/s][Astep: 222
extend+tolist() time: 0.00042724609375

Evaluating:  98%|█████████▊| 223/228 [01:35<00:01,  2.51it/s][Astep: 223
extend+tolist() time: 0.00037598609924316406

Evaluating:  98%|█████████▊| 224/228 [01:36<00:01,  2.47it/s][Astep: 224
extend+tolist() time: 0.0007827281951904297

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.46it/s][Astep: 225
extend+tolist() time: 0.0004429817199707031

Evaluating:  99%|█████████▉| 226/228 [01:37<00:00,  2.49it/s][Astep: 226
extend+tolist() time: 0.0005550384521484375

Evaluating: 100%|█████████▉| 227/228 [01:37<00:00,  2.45it/s][Astep: 227
extend+tolist() time: 0.00048422813415527344

Evaluating: 100%|██████████| 228/228 [01:37<00:00,  2.46it/s][A09/08/2023 23:22:34 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:22:35 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:22:36 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:22:36 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:22:36 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:39<00:00,  2.29it/s]
09/08/2023 23:22:36 - INFO - __main__ -   Step: 1600, Validation Metrics: {'pred_1_num': 9273, 'pred_-1_num': 1482, 'pred_0_num': 46, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.775298583464494, 'f1_micro': 0.775298583464494, 'f1_macro': 0.4411350922199236, 'f1_weighted': 0.7513767333543938, 'f1_-1': 0.39107611548556426, 'f1_0': 0.06423357664233577, 'f1_1': 0.8680955845318709, 'precision_micro': 0.775298583464494, 'precision_macro': 0.5722756287265193, 'precision_weighted': 0.7522583730478247, 'precision_-1': 0.40215924426450744, 'precision_0': 0.4782608695652174, 'precision_1': 0.8364067723498328, 'recall_micro': 0.775298583464494, 'recall_macro': 0.43909880310703153, 'recall_weighted': 0.775298583464494, 'recall_-1': 0.38058748403575987, 'recall_0': 0.03442879499217527, 'recall_1': 0.9022801302931596, 'roc_auc_micro': 0.9126022816196395, 'roc_auc_macro': 0.7519260037015091, 'roc_auc_weighted': 0.7322634316547947, 'roc_auc_-1': 0.8051619726441899, 'roc_auc_0': 0.7315824796358461, 'roc_auc_1': 0.7190335588244916}
[2023-09-08 23:22:57,508] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1601/66600 [2:00:07<917:58:08, 50.84s/it]09/08/2023 23:22:57 - INFO - __main__ -   Step: 1601, LR: 1.6032044060583302e-05, Loss: 0.5001907348632812
[2023-09-08 23:23:17,562] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1602/66600 [2:00:27<751:11:21, 41.61s/it]09/08/2023 23:23:17 - INFO - __main__ -   Step: 1602, LR: 1.6042057829515583e-05, Loss: 0.44818350672721863
[2023-09-08 23:23:38,604] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1603/66600 [2:00:48<639:47:47, 35.44s/it]09/08/2023 23:23:38 - INFO - __main__ -   Step: 1603, LR: 1.605207159844787e-05, Loss: 0.4598131775856018
[2023-09-08 23:23:59,116] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1604/66600 [2:01:08<558:57:18, 30.96s/it]09/08/2023 23:23:59 - INFO - __main__ -   Step: 1604, LR: 1.606208536738015e-05, Loss: 0.44686999917030334
[2023-09-08 23:24:19,952] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1605/66600 [2:01:29<504:06:43, 27.92s/it]09/08/2023 23:24:19 - INFO - __main__ -   Step: 1605, LR: 1.607209913631243e-05, Loss: 0.39656469225883484
[2023-09-08 23:24:40,471] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1606/66600 [2:01:50<464:00:23, 25.70s/it]09/08/2023 23:24:40 - INFO - __main__ -   Step: 1606, LR: 1.6082112905244713e-05, Loss: 0.40352481603622437
[2023-09-08 23:25:00,803] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1607/66600 [2:02:10<434:55:19, 24.09s/it]09/08/2023 23:25:00 - INFO - __main__ -   Step: 1607, LR: 1.6092126674176995e-05, Loss: 0.420571506023407
[2023-09-08 23:25:21,543] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1608/66600 [2:02:31<416:46:01, 23.09s/it]09/08/2023 23:25:21 - INFO - __main__ -   Step: 1608, LR: 1.6102140443109276e-05, Loss: 0.4070125222206116
[2023-09-08 23:25:41,960] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1609/66600 [2:02:51<402:18:45, 22.29s/it]09/08/2023 23:25:41 - INFO - __main__ -   Step: 1609, LR: 1.6112154212041558e-05, Loss: 0.4676974415779114
[2023-09-08 23:26:02,761] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1610/66600 [2:03:12<394:15:56, 21.84s/it]09/08/2023 23:26:02 - INFO - __main__ -   Step: 1610, LR: 1.612216798097384e-05, Loss: 0.3851556181907654
[2023-09-08 23:26:23,714] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1611/66600 [2:03:33<389:27:30, 21.57s/it]09/08/2023 23:26:23 - INFO - __main__ -   Step: 1611, LR: 1.613218174990612e-05, Loss: 0.3971783518791199
[2023-09-08 23:26:43,800] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1612/66600 [2:03:53<381:23:46, 21.13s/it]09/08/2023 23:26:43 - INFO - __main__ -   Step: 1612, LR: 1.6142195518838403e-05, Loss: 0.4119311571121216
[2023-09-08 23:27:04,006] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1613/66600 [2:04:13<376:23:52, 20.85s/it]09/08/2023 23:27:04 - INFO - __main__ -   Step: 1613, LR: 1.6152209287770684e-05, Loss: 0.4502013623714447
[2023-09-08 23:27:24,562] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1614/66600 [2:04:34<374:47:45, 20.76s/it]09/08/2023 23:27:24 - INFO - __main__ -   Step: 1614, LR: 1.616222305670297e-05, Loss: 0.43040353059768677
[2023-09-08 23:27:45,767] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1615/66600 [2:04:55<377:11:13, 20.90s/it]09/08/2023 23:27:45 - INFO - __main__ -   Step: 1615, LR: 1.617223682563525e-05, Loss: 0.4389633536338806
[2023-09-08 23:28:06,319] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1616/66600 [2:05:15<375:19:32, 20.79s/it]09/08/2023 23:28:06 - INFO - __main__ -   Step: 1616, LR: 1.6182250594567533e-05, Loss: 0.444680392742157
[2023-09-08 23:28:27,352] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1617/66600 [2:05:36<376:37:16, 20.86s/it]09/08/2023 23:28:27 - INFO - __main__ -   Step: 1617, LR: 1.6192264363499814e-05, Loss: 0.38493382930755615
[2023-09-08 23:28:48,234] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1618/66600 [2:05:57<376:42:47, 20.87s/it]09/08/2023 23:28:48 - INFO - __main__ -   Step: 1618, LR: 1.6202278132432096e-05, Loss: 0.431203156709671
[2023-09-08 23:29:08,605] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1619/66600 [2:06:18<374:00:20, 20.72s/it]09/08/2023 23:29:08 - INFO - __main__ -   Step: 1619, LR: 1.6212291901364377e-05, Loss: 0.46980947256088257
[2023-09-08 23:29:28,529] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1620/66600 [2:06:38<369:41:11, 20.48s/it]09/08/2023 23:29:28 - INFO - __main__ -   Step: 1620, LR: 1.622230567029666e-05, Loss: 0.41169363260269165
09/08/2023 23:29:28 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0019245147705078125

Evaluating:   0%|          | 1/228 [00:00<01:52,  2.01it/s][Astep: 1
extend+tolist() time: 0.0010788440704345703

Evaluating:   1%|          | 2/228 [00:00<01:37,  2.31it/s][Astep: 2
extend+tolist() time: 0.0022330284118652344

Evaluating:   1%|▏         | 3/228 [00:01<01:53,  1.98it/s][Astep: 3
extend+tolist() time: 0.001963376998901367

Evaluating:   2%|▏         | 4/228 [00:01<01:43,  2.16it/s][Astep: 4
extend+tolist() time: 0.0010466575622558594

Evaluating:   2%|▏         | 5/228 [00:02<01:49,  2.04it/s][Astep: 5
extend+tolist() time: 0.0023717880249023438

Evaluating:   3%|▎         | 6/228 [00:02<01:42,  2.17it/s][Astep: 6
extend+tolist() time: 0.0019621849060058594

Evaluating:   3%|▎         | 7/228 [00:03<01:40,  2.19it/s][Astep: 7
extend+tolist() time: 0.001383066177368164

Evaluating:   4%|▎         | 8/228 [00:03<01:36,  2.29it/s][Astep: 8
extend+tolist() time: 0.0007565021514892578

Evaluating:   4%|▍         | 9/228 [00:04<01:32,  2.37it/s][Astep: 9
extend+tolist() time: 0.0012500286102294922

Evaluating:   4%|▍         | 10/228 [00:04<01:32,  2.36it/s][Astep: 10
extend+tolist() time: 0.0012423992156982422

Evaluating:   5%|▍         | 11/228 [00:04<01:29,  2.41it/s][Astep: 11
extend+tolist() time: 0.0005817413330078125

Evaluating:   5%|▌         | 12/228 [00:05<01:30,  2.39it/s][Astep: 12
extend+tolist() time: 0.0006802082061767578

Evaluating:   6%|▌         | 13/228 [00:05<01:28,  2.42it/s][Astep: 13
extend+tolist() time: 0.001043081283569336

Evaluating:   6%|▌         | 14/228 [00:06<01:27,  2.45it/s][Astep: 14
extend+tolist() time: 0.0005514621734619141

Evaluating:   7%|▋         | 15/228 [00:06<01:27,  2.43it/s][Astep: 15
extend+tolist() time: 0.0006113052368164062

Evaluating:   7%|▋         | 16/228 [00:06<01:25,  2.47it/s][Astep: 16
extend+tolist() time: 0.16782021522521973

Evaluating:   7%|▋         | 17/228 [00:07<01:46,  1.99it/s][Astep: 17
extend+tolist() time: 0.0009090900421142578

Evaluating:   8%|▊         | 18/228 [00:08<01:38,  2.13it/s][Astep: 18
extend+tolist() time: 0.0015716552734375

Evaluating:   8%|▊         | 19/228 [00:08<01:35,  2.18it/s][Astep: 19
extend+tolist() time: 0.0013136863708496094

Evaluating:   9%|▉         | 20/228 [00:08<01:31,  2.27it/s][Astep: 20
extend+tolist() time: 0.0007526874542236328

Evaluating:   9%|▉         | 21/228 [00:09<01:30,  2.29it/s][Astep: 21
extend+tolist() time: 0.0010364055633544922

Evaluating:  10%|▉         | 22/228 [00:09<01:27,  2.36it/s][Astep: 22
extend+tolist() time: 0.0007224082946777344

Evaluating:  10%|█         | 23/228 [00:10<01:24,  2.42it/s][Astep: 23
extend+tolist() time: 0.0011072158813476562

Evaluating:  11%|█         | 24/228 [00:10<01:25,  2.40it/s][Astep: 24
extend+tolist() time: 0.0014622211456298828

Evaluating:  11%|█         | 25/228 [00:10<01:23,  2.42it/s][Astep: 25
extend+tolist() time: 0.0014379024505615234

Evaluating:  11%|█▏        | 26/228 [00:11<01:24,  2.39it/s][Astep: 26
extend+tolist() time: 0.0012063980102539062

Evaluating:  12%|█▏        | 27/228 [00:11<01:22,  2.44it/s][Astep: 27
extend+tolist() time: 0.0016970634460449219

Evaluating:  12%|█▏        | 28/228 [00:12<01:21,  2.44it/s][Astep: 28
extend+tolist() time: 0.00032973289489746094

Evaluating:  13%|█▎        | 29/228 [00:12<01:31,  2.17it/s][Astep: 29
extend+tolist() time: 0.0007009506225585938

Evaluating:  13%|█▎        | 30/228 [00:13<01:27,  2.27it/s][Astep: 30
extend+tolist() time: 0.0015778541564941406

Evaluating:  14%|█▎        | 31/228 [00:13<01:26,  2.28it/s][Astep: 31
extend+tolist() time: 0.000579833984375

Evaluating:  14%|█▍        | 32/228 [00:13<01:23,  2.36it/s][Astep: 32
extend+tolist() time: 0.00138092041015625

Evaluating:  14%|█▍        | 33/228 [00:14<01:22,  2.36it/s][Astep: 33
extend+tolist() time: 0.0016222000122070312

Evaluating:  15%|█▍        | 34/228 [00:14<01:32,  2.11it/s][Astep: 34
extend+tolist() time: 0.0008687973022460938

Evaluating:  15%|█▌        | 35/228 [00:15<01:28,  2.19it/s][Astep: 35
extend+tolist() time: 0.0010905265808105469

Evaluating:  16%|█▌        | 36/228 [00:15<01:24,  2.26it/s][Astep: 36
extend+tolist() time: 0.0008077621459960938

Evaluating:  16%|█▌        | 37/228 [00:16<01:21,  2.34it/s][Astep: 37
extend+tolist() time: 0.0017337799072265625

Evaluating:  17%|█▋        | 38/228 [00:16<01:22,  2.29it/s][Astep: 38
extend+tolist() time: 0.0011098384857177734

Evaluating:  17%|█▋        | 39/228 [00:17<01:19,  2.36it/s][Astep: 39
extend+tolist() time: 0.0007169246673583984

Evaluating:  18%|█▊        | 40/228 [00:17<01:20,  2.34it/s][Astep: 40
extend+tolist() time: 0.0010564327239990234

Evaluating:  18%|█▊        | 41/228 [00:17<01:17,  2.40it/s][Astep: 41
extend+tolist() time: 0.0008335113525390625

Evaluating:  18%|█▊        | 42/228 [00:18<01:16,  2.44it/s][Astep: 42
extend+tolist() time: 0.0016782283782958984

Evaluating:  19%|█▉        | 43/228 [00:18<01:18,  2.37it/s][Astep: 43
extend+tolist() time: 0.0018253326416015625

Evaluating:  19%|█▉        | 44/228 [00:19<01:17,  2.39it/s][Astep: 44
extend+tolist() time: 0.0007429122924804688

Evaluating:  20%|█▉        | 45/228 [00:19<01:17,  2.35it/s][Astep: 45
extend+tolist() time: 0.0018076896667480469

Evaluating:  20%|██        | 46/228 [00:19<01:16,  2.38it/s][Astep: 46
extend+tolist() time: 0.001861572265625

Evaluating:  21%|██        | 47/228 [00:20<01:16,  2.38it/s][Astep: 47
extend+tolist() time: 0.1532735824584961

Evaluating:  21%|██        | 48/228 [00:20<01:23,  2.15it/s][Astep: 48
extend+tolist() time: 0.0017774105072021484

Evaluating:  21%|██▏       | 49/228 [00:21<01:20,  2.21it/s][Astep: 49
extend+tolist() time: 0.0009119510650634766

Evaluating:  22%|██▏       | 50/228 [00:21<01:18,  2.26it/s][Astep: 50
extend+tolist() time: 0.0016047954559326172

Evaluating:  22%|██▏       | 51/228 [00:22<01:16,  2.31it/s][Astep: 51
extend+tolist() time: 0.0015273094177246094

Evaluating:  23%|██▎       | 52/228 [00:22<01:17,  2.28it/s][Astep: 52
extend+tolist() time: 0.0013470649719238281

Evaluating:  23%|██▎       | 53/228 [00:23<01:14,  2.35it/s][Astep: 53
extend+tolist() time: 0.001628875732421875

Evaluating:  24%|██▎       | 54/228 [00:23<01:14,  2.33it/s][Astep: 54
extend+tolist() time: 0.00079345703125

Evaluating:  24%|██▍       | 55/228 [00:23<01:12,  2.39it/s][Astep: 55
extend+tolist() time: 0.0011811256408691406

Evaluating:  25%|██▍       | 56/228 [00:24<01:10,  2.44it/s][Astep: 56
extend+tolist() time: 0.0011534690856933594

Evaluating:  25%|██▌       | 57/228 [00:24<01:12,  2.37it/s][Astep: 57
extend+tolist() time: 0.0010564327239990234

Evaluating:  25%|██▌       | 58/228 [00:25<01:09,  2.44it/s][Astep: 58
extend+tolist() time: 0.0008745193481445312

Evaluating:  26%|██▌       | 59/228 [00:25<01:10,  2.40it/s][Astep: 59
extend+tolist() time: 0.0013735294342041016

Evaluating:  26%|██▋       | 60/228 [00:25<01:09,  2.41it/s][Astep: 60
extend+tolist() time: 0.0007257461547851562

Evaluating:  27%|██▋       | 61/228 [00:26<01:17,  2.14it/s][Astep: 61
extend+tolist() time: 0.0012505054473876953

Evaluating:  27%|██▋       | 62/228 [00:26<01:14,  2.23it/s][Astep: 62
extend+tolist() time: 0.0007648468017578125

Evaluating:  28%|██▊       | 63/228 [00:27<01:11,  2.32it/s][Astep: 63
extend+tolist() time: 0.0012636184692382812

Evaluating:  28%|██▊       | 64/228 [00:27<01:11,  2.30it/s][Astep: 64
extend+tolist() time: 0.0007967948913574219

Evaluating:  29%|██▊       | 65/228 [00:28<01:08,  2.37it/s][Astep: 65
extend+tolist() time: 0.0012221336364746094

Evaluating:  29%|██▉       | 66/228 [00:28<01:08,  2.36it/s][Astep: 66
extend+tolist() time: 0.0007543563842773438

Evaluating:  29%|██▉       | 67/228 [00:28<01:07,  2.38it/s][Astep: 67
extend+tolist() time: 0.0013217926025390625

Evaluating:  30%|██▉       | 68/228 [00:29<01:15,  2.13it/s][Astep: 68
extend+tolist() time: 0.0006761550903320312

Evaluating:  30%|███       | 69/228 [00:29<01:11,  2.22it/s][Astep: 69
extend+tolist() time: 0.0014905929565429688

Evaluating:  31%|███       | 70/228 [00:30<01:08,  2.30it/s][Astep: 70
extend+tolist() time: 0.0014410018920898438

Evaluating:  31%|███       | 71/228 [00:30<01:09,  2.26it/s][Astep: 71
extend+tolist() time: 0.0009419918060302734

Evaluating:  32%|███▏      | 72/228 [00:31<01:06,  2.34it/s][Astep: 72
extend+tolist() time: 0.0007770061492919922

Evaluating:  32%|███▏      | 73/228 [00:31<01:07,  2.31it/s][Astep: 73
extend+tolist() time: 0.0005233287811279297

Evaluating:  32%|███▏      | 74/228 [00:32<01:04,  2.39it/s][Astep: 74
extend+tolist() time: 0.0012552738189697266

Evaluating:  33%|███▎      | 75/228 [00:32<01:02,  2.44it/s][Astep: 75
extend+tolist() time: 0.0016446113586425781

Evaluating:  33%|███▎      | 76/228 [00:32<01:04,  2.34it/s][Astep: 76
extend+tolist() time: 0.0006279945373535156

Evaluating:  34%|███▍      | 77/228 [00:33<01:02,  2.42it/s][Astep: 77
extend+tolist() time: 0.0018086433410644531

Evaluating:  34%|███▍      | 78/228 [00:33<01:04,  2.34it/s][Astep: 78
extend+tolist() time: 0.0011742115020751953

Evaluating:  35%|███▍      | 79/228 [00:34<01:02,  2.40it/s][Astep: 79
extend+tolist() time: 0.0011112689971923828

Evaluating:  35%|███▌      | 80/228 [00:34<01:01,  2.41it/s][Astep: 80
extend+tolist() time: 0.0013489723205566406

Evaluating:  36%|███▌      | 81/228 [00:34<01:01,  2.39it/s][Astep: 81
extend+tolist() time: 0.0008463859558105469

Evaluating:  36%|███▌      | 82/228 [00:35<00:59,  2.45it/s][Astep: 82
extend+tolist() time: 0.0012929439544677734

Evaluating:  36%|███▋      | 83/228 [00:35<01:01,  2.37it/s][Astep: 83
extend+tolist() time: 0.0006763935089111328

Evaluating:  37%|███▋      | 84/228 [00:36<00:59,  2.44it/s][Astep: 84
extend+tolist() time: 0.0014064311981201172

Evaluating:  37%|███▋      | 85/228 [00:36<00:58,  2.44it/s][Astep: 85
extend+tolist() time: 0.000888824462890625

Evaluating:  38%|███▊      | 86/228 [00:37<00:58,  2.41it/s][Astep: 86
extend+tolist() time: 0.18270087242126465

Evaluating:  38%|███▊      | 87/228 [00:37<01:13,  1.92it/s][Astep: 87
extend+tolist() time: 0.0013358592987060547

Evaluating:  39%|███▊      | 88/228 [00:38<01:07,  2.07it/s][Astep: 88
extend+tolist() time: 0.0009093284606933594

Evaluating:  39%|███▉      | 89/228 [00:38<01:03,  2.17it/s][Astep: 89
extend+tolist() time: 0.0010991096496582031

Evaluating:  39%|███▉      | 90/228 [00:39<01:02,  2.21it/s][Astep: 90
extend+tolist() time: 0.0009219646453857422

Evaluating:  40%|███▉      | 91/228 [00:39<00:59,  2.30it/s][Astep: 91
extend+tolist() time: 0.0007538795471191406

Evaluating:  40%|████      | 92/228 [00:39<00:59,  2.28it/s][Astep: 92
extend+tolist() time: 0.0011591911315917969

Evaluating:  41%|████      | 93/228 [00:40<00:57,  2.35it/s][Astep: 93
extend+tolist() time: 0.0009763240814208984

Evaluating:  41%|████      | 94/228 [00:40<00:57,  2.34it/s][Astep: 94
extend+tolist() time: 0.0011181831359863281

Evaluating:  42%|████▏     | 95/228 [00:41<00:55,  2.38it/s][Astep: 95
extend+tolist() time: 0.0011439323425292969

Evaluating:  42%|████▏     | 96/228 [00:41<00:54,  2.41it/s][Astep: 96
extend+tolist() time: 0.0013451576232910156

Evaluating:  43%|████▎     | 97/228 [00:41<00:55,  2.37it/s][Astep: 97
extend+tolist() time: 0.0011403560638427734

Evaluating:  43%|████▎     | 98/228 [00:42<00:53,  2.42it/s][Astep: 98
extend+tolist() time: 0.0009064674377441406

Evaluating:  43%|████▎     | 99/228 [00:42<00:53,  2.40it/s][Astep: 99
extend+tolist() time: 0.0013282299041748047

Evaluating:  44%|████▍     | 100/228 [00:43<00:53,  2.41it/s][Astep: 100
extend+tolist() time: 0.0007052421569824219

Evaluating:  44%|████▍     | 101/228 [00:43<00:51,  2.45it/s][Astep: 101
extend+tolist() time: 0.0012950897216796875

Evaluating:  45%|████▍     | 102/228 [00:44<00:52,  2.40it/s][Astep: 102
extend+tolist() time: 0.0006997585296630859

Evaluating:  45%|████▌     | 103/228 [00:44<00:50,  2.48it/s][Astep: 103
extend+tolist() time: 0.0011527538299560547

Evaluating:  46%|████▌     | 104/228 [00:44<00:50,  2.48it/s][Astep: 104
extend+tolist() time: 0.0007040500640869141

Evaluating:  46%|████▌     | 105/228 [00:45<00:56,  2.18it/s][Astep: 105
extend+tolist() time: 0.0012712478637695312

Evaluating:  46%|████▋     | 106/228 [00:45<00:53,  2.27it/s][Astep: 106
extend+tolist() time: 0.0013134479522705078

Evaluating:  47%|████▋     | 107/228 [00:46<00:52,  2.31it/s][Astep: 107
extend+tolist() time: 0.0012357234954833984

Evaluating:  47%|████▋     | 108/228 [00:46<00:49,  2.41it/s][Astep: 108
extend+tolist() time: 0.0007767677307128906

Evaluating:  48%|████▊     | 109/228 [00:46<00:49,  2.41it/s][Astep: 109
extend+tolist() time: 0.0012509822845458984

Evaluating:  48%|████▊     | 110/228 [00:47<00:47,  2.48it/s][Astep: 110
extend+tolist() time: 0.0006248950958251953

Evaluating:  49%|████▊     | 111/228 [00:47<00:46,  2.54it/s][Astep: 111
extend+tolist() time: 0.0018279552459716797

Evaluating:  49%|████▉     | 112/228 [00:48<00:47,  2.43it/s][Astep: 112
extend+tolist() time: 0.0007534027099609375

Evaluating:  50%|████▉     | 113/228 [00:48<00:52,  2.20it/s][Astep: 113
extend+tolist() time: 0.0006890296936035156

Evaluating:  50%|█████     | 114/228 [00:49<00:50,  2.24it/s][Astep: 114
extend+tolist() time: 0.0015485286712646484

Evaluating:  50%|█████     | 115/228 [00:49<00:48,  2.32it/s][Astep: 115
extend+tolist() time: 0.0006525516510009766

Evaluating:  51%|█████     | 116/228 [00:49<00:47,  2.33it/s][Astep: 116
extend+tolist() time: 0.0012493133544921875

Evaluating:  51%|█████▏    | 117/228 [00:50<00:46,  2.39it/s][Astep: 117
extend+tolist() time: 0.0008075237274169922

Evaluating:  52%|█████▏    | 118/228 [00:50<00:44,  2.46it/s][Astep: 118
extend+tolist() time: 0.0009865760803222656

Evaluating:  52%|█████▏    | 119/228 [00:51<00:45,  2.41it/s][Astep: 119
extend+tolist() time: 0.0007119178771972656

Evaluating:  53%|█████▎    | 120/228 [00:51<00:43,  2.48it/s][Astep: 120
extend+tolist() time: 0.0006215572357177734

Evaluating:  53%|█████▎    | 121/228 [00:51<00:43,  2.45it/s][Astep: 121
extend+tolist() time: 0.001102447509765625

Evaluating:  54%|█████▎    | 122/228 [00:52<00:42,  2.48it/s][Astep: 122
extend+tolist() time: 0.0006651878356933594

Evaluating:  54%|█████▍    | 123/228 [00:52<00:41,  2.53it/s][Astep: 123
extend+tolist() time: 0.0010120868682861328

Evaluating:  54%|█████▍    | 124/228 [00:53<00:42,  2.46it/s][Astep: 124
extend+tolist() time: 0.0008022785186767578

Evaluating:  55%|█████▍    | 125/228 [00:53<00:40,  2.53it/s][Astep: 125
extend+tolist() time: 0.0004303455352783203

Evaluating:  55%|█████▌    | 126/228 [00:53<00:40,  2.50it/s][Astep: 126
extend+tolist() time: 0.0017769336700439453

Evaluating:  56%|█████▌    | 127/228 [00:54<00:40,  2.49it/s][Astep: 127
extend+tolist() time: 0.001657247543334961

Evaluating:  56%|█████▌    | 128/228 [00:54<00:39,  2.52it/s][Astep: 128
extend+tolist() time: 0.0007085800170898438

Evaluating:  57%|█████▋    | 129/228 [00:55<00:40,  2.45it/s][Astep: 129
extend+tolist() time: 0.0016994476318359375

Evaluating:  57%|█████▋    | 130/228 [00:55<00:39,  2.50it/s][Astep: 130
extend+tolist() time: 0.0012433528900146484

Evaluating:  57%|█████▋    | 131/228 [00:55<00:39,  2.48it/s][Astep: 131
extend+tolist() time: 0.00045871734619140625

Evaluating:  58%|█████▊    | 132/228 [00:56<00:38,  2.51it/s][Astep: 132
extend+tolist() time: 0.001043558120727539

Evaluating:  58%|█████▊    | 133/228 [00:56<00:37,  2.54it/s][Astep: 133
extend+tolist() time: 0.0009348392486572266

Evaluating:  59%|█████▉    | 134/228 [00:57<00:38,  2.46it/s][Astep: 134
extend+tolist() time: 0.0009679794311523438

Evaluating:  59%|█████▉    | 135/228 [00:57<00:37,  2.50it/s][Astep: 135
extend+tolist() time: 0.0009162425994873047

Evaluating:  60%|█████▉    | 136/228 [00:57<00:36,  2.50it/s][Astep: 136
extend+tolist() time: 0.0008001327514648438

Evaluating:  60%|██████    | 137/228 [00:58<00:36,  2.48it/s][Astep: 137
extend+tolist() time: 0.0003833770751953125

Evaluating:  61%|██████    | 138/228 [00:58<00:35,  2.55it/s][Astep: 138
extend+tolist() time: 0.0012247562408447266

Evaluating:  61%|██████    | 139/228 [00:59<00:35,  2.47it/s][Astep: 139
extend+tolist() time: 0.0004513263702392578

Evaluating:  61%|██████▏   | 140/228 [00:59<00:34,  2.54it/s][Astep: 140
extend+tolist() time: 0.0007476806640625

Evaluating:  62%|██████▏   | 141/228 [00:59<00:33,  2.57it/s][Astep: 141
extend+tolist() time: 0.0007274150848388672

Evaluating:  62%|██████▏   | 142/228 [01:00<00:34,  2.48it/s][Astep: 142
extend+tolist() time: 0.000553131103515625

Evaluating:  63%|██████▎   | 143/228 [01:00<00:33,  2.54it/s][Astep: 143
extend+tolist() time: 0.00034499168395996094

Evaluating:  63%|██████▎   | 144/228 [01:01<00:38,  2.18it/s][Astep: 144
extend+tolist() time: 0.25046515464782715

Evaluating:  64%|██████▎   | 145/228 [01:01<00:42,  1.97it/s][Astep: 145
extend+tolist() time: 0.0004918575286865234

Evaluating:  64%|██████▍   | 146/228 [01:02<00:39,  2.05it/s][Astep: 146
extend+tolist() time: 0.0007982254028320312

Evaluating:  64%|██████▍   | 147/228 [01:02<00:37,  2.18it/s][Astep: 147
extend+tolist() time: 0.0007607936859130859

Evaluating:  65%|██████▍   | 148/228 [01:03<00:36,  2.20it/s][Astep: 148
extend+tolist() time: 0.0010581016540527344

Evaluating:  65%|██████▌   | 149/228 [01:03<00:34,  2.29it/s][Astep: 149
extend+tolist() time: 0.0004131793975830078

Evaluating:  66%|██████▌   | 150/228 [01:04<00:33,  2.32it/s][Astep: 150
extend+tolist() time: 0.0009212493896484375

Evaluating:  66%|██████▌   | 151/228 [01:04<00:33,  2.32it/s][Astep: 151
extend+tolist() time: 0.0010788440704345703

Evaluating:  67%|██████▋   | 152/228 [01:04<00:31,  2.38it/s][Astep: 152
extend+tolist() time: 0.000919342041015625

Evaluating:  67%|██████▋   | 153/228 [01:05<00:32,  2.31it/s][Astep: 153
extend+tolist() time: 0.0014104843139648438

Evaluating:  68%|██████▊   | 154/228 [01:05<00:31,  2.37it/s][Astep: 154
extend+tolist() time: 0.0020062923431396484

Evaluating:  68%|██████▊   | 155/228 [01:06<00:31,  2.31it/s][Astep: 155
extend+tolist() time: 0.0006926059722900391

Evaluating:  68%|██████▊   | 156/228 [01:06<00:30,  2.35it/s][Astep: 156
extend+tolist() time: 0.0005903244018554688

Evaluating:  69%|██████▉   | 157/228 [01:06<00:29,  2.42it/s][Astep: 157
extend+tolist() time: 0.0011203289031982422

Evaluating:  69%|██████▉   | 158/228 [01:07<00:29,  2.35it/s][Astep: 158
extend+tolist() time: 0.0005142688751220703

Evaluating:  70%|██████▉   | 159/228 [01:07<00:28,  2.42it/s][Astep: 159
extend+tolist() time: 0.0007567405700683594

Evaluating:  70%|███████   | 160/228 [01:08<00:28,  2.39it/s][Astep: 160
extend+tolist() time: 0.0008218288421630859

Evaluating:  71%|███████   | 161/228 [01:08<00:27,  2.43it/s][Astep: 161
extend+tolist() time: 0.0008211135864257812

Evaluating:  71%|███████   | 162/228 [01:09<00:26,  2.48it/s][Astep: 162
extend+tolist() time: 0.0005064010620117188

Evaluating:  71%|███████▏  | 163/228 [01:09<00:26,  2.41it/s][Astep: 163
extend+tolist() time: 0.00043129920959472656

Evaluating:  72%|███████▏  | 164/228 [01:09<00:25,  2.47it/s][Astep: 164
extend+tolist() time: 0.001027822494506836

Evaluating:  72%|███████▏  | 165/228 [01:10<00:26,  2.42it/s][Astep: 165
extend+tolist() time: 0.0004551410675048828

Evaluating:  73%|███████▎  | 166/228 [01:10<00:25,  2.42it/s][Astep: 166
extend+tolist() time: 0.0004012584686279297

Evaluating:  73%|███████▎  | 167/228 [01:11<00:24,  2.47it/s][Astep: 167
extend+tolist() time: 0.0005896091461181641

Evaluating:  74%|███████▎  | 168/228 [01:11<00:24,  2.41it/s][Astep: 168
extend+tolist() time: 0.0016357898712158203

Evaluating:  74%|███████▍  | 169/228 [01:11<00:24,  2.44it/s][Astep: 169
extend+tolist() time: 0.0003795623779296875

Evaluating:  75%|███████▍  | 170/228 [01:12<00:24,  2.41it/s][Astep: 170
extend+tolist() time: 0.0012969970703125

Evaluating:  75%|███████▌  | 171/228 [01:12<00:23,  2.43it/s][Astep: 171
extend+tolist() time: 0.0003204345703125

Evaluating:  75%|███████▌  | 172/228 [01:13<00:22,  2.48it/s][Astep: 172
extend+tolist() time: 0.0008223056793212891

Evaluating:  76%|███████▌  | 173/228 [01:13<00:22,  2.40it/s][Astep: 173
extend+tolist() time: 0.0016379356384277344

Evaluating:  76%|███████▋  | 174/228 [01:13<00:22,  2.43it/s][Astep: 174
extend+tolist() time: 0.0018379688262939453

Evaluating:  77%|███████▋  | 175/228 [01:14<00:22,  2.35it/s][Astep: 175
extend+tolist() time: 0.0008139610290527344

Evaluating:  77%|███████▋  | 176/228 [01:15<00:25,  2.01it/s][Astep: 176
extend+tolist() time: 0.0010361671447753906

Evaluating:  78%|███████▊  | 177/228 [01:15<00:24,  2.09it/s][Astep: 177
extend+tolist() time: 0.0006148815155029297

Evaluating:  78%|███████▊  | 178/228 [01:15<00:22,  2.23it/s][Astep: 178
extend+tolist() time: 0.0016245841979980469

Evaluating:  79%|███████▊  | 179/228 [01:16<00:21,  2.23it/s][Astep: 179
extend+tolist() time: 0.0004165172576904297

Evaluating:  79%|███████▉  | 180/228 [01:16<00:20,  2.29it/s][Astep: 180
extend+tolist() time: 0.0003859996795654297

Evaluating:  79%|███████▉  | 181/228 [01:17<00:19,  2.37it/s][Astep: 181
extend+tolist() time: 0.0006284713745117188

Evaluating:  80%|███████▉  | 182/228 [01:17<00:19,  2.33it/s][Astep: 182
extend+tolist() time: 0.0012216567993164062

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.39it/s][Astep: 183
extend+tolist() time: 0.0006330013275146484

Evaluating:  81%|████████  | 184/228 [01:18<00:18,  2.36it/s][Astep: 184
extend+tolist() time: 0.0004839897155761719

Evaluating:  81%|████████  | 185/228 [01:18<00:18,  2.38it/s][Astep: 185
extend+tolist() time: 0.00151824951171875

Evaluating:  82%|████████▏ | 186/228 [01:19<00:17,  2.44it/s][Astep: 186
extend+tolist() time: 0.0013725757598876953

Evaluating:  82%|████████▏ | 187/228 [01:19<00:17,  2.38it/s][Astep: 187
extend+tolist() time: 0.0004603862762451172

Evaluating:  82%|████████▏ | 188/228 [01:20<00:16,  2.46it/s][Astep: 188
extend+tolist() time: 0.000667572021484375

Evaluating:  83%|████████▎ | 189/228 [01:20<00:16,  2.43it/s][Astep: 189
extend+tolist() time: 0.00035190582275390625

Evaluating:  83%|████████▎ | 190/228 [01:20<00:15,  2.47it/s][Astep: 190
extend+tolist() time: 0.0015757083892822266

Evaluating:  84%|████████▍ | 191/228 [01:21<00:14,  2.50it/s][Astep: 191
extend+tolist() time: 0.000701904296875

Evaluating:  84%|████████▍ | 192/228 [01:21<00:14,  2.42it/s][Astep: 192
extend+tolist() time: 0.0010540485382080078

Evaluating:  85%|████████▍ | 193/228 [01:22<00:16,  2.09it/s][Astep: 193
extend+tolist() time: 0.0010442733764648438

Evaluating:  85%|████████▌ | 194/228 [01:22<00:15,  2.19it/s][Astep: 194
extend+tolist() time: 0.0005950927734375

Evaluating:  86%|████████▌ | 195/228 [01:23<00:14,  2.32it/s][Astep: 195
extend+tolist() time: 0.0005400180816650391

Evaluating:  86%|████████▌ | 196/228 [01:23<00:13,  2.31it/s][Astep: 196
extend+tolist() time: 0.0006089210510253906

Evaluating:  86%|████████▋ | 197/228 [01:23<00:13,  2.36it/s][Astep: 197
extend+tolist() time: 0.0009999275207519531

Evaluating:  87%|████████▋ | 198/228 [01:24<00:12,  2.38it/s][Astep: 198
extend+tolist() time: 0.0010547637939453125

Evaluating:  87%|████████▋ | 199/228 [01:24<00:12,  2.38it/s][Astep: 199
extend+tolist() time: 0.001875162124633789

Evaluating:  88%|████████▊ | 200/228 [01:25<00:11,  2.40it/s][Astep: 200
extend+tolist() time: 0.00069427490234375

Evaluating:  88%|████████▊ | 201/228 [01:25<00:11,  2.34it/s][Astep: 201
extend+tolist() time: 0.0006198883056640625

Evaluating:  89%|████████▊ | 202/228 [01:26<00:10,  2.42it/s][Astep: 202
extend+tolist() time: 0.000400543212890625

Evaluating:  89%|████████▉ | 203/228 [01:26<00:10,  2.41it/s][Astep: 203
extend+tolist() time: 0.0009753704071044922

Evaluating:  89%|████████▉ | 204/228 [01:26<00:09,  2.40it/s][Astep: 204
extend+tolist() time: 0.0004162788391113281

Evaluating:  90%|████████▉ | 205/228 [01:27<00:09,  2.46it/s][Astep: 205
extend+tolist() time: 0.0003077983856201172

Evaluating:  90%|█████████ | 206/228 [01:27<00:09,  2.39it/s][Astep: 206
extend+tolist() time: 0.0005970001220703125

Evaluating:  91%|█████████ | 207/228 [01:28<00:08,  2.45it/s][Astep: 207
extend+tolist() time: 0.001055002212524414

Evaluating:  91%|█████████ | 208/228 [01:28<00:08,  2.43it/s][Astep: 208
extend+tolist() time: 0.0007009506225585938

Evaluating:  92%|█████████▏| 209/228 [01:28<00:07,  2.42it/s][Astep: 209
extend+tolist() time: 0.0006103515625

Evaluating:  92%|█████████▏| 210/228 [01:29<00:07,  2.46it/s][Astep: 210
extend+tolist() time: 0.0011026859283447266

Evaluating:  93%|█████████▎| 211/228 [01:29<00:07,  2.38it/s][Astep: 211
extend+tolist() time: 0.0011560916900634766

Evaluating:  93%|█████████▎| 212/228 [01:30<00:06,  2.42it/s][Astep: 212
extend+tolist() time: 0.0013566017150878906

Evaluating:  93%|█████████▎| 213/228 [01:30<00:06,  2.40it/s][Astep: 213
extend+tolist() time: 0.0007526874542236328

Evaluating:  94%|█████████▍| 214/228 [01:30<00:05,  2.43it/s][Astep: 214
extend+tolist() time: 0.0012569427490234375

Evaluating:  94%|█████████▍| 215/228 [01:31<00:05,  2.47it/s][Astep: 215
extend+tolist() time: 0.000667572021484375

Evaluating:  95%|█████████▍| 216/228 [01:31<00:05,  2.39it/s][Astep: 216
extend+tolist() time: 0.0005619525909423828

Evaluating:  95%|█████████▌| 217/228 [01:32<00:04,  2.46it/s][Astep: 217
extend+tolist() time: 0.0009713172912597656

Evaluating:  96%|█████████▌| 218/228 [01:32<00:04,  2.44it/s][Astep: 218
extend+tolist() time: 0.0010523796081542969

Evaluating:  96%|█████████▌| 219/228 [01:33<00:03,  2.45it/s][Astep: 219
extend+tolist() time: 0.0009377002716064453

Evaluating:  96%|█████████▋| 220/228 [01:33<00:03,  2.49it/s][Astep: 220
extend+tolist() time: 0.0003972053527832031

Evaluating:  97%|█████████▋| 221/228 [01:33<00:02,  2.41it/s][Astep: 221
extend+tolist() time: 0.0006663799285888672

Evaluating:  97%|█████████▋| 222/228 [01:34<00:02,  2.45it/s][Astep: 222
extend+tolist() time: 0.00042700767517089844

Evaluating:  98%|█████████▊| 223/228 [01:34<00:02,  2.41it/s][Astep: 223
extend+tolist() time: 0.00039315223693847656

Evaluating:  98%|█████████▊| 224/228 [01:35<00:01,  2.43it/s][Astep: 224
extend+tolist() time: 0.00036835670471191406

Evaluating:  99%|█████████▊| 225/228 [01:35<00:01,  2.48it/s][Astep: 225
extend+tolist() time: 0.00042438507080078125

Evaluating:  99%|█████████▉| 226/228 [01:35<00:00,  2.40it/s][Astep: 226
extend+tolist() time: 0.0005457401275634766

Evaluating: 100%|█████████▉| 227/228 [01:36<00:00,  2.44it/s][Astep: 227
extend+tolist() time: 0.0004968643188476562

Evaluating: 100%|██████████| 228/228 [01:36<00:00,  2.34it/s][A09/08/2023 23:31:05 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 23:31:05 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:31:05 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:31:06 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:31:06 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:31:06 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:31:06 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:31:06 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:31:06 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:31:06 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:31:06 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:31:06 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:31:06 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:31:07 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-75672db8-b763-46b8-911a-860169883760-1-0.arrow
09/08/2023 23:31:07 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:31:07 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:31:08 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:39<00:00,  2.29it/s]
09/08/2023 23:31:08 - INFO - __main__ -   Step: 1620, Validation Metrics: {'pred_1_num': 9997, 'pred_-1_num': 769, 'pred_0_num': 35, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.8006666049439867, 'f1_micro': 0.8006666049439867, 'f1_macro': 0.42530849332856097, 'f1_weighted': 0.7570513302638208, 'f1_-1': 0.3331905781584582, 'f1_0': 0.05637982195845697, 'f1_1': 0.8863550798687678, 'precision_micro': 0.8006666049439867, 'precision_macro': 0.6243187241886851, 'precision_weighted': 0.7614368236562468, 'precision_-1': 0.505851755526658, 'precision_0': 0.5428571428571428, 'precision_1': 0.8242472741822546, 'recall_micro': 0.8006666049439867, 'recall_macro': 0.4122409746180074, 'recall_weighted': 0.8006666049439867, 'recall_-1': 0.24840357598978288, 'recall_0': 0.0297339593114241, 'recall_1': 0.9585853885528153, 'roc_auc_micro': 0.9202526223688633, 'roc_auc_macro': 0.7587562493010047, 'roc_auc_weighted': 0.740207311174161, 'roc_auc_-1': 0.8136307470400034, 'roc_auc_0': 0.7354534167765454, 'roc_auc_1': 0.7271845840864654}
[2023-09-08 23:31:28,717] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1621/66600 [2:08:38<909:35:02, 50.39s/it]09/08/2023 23:31:28 - INFO - __main__ -   Step: 1621, LR: 1.623231943922894e-05, Loss: 0.39169466495513916
[2023-09-08 23:31:49,401] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1622/66600 [2:08:58<748:41:59, 41.48s/it]09/08/2023 23:31:49 - INFO - __main__ -   Step: 1622, LR: 1.6242333208161222e-05, Loss: 0.4112791121006012
[2023-09-08 23:32:10,369] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1623/66600 [2:09:19<637:36:59, 35.33s/it]09/08/2023 23:32:10 - INFO - __main__ -   Step: 1623, LR: 1.6252346977093504e-05, Loss: 0.48687368631362915
[2023-09-08 23:32:30,671] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1624/66600 [2:09:40<556:15:06, 30.82s/it]09/08/2023 23:32:30 - INFO - __main__ -   Step: 1624, LR: 1.6262360746025785e-05, Loss: 0.41131216287612915
[2023-09-08 23:32:51,507] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1625/66600 [2:10:01<502:11:32, 27.82s/it]09/08/2023 23:32:51 - INFO - __main__ -   Step: 1625, LR: 1.627237451495807e-05, Loss: 0.3838690519332886
[2023-09-08 23:33:12,627] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1626/66600 [2:10:22<465:52:56, 25.81s/it]09/08/2023 23:33:12 - INFO - __main__ -   Step: 1626, LR: 1.6282388283890352e-05, Loss: 0.36112895607948303
[2023-09-08 23:33:33,564] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1627/66600 [2:10:43<439:28:29, 24.35s/it]09/08/2023 23:33:33 - INFO - __main__ -   Step: 1627, LR: 1.6292402052822634e-05, Loss: 0.39583486318588257
[2023-09-08 23:33:54,321] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1628/66600 [2:11:03<420:00:53, 23.27s/it]09/08/2023 23:33:54 - INFO - __main__ -   Step: 1628, LR: 1.6302415821754912e-05, Loss: 0.36120831966400146
[2023-09-08 23:34:15,173] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1629/66600 [2:11:24<406:53:58, 22.55s/it]09/08/2023 23:34:15 - INFO - __main__ -   Step: 1629, LR: 1.6312429590687197e-05, Loss: 0.37471699714660645
[2023-09-08 23:34:35,811] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1630/66600 [2:11:45<396:33:45, 21.97s/it]09/08/2023 23:34:35 - INFO - __main__ -   Step: 1630, LR: 1.632244335961948e-05, Loss: 0.37884700298309326
[2023-09-08 23:34:56,556] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1631/66600 [2:12:06<389:54:31, 21.61s/it]09/08/2023 23:34:56 - INFO - __main__ -   Step: 1631, LR: 1.633245712855176e-05, Loss: 0.40386447310447693
[2023-09-08 23:35:16,882] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1632/66600 [2:12:26<382:58:32, 21.22s/it]09/08/2023 23:35:16 - INFO - __main__ -   Step: 1632, LR: 1.634247089748404e-05, Loss: 0.45432883501052856
[2023-09-08 23:35:37,513] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1633/66600 [2:12:47<379:46:31, 21.04s/it]09/08/2023 23:35:37 - INFO - __main__ -   Step: 1633, LR: 1.6352484666416323e-05, Loss: 0.31507471203804016
[2023-09-08 23:35:58,608] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1634/66600 [2:13:08<380:02:35, 21.06s/it]09/08/2023 23:35:58 - INFO - __main__ -   Step: 1634, LR: 1.6362498435348605e-05, Loss: 0.31399184465408325
[2023-09-08 23:36:19,309] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1635/66600 [2:13:28<378:05:45, 20.95s/it]09/08/2023 23:36:19 - INFO - __main__ -   Step: 1635, LR: 1.637251220428089e-05, Loss: 0.36786308884620667
[2023-09-08 23:36:40,618] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1636/66600 [2:13:50<380:01:19, 21.06s/it]09/08/2023 23:36:40 - INFO - __main__ -   Step: 1636, LR: 1.638252597321317e-05, Loss: 0.36351755261421204
[2023-09-08 23:37:01,765] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1637/66600 [2:14:11<380:29:32, 21.09s/it]09/08/2023 23:37:01 - INFO - __main__ -   Step: 1637, LR: 1.6392539742145453e-05, Loss: 0.4284932613372803
[2023-09-08 23:37:21,863] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1638/66600 [2:14:31<375:08:29, 20.79s/it]09/08/2023 23:37:21 - INFO - __main__ -   Step: 1638, LR: 1.640255351107773e-05, Loss: 0.43299949169158936
[2023-09-08 23:37:42,420] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1639/66600 [2:14:51<373:52:44, 20.72s/it]09/08/2023 23:37:42 - INFO - __main__ -   Step: 1639, LR: 1.6412567280010013e-05, Loss: 0.46429914236068726
[2023-09-08 23:38:03,508] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1640/66600 [2:15:13<375:51:47, 20.83s/it]09/08/2023 23:38:03 - INFO - __main__ -   Step: 1640, LR: 1.6422581048942298e-05, Loss: 0.41940611600875854
09/08/2023 23:38:03 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0028731822967529297

Evaluating:   0%|          | 1/228 [00:00<01:53,  2.00it/s][Astep: 1
extend+tolist() time: 0.0015900135040283203

Evaluating:   1%|          | 2/228 [00:00<01:41,  2.22it/s][Astep: 2
extend+tolist() time: 0.0016870498657226562

Evaluating:   1%|▏         | 3/228 [00:01<01:38,  2.27it/s][Astep: 3
extend+tolist() time: 0.0022301673889160156

Evaluating:   2%|▏         | 4/228 [00:01<01:37,  2.31it/s][Astep: 4
extend+tolist() time: 0.0015497207641601562

Evaluating:   2%|▏         | 5/228 [00:02<01:35,  2.34it/s][Astep: 5
extend+tolist() time: 0.0021135807037353516

Evaluating:   3%|▎         | 6/228 [00:02<01:45,  2.11it/s][Astep: 6
extend+tolist() time: 0.0019369125366210938

Evaluating:   3%|▎         | 7/228 [00:03<01:49,  2.01it/s][Astep: 7
extend+tolist() time: 0.000997781753540039

Evaluating:   4%|▎         | 8/228 [00:03<01:44,  2.11it/s][Astep: 8
extend+tolist() time: 0.0012254714965820312

Evaluating:   4%|▍         | 9/228 [00:04<01:39,  2.21it/s][Astep: 9
extend+tolist() time: 0.0008149147033691406

Evaluating:   4%|▍         | 10/228 [00:04<01:36,  2.25it/s][Astep: 10
extend+tolist() time: 0.0013484954833984375

Evaluating:   5%|▍         | 11/228 [00:04<01:33,  2.31it/s][Astep: 11
extend+tolist() time: 0.0005488395690917969

Evaluating:   5%|▌         | 12/228 [00:05<01:31,  2.37it/s][Astep: 12
extend+tolist() time: 0.0010776519775390625

Evaluating:   6%|▌         | 13/228 [00:05<01:29,  2.40it/s][Astep: 13
extend+tolist() time: 0.0005698204040527344

Evaluating:   6%|▌         | 14/228 [00:06<01:27,  2.43it/s][Astep: 14
extend+tolist() time: 0.0005636215209960938

Evaluating:   7%|▋         | 15/228 [00:06<01:37,  2.18it/s][Astep: 15
extend+tolist() time: 0.14352798461914062

Evaluating:   7%|▋         | 16/228 [00:07<01:42,  2.07it/s][Astep: 16
extend+tolist() time: 0.0006368160247802734

Evaluating:   7%|▋         | 17/228 [00:07<01:38,  2.14it/s][Astep: 17
extend+tolist() time: 0.0013267993927001953

Evaluating:   8%|▊         | 18/228 [00:08<01:34,  2.22it/s][Astep: 18
extend+tolist() time: 0.0014998912811279297

Evaluating:   8%|▊         | 19/228 [00:08<01:33,  2.23it/s][Astep: 19
extend+tolist() time: 0.0009629726409912109

Evaluating:   9%|▉         | 20/228 [00:08<01:30,  2.31it/s][Astep: 20
extend+tolist() time: 0.0011448860168457031

Evaluating:   9%|▉         | 21/228 [00:09<01:26,  2.38it/s][Astep: 21
extend+tolist() time: 0.0006608963012695312

Evaluating:  10%|▉         | 22/228 [00:09<01:27,  2.35it/s][Astep: 22
extend+tolist() time: 0.0011987686157226562

Evaluating:  10%|█         | 23/228 [00:10<01:26,  2.38it/s][Astep: 23
extend+tolist() time: 0.0007002353668212891

Evaluating:  11%|█         | 24/228 [00:10<01:26,  2.36it/s][Astep: 24
extend+tolist() time: 0.0015988349914550781

Evaluating:  11%|█         | 25/228 [00:11<01:25,  2.36it/s][Astep: 25
extend+tolist() time: 0.0018699169158935547

Evaluating:  11%|█▏        | 26/228 [00:11<01:25,  2.36it/s][Astep: 26
extend+tolist() time: 0.0007557868957519531

Evaluating:  12%|█▏        | 27/228 [00:11<01:24,  2.39it/s][Astep: 27
extend+tolist() time: 0.0017578601837158203

Evaluating:  12%|█▏        | 28/228 [00:12<01:23,  2.38it/s][Astep: 28
extend+tolist() time: 0.00033283233642578125

Evaluating:  13%|█▎        | 29/228 [00:12<01:24,  2.37it/s][Astep: 29
extend+tolist() time: 0.0011286735534667969

Evaluating:  13%|█▎        | 30/228 [00:13<01:22,  2.40it/s][Astep: 30
extend+tolist() time: 0.0010862350463867188

Evaluating:  14%|█▎        | 31/228 [00:13<01:23,  2.37it/s][Astep: 31
extend+tolist() time: 0.0008144378662109375

Evaluating:  14%|█▍        | 32/228 [00:13<01:22,  2.37it/s][Astep: 32
extend+tolist() time: 0.001007080078125

Evaluating:  14%|█▍        | 33/228 [00:14<01:20,  2.41it/s][Astep: 33
extend+tolist() time: 0.0012655258178710938

Evaluating:  15%|█▍        | 34/228 [00:14<01:22,  2.35it/s][Astep: 34
extend+tolist() time: 0.0013861656188964844

Evaluating:  15%|█▌        | 35/228 [00:15<01:21,  2.37it/s][Astep: 35
extend+tolist() time: 0.0006911754608154297

Evaluating:  16%|█▌        | 36/228 [00:15<01:30,  2.13it/s][Astep: 36
extend+tolist() time: 0.0012450218200683594

Evaluating:  16%|█▌        | 37/228 [00:16<01:35,  2.00it/s][Astep: 37
extend+tolist() time: 0.001630544662475586

Evaluating:  17%|█▋        | 38/228 [00:16<01:32,  2.06it/s][Astep: 38
extend+tolist() time: 0.00075531005859375

Evaluating:  17%|█▋        | 39/228 [00:17<01:27,  2.16it/s][Astep: 39
extend+tolist() time: 0.00110626220703125

Evaluating:  18%|█▊        | 40/228 [00:17<01:25,  2.19it/s][Astep: 40
extend+tolist() time: 0.0006406307220458984

Evaluating:  18%|█▊        | 41/228 [00:18<01:22,  2.26it/s][Astep: 41
extend+tolist() time: 0.0008661746978759766

Evaluating:  18%|█▊        | 42/228 [00:18<01:20,  2.30it/s][Astep: 42
extend+tolist() time: 0.001739501953125

Evaluating:  19%|█▉        | 43/228 [00:18<01:21,  2.27it/s][Astep: 43
extend+tolist() time: 0.0018804073333740234

Evaluating:  19%|█▉        | 44/228 [00:19<01:20,  2.29it/s][Astep: 44
extend+tolist() time: 0.001104116439819336

Evaluating:  20%|█▉        | 45/228 [00:19<01:20,  2.28it/s][Astep: 45
extend+tolist() time: 0.0015931129455566406

Evaluating:  20%|██        | 46/228 [00:20<01:18,  2.31it/s][Astep: 46
extend+tolist() time: 0.0012478828430175781

Evaluating:  21%|██        | 47/228 [00:20<01:29,  2.02it/s][Astep: 47
extend+tolist() time: 0.15149927139282227

Evaluating:  21%|██        | 48/228 [00:21<01:33,  1.92it/s][Astep: 48
extend+tolist() time: 0.0017278194427490234

Evaluating:  21%|██▏       | 49/228 [00:21<01:28,  2.01it/s][Astep: 49
extend+tolist() time: 0.0012323856353759766

Evaluating:  22%|██▏       | 50/228 [00:22<01:23,  2.12it/s][Astep: 50
extend+tolist() time: 0.00153350830078125

Evaluating:  22%|██▏       | 51/228 [00:22<01:22,  2.15it/s][Astep: 51
extend+tolist() time: 0.001222848892211914

Evaluating:  23%|██▎       | 52/228 [00:23<01:19,  2.21it/s][Astep: 52
extend+tolist() time: 0.0014238357543945312

Evaluating:  23%|██▎       | 53/228 [00:23<01:16,  2.28it/s][Astep: 53
extend+tolist() time: 0.0016391277313232422

Evaluating:  24%|██▎       | 54/228 [00:24<01:17,  2.25it/s][Astep: 54
extend+tolist() time: 0.0012133121490478516

Evaluating:  24%|██▍       | 55/228 [00:24<01:15,  2.31it/s][Astep: 55
extend+tolist() time: 0.0008094310760498047

Evaluating:  25%|██▍       | 56/228 [00:24<01:13,  2.33it/s][Astep: 56
extend+tolist() time: 0.0016183853149414062

Evaluating:  25%|██▌       | 57/228 [00:25<01:12,  2.36it/s][Astep: 57
extend+tolist() time: 0.000598907470703125

Evaluating:  25%|██▌       | 58/228 [00:25<01:10,  2.40it/s][Astep: 58
extend+tolist() time: 0.0013213157653808594

Evaluating:  26%|██▌       | 59/228 [00:26<01:09,  2.41it/s][Astep: 59
extend+tolist() time: 0.0009374618530273438

Evaluating:  26%|██▋       | 60/228 [00:26<01:09,  2.43it/s][Astep: 60
extend+tolist() time: 0.0011708736419677734

Evaluating:  27%|██▋       | 61/228 [00:26<01:09,  2.41it/s][Astep: 61
extend+tolist() time: 0.0008733272552490234

Evaluating:  27%|██▋       | 62/228 [00:27<01:08,  2.41it/s][Astep: 62
extend+tolist() time: 0.0012552738189697266

Evaluating:  28%|██▊       | 63/228 [00:27<01:08,  2.41it/s][Astep: 63
extend+tolist() time: 0.0013430118560791016

Evaluating:  28%|██▊       | 64/228 [00:28<01:08,  2.40it/s][Astep: 64
extend+tolist() time: 0.0013201236724853516

Evaluating:  29%|██▊       | 65/228 [00:28<01:06,  2.44it/s][Astep: 65
extend+tolist() time: 0.0008063316345214844

Evaluating:  29%|██▉       | 66/228 [00:29<01:07,  2.40it/s][Astep: 66
extend+tolist() time: 0.0011756420135498047

Evaluating:  29%|██▉       | 67/228 [00:29<01:06,  2.42it/s][Astep: 67
extend+tolist() time: 0.0009188652038574219

Evaluating:  30%|██▉       | 68/228 [00:29<01:06,  2.41it/s][Astep: 68
extend+tolist() time: 0.0014033317565917969

Evaluating:  30%|███       | 69/228 [00:30<01:04,  2.45it/s][Astep: 69
extend+tolist() time: 0.001470327377319336

Evaluating:  31%|███       | 70/228 [00:30<01:13,  2.16it/s][Astep: 70
extend+tolist() time: 0.0010874271392822266

Evaluating:  31%|███       | 71/228 [00:31<01:17,  2.02it/s][Astep: 71
extend+tolist() time: 0.0014202594757080078

Evaluating:  32%|███▏      | 72/228 [00:31<01:12,  2.15it/s][Astep: 72
extend+tolist() time: 0.0007472038269042969

Evaluating:  32%|███▏      | 73/228 [00:32<01:08,  2.26it/s][Astep: 73
extend+tolist() time: 0.0009200572967529297

Evaluating:  32%|███▏      | 74/228 [00:32<01:05,  2.34it/s][Astep: 74
extend+tolist() time: 0.0007729530334472656

Evaluating:  33%|███▎      | 75/228 [00:32<01:05,  2.35it/s][Astep: 75
extend+tolist() time: 0.0017385482788085938

Evaluating:  33%|███▎      | 76/228 [00:33<01:04,  2.37it/s][Astep: 76
extend+tolist() time: 0.0006525516510009766

Evaluating:  34%|███▍      | 77/228 [00:33<01:01,  2.45it/s][Astep: 77
extend+tolist() time: 0.0019004344940185547

Evaluating:  34%|███▍      | 78/228 [00:34<01:02,  2.39it/s][Astep: 78
extend+tolist() time: 0.0012276172637939453

Evaluating:  35%|███▍      | 79/228 [00:34<01:01,  2.43it/s][Astep: 79
extend+tolist() time: 0.0013082027435302734

Evaluating:  35%|███▌      | 80/228 [00:35<01:01,  2.40it/s][Astep: 80
extend+tolist() time: 0.0009517669677734375

Evaluating:  36%|███▌      | 81/228 [00:35<01:00,  2.41it/s][Astep: 81
extend+tolist() time: 0.0013341903686523438

Evaluating:  36%|███▌      | 82/228 [00:35<00:59,  2.43it/s][Astep: 82
extend+tolist() time: 0.0008461475372314453

Evaluating:  36%|███▋      | 83/228 [00:36<00:59,  2.45it/s][Astep: 83
extend+tolist() time: 0.0011560916900634766

Evaluating:  37%|███▋      | 84/228 [00:36<01:07,  2.14it/s][Astep: 84
extend+tolist() time: 0.0010194778442382812

Evaluating:  37%|███▋      | 85/228 [00:37<01:04,  2.23it/s][Astep: 85
extend+tolist() time: 0.17457938194274902

Evaluating:  38%|███▊      | 86/228 [00:37<01:09,  2.06it/s][Astep: 86
extend+tolist() time: 0.0013134479522705078

Evaluating:  38%|███▊      | 87/228 [00:38<01:06,  2.13it/s][Astep: 87
extend+tolist() time: 0.0008630752563476562

Evaluating:  39%|███▊      | 88/228 [00:38<01:02,  2.23it/s][Astep: 88
extend+tolist() time: 0.0011320114135742188

Evaluating:  39%|███▉      | 89/228 [00:39<01:01,  2.26it/s][Astep: 89
extend+tolist() time: 0.0007240772247314453

Evaluating:  39%|███▉      | 90/228 [00:39<00:59,  2.33it/s][Astep: 90
extend+tolist() time: 0.0013914108276367188

Evaluating:  40%|███▉      | 91/228 [00:39<00:57,  2.37it/s][Astep: 91
extend+tolist() time: 0.0007681846618652344

Evaluating:  40%|████      | 92/228 [00:40<00:56,  2.39it/s][Astep: 92
extend+tolist() time: 0.00081634521484375

Evaluating:  41%|████      | 93/228 [00:40<00:55,  2.43it/s][Astep: 93
extend+tolist() time: 0.0014734268188476562

Evaluating:  41%|████      | 94/228 [00:41<00:56,  2.38it/s][Astep: 94
extend+tolist() time: 0.0007662773132324219

Evaluating:  42%|████▏     | 95/228 [00:41<00:55,  2.40it/s][Astep: 95
extend+tolist() time: 0.0016009807586669922

Evaluating:  42%|████▏     | 96/228 [00:42<00:55,  2.37it/s][Astep: 96
extend+tolist() time: 0.0009894371032714844

Evaluating:  43%|████▎     | 97/228 [00:42<00:54,  2.39it/s][Astep: 97
extend+tolist() time: 0.0013189315795898438

Evaluating:  43%|████▎     | 98/228 [00:42<00:53,  2.41it/s][Astep: 98
extend+tolist() time: 0.0012810230255126953

Evaluating:  43%|████▎     | 99/228 [00:43<00:54,  2.37it/s][Astep: 99
extend+tolist() time: 0.0009188652038574219

Evaluating:  44%|████▍     | 100/228 [00:43<00:53,  2.39it/s][Astep: 100
extend+tolist() time: 0.001209259033203125

Evaluating:  44%|████▍     | 101/228 [00:44<00:53,  2.36it/s][Astep: 101
extend+tolist() time: 0.0008254051208496094

Evaluating:  45%|████▍     | 102/228 [00:44<00:53,  2.37it/s][Astep: 102
extend+tolist() time: 0.0011699199676513672

Evaluating:  45%|████▌     | 103/228 [00:44<00:52,  2.40it/s][Astep: 103
extend+tolist() time: 0.0007855892181396484

Evaluating:  46%|████▌     | 104/228 [00:45<00:52,  2.35it/s][Astep: 104
extend+tolist() time: 0.0007214546203613281

Evaluating:  46%|████▌     | 105/228 [00:45<00:51,  2.37it/s][Astep: 105
extend+tolist() time: 0.0008349418640136719

Evaluating:  46%|████▋     | 106/228 [00:46<00:52,  2.33it/s][Astep: 106
extend+tolist() time: 0.001833200454711914

Evaluating:  47%|████▋     | 107/228 [00:46<00:52,  2.32it/s][Astep: 107
extend+tolist() time: 0.0007941722869873047

Evaluating:  47%|████▋     | 108/228 [00:47<00:51,  2.33it/s][Astep: 108
extend+tolist() time: 0.0014503002166748047

Evaluating:  48%|████▊     | 109/228 [00:47<00:51,  2.33it/s][Astep: 109
extend+tolist() time: 0.0008647441864013672

Evaluating:  48%|████▊     | 110/228 [00:47<00:49,  2.38it/s][Astep: 110
extend+tolist() time: 0.0010895729064941406

Evaluating:  49%|████▊     | 111/228 [00:48<00:49,  2.34it/s][Astep: 111
extend+tolist() time: 0.0018134117126464844

Evaluating:  49%|████▉     | 112/228 [00:48<00:49,  2.33it/s][Astep: 112
extend+tolist() time: 0.00040268898010253906

Evaluating:  50%|████▉     | 113/228 [00:49<00:49,  2.32it/s][Astep: 113
extend+tolist() time: 0.0007312297821044922

Evaluating:  50%|█████     | 114/228 [00:49<00:48,  2.35it/s][Astep: 114
extend+tolist() time: 0.0015997886657714844

Evaluating:  50%|█████     | 115/228 [00:50<00:47,  2.38it/s][Astep: 115
extend+tolist() time: 0.0010743141174316406

Evaluating:  51%|█████     | 116/228 [00:50<00:53,  2.11it/s][Astep: 116
extend+tolist() time: 0.0008618831634521484

Evaluating:  51%|█████▏    | 117/228 [00:51<00:50,  2.22it/s][Astep: 117
extend+tolist() time: 0.0012824535369873047

Evaluating:  52%|█████▏    | 118/228 [00:51<00:49,  2.24it/s][Astep: 118
extend+tolist() time: 0.0005805492401123047

Evaluating:  52%|█████▏    | 119/228 [00:51<00:47,  2.30it/s][Astep: 119
extend+tolist() time: 0.0007412433624267578

Evaluating:  53%|█████▎    | 120/228 [00:52<00:47,  2.29it/s][Astep: 120
extend+tolist() time: 0.0011339187622070312

Evaluating:  53%|█████▎    | 121/228 [00:52<00:45,  2.34it/s][Astep: 121
extend+tolist() time: 0.0006551742553710938

Evaluating:  54%|█████▎    | 122/228 [00:53<00:45,  2.35it/s][Astep: 122
extend+tolist() time: 0.0011398792266845703

Evaluating:  54%|█████▍    | 123/228 [00:53<00:44,  2.37it/s][Astep: 123
extend+tolist() time: 0.0006213188171386719

Evaluating:  54%|█████▍    | 124/228 [00:53<00:43,  2.39it/s][Astep: 124
extend+tolist() time: 0.0007996559143066406

Evaluating:  55%|█████▍    | 125/228 [00:54<00:43,  2.35it/s][Astep: 125
extend+tolist() time: 0.0008878707885742188

Evaluating:  55%|█████▌    | 126/228 [00:54<00:42,  2.40it/s][Astep: 126
extend+tolist() time: 0.0016200542449951172

Evaluating:  56%|█████▌    | 127/228 [00:55<00:42,  2.36it/s][Astep: 127
extend+tolist() time: 0.0012650489807128906

Evaluating:  56%|█████▌    | 128/228 [00:55<00:42,  2.36it/s][Astep: 128
extend+tolist() time: 0.0011587142944335938

Evaluating:  57%|█████▋    | 129/228 [00:56<00:41,  2.41it/s][Astep: 129
extend+tolist() time: 0.0007829666137695312

Evaluating:  57%|█████▋    | 130/228 [00:56<00:41,  2.39it/s][Astep: 130
extend+tolist() time: 0.0013086795806884766

Evaluating:  57%|█████▋    | 131/228 [00:56<00:40,  2.40it/s][Astep: 131
extend+tolist() time: 0.0004665851593017578

Evaluating:  58%|█████▊    | 132/228 [00:57<00:40,  2.38it/s][Astep: 132
extend+tolist() time: 0.0014660358428955078

Evaluating:  58%|█████▊    | 133/228 [00:57<00:39,  2.39it/s][Astep: 133
extend+tolist() time: 0.0004298686981201172

Evaluating:  59%|█████▉    | 134/228 [00:58<00:38,  2.45it/s][Astep: 134
extend+tolist() time: 0.0013811588287353516

Evaluating:  59%|█████▉    | 135/228 [00:58<00:38,  2.40it/s][Astep: 135
extend+tolist() time: 0.0004410743713378906

Evaluating:  60%|█████▉    | 136/228 [00:58<00:37,  2.43it/s][Astep: 136
extend+tolist() time: 0.0012288093566894531

Evaluating:  60%|██████    | 137/228 [00:59<00:44,  2.05it/s][Astep: 137
extend+tolist() time: 0.00038743019104003906

Evaluating:  61%|██████    | 138/228 [01:00<00:41,  2.16it/s][Astep: 138
extend+tolist() time: 0.0007309913635253906

Evaluating:  61%|██████    | 139/228 [01:00<00:40,  2.19it/s][Astep: 139
extend+tolist() time: 0.00047135353088378906

Evaluating:  61%|██████▏   | 140/228 [01:00<00:38,  2.26it/s][Astep: 140
extend+tolist() time: 0.0007483959197998047

Evaluating:  62%|██████▏   | 141/228 [01:01<00:38,  2.25it/s][Astep: 141
extend+tolist() time: 0.001001596450805664

Evaluating:  62%|██████▏   | 142/228 [01:01<00:37,  2.32it/s][Astep: 142
extend+tolist() time: 0.2646512985229492

Evaluating:  63%|██████▎   | 143/228 [01:02<00:42,  2.00it/s][Astep: 143
extend+tolist() time: 0.00033664703369140625

Evaluating:  63%|██████▎   | 144/228 [01:02<00:39,  2.12it/s][Astep: 144
extend+tolist() time: 0.001071929931640625

Evaluating:  64%|██████▎   | 145/228 [01:03<00:37,  2.24it/s][Astep: 145
extend+tolist() time: 0.0004665851593017578

Evaluating:  64%|██████▍   | 146/228 [01:03<00:35,  2.28it/s][Astep: 146
extend+tolist() time: 0.0003807544708251953

Evaluating:  64%|██████▍   | 147/228 [01:04<00:34,  2.33it/s][Astep: 147
extend+tolist() time: 0.0011227130889892578

Evaluating:  65%|██████▍   | 148/228 [01:04<00:34,  2.33it/s][Astep: 148
extend+tolist() time: 0.0006501674652099609

Evaluating:  65%|██████▌   | 149/228 [01:04<00:33,  2.38it/s][Astep: 149
extend+tolist() time: 0.0003390312194824219

Evaluating:  66%|██████▌   | 150/228 [01:05<00:31,  2.44it/s][Astep: 150
extend+tolist() time: 0.0012395381927490234

Evaluating:  66%|██████▌   | 151/228 [01:05<00:32,  2.40it/s][Astep: 151
extend+tolist() time: 0.0005924701690673828

Evaluating:  67%|██████▋   | 152/228 [01:06<00:31,  2.43it/s][Astep: 152
extend+tolist() time: 0.0011968612670898438

Evaluating:  67%|██████▋   | 153/228 [01:06<00:31,  2.39it/s][Astep: 153
extend+tolist() time: 0.0008766651153564453

Evaluating:  68%|██████▊   | 154/228 [01:06<00:30,  2.40it/s][Astep: 154
extend+tolist() time: 0.0018739700317382812

Evaluating:  68%|██████▊   | 155/228 [01:07<00:31,  2.34it/s][Astep: 155
extend+tolist() time: 0.0009806156158447266

Evaluating:  68%|██████▊   | 156/228 [01:07<00:30,  2.38it/s][Astep: 156
extend+tolist() time: 0.0005471706390380859

Evaluating:  69%|██████▉   | 157/228 [01:08<00:29,  2.41it/s][Astep: 157
extend+tolist() time: 0.0006814002990722656

Evaluating:  69%|██████▉   | 158/228 [01:08<00:29,  2.38it/s][Astep: 158
extend+tolist() time: 0.0005218982696533203

Evaluating:  70%|██████▉   | 159/228 [01:09<00:28,  2.41it/s][Astep: 159
extend+tolist() time: 0.001176595687866211

Evaluating:  70%|███████   | 160/228 [01:09<00:28,  2.41it/s][Astep: 160
extend+tolist() time: 0.00040149688720703125

Evaluating:  71%|███████   | 161/228 [01:09<00:27,  2.43it/s][Astep: 161
extend+tolist() time: 0.0007989406585693359

Evaluating:  71%|███████   | 162/228 [01:10<00:27,  2.44it/s][Astep: 162
extend+tolist() time: 0.0009446144104003906

Evaluating:  71%|███████▏  | 163/228 [01:10<00:27,  2.40it/s][Astep: 163
extend+tolist() time: 0.0004055500030517578

Evaluating:  72%|███████▏  | 164/228 [01:11<00:26,  2.42it/s][Astep: 164
extend+tolist() time: 0.0005943775177001953

Evaluating:  72%|███████▏  | 165/228 [01:11<00:26,  2.41it/s][Astep: 165
extend+tolist() time: 0.0004646778106689453

Evaluating:  73%|███████▎  | 166/228 [01:11<00:26,  2.37it/s][Astep: 166
extend+tolist() time: 0.0008649826049804688

Evaluating:  73%|███████▎  | 167/228 [01:12<00:25,  2.43it/s][Astep: 167
extend+tolist() time: 0.0005624294281005859

Evaluating:  74%|███████▎  | 168/228 [01:12<00:24,  2.41it/s][Astep: 168
extend+tolist() time: 0.0016217231750488281

Evaluating:  74%|███████▍  | 169/228 [01:13<00:24,  2.41it/s][Astep: 169
extend+tolist() time: 0.0003857612609863281

Evaluating:  75%|███████▍  | 170/228 [01:13<00:24,  2.39it/s][Astep: 170
extend+tolist() time: 0.0009443759918212891

Evaluating:  75%|███████▌  | 171/228 [01:14<00:23,  2.41it/s][Astep: 171
extend+tolist() time: 0.0003209114074707031

Evaluating:  75%|███████▌  | 172/228 [01:14<00:22,  2.44it/s][Astep: 172
extend+tolist() time: 0.0012900829315185547

Evaluating:  76%|███████▌  | 173/228 [01:14<00:22,  2.40it/s][Astep: 173
extend+tolist() time: 0.001567840576171875

Evaluating:  76%|███████▋  | 174/228 [01:15<00:22,  2.40it/s][Astep: 174
extend+tolist() time: 0.0014655590057373047

Evaluating:  77%|███████▋  | 175/228 [01:15<00:22,  2.34it/s][Astep: 175
extend+tolist() time: 0.00128173828125

Evaluating:  77%|███████▋  | 176/228 [01:16<00:21,  2.38it/s][Astep: 176
extend+tolist() time: 0.0006575584411621094

Evaluating:  78%|███████▊  | 177/228 [01:16<00:20,  2.43it/s][Astep: 177
extend+tolist() time: 0.0006170272827148438

Evaluating:  78%|███████▊  | 178/228 [01:16<00:20,  2.39it/s][Astep: 178
extend+tolist() time: 0.0017368793487548828

Evaluating:  79%|███████▊  | 179/228 [01:17<00:20,  2.39it/s][Astep: 179
extend+tolist() time: 0.00040411949157714844

Evaluating:  79%|███████▉  | 180/228 [01:17<00:20,  2.36it/s][Astep: 180
extend+tolist() time: 0.0007786750793457031

Evaluating:  79%|███████▉  | 181/228 [01:18<00:19,  2.40it/s][Astep: 181
extend+tolist() time: 0.0006394386291503906

Evaluating:  80%|███████▉  | 182/228 [01:18<00:19,  2.39it/s][Astep: 182
extend+tolist() time: 0.0007827281951904297

Evaluating:  80%|████████  | 183/228 [01:19<00:18,  2.41it/s][Astep: 183
extend+tolist() time: 0.0011229515075683594

Evaluating:  81%|████████  | 184/228 [01:19<00:18,  2.44it/s][Astep: 184
extend+tolist() time: 0.00047707557678222656

Evaluating:  81%|████████  | 185/228 [01:19<00:18,  2.39it/s][Astep: 185
extend+tolist() time: 0.0011322498321533203

Evaluating:  82%|████████▏ | 186/228 [01:20<00:17,  2.38it/s][Astep: 186
extend+tolist() time: 0.0015115737915039062

Evaluating:  82%|████████▏ | 187/228 [01:20<00:17,  2.35it/s][Astep: 187
extend+tolist() time: 0.0004885196685791016

Evaluating:  82%|████████▏ | 188/228 [01:21<00:16,  2.38it/s][Astep: 188
extend+tolist() time: 0.0011105537414550781

Evaluating:  83%|████████▎ | 189/228 [01:21<00:16,  2.43it/s][Astep: 189
extend+tolist() time: 0.0003497600555419922

Evaluating:  83%|████████▎ | 190/228 [01:21<00:15,  2.40it/s][Astep: 190
extend+tolist() time: 0.0011687278747558594

Evaluating:  84%|████████▍ | 191/228 [01:22<00:15,  2.38it/s][Astep: 191
extend+tolist() time: 0.0011699199676513672

Evaluating:  84%|████████▍ | 192/228 [01:22<00:15,  2.32it/s][Astep: 192
extend+tolist() time: 0.0004429817199707031

Evaluating:  85%|████████▍ | 193/228 [01:23<00:14,  2.36it/s][Astep: 193
extend+tolist() time: 0.0014405250549316406

Evaluating:  85%|████████▌ | 194/228 [01:23<00:14,  2.35it/s][Astep: 194
extend+tolist() time: 0.0006003379821777344

Evaluating:  86%|████████▌ | 195/228 [01:24<00:13,  2.39it/s][Astep: 195
extend+tolist() time: 0.0005517005920410156

Evaluating:  86%|████████▌ | 196/228 [01:24<00:15,  2.03it/s][Astep: 196
extend+tolist() time: 0.0012500286102294922

Evaluating:  86%|████████▋ | 197/228 [01:25<00:14,  2.13it/s][Astep: 197
extend+tolist() time: 0.0006701946258544922

Evaluating:  87%|████████▋ | 198/228 [01:25<00:13,  2.25it/s][Astep: 198
extend+tolist() time: 0.0006220340728759766

Evaluating:  87%|████████▋ | 199/228 [01:25<00:12,  2.27it/s][Astep: 199
extend+tolist() time: 0.001971721649169922

Evaluating:  88%|████████▊ | 200/228 [01:26<00:12,  2.30it/s][Astep: 200
extend+tolist() time: 0.0007040500640869141

Evaluating:  88%|████████▊ | 201/228 [01:26<00:11,  2.29it/s][Astep: 201
extend+tolist() time: 0.0009958744049072266

Evaluating:  89%|████████▊ | 202/228 [01:27<00:11,  2.35it/s][Astep: 202
extend+tolist() time: 0.0003871917724609375

Evaluating:  89%|████████▉ | 203/228 [01:27<00:10,  2.43it/s][Astep: 203
extend+tolist() time: 0.000522613525390625

Evaluating:  89%|████████▉ | 204/228 [01:28<00:10,  2.38it/s][Astep: 204
extend+tolist() time: 0.0004115104675292969

Evaluating:  90%|████████▉ | 205/228 [01:28<00:09,  2.38it/s][Astep: 205
extend+tolist() time: 0.0007195472717285156

Evaluating:  90%|█████████ | 206/228 [01:28<00:09,  2.36it/s][Astep: 206
extend+tolist() time: 0.0006115436553955078

Evaluating:  91%|█████████ | 207/228 [01:29<00:08,  2.40it/s][Astep: 207
extend+tolist() time: 0.0006110668182373047

Evaluating:  91%|█████████ | 208/228 [01:29<00:08,  2.45it/s][Astep: 208
extend+tolist() time: 0.00112152099609375

Evaluating:  92%|█████████▏| 209/228 [01:30<00:07,  2.41it/s][Astep: 209
extend+tolist() time: 0.0006010532379150391

Evaluating:  92%|█████████▏| 210/228 [01:30<00:07,  2.44it/s][Astep: 210
extend+tolist() time: 0.0006079673767089844

Evaluating:  93%|█████████▎| 211/228 [01:30<00:07,  2.40it/s][Astep: 211
extend+tolist() time: 0.0015718936920166016

Evaluating:  93%|█████████▎| 212/228 [01:31<00:06,  2.40it/s][Astep: 212
extend+tolist() time: 0.0009012222290039062

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.43it/s][Astep: 213
extend+tolist() time: 0.0011844635009765625

Evaluating:  94%|█████████▍| 214/228 [01:32<00:05,  2.39it/s][Astep: 214
extend+tolist() time: 0.0008566379547119141

Evaluating:  94%|█████████▍| 215/228 [01:32<00:05,  2.41it/s][Astep: 215
extend+tolist() time: 0.001081705093383789

Evaluating:  95%|█████████▍| 216/228 [01:33<00:05,  2.38it/s][Astep: 216
extend+tolist() time: 0.0005657672882080078

Evaluating:  95%|█████████▌| 217/228 [01:33<00:04,  2.43it/s][Astep: 217
extend+tolist() time: 0.0005671977996826172

Evaluating:  96%|█████████▌| 218/228 [01:33<00:04,  2.47it/s][Astep: 218
extend+tolist() time: 0.0014507770538330078

Evaluating:  96%|█████████▌| 219/228 [01:34<00:03,  2.45it/s][Astep: 219
extend+tolist() time: 0.0004940032958984375

Evaluating:  96%|█████████▋| 220/228 [01:34<00:03,  2.47it/s][Astep: 220
extend+tolist() time: 0.00040078163146972656

Evaluating:  97%|█████████▋| 221/228 [01:35<00:02,  2.42it/s][Astep: 221
extend+tolist() time: 0.0010192394256591797

Evaluating:  97%|█████████▋| 222/228 [01:35<00:02,  2.44it/s][Astep: 222
extend+tolist() time: 0.00041222572326660156

Evaluating:  98%|█████████▊| 223/228 [01:35<00:02,  2.48it/s][Astep: 223
extend+tolist() time: 0.00038814544677734375

Evaluating:  98%|█████████▊| 224/228 [01:36<00:01,  2.49it/s][Astep: 224
extend+tolist() time: 0.0003714561462402344

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.53it/s][Astep: 225
extend+tolist() time: 0.0004360675811767578

Evaluating:  99%|█████████▉| 226/228 [01:37<00:00,  2.48it/s][Astep: 226
extend+tolist() time: 0.0009865760803222656

Evaluating: 100%|█████████▉| 227/228 [01:37<00:00,  2.49it/s][Astep: 227
extend+tolist() time: 0.000492095947265625

Evaluating: 100%|██████████| 228/228 [01:37<00:00,  2.48it/s][A09/08/2023 23:39:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 23:39:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:39:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:39:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:39:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:39:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:39:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:39:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:39:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:39:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:39:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:39:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:39:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:39:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:39:43 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:39:43 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:39:43 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:39<00:00,  2.28it/s]
09/08/2023 23:39:43 - INFO - __main__ -   Step: 1640, Validation Metrics: {'pred_1_num': 9781, 'pred_-1_num': 957, 'pred_0_num': 63, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7905749467641885, 'f1_micro': 0.7905749467641884, 'f1_macro': 0.4299396278441929, 'f1_weighted': 0.7538306567520093, 'f1_-1': 0.34799841458581054, 'f1_0': 0.06267806267806267, 'f1_1': 0.8791424062687053, 'precision_micro': 0.7905749467641885, 'precision_macro': 0.544606151898968, 'precision_weighted': 0.7444524107960352, 'precision_-1': 0.4587251828631139, 'precision_0': 0.3492063492063492, 'precision_1': 0.825886923627441, 'recall_micro': 0.7905749467641885, 'recall_macro': 0.41816675495569405, 'recall_weighted': 0.7905749467641885, 'recall_-1': 0.28033205619412516, 'recall_0': 0.03442879499217527, 'recall_1': 0.9397394136807817, 'roc_auc_micro': 0.921681376548227, 'roc_auc_macro': 0.7632598043343513, 'roc_auc_weighted': 0.7601345162942119, 'roc_auc_-1': 0.8309159653464491, 'roc_auc_0': 0.7077279989059859, 'roc_auc_1': 0.7511354487506187}
[2023-09-08 23:40:04,644] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1641/66600 [2:17:14<918:50:22, 50.92s/it]09/08/2023 23:40:04 - INFO - __main__ -   Step: 1641, LR: 1.643259481787458e-05, Loss: 0.3842746615409851
[2023-09-08 23:40:25,521] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1642/66600 [2:17:35<756:11:27, 41.91s/it]09/08/2023 23:40:25 - INFO - __main__ -   Step: 1642, LR: 1.644260858680686e-05, Loss: 0.42974725365638733
[2023-09-08 23:40:45,984] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1643/66600 [2:17:55<640:05:46, 35.47s/it]09/08/2023 23:40:45 - INFO - __main__ -   Step: 1643, LR: 1.6452622355739143e-05, Loss: 0.4470476508140564
[2023-09-08 23:41:06,229] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1644/66600 [2:18:15<557:38:34, 30.91s/it]09/08/2023 23:41:06 - INFO - __main__ -   Step: 1644, LR: 1.6462636124671424e-05, Loss: 0.4559398889541626
[2023-09-08 23:41:26,495] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1645/66600 [2:18:36<500:02:37, 27.71s/it]09/08/2023 23:41:26 - INFO - __main__ -   Step: 1645, LR: 1.6472649893603706e-05, Loss: 0.3904501795768738
[2023-09-08 23:41:46,674] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1646/66600 [2:18:56<459:14:59, 25.45s/it]09/08/2023 23:41:46 - INFO - __main__ -   Step: 1646, LR: 1.648266366253599e-05, Loss: 0.39592796564102173
[2023-09-08 23:42:07,685] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1647/66600 [2:19:17<435:11:45, 24.12s/it]09/08/2023 23:42:07 - INFO - __main__ -   Step: 1647, LR: 1.649267743146827e-05, Loss: 0.4133096933364868
[2023-09-08 23:42:28,516] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1648/66600 [2:19:38<417:23:07, 23.13s/it]09/08/2023 23:42:28 - INFO - __main__ -   Step: 1648, LR: 1.650269120040055e-05, Loss: 0.3262879252433777
[2023-09-08 23:42:49,556] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1649/66600 [2:19:59<406:02:50, 22.51s/it]09/08/2023 23:42:49 - INFO - __main__ -   Step: 1649, LR: 1.6512704969332832e-05, Loss: 0.4153389632701874
[2023-09-08 23:43:10,531] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1650/66600 [2:20:20<397:45:15, 22.05s/it]09/08/2023 23:43:10 - INFO - __main__ -   Step: 1650, LR: 1.6522718738265114e-05, Loss: 0.4738103747367859
[2023-09-08 23:43:31,156] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1651/66600 [2:20:40<390:03:12, 21.62s/it]09/08/2023 23:43:31 - INFO - __main__ -   Step: 1651, LR: 1.65327325071974e-05, Loss: 0.47991812229156494
[2023-09-08 23:43:51,776] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1652/66600 [2:21:01<384:38:06, 21.32s/it]09/08/2023 23:43:51 - INFO - __main__ -   Step: 1652, LR: 1.654274627612968e-05, Loss: 0.39660853147506714
[2023-09-08 23:44:11,843] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1653/66600 [2:21:21<377:51:09, 20.94s/it]09/08/2023 23:44:11 - INFO - __main__ -   Step: 1653, LR: 1.6552760045061962e-05, Loss: 0.45270073413848877
[2023-09-08 23:44:32,345] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1654/66600 [2:21:41<375:27:07, 20.81s/it]09/08/2023 23:44:32 - INFO - __main__ -   Step: 1654, LR: 1.6562773813994244e-05, Loss: 0.4448001980781555
[2023-09-08 23:44:52,775] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1655/66600 [2:22:02<373:22:40, 20.70s/it]09/08/2023 23:44:52 - INFO - __main__ -   Step: 1655, LR: 1.6572787582926525e-05, Loss: 0.4964871108531952
[2023-09-08 23:45:13,665] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1656/66600 [2:22:23<374:24:58, 20.75s/it]09/08/2023 23:45:13 - INFO - __main__ -   Step: 1656, LR: 1.6582801351858807e-05, Loss: 0.43064188957214355
[2023-09-08 23:45:34,225] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1657/66600 [2:22:43<373:21:37, 20.70s/it]09/08/2023 23:45:34 - INFO - __main__ -   Step: 1657, LR: 1.659281512079109e-05, Loss: 0.46952393651008606
[2023-09-08 23:45:54,501] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1658/66600 [2:23:04<371:04:34, 20.57s/it]09/08/2023 23:45:54 - INFO - __main__ -   Step: 1658, LR: 1.660282888972337e-05, Loss: 0.3896319270133972
[2023-09-08 23:46:14,987] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1659/66600 [2:23:24<370:36:59, 20.55s/it]09/08/2023 23:46:14 - INFO - __main__ -   Step: 1659, LR: 1.6612842658655652e-05, Loss: 0.37743741273880005
[2023-09-08 23:46:35,468] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1660/66600 [2:23:45<370:15:45, 20.53s/it]09/08/2023 23:46:35 - INFO - __main__ -   Step: 1660, LR: 1.6622856427587933e-05, Loss: 0.395255982875824
09/08/2023 23:46:35 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.002445220947265625

Evaluating:   0%|          | 1/228 [00:00<01:48,  2.09it/s][Astep: 1
extend+tolist() time: 0.0010874271392822266

Evaluating:   1%|          | 2/228 [00:01<01:57,  1.92it/s][Astep: 2
extend+tolist() time: 0.0022389888763427734

Evaluating:   1%|▏         | 3/228 [00:01<02:00,  1.86it/s][Astep: 3
extend+tolist() time: 0.001953601837158203

Evaluating:   2%|▏         | 4/228 [00:02<01:50,  2.02it/s][Astep: 4
extend+tolist() time: 0.001478433609008789

Evaluating:   2%|▏         | 5/228 [00:02<01:42,  2.18it/s][Astep: 5
extend+tolist() time: 0.0015838146209716797

Evaluating:   3%|▎         | 6/228 [00:02<01:40,  2.21it/s][Astep: 6
extend+tolist() time: 0.0023322105407714844

Evaluating:   3%|▎         | 7/228 [00:03<01:48,  2.04it/s][Astep: 7
extend+tolist() time: 0.0013980865478515625

Evaluating:   4%|▎         | 8/228 [00:03<01:43,  2.13it/s][Astep: 8
extend+tolist() time: 0.0011208057403564453

Evaluating:   4%|▍         | 9/228 [00:04<01:37,  2.25it/s][Astep: 9
extend+tolist() time: 0.0008363723754882812

Evaluating:   4%|▍         | 10/228 [00:04<01:33,  2.33it/s][Astep: 10
extend+tolist() time: 0.0013098716735839844

Evaluating:   5%|▍         | 11/228 [00:05<01:32,  2.36it/s][Astep: 11
extend+tolist() time: 0.0005598068237304688

Evaluating:   5%|▌         | 12/228 [00:05<01:29,  2.42it/s][Astep: 12
extend+tolist() time: 0.0006725788116455078

Evaluating:   6%|▌         | 13/228 [00:05<01:28,  2.43it/s][Astep: 13
extend+tolist() time: 0.0010342597961425781

Evaluating:   6%|▌         | 14/228 [00:06<01:25,  2.51it/s][Astep: 14
extend+tolist() time: 0.0005590915679931641

Evaluating:   7%|▋         | 15/228 [00:06<01:23,  2.56it/s][Astep: 15
extend+tolist() time: 0.0006134510040283203

Evaluating:   7%|▋         | 16/228 [00:06<01:23,  2.53it/s][Astep: 16
extend+tolist() time: 0.0011010169982910156

Evaluating:   7%|▋         | 17/228 [00:07<01:22,  2.55it/s][Astep: 17
extend+tolist() time: 0.0008556842803955078

Evaluating:   8%|▊         | 18/228 [00:07<01:21,  2.56it/s][Astep: 18
extend+tolist() time: 0.0016188621520996094

Evaluating:   8%|▊         | 19/228 [00:08<01:24,  2.48it/s][Astep: 19
extend+tolist() time: 0.151031494140625

Evaluating:   9%|▉         | 20/228 [00:08<01:32,  2.25it/s][Astep: 20
extend+tolist() time: 0.0007920265197753906

Evaluating:   9%|▉         | 21/228 [00:09<01:29,  2.30it/s][Astep: 21
extend+tolist() time: 0.0010280609130859375

Evaluating:  10%|▉         | 22/228 [00:09<01:26,  2.37it/s][Astep: 22
extend+tolist() time: 0.0007421970367431641

Evaluating:  10%|█         | 23/228 [00:09<01:25,  2.38it/s][Astep: 23
extend+tolist() time: 0.001088857650756836

Evaluating:  11%|█         | 24/228 [00:10<01:23,  2.44it/s][Astep: 24
extend+tolist() time: 0.0011112689971923828

Evaluating:  11%|█         | 25/228 [00:10<01:22,  2.45it/s][Astep: 25
extend+tolist() time: 0.0014328956604003906

Evaluating:  11%|█▏        | 26/228 [00:11<01:24,  2.40it/s][Astep: 26
extend+tolist() time: 0.0007092952728271484

Evaluating:  12%|█▏        | 27/228 [00:11<01:21,  2.45it/s][Astep: 27
extend+tolist() time: 0.0017244815826416016

Evaluating:  12%|█▏        | 28/228 [00:11<01:22,  2.42it/s][Astep: 28
extend+tolist() time: 0.000331878662109375

Evaluating:  13%|█▎        | 29/228 [00:12<01:29,  2.22it/s][Astep: 29
extend+tolist() time: 0.0007331371307373047

Evaluating:  13%|█▎        | 30/228 [00:12<01:27,  2.27it/s][Astep: 30
extend+tolist() time: 0.0015408992767333984

Evaluating:  14%|█▎        | 31/228 [00:13<01:24,  2.33it/s][Astep: 31
extend+tolist() time: 0.0006082057952880859

Evaluating:  14%|█▍        | 32/228 [00:13<01:21,  2.40it/s][Astep: 32
extend+tolist() time: 0.0014061927795410156

Evaluating:  14%|█▍        | 33/228 [00:14<01:21,  2.39it/s][Astep: 33
extend+tolist() time: 0.0016551017761230469

Evaluating:  15%|█▍        | 34/228 [00:14<01:20,  2.42it/s][Astep: 34
extend+tolist() time: 0.0008611679077148438

Evaluating:  15%|█▌        | 35/228 [00:14<01:19,  2.42it/s][Astep: 35
extend+tolist() time: 0.0006551742553710938

Evaluating:  16%|█▌        | 36/228 [00:15<01:18,  2.46it/s][Astep: 36
extend+tolist() time: 0.0007643699645996094

Evaluating:  16%|█▌        | 37/228 [00:15<01:17,  2.48it/s][Astep: 37
extend+tolist() time: 0.0017731189727783203

Evaluating:  17%|█▋        | 38/228 [00:16<01:27,  2.18it/s][Astep: 38
extend+tolist() time: 0.0011377334594726562

Evaluating:  17%|█▋        | 39/228 [00:16<01:22,  2.28it/s][Astep: 39
extend+tolist() time: 0.0007193088531494141

Evaluating:  18%|█▊        | 40/228 [00:17<01:21,  2.31it/s][Astep: 40
extend+tolist() time: 0.0010030269622802734

Evaluating:  18%|█▊        | 41/228 [00:17<01:18,  2.39it/s][Astep: 41
extend+tolist() time: 0.0008492469787597656

Evaluating:  18%|█▊        | 42/228 [00:17<01:16,  2.44it/s][Astep: 42
extend+tolist() time: 0.0016567707061767578

Evaluating:  19%|█▉        | 43/228 [00:18<01:18,  2.37it/s][Astep: 43
extend+tolist() time: 0.0018124580383300781

Evaluating:  19%|█▉        | 44/228 [00:18<01:17,  2.39it/s][Astep: 44
extend+tolist() time: 0.0007576942443847656

Evaluating:  20%|█▉        | 45/228 [00:19<01:16,  2.39it/s][Astep: 45
extend+tolist() time: 0.00170135498046875

Evaluating:  20%|██        | 46/228 [00:19<01:15,  2.41it/s][Astep: 46
extend+tolist() time: 0.0015823841094970703

Evaluating:  21%|██        | 47/228 [00:20<01:16,  2.38it/s][Astep: 47
extend+tolist() time: 0.0014443397521972656

Evaluating:  21%|██        | 48/228 [00:20<01:14,  2.42it/s][Astep: 48
extend+tolist() time: 0.0011782646179199219

Evaluating:  21%|██▏       | 49/228 [00:20<01:13,  2.44it/s][Astep: 49
extend+tolist() time: 0.0009207725524902344

Evaluating:  22%|██▏       | 50/228 [00:21<01:14,  2.40it/s][Astep: 50
extend+tolist() time: 0.15729641914367676

Evaluating:  22%|██▏       | 51/228 [00:21<01:21,  2.16it/s][Astep: 51
extend+tolist() time: 0.0016574859619140625

Evaluating:  23%|██▎       | 52/228 [00:22<01:20,  2.19it/s][Astep: 52
extend+tolist() time: 0.0012848377227783203

Evaluating:  23%|██▎       | 53/228 [00:22<01:16,  2.28it/s][Astep: 53
extend+tolist() time: 0.0012748241424560547

Evaluating:  24%|██▎       | 54/228 [00:23<01:16,  2.28it/s][Astep: 54
extend+tolist() time: 0.0008265972137451172

Evaluating:  24%|██▍       | 55/228 [00:23<01:13,  2.35it/s][Astep: 55
extend+tolist() time: 0.0012218952178955078

Evaluating:  25%|██▍       | 56/228 [00:23<01:11,  2.41it/s][Astep: 56
extend+tolist() time: 0.001150369644165039

Evaluating:  25%|██▌       | 57/228 [00:24<01:12,  2.37it/s][Astep: 57
extend+tolist() time: 0.0010509490966796875

Evaluating:  25%|██▌       | 58/228 [00:24<01:09,  2.44it/s][Astep: 58
extend+tolist() time: 0.0008869171142578125

Evaluating:  26%|██▌       | 59/228 [00:25<01:10,  2.39it/s][Astep: 59
extend+tolist() time: 0.001348257064819336

Evaluating:  26%|██▋       | 60/228 [00:25<01:08,  2.45it/s][Astep: 60
extend+tolist() time: 0.0007297992706298828

Evaluating:  27%|██▋       | 61/228 [00:26<01:17,  2.15it/s][Astep: 61
extend+tolist() time: 0.0013093948364257812

Evaluating:  27%|██▋       | 62/228 [00:26<01:13,  2.27it/s][Astep: 62
extend+tolist() time: 0.0007956027984619141

Evaluating:  28%|██▊       | 63/228 [00:26<01:09,  2.36it/s][Astep: 63
extend+tolist() time: 0.00125885009765625

Evaluating:  28%|██▊       | 64/228 [00:27<01:10,  2.33it/s][Astep: 64
extend+tolist() time: 0.0007910728454589844

Evaluating:  29%|██▊       | 65/228 [00:27<01:08,  2.40it/s][Astep: 65
extend+tolist() time: 0.0012097358703613281

Evaluating:  29%|██▉       | 66/228 [00:28<01:08,  2.35it/s][Astep: 66
extend+tolist() time: 0.0007679462432861328

Evaluating:  29%|██▉       | 67/228 [00:28<01:06,  2.42it/s][Astep: 67
extend+tolist() time: 0.0013492107391357422

Evaluating:  30%|██▉       | 68/228 [00:28<01:05,  2.46it/s][Astep: 68
extend+tolist() time: 0.0006864070892333984

Evaluating:  30%|███       | 69/228 [00:29<01:06,  2.40it/s][Astep: 69
extend+tolist() time: 0.0014972686767578125

Evaluating:  31%|███       | 70/228 [00:29<01:04,  2.45it/s][Astep: 70
extend+tolist() time: 0.0014767646789550781

Evaluating:  31%|███       | 71/228 [00:30<01:14,  2.12it/s][Astep: 71
extend+tolist() time: 0.0013477802276611328

Evaluating:  32%|███▏      | 72/228 [00:30<01:09,  2.24it/s][Astep: 72
extend+tolist() time: 0.0007991790771484375

Evaluating:  32%|███▏      | 73/228 [00:31<01:08,  2.25it/s][Astep: 73
extend+tolist() time: 0.0005083084106445312

Evaluating:  32%|███▏      | 74/228 [00:31<01:05,  2.35it/s][Astep: 74
extend+tolist() time: 0.001173257827758789

Evaluating:  33%|███▎      | 75/228 [00:32<01:03,  2.42it/s][Astep: 75
extend+tolist() time: 0.001596689224243164

Evaluating:  33%|███▎      | 76/228 [00:32<01:04,  2.35it/s][Astep: 76
extend+tolist() time: 0.0006299018859863281

Evaluating:  34%|███▍      | 77/228 [00:32<01:02,  2.42it/s][Astep: 77
extend+tolist() time: 0.0019054412841796875

Evaluating:  34%|███▍      | 78/228 [00:33<01:04,  2.32it/s][Astep: 78
extend+tolist() time: 0.0012333393096923828

Evaluating:  35%|███▍      | 79/228 [00:33<01:02,  2.39it/s][Astep: 79
extend+tolist() time: 0.0008504390716552734

Evaluating:  35%|███▌      | 80/228 [00:34<01:00,  2.46it/s][Astep: 80
extend+tolist() time: 0.001360177993774414

Evaluating:  36%|███▌      | 81/228 [00:34<01:01,  2.38it/s][Astep: 81
extend+tolist() time: 0.0008578300476074219

Evaluating:  36%|███▌      | 82/228 [00:34<00:59,  2.44it/s][Astep: 82
extend+tolist() time: 0.0013842582702636719

Evaluating:  36%|███▋      | 83/228 [00:35<01:00,  2.38it/s][Astep: 83
extend+tolist() time: 0.0006890296936035156

Evaluating:  37%|███▋      | 84/228 [00:35<00:58,  2.45it/s][Astep: 84
extend+tolist() time: 0.0014462471008300781

Evaluating:  37%|███▋      | 85/228 [00:36<00:57,  2.50it/s][Astep: 85
extend+tolist() time: 0.0012929439544677734

Evaluating:  38%|███▊      | 86/228 [00:36<00:58,  2.41it/s][Astep: 86
extend+tolist() time: 0.0008897781372070312

Evaluating:  38%|███▊      | 87/228 [00:36<00:57,  2.45it/s][Astep: 87
extend+tolist() time: 0.0013794898986816406

Evaluating:  39%|███▊      | 88/228 [00:37<01:01,  2.28it/s][Astep: 88
extend+tolist() time: 0.0007469654083251953

Evaluating:  39%|███▉      | 89/228 [00:37<00:58,  2.38it/s][Astep: 89
extend+tolist() time: 0.0014231204986572266

Evaluating:  39%|███▉      | 90/228 [00:38<00:57,  2.42it/s][Astep: 90
extend+tolist() time: 0.0009453296661376953

Evaluating:  40%|███▉      | 91/228 [00:38<00:57,  2.38it/s][Astep: 91
extend+tolist() time: 0.1972806453704834

Evaluating:  40%|████      | 92/228 [00:39<01:03,  2.13it/s][Astep: 92
extend+tolist() time: 0.0007965564727783203

Evaluating:  41%|████      | 93/228 [00:39<01:01,  2.20it/s][Astep: 93
extend+tolist() time: 0.0014195442199707031

Evaluating:  41%|████      | 94/228 [00:40<00:58,  2.28it/s][Astep: 94
extend+tolist() time: 0.0010552406311035156

Evaluating:  42%|████▏     | 95/228 [00:40<00:58,  2.26it/s][Astep: 95
extend+tolist() time: 0.0011446475982666016

Evaluating:  42%|████▏     | 96/228 [00:40<00:56,  2.33it/s][Astep: 96
extend+tolist() time: 0.0013744831085205078

Evaluating:  43%|████▎     | 97/228 [00:41<00:57,  2.29it/s][Astep: 97
extend+tolist() time: 0.0011203289031982422

Evaluating:  43%|████▎     | 98/228 [00:41<00:54,  2.38it/s][Astep: 98
extend+tolist() time: 0.0008840560913085938

Evaluating:  43%|████▎     | 99/228 [00:42<00:53,  2.43it/s][Astep: 99
extend+tolist() time: 0.0013537406921386719

Evaluating:  44%|████▍     | 100/228 [00:42<00:53,  2.38it/s][Astep: 100
extend+tolist() time: 0.0006976127624511719

Evaluating:  44%|████▍     | 101/228 [00:43<00:51,  2.44it/s][Astep: 101
extend+tolist() time: 0.0012812614440917969

Evaluating:  45%|████▍     | 102/228 [00:43<00:52,  2.38it/s][Astep: 102
extend+tolist() time: 0.0007174015045166016

Evaluating:  45%|████▌     | 103/228 [00:43<00:51,  2.45it/s][Astep: 103
extend+tolist() time: 0.0011861324310302734

Evaluating:  46%|████▌     | 104/228 [00:44<00:49,  2.50it/s][Astep: 104
extend+tolist() time: 0.0006978511810302734

Evaluating:  46%|████▌     | 105/228 [00:44<00:57,  2.15it/s][Astep: 105
extend+tolist() time: 0.001222372055053711

Evaluating:  46%|████▋     | 106/228 [00:45<00:54,  2.26it/s][Astep: 106
extend+tolist() time: 0.0016734600067138672

Evaluating:  47%|████▋     | 107/228 [00:45<00:54,  2.23it/s][Astep: 107
extend+tolist() time: 0.0007660388946533203

Evaluating:  47%|████▋     | 108/228 [00:46<00:51,  2.32it/s][Astep: 108
extend+tolist() time: 0.001210927963256836

Evaluating:  48%|████▊     | 109/228 [00:46<00:51,  2.30it/s][Astep: 109
extend+tolist() time: 0.0008499622344970703

Evaluating:  48%|████▊     | 110/228 [00:46<00:49,  2.38it/s][Astep: 110
extend+tolist() time: 0.0006241798400878906

Evaluating:  49%|████▊     | 111/228 [00:47<00:47,  2.44it/s][Astep: 111
extend+tolist() time: 0.001882791519165039

Evaluating:  49%|████▉     | 112/228 [00:47<00:49,  2.35it/s][Astep: 112
extend+tolist() time: 0.0007319450378417969

Evaluating:  50%|████▉     | 113/228 [00:48<00:47,  2.44it/s][Astep: 113
extend+tolist() time: 0.0007195472717285156

Evaluating:  50%|█████     | 114/228 [00:48<00:47,  2.40it/s][Astep: 114
extend+tolist() time: 0.0015625953674316406

Evaluating:  50%|█████     | 115/228 [00:48<00:46,  2.45it/s][Astep: 115
extend+tolist() time: 0.0006625652313232422

Evaluating:  51%|█████     | 116/228 [00:49<00:44,  2.50it/s][Astep: 116
extend+tolist() time: 0.0012478828430175781

Evaluating:  51%|█████▏    | 117/228 [00:49<00:45,  2.44it/s][Astep: 117
extend+tolist() time: 0.0008280277252197266

Evaluating:  52%|█████▏    | 118/228 [00:50<00:44,  2.49it/s][Astep: 118
extend+tolist() time: 0.0009932518005371094

Evaluating:  52%|█████▏    | 119/228 [00:50<00:51,  2.11it/s][Astep: 119
extend+tolist() time: 0.0006964206695556641

Evaluating:  53%|█████▎    | 120/228 [00:51<00:48,  2.24it/s][Astep: 120
extend+tolist() time: 0.0006155967712402344

Evaluating:  53%|█████▎    | 121/228 [00:51<00:47,  2.27it/s][Astep: 121
extend+tolist() time: 0.0010666847229003906

Evaluating:  54%|█████▎    | 122/228 [00:51<00:44,  2.38it/s][Astep: 122
extend+tolist() time: 0.0006725788116455078

Evaluating:  54%|█████▍    | 123/228 [00:52<00:42,  2.46it/s][Astep: 123
extend+tolist() time: 0.0010082721710205078

Evaluating:  54%|█████▍    | 124/228 [00:52<00:42,  2.42it/s][Astep: 124
extend+tolist() time: 0.0008156299591064453

Evaluating:  55%|█████▍    | 125/228 [00:53<00:41,  2.49it/s][Astep: 125
extend+tolist() time: 0.0004324913024902344

Evaluating:  55%|█████▌    | 126/228 [00:53<00:41,  2.47it/s][Astep: 126
extend+tolist() time: 0.0018208026885986328

Evaluating:  56%|█████▌    | 127/228 [00:53<00:41,  2.46it/s][Astep: 127
extend+tolist() time: 0.0016655921936035156

Evaluating:  56%|█████▌    | 128/228 [00:54<00:40,  2.47it/s][Astep: 128
extend+tolist() time: 0.0010476112365722656

Evaluating:  57%|█████▋    | 129/228 [00:54<00:41,  2.41it/s][Astep: 129
extend+tolist() time: 0.0007715225219726562

Evaluating:  57%|█████▋    | 130/228 [00:55<00:39,  2.47it/s][Astep: 130
extend+tolist() time: 0.001323699951171875

Evaluating:  57%|█████▋    | 131/228 [00:55<00:39,  2.44it/s][Astep: 131
extend+tolist() time: 0.0004451274871826172

Evaluating:  58%|█████▊    | 132/228 [00:55<00:38,  2.52it/s][Astep: 132
extend+tolist() time: 0.001432657241821289

Evaluating:  58%|█████▊    | 133/228 [00:56<00:37,  2.54it/s][Astep: 133
extend+tolist() time: 0.00043201446533203125

Evaluating:  59%|█████▉    | 134/228 [00:56<00:37,  2.48it/s][Astep: 134
extend+tolist() time: 0.0009393692016601562

Evaluating:  59%|█████▉    | 135/228 [00:57<00:36,  2.52it/s][Astep: 135
extend+tolist() time: 0.0008664131164550781

Evaluating:  60%|█████▉    | 136/228 [00:57<00:35,  2.57it/s][Astep: 136
extend+tolist() time: 0.00081634521484375

Evaluating:  60%|██████    | 137/228 [00:57<00:36,  2.49it/s][Astep: 137
extend+tolist() time: 0.00038242340087890625

Evaluating:  61%|██████    | 138/228 [00:58<00:35,  2.55it/s][Astep: 138
extend+tolist() time: 0.0012352466583251953

Evaluating:  61%|██████    | 139/228 [00:58<00:36,  2.46it/s][Astep: 139
extend+tolist() time: 0.0004525184631347656

Evaluating:  61%|██████▏   | 140/228 [00:59<00:34,  2.51it/s][Astep: 140
extend+tolist() time: 0.0011162757873535156

Evaluating:  62%|██████▏   | 141/228 [00:59<00:34,  2.53it/s][Astep: 141
extend+tolist() time: 0.0007395744323730469

Evaluating:  62%|██████▏   | 142/228 [00:59<00:35,  2.46it/s][Astep: 142
extend+tolist() time: 0.0005462169647216797

Evaluating:  63%|██████▎   | 143/228 [01:00<00:33,  2.51it/s][Astep: 143
extend+tolist() time: 0.0007956027984619141

Evaluating:  63%|██████▎   | 144/228 [01:00<00:34,  2.44it/s][Astep: 144
extend+tolist() time: 0.0006701946258544922

Evaluating:  64%|██████▎   | 145/228 [01:01<00:33,  2.49it/s][Astep: 145
extend+tolist() time: 0.00044417381286621094

Evaluating:  64%|██████▍   | 146/228 [01:01<00:32,  2.53it/s][Astep: 146
extend+tolist() time: 0.0003724098205566406

Evaluating:  64%|██████▍   | 147/228 [01:02<00:33,  2.44it/s][Astep: 147
extend+tolist() time: 0.0011296272277832031

Evaluating:  65%|██████▍   | 148/228 [01:02<00:32,  2.49it/s][Astep: 148
extend+tolist() time: 0.0007002353668212891

Evaluating:  65%|██████▌   | 149/228 [01:02<00:32,  2.42it/s][Astep: 149
extend+tolist() time: 0.00039005279541015625

Evaluating:  66%|██████▌   | 150/228 [01:03<00:31,  2.49it/s][Astep: 150
extend+tolist() time: 0.0013289451599121094

Evaluating:  66%|██████▌   | 151/228 [01:03<00:30,  2.51it/s][Astep: 151
extend+tolist() time: 0.0006668567657470703

Evaluating:  67%|██████▋   | 152/228 [01:04<00:31,  2.43it/s][Astep: 152
extend+tolist() time: 0.0012538433074951172

Evaluating:  67%|██████▋   | 153/228 [01:04<00:30,  2.47it/s][Astep: 153
extend+tolist() time: 0.0010232925415039062

Evaluating:  68%|██████▊   | 154/228 [01:04<00:31,  2.38it/s][Astep: 154
extend+tolist() time: 0.24158954620361328

Evaluating:  68%|██████▊   | 155/228 [01:05<00:35,  2.05it/s][Astep: 155
extend+tolist() time: 0.001115560531616211

Evaluating:  68%|██████▊   | 156/228 [01:05<00:34,  2.12it/s][Astep: 156
extend+tolist() time: 0.0005362033843994141

Evaluating:  69%|██████▉   | 157/228 [01:06<00:31,  2.24it/s][Astep: 157
extend+tolist() time: 0.0013127326965332031

Evaluating:  69%|██████▉   | 158/228 [01:06<00:30,  2.32it/s][Astep: 158
extend+tolist() time: 0.00048089027404785156

Evaluating:  70%|██████▉   | 159/228 [01:07<00:30,  2.26it/s][Astep: 159
extend+tolist() time: 0.0007266998291015625

Evaluating:  70%|███████   | 160/228 [01:07<00:28,  2.36it/s][Astep: 160
extend+tolist() time: 0.0007619857788085938

Evaluating:  71%|███████   | 161/228 [01:08<00:28,  2.34it/s][Astep: 161
extend+tolist() time: 0.0008008480072021484

Evaluating:  71%|███████   | 162/228 [01:08<00:27,  2.41it/s][Astep: 162
extend+tolist() time: 0.0005414485931396484

Evaluating:  71%|███████▏  | 163/228 [01:08<00:27,  2.37it/s][Astep: 163
extend+tolist() time: 0.0008862018585205078

Evaluating:  72%|███████▏  | 164/228 [01:09<00:26,  2.45it/s][Astep: 164
extend+tolist() time: 0.0005567073822021484

Evaluating:  72%|███████▏  | 165/228 [01:09<00:25,  2.50it/s][Astep: 165
extend+tolist() time: 0.0004630088806152344

Evaluating:  73%|███████▎  | 166/228 [01:10<00:25,  2.44it/s][Astep: 166
extend+tolist() time: 0.00038909912109375

Evaluating:  73%|███████▎  | 167/228 [01:10<00:24,  2.50it/s][Astep: 167
extend+tolist() time: 0.0012881755828857422

Evaluating:  74%|███████▎  | 168/228 [01:10<00:23,  2.52it/s][Astep: 168
extend+tolist() time: 0.0011937618255615234

Evaluating:  74%|███████▍  | 169/228 [01:11<00:24,  2.45it/s][Astep: 169
extend+tolist() time: 0.0003707408905029297

Evaluating:  75%|███████▍  | 170/228 [01:11<00:23,  2.50it/s][Astep: 170
extend+tolist() time: 0.0014166831970214844

Evaluating:  75%|███████▌  | 171/228 [01:12<00:23,  2.42it/s][Astep: 171
extend+tolist() time: 0.0002987384796142578

Evaluating:  75%|███████▌  | 172/228 [01:12<00:22,  2.48it/s][Astep: 172
extend+tolist() time: 0.0010724067687988281

Evaluating:  76%|███████▌  | 173/228 [01:12<00:22,  2.50it/s][Astep: 173
extend+tolist() time: 0.0016090869903564453

Evaluating:  76%|███████▋  | 174/228 [01:13<00:22,  2.42it/s][Astep: 174
extend+tolist() time: 0.0018019676208496094

Evaluating:  77%|███████▋  | 175/228 [01:13<00:21,  2.43it/s][Astep: 175
extend+tolist() time: 0.0008373260498046875

Evaluating:  77%|███████▋  | 176/228 [01:14<00:24,  2.12it/s][Astep: 176
extend+tolist() time: 0.0010595321655273438

Evaluating:  78%|███████▊  | 177/228 [01:14<00:22,  2.24it/s][Astep: 177
extend+tolist() time: 0.0006175041198730469

Evaluating:  78%|███████▊  | 178/228 [01:15<00:22,  2.24it/s][Astep: 178
extend+tolist() time: 0.0016183853149414062

Evaluating:  79%|███████▊  | 179/228 [01:15<00:21,  2.32it/s][Astep: 179
extend+tolist() time: 0.0004067420959472656

Evaluating:  79%|███████▉  | 180/228 [01:15<00:20,  2.33it/s][Astep: 180
extend+tolist() time: 0.0003826618194580078

Evaluating:  79%|███████▉  | 181/228 [01:16<00:19,  2.42it/s][Astep: 181
extend+tolist() time: 0.0006177425384521484

Evaluating:  80%|███████▉  | 182/228 [01:16<00:18,  2.47it/s][Astep: 182
extend+tolist() time: 0.001188039779663086

Evaluating:  80%|████████  | 183/228 [01:17<00:18,  2.39it/s][Astep: 183
extend+tolist() time: 0.0006372928619384766

Evaluating:  81%|████████  | 184/228 [01:17<00:17,  2.45it/s][Astep: 184
extend+tolist() time: 0.00044274330139160156

Evaluating:  81%|████████  | 185/228 [01:17<00:17,  2.40it/s][Astep: 185
extend+tolist() time: 0.0014977455139160156

Evaluating:  82%|████████▏ | 186/228 [01:18<00:17,  2.44it/s][Astep: 186
extend+tolist() time: 0.001344919204711914

Evaluating:  82%|████████▏ | 187/228 [01:18<00:16,  2.48it/s][Astep: 187
extend+tolist() time: 0.00045299530029296875

Evaluating:  82%|████████▏ | 188/228 [01:19<00:16,  2.42it/s][Astep: 188
extend+tolist() time: 0.0007169246673583984

Evaluating:  83%|████████▎ | 189/228 [01:19<00:15,  2.48it/s][Astep: 189
extend+tolist() time: 0.00038623809814453125

Evaluating:  83%|████████▎ | 190/228 [01:20<00:15,  2.41it/s][Astep: 190
extend+tolist() time: 0.0016384124755859375

Evaluating:  84%|████████▍ | 191/228 [01:20<00:15,  2.45it/s][Astep: 191
extend+tolist() time: 0.0006930828094482422

Evaluating:  84%|████████▍ | 192/228 [01:20<00:14,  2.50it/s][Astep: 192
extend+tolist() time: 0.0007960796356201172

Evaluating:  85%|████████▍ | 193/228 [01:21<00:14,  2.41it/s][Astep: 193
extend+tolist() time: 0.0010178089141845703

Evaluating:  85%|████████▌ | 194/228 [01:21<00:13,  2.45it/s][Astep: 194
extend+tolist() time: 0.0010406970977783203

Evaluating:  86%|████████▌ | 195/228 [01:22<00:13,  2.38it/s][Astep: 195
extend+tolist() time: 0.0005426406860351562

Evaluating:  86%|████████▌ | 196/228 [01:22<00:13,  2.44it/s][Astep: 196
extend+tolist() time: 0.0005934238433837891

Evaluating:  86%|████████▋ | 197/228 [01:22<00:12,  2.48it/s][Astep: 197
extend+tolist() time: 0.0010738372802734375

Evaluating:  87%|████████▋ | 198/228 [01:23<00:12,  2.40it/s][Astep: 198
extend+tolist() time: 0.0005791187286376953

Evaluating:  87%|████████▋ | 199/228 [01:23<00:11,  2.45it/s][Astep: 199
extend+tolist() time: 0.0018520355224609375

Evaluating:  88%|████████▊ | 200/228 [01:24<00:11,  2.34it/s][Astep: 200
extend+tolist() time: 0.0007109642028808594

Evaluating:  88%|████████▊ | 201/228 [01:24<00:13,  2.00it/s][Astep: 201
extend+tolist() time: 0.0006008148193359375

Evaluating:  89%|████████▊ | 202/228 [01:25<00:12,  2.09it/s][Astep: 202
extend+tolist() time: 0.0008175373077392578

Evaluating:  89%|████████▉ | 203/228 [01:25<00:11,  2.22it/s][Astep: 203
extend+tolist() time: 0.0007836818695068359

Evaluating:  89%|████████▉ | 204/228 [01:26<00:10,  2.31it/s][Astep: 204
extend+tolist() time: 0.0004029273986816406

Evaluating:  90%|████████▉ | 205/228 [01:26<00:09,  2.30it/s][Astep: 205
extend+tolist() time: 0.000301361083984375

Evaluating:  90%|█████████ | 206/228 [01:26<00:09,  2.39it/s][Astep: 206
extend+tolist() time: 0.0006120204925537109

Evaluating:  91%|█████████ | 207/228 [01:27<00:08,  2.34it/s][Astep: 207
extend+tolist() time: 0.001058816909790039

Evaluating:  91%|█████████ | 208/228 [01:27<00:08,  2.34it/s][Astep: 208
extend+tolist() time: 0.0007112026214599609

Evaluating:  92%|█████████▏| 209/228 [01:28<00:08,  2.30it/s][Astep: 209
extend+tolist() time: 0.0006091594696044922

Evaluating:  92%|█████████▏| 210/228 [01:28<00:07,  2.36it/s][Astep: 210
extend+tolist() time: 0.001043558120727539

Evaluating:  93%|█████████▎| 211/228 [01:28<00:07,  2.41it/s][Astep: 211
extend+tolist() time: 0.0010864734649658203

Evaluating:  93%|█████████▎| 212/228 [01:29<00:06,  2.32it/s][Astep: 212
extend+tolist() time: 0.0017495155334472656

Evaluating:  93%|█████████▎| 213/228 [01:29<00:06,  2.37it/s][Astep: 213
extend+tolist() time: 0.0007584095001220703

Evaluating:  94%|█████████▍| 214/228 [01:30<00:06,  2.32it/s][Astep: 214
extend+tolist() time: 0.0012438297271728516

Evaluating:  94%|█████████▍| 215/228 [01:30<00:05,  2.37it/s][Astep: 215
extend+tolist() time: 0.0006589889526367188

Evaluating:  95%|█████████▍| 216/228 [01:31<00:04,  2.42it/s][Astep: 216
extend+tolist() time: 0.0005505084991455078

Evaluating:  95%|█████████▌| 217/228 [01:31<00:04,  2.35it/s][Astep: 217
extend+tolist() time: 0.0009639263153076172

Evaluating:  96%|█████████▌| 218/228 [01:31<00:04,  2.41it/s][Astep: 218
extend+tolist() time: 0.0010285377502441406

Evaluating:  96%|█████████▌| 219/228 [01:32<00:03,  2.32it/s][Astep: 219
extend+tolist() time: 0.0009021759033203125

Evaluating:  96%|█████████▋| 220/228 [01:32<00:03,  2.36it/s][Astep: 220
extend+tolist() time: 0.00040531158447265625

Evaluating:  97%|█████████▋| 221/228 [01:33<00:03,  2.30it/s][Astep: 221
extend+tolist() time: 0.0006425380706787109

Evaluating:  97%|█████████▋| 222/228 [01:33<00:02,  2.34it/s][Astep: 222
extend+tolist() time: 0.00042128562927246094

Evaluating:  98%|█████████▊| 223/228 [01:34<00:02,  2.38it/s][Astep: 223
extend+tolist() time: 0.0008335113525390625

Evaluating:  98%|█████████▊| 224/228 [01:34<00:01,  2.32it/s][Astep: 224
extend+tolist() time: 0.0003693103790283203

Evaluating:  99%|█████████▊| 225/228 [01:34<00:01,  2.38it/s][Astep: 225
extend+tolist() time: 0.0004382133483886719

Evaluating:  99%|█████████▉| 226/228 [01:35<00:00,  2.33it/s][Astep: 226
extend+tolist() time: 0.0005390644073486328

Evaluating: 100%|█████████▉| 227/228 [01:35<00:00,  2.39it/s][Astep: 227
extend+tolist() time: 0.0011479854583740234

Evaluating: 100%|██████████| 228/228 [01:36<00:00,  2.37it/s][A09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:48:12 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:48:13 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:48:13 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:48:13 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:48:13 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:38<00:00,  2.32it/s]
09/08/2023 23:48:13 - INFO - __main__ -   Step: 1660, Validation Metrics: {'pred_1_num': 10087, 'pred_-1_num': 700, 'pred_0_num': 14, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.8006666049439867, 'f1_micro': 0.8006666049439867, 'f1_macro': 0.4117657113372702, 'f1_weighted': 0.7531698571112476, 'f1_-1': 0.3186231244483671, 'f1_0': 0.030627871362940276, 'f1_1': 0.8860461382005032, 'precision_micro': 0.8006666049439867, 'precision_macro': 0.6835203727570139, 'precision_weighted': 0.7700750407846514, 'precision_-1': 0.5157142857142857, 'precision_0': 0.7142857142857143, 'precision_1': 0.820561118271042, 'recall_micro': 0.8006666049439867, 'recall_macro': 0.4030209318305223, 'recall_weighted': 0.8006666049439867, 'recall_-1': 0.2305236270753512, 'recall_0': 0.01564945226917058, 'recall_1': 0.9628897161470451, 'roc_auc_micro': 0.9295588314444613, 'roc_auc_macro': 0.7882336962008446, 'roc_auc_weighted': 0.786820208060781, 'roc_auc_-1': 0.8531877311659997, 'roc_auc_0': 0.7327655825393877, 'roc_auc_1': 0.7787477748971466}
[2023-09-08 23:48:34,081] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1661/66600 [2:25:43<901:03:52, 49.95s/it]09/08/2023 23:48:34 - INFO - __main__ -   Step: 1661, LR: 1.6632870196520215e-05, Loss: 0.3479886054992676
[2023-09-08 23:48:54,620] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1662/66600 [2:26:04<741:52:58, 41.13s/it]09/08/2023 23:48:54 - INFO - __main__ -   Step: 1662, LR: 1.66428839654525e-05, Loss: 0.3745633363723755
[2023-09-08 23:49:15,623] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1663/66600 [2:26:25<632:58:00, 35.09s/it]09/08/2023 23:49:15 - INFO - __main__ -   Step: 1663, LR: 1.665289773438478e-05, Loss: 0.4029552936553955
[2023-09-08 23:49:36,115] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▏         | 1664/66600 [2:26:45<553:57:27, 30.71s/it]09/08/2023 23:49:36 - INFO - __main__ -   Step: 1664, LR: 1.6662911503317063e-05, Loss: 0.42513570189476013
[2023-09-08 23:49:56,539] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  2%|▎         | 1665/66600 [2:27:06<498:16:55, 27.62s/it]09/08/2023 23:49:56 - INFO - __main__ -   Step: 1665, LR: 1.6672925272249345e-05, Loss: 0.35151779651641846
[2023-09-08 23:50:17,057] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1666/66600 [2:27:26<459:48:59, 25.49s/it]09/08/2023 23:50:17 - INFO - __main__ -   Step: 1666, LR: 1.6682939041181626e-05, Loss: 0.4322741627693176
[2023-09-08 23:50:37,509] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1667/66600 [2:27:47<432:32:15, 23.98s/it]09/08/2023 23:50:37 - INFO - __main__ -   Step: 1667, LR: 1.6692952810113908e-05, Loss: 0.4088590145111084
[2023-09-08 23:50:58,379] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1668/66600 [2:28:07<415:41:48, 23.05s/it]09/08/2023 23:50:58 - INFO - __main__ -   Step: 1668, LR: 1.670296657904619e-05, Loss: 0.4555248022079468
[2023-09-08 23:51:18,629] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1669/66600 [2:28:28<400:33:30, 22.21s/it]09/08/2023 23:51:18 - INFO - __main__ -   Step: 1669, LR: 1.671298034797847e-05, Loss: 0.3911479413509369
[2023-09-08 23:51:39,102] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1670/66600 [2:28:48<391:09:36, 21.69s/it]09/08/2023 23:51:39 - INFO - __main__ -   Step: 1670, LR: 1.6722994116910753e-05, Loss: 0.4266324043273926
[2023-09-08 23:51:59,211] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1671/66600 [2:29:08<382:36:48, 21.21s/it]09/08/2023 23:51:59 - INFO - __main__ -   Step: 1671, LR: 1.6733007885843034e-05, Loss: 0.4535819888114929
[2023-09-08 23:52:19,514] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1672/66600 [2:29:29<377:40:44, 20.94s/it]09/08/2023 23:52:19 - INFO - __main__ -   Step: 1672, LR: 1.674302165477532e-05, Loss: 0.4041270613670349
[2023-09-08 23:52:39,177] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1673/66600 [2:29:48<370:45:21, 20.56s/it]09/08/2023 23:52:39 - INFO - __main__ -   Step: 1673, LR: 1.67530354237076e-05, Loss: 0.32190898060798645
[2023-09-08 23:52:59,624] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1674/66600 [2:30:09<370:09:26, 20.52s/it]09/08/2023 23:52:59 - INFO - __main__ -   Step: 1674, LR: 1.6763049192639883e-05, Loss: 0.3874001204967499
[2023-09-08 23:53:20,624] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1675/66600 [2:30:30<372:43:18, 20.67s/it]09/08/2023 23:53:20 - INFO - __main__ -   Step: 1675, LR: 1.6773062961572164e-05, Loss: 0.37121307849884033
[2023-09-08 23:53:40,568] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1676/66600 [2:30:50<368:48:32, 20.45s/it]09/08/2023 23:53:40 - INFO - __main__ -   Step: 1676, LR: 1.6783076730504442e-05, Loss: 0.44782334566116333
[2023-09-08 23:54:01,107] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1677/66600 [2:31:10<369:16:51, 20.48s/it]09/08/2023 23:54:01 - INFO - __main__ -   Step: 1677, LR: 1.6793090499436727e-05, Loss: 0.41776272654533386
[2023-09-08 23:54:21,865] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1678/66600 [2:31:31<370:47:50, 20.56s/it]09/08/2023 23:54:21 - INFO - __main__ -   Step: 1678, LR: 1.680310426836901e-05, Loss: 0.37170958518981934
[2023-09-08 23:54:42,689] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1679/66600 [2:31:52<372:12:49, 20.64s/it]09/08/2023 23:54:42 - INFO - __main__ -   Step: 1679, LR: 1.681311803730129e-05, Loss: 0.38423898816108704
[2023-09-08 23:55:03,193] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1680/66600 [2:32:12<371:28:22, 20.60s/it]09/08/2023 23:55:03 - INFO - __main__ -   Step: 1680, LR: 1.6823131806233572e-05, Loss: 0.3902563452720642
09/08/2023 23:55:03 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0028297901153564453

Evaluating:   0%|          | 1/228 [00:00<01:43,  2.19it/s][Astep: 1
extend+tolist() time: 0.0016193389892578125

Evaluating:   1%|          | 2/228 [00:00<01:38,  2.29it/s][Astep: 2
extend+tolist() time: 0.002078533172607422

Evaluating:   1%|▏         | 3/228 [00:01<01:36,  2.34it/s][Astep: 3
extend+tolist() time: 0.15839052200317383

Evaluating:   2%|▏         | 4/228 [00:01<01:49,  2.05it/s][Astep: 4
extend+tolist() time: 0.0010237693786621094

Evaluating:   2%|▏         | 5/228 [00:02<01:41,  2.20it/s][Astep: 5
extend+tolist() time: 0.0022859573364257812

Evaluating:   3%|▎         | 6/228 [00:02<01:37,  2.28it/s][Astep: 6
extend+tolist() time: 0.0020325183868408203

Evaluating:   3%|▎         | 7/228 [00:03<01:36,  2.30it/s][Astep: 7
extend+tolist() time: 0.001323699951171875

Evaluating:   4%|▎         | 8/228 [00:03<01:32,  2.37it/s][Astep: 8
extend+tolist() time: 0.000762939453125

Evaluating:   4%|▍         | 9/228 [00:04<01:43,  2.12it/s][Astep: 9
extend+tolist() time: 0.0012159347534179688

Evaluating:   4%|▍         | 10/228 [00:04<01:37,  2.23it/s][Astep: 10
extend+tolist() time: 0.0008642673492431641

Evaluating:   5%|▍         | 11/228 [00:04<01:36,  2.25it/s][Astep: 11
extend+tolist() time: 0.0009663105010986328

Evaluating:   5%|▌         | 12/228 [00:05<01:32,  2.34it/s][Astep: 12
extend+tolist() time: 0.0009140968322753906

Evaluating:   6%|▌         | 13/228 [00:05<01:31,  2.36it/s][Astep: 13
extend+tolist() time: 0.0009582042694091797

Evaluating:   6%|▌         | 14/228 [00:06<01:30,  2.37it/s][Astep: 14
extend+tolist() time: 0.0005712509155273438

Evaluating:   7%|▋         | 15/228 [00:06<01:37,  2.18it/s][Astep: 15
extend+tolist() time: 0.0005991458892822266

Evaluating:   7%|▋         | 16/228 [00:07<01:35,  2.22it/s][Astep: 16
extend+tolist() time: 0.0010540485382080078

Evaluating:   7%|▋         | 17/228 [00:07<01:31,  2.30it/s][Astep: 17
extend+tolist() time: 0.0008845329284667969

Evaluating:   8%|▊         | 18/228 [00:07<01:31,  2.30it/s][Astep: 18
extend+tolist() time: 0.0015568733215332031

Evaluating:   8%|▊         | 19/228 [00:08<01:29,  2.34it/s][Astep: 19
extend+tolist() time: 0.0011649131774902344

Evaluating:   9%|▉         | 20/228 [00:08<01:28,  2.35it/s][Astep: 20
extend+tolist() time: 0.0007295608520507812

Evaluating:   9%|▉         | 21/228 [00:09<01:27,  2.37it/s][Astep: 21
extend+tolist() time: 0.0006704330444335938

Evaluating:  10%|▉         | 22/228 [00:09<01:25,  2.41it/s][Astep: 22
extend+tolist() time: 0.001215219497680664

Evaluating:  10%|█         | 23/228 [00:10<01:26,  2.36it/s][Astep: 23
extend+tolist() time: 0.0006823539733886719

Evaluating:  11%|█         | 24/228 [00:10<01:24,  2.40it/s][Astep: 24
extend+tolist() time: 0.0015206336975097656

Evaluating:  11%|█         | 25/228 [00:10<01:26,  2.36it/s][Astep: 25
extend+tolist() time: 0.001811981201171875

Evaluating:  11%|█▏        | 26/228 [00:11<01:26,  2.33it/s][Astep: 26
extend+tolist() time: 0.0007262229919433594

Evaluating:  12%|█▏        | 27/228 [00:11<01:24,  2.38it/s][Astep: 27
extend+tolist() time: 0.001691579818725586

Evaluating:  12%|█▏        | 28/228 [00:12<01:26,  2.30it/s][Astep: 28
extend+tolist() time: 0.0003447532653808594

Evaluating:  13%|█▎        | 29/228 [00:12<01:24,  2.36it/s][Astep: 29
extend+tolist() time: 0.0011181831359863281

Evaluating:  13%|█▎        | 30/228 [00:13<01:25,  2.30it/s][Astep: 30
extend+tolist() time: 0.001455068588256836

Evaluating:  14%|█▎        | 31/228 [00:13<01:24,  2.33it/s][Astep: 31
extend+tolist() time: 0.0005753040313720703

Evaluating:  14%|█▍        | 32/228 [00:13<01:24,  2.32it/s][Astep: 32
extend+tolist() time: 0.001382589340209961

Evaluating:  14%|█▍        | 33/228 [00:14<01:23,  2.33it/s][Astep: 33
extend+tolist() time: 0.001260519027709961

Evaluating:  15%|█▍        | 34/228 [00:14<01:32,  2.09it/s][Astep: 34
extend+tolist() time: 0.0008718967437744141

Evaluating:  15%|█▌        | 35/228 [00:15<01:28,  2.18it/s][Astep: 35
extend+tolist() time: 0.001027822494506836

Evaluating:  16%|█▌        | 36/228 [00:15<01:25,  2.25it/s][Astep: 36
extend+tolist() time: 0.0007805824279785156

Evaluating:  16%|█▌        | 37/228 [00:16<01:25,  2.23it/s][Astep: 37
extend+tolist() time: 0.0016188621520996094

Evaluating:  17%|█▋        | 38/228 [00:16<01:23,  2.27it/s][Astep: 38
extend+tolist() time: 0.0011150836944580078

Evaluating:  17%|█▋        | 39/228 [00:17<01:24,  2.24it/s][Astep: 39
extend+tolist() time: 0.0007414817810058594

Evaluating:  18%|█▊        | 40/228 [00:17<01:21,  2.31it/s][Astep: 40
extend+tolist() time: 0.0008642673492431641

Evaluating:  18%|█▊        | 41/228 [00:17<01:20,  2.32it/s][Astep: 41
extend+tolist() time: 0.0012750625610351562

Evaluating:  18%|█▊        | 42/228 [00:18<01:20,  2.31it/s][Astep: 42
extend+tolist() time: 0.0015909671783447266

Evaluating:  19%|█▉        | 43/228 [00:18<01:32,  2.01it/s][Astep: 43
extend+tolist() time: 0.0018451213836669922

Evaluating:  19%|█▉        | 44/228 [00:19<01:28,  2.08it/s][Astep: 44
extend+tolist() time: 0.0007703304290771484

Evaluating:  20%|█▉        | 45/228 [00:19<01:24,  2.17it/s][Astep: 45
extend+tolist() time: 0.0016849040985107422

Evaluating:  20%|██        | 46/228 [00:20<01:24,  2.15it/s][Astep: 46
extend+tolist() time: 0.001631021499633789

Evaluating:  21%|██        | 47/228 [00:20<01:30,  2.01it/s][Astep: 47
extend+tolist() time: 0.0014925003051757812

Evaluating:  21%|██        | 48/228 [00:21<01:27,  2.05it/s][Astep: 48
extend+tolist() time: 0.0011920928955078125

Evaluating:  21%|██▏       | 49/228 [00:21<01:24,  2.13it/s][Astep: 49
extend+tolist() time: 0.00136566162109375

Evaluating:  22%|██▏       | 50/228 [00:22<01:23,  2.14it/s][Astep: 50
extend+tolist() time: 0.0016129016876220703

Evaluating:  22%|██▏       | 51/228 [00:22<01:20,  2.21it/s][Astep: 51
extend+tolist() time: 0.0015540122985839844

Evaluating:  23%|██▎       | 52/228 [00:23<01:19,  2.21it/s][Astep: 52
extend+tolist() time: 0.0009784698486328125

Evaluating:  23%|██▎       | 53/228 [00:23<01:16,  2.28it/s][Astep: 53
extend+tolist() time: 0.0017094612121582031

Evaluating:  24%|██▎       | 54/228 [00:23<01:15,  2.31it/s][Astep: 54
extend+tolist() time: 0.0012166500091552734

Evaluating:  24%|██▍       | 55/228 [00:24<01:16,  2.27it/s][Astep: 55
extend+tolist() time: 0.0007791519165039062

Evaluating:  25%|██▍       | 56/228 [00:24<01:13,  2.34it/s][Astep: 56
extend+tolist() time: 0.001621246337890625

Evaluating:  25%|██▌       | 57/228 [00:25<01:15,  2.27it/s][Astep: 57
extend+tolist() time: 0.0005857944488525391

Evaluating:  25%|██▌       | 58/228 [00:25<01:12,  2.35it/s][Astep: 58
extend+tolist() time: 0.0013248920440673828

Evaluating:  26%|██▌       | 59/228 [00:26<01:12,  2.32it/s][Astep: 59
extend+tolist() time: 0.0009186267852783203

Evaluating:  26%|██▋       | 60/228 [00:26<01:11,  2.34it/s][Astep: 60
extend+tolist() time: 0.0011477470397949219

Evaluating:  27%|██▋       | 61/228 [00:26<01:09,  2.39it/s][Astep: 61
extend+tolist() time: 0.0008606910705566406

Evaluating:  27%|██▋       | 62/228 [00:27<01:11,  2.33it/s][Astep: 62
extend+tolist() time: 0.001226663589477539

Evaluating:  28%|██▊       | 63/228 [00:27<01:09,  2.39it/s][Astep: 63
extend+tolist() time: 0.0008313655853271484

Evaluating:  28%|██▊       | 64/228 [00:28<01:10,  2.33it/s][Astep: 64
extend+tolist() time: 0.001291036605834961

Evaluating:  29%|██▊       | 65/228 [00:28<01:08,  2.38it/s][Astep: 65
extend+tolist() time: 0.0008423328399658203

Evaluating:  29%|██▉       | 66/228 [00:29<01:06,  2.43it/s][Astep: 66
extend+tolist() time: 0.17792463302612305

Evaluating:  29%|██▉       | 67/228 [00:29<01:16,  2.11it/s][Astep: 67
extend+tolist() time: 0.0013022422790527344

Evaluating:  30%|██▉       | 68/228 [00:30<01:11,  2.22it/s][Astep: 68
extend+tolist() time: 0.0006716251373291016

Evaluating:  30%|███       | 69/228 [00:30<01:10,  2.24it/s][Astep: 69
extend+tolist() time: 0.0014903545379638672

Evaluating:  31%|███       | 70/228 [00:30<01:08,  2.32it/s][Astep: 70
extend+tolist() time: 0.0014176368713378906

Evaluating:  31%|███       | 71/228 [00:31<01:08,  2.29it/s][Astep: 71
extend+tolist() time: 0.0009322166442871094

Evaluating:  32%|███▏      | 72/228 [00:31<01:06,  2.36it/s][Astep: 72
extend+tolist() time: 0.0016808509826660156

Evaluating:  32%|███▏      | 73/228 [00:32<01:05,  2.37it/s][Astep: 73
extend+tolist() time: 0.0005376338958740234

Evaluating:  32%|███▏      | 74/228 [00:32<01:05,  2.37it/s][Astep: 74
extend+tolist() time: 0.0011327266693115234

Evaluating:  33%|███▎      | 75/228 [00:32<01:03,  2.41it/s][Astep: 75
extend+tolist() time: 0.0016436576843261719

Evaluating:  33%|███▎      | 76/228 [00:33<01:05,  2.32it/s][Astep: 76
extend+tolist() time: 0.0006394386291503906

Evaluating:  34%|███▍      | 77/228 [00:33<01:11,  2.12it/s][Astep: 77
extend+tolist() time: 0.0018284320831298828

Evaluating:  34%|███▍      | 78/228 [00:34<01:10,  2.13it/s][Astep: 78
extend+tolist() time: 0.0008625984191894531

Evaluating:  35%|███▍      | 79/228 [00:34<01:06,  2.24it/s][Astep: 79
extend+tolist() time: 0.0013401508331298828

Evaluating:  35%|███▌      | 80/228 [00:35<01:05,  2.25it/s][Astep: 80
extend+tolist() time: 0.0014796257019042969

Evaluating:  36%|███▌      | 81/228 [00:35<01:04,  2.30it/s][Astep: 81
extend+tolist() time: 0.0008757114410400391

Evaluating:  36%|███▌      | 82/228 [00:36<01:01,  2.36it/s][Astep: 82
extend+tolist() time: 0.0012352466583251953

Evaluating:  36%|███▋      | 83/228 [00:36<01:02,  2.30it/s][Astep: 83
extend+tolist() time: 0.0007061958312988281

Evaluating:  37%|███▋      | 84/228 [00:37<01:10,  2.05it/s][Astep: 84
extend+tolist() time: 0.001424551010131836

Evaluating:  37%|███▋      | 85/228 [00:37<01:08,  2.10it/s][Astep: 85
extend+tolist() time: 0.00092315673828125

Evaluating:  38%|███▊      | 86/228 [00:37<01:04,  2.21it/s][Astep: 86
extend+tolist() time: 0.001316070556640625

Evaluating:  38%|███▊      | 87/228 [00:38<01:03,  2.21it/s][Astep: 87
extend+tolist() time: 0.0012326240539550781

Evaluating:  39%|███▊      | 88/228 [00:38<01:01,  2.29it/s][Astep: 88
extend+tolist() time: 0.0007593631744384766

Evaluating:  39%|███▉      | 89/228 [00:39<01:00,  2.31it/s][Astep: 89
extend+tolist() time: 0.0007393360137939453

Evaluating:  39%|███▉      | 90/228 [00:39<00:58,  2.35it/s][Astep: 90
extend+tolist() time: 0.0013909339904785156

Evaluating:  40%|███▉      | 91/228 [00:40<00:57,  2.40it/s][Astep: 91
extend+tolist() time: 0.001104593276977539

Evaluating:  40%|████      | 92/228 [00:40<00:58,  2.34it/s][Astep: 92
extend+tolist() time: 0.0007965564727783203

Evaluating:  41%|████      | 93/228 [00:40<00:56,  2.39it/s][Astep: 93
extend+tolist() time: 0.0014107227325439453

Evaluating:  41%|████      | 94/228 [00:41<00:57,  2.34it/s][Astep: 94
extend+tolist() time: 0.0007104873657226562

Evaluating:  42%|████▏     | 95/228 [00:41<00:56,  2.37it/s][Astep: 95
extend+tolist() time: 0.0016014575958251953

Evaluating:  42%|████▏     | 96/228 [00:42<00:55,  2.40it/s][Astep: 96
extend+tolist() time: 0.0009303092956542969

Evaluating:  43%|████▎     | 97/228 [00:42<00:56,  2.33it/s][Astep: 97
extend+tolist() time: 0.001268148422241211

Evaluating:  43%|████▎     | 98/228 [00:43<00:54,  2.38it/s][Astep: 98
extend+tolist() time: 0.0012516975402832031

Evaluating:  43%|████▎     | 99/228 [00:43<00:55,  2.32it/s][Astep: 99
extend+tolist() time: 0.0008687973022460938

Evaluating:  44%|████▍     | 100/228 [00:43<00:53,  2.37it/s][Astep: 100
extend+tolist() time: 0.00141143798828125

Evaluating:  44%|████▍     | 101/228 [00:44<00:52,  2.40it/s][Astep: 101
extend+tolist() time: 0.0008261203765869141

Evaluating:  45%|████▍     | 102/228 [00:44<00:52,  2.38it/s][Astep: 102
extend+tolist() time: 0.0011413097381591797

Evaluating:  45%|████▌     | 103/228 [00:45<00:51,  2.43it/s][Astep: 103
extend+tolist() time: 0.0007624626159667969

Evaluating:  46%|████▌     | 104/228 [00:45<00:52,  2.36it/s][Astep: 104
extend+tolist() time: 0.001146078109741211

Evaluating:  46%|████▌     | 105/228 [00:45<00:50,  2.42it/s][Astep: 105
extend+tolist() time: 0.0008215904235839844

Evaluating:  46%|████▋     | 106/228 [00:46<00:50,  2.40it/s][Astep: 106
extend+tolist() time: 0.0018463134765625

Evaluating:  47%|████▋     | 107/228 [00:46<00:50,  2.38it/s][Astep: 107
extend+tolist() time: 0.0007817745208740234

Evaluating:  47%|████▋     | 108/228 [00:47<00:49,  2.42it/s][Astep: 108
extend+tolist() time: 0.0012252330780029297

Evaluating:  48%|████▊     | 109/228 [00:47<00:50,  2.34it/s][Astep: 109
extend+tolist() time: 0.0012123584747314453

Evaluating:  48%|████▊     | 110/228 [00:48<00:49,  2.39it/s][Astep: 110
extend+tolist() time: 0.0006322860717773438

Evaluating:  49%|████▊     | 111/228 [00:48<00:50,  2.33it/s][Astep: 111
extend+tolist() time: 0.23567795753479004

Evaluating:  49%|████▉     | 112/228 [00:49<00:57,  2.03it/s][Astep: 112
extend+tolist() time: 0.0003750324249267578

Evaluating:  50%|████▉     | 113/228 [00:49<00:54,  2.10it/s][Astep: 113
extend+tolist() time: 0.001119375228881836

Evaluating:  50%|█████     | 114/228 [00:50<00:51,  2.22it/s][Astep: 114
extend+tolist() time: 0.0011141300201416016

Evaluating:  50%|█████     | 115/228 [00:50<00:50,  2.24it/s][Astep: 115
extend+tolist() time: 0.0006365776062011719

Evaluating:  51%|█████     | 116/228 [00:50<00:49,  2.27it/s][Astep: 116
extend+tolist() time: 0.0008256435394287109

Evaluating:  51%|█████▏    | 117/228 [00:51<00:47,  2.35it/s][Astep: 117
extend+tolist() time: 0.0008292198181152344

Evaluating:  52%|█████▏    | 118/228 [00:51<00:47,  2.30it/s][Astep: 118
extend+tolist() time: 0.0005452632904052734

Evaluating:  52%|█████▏    | 119/228 [00:52<00:46,  2.36it/s][Astep: 119
extend+tolist() time: 0.0011610984802246094

Evaluating:  53%|█████▎    | 120/228 [00:52<00:46,  2.34it/s][Astep: 120
extend+tolist() time: 0.0006632804870605469

Evaluating:  53%|█████▎    | 121/228 [00:52<00:45,  2.37it/s][Astep: 121
extend+tolist() time: 0.0010690689086914062

Evaluating:  54%|█████▎    | 122/228 [00:53<00:43,  2.41it/s][Astep: 122
extend+tolist() time: 0.0006508827209472656

Evaluating:  54%|█████▍    | 123/228 [00:53<00:45,  2.33it/s][Astep: 123
extend+tolist() time: 0.0005931854248046875

Evaluating:  54%|█████▍    | 124/228 [00:54<00:43,  2.39it/s][Astep: 124
extend+tolist() time: 0.0012814998626708984

Evaluating:  55%|█████▍    | 125/228 [00:54<00:44,  2.33it/s][Astep: 125
extend+tolist() time: 0.00044918060302734375

Evaluating:  55%|█████▌    | 126/228 [00:55<00:42,  2.40it/s][Astep: 126
extend+tolist() time: 0.0019385814666748047

Evaluating:  56%|█████▌    | 127/228 [00:55<00:42,  2.36it/s][Astep: 127
extend+tolist() time: 0.0016584396362304688

Evaluating:  56%|█████▌    | 128/228 [00:56<00:49,  2.03it/s][Astep: 128
extend+tolist() time: 0.0007379055023193359

Evaluating:  57%|█████▋    | 129/228 [00:56<00:47,  2.10it/s][Astep: 129
extend+tolist() time: 0.0011432170867919922

Evaluating:  57%|█████▋    | 130/228 [00:56<00:44,  2.20it/s][Astep: 130
extend+tolist() time: 0.0008823871612548828

Evaluating:  57%|█████▋    | 131/228 [00:57<00:42,  2.29it/s][Astep: 131
extend+tolist() time: 0.0004467964172363281

Evaluating:  58%|█████▊    | 132/228 [00:57<00:42,  2.27it/s][Astep: 132
extend+tolist() time: 0.0010654926300048828

Evaluating:  58%|█████▊    | 133/228 [00:58<00:40,  2.33it/s][Astep: 133
extend+tolist() time: 0.0008904933929443359

Evaluating:  59%|█████▉    | 134/228 [00:58<00:40,  2.34it/s][Astep: 134
extend+tolist() time: 0.0009348392486572266

Evaluating:  59%|█████▉    | 135/228 [00:59<00:39,  2.36it/s][Astep: 135
extend+tolist() time: 0.0008416175842285156

Evaluating:  60%|█████▉    | 136/228 [00:59<00:39,  2.34it/s][Astep: 136
extend+tolist() time: 0.0008385181427001953

Evaluating:  60%|██████    | 137/228 [01:00<00:44,  2.04it/s][Astep: 137
extend+tolist() time: 0.0005970001220703125

Evaluating:  61%|██████    | 138/228 [01:00<00:42,  2.14it/s][Astep: 138
extend+tolist() time: 0.0012085437774658203

Evaluating:  61%|██████    | 139/228 [01:00<00:40,  2.20it/s][Astep: 139
extend+tolist() time: 0.0004525184631347656

Evaluating:  61%|██████▏   | 140/228 [01:01<00:38,  2.30it/s][Astep: 140
extend+tolist() time: 0.0007390975952148438

Evaluating:  62%|██████▏   | 141/228 [01:01<00:38,  2.26it/s][Astep: 141
extend+tolist() time: 0.0012145042419433594

Evaluating:  62%|██████▏   | 142/228 [01:02<00:36,  2.34it/s][Astep: 142
extend+tolist() time: 0.0005738735198974609

Evaluating:  63%|██████▎   | 143/228 [01:02<00:36,  2.36it/s][Astep: 143
extend+tolist() time: 0.00034165382385253906

Evaluating:  63%|██████▎   | 144/228 [01:03<00:35,  2.37it/s][Astep: 144
extend+tolist() time: 0.0011289119720458984

Evaluating:  64%|██████▎   | 145/228 [01:03<00:34,  2.41it/s][Astep: 145
extend+tolist() time: 0.0004608631134033203

Evaluating:  64%|██████▍   | 146/228 [01:03<00:34,  2.36it/s][Astep: 146
extend+tolist() time: 0.00037479400634765625

Evaluating:  64%|██████▍   | 147/228 [01:04<00:33,  2.42it/s][Astep: 147
extend+tolist() time: 0.0011143684387207031

Evaluating:  65%|██████▍   | 148/228 [01:04<00:33,  2.37it/s][Astep: 148
extend+tolist() time: 0.0006580352783203125

Evaluating:  65%|██████▌   | 149/228 [01:05<00:32,  2.40it/s][Astep: 149
extend+tolist() time: 0.00035500526428222656

Evaluating:  66%|██████▌   | 150/228 [01:05<00:31,  2.47it/s][Astep: 150
extend+tolist() time: 0.0012383460998535156

Evaluating:  66%|██████▌   | 151/228 [01:05<00:32,  2.39it/s][Astep: 151
extend+tolist() time: 0.0005667209625244141

Evaluating:  67%|██████▋   | 152/228 [01:06<00:31,  2.45it/s][Astep: 152
extend+tolist() time: 0.0011775493621826172

Evaluating:  67%|██████▋   | 153/228 [01:06<00:30,  2.43it/s][Astep: 153
extend+tolist() time: 0.0008821487426757812

Evaluating:  68%|██████▊   | 154/228 [01:07<00:30,  2.44it/s][Astep: 154
extend+tolist() time: 0.0018868446350097656

Evaluating:  68%|██████▊   | 155/228 [01:07<00:29,  2.44it/s][Astep: 155
extend+tolist() time: 0.001043081283569336

Evaluating:  68%|██████▊   | 156/228 [01:08<00:30,  2.37it/s][Astep: 156
extend+tolist() time: 0.0005559921264648438

Evaluating:  69%|██████▉   | 157/228 [01:08<00:29,  2.44it/s][Astep: 157
extend+tolist() time: 0.0007262229919433594

Evaluating:  69%|██████▉   | 158/228 [01:08<00:29,  2.40it/s][Astep: 158
extend+tolist() time: 0.0008924007415771484

Evaluating:  70%|██████▉   | 159/228 [01:09<00:28,  2.43it/s][Astep: 159
extend+tolist() time: 0.0007390975952148438

Evaluating:  70%|███████   | 160/228 [01:09<00:27,  2.47it/s][Astep: 160
extend+tolist() time: 0.0003986358642578125

Evaluating:  71%|███████   | 161/228 [01:10<00:27,  2.40it/s][Astep: 161
extend+tolist() time: 0.0012395381927490234

Evaluating:  71%|███████   | 162/228 [01:10<00:26,  2.45it/s][Astep: 162
extend+tolist() time: 0.0005066394805908203

Evaluating:  71%|███████▏  | 163/228 [01:10<00:27,  2.41it/s][Astep: 163
extend+tolist() time: 0.00040793418884277344

Evaluating:  72%|███████▏  | 164/228 [01:11<00:25,  2.47it/s][Astep: 164
extend+tolist() time: 0.0005905628204345703

Evaluating:  72%|███████▏  | 165/228 [01:11<00:25,  2.51it/s][Astep: 165
extend+tolist() time: 0.0008881092071533203

Evaluating:  73%|███████▎  | 166/228 [01:12<00:25,  2.42it/s][Astep: 166
extend+tolist() time: 0.0003762245178222656

Evaluating:  73%|███████▎  | 167/228 [01:12<00:24,  2.48it/s][Astep: 167
extend+tolist() time: 0.0005762577056884766

Evaluating:  74%|███████▎  | 168/228 [01:12<00:24,  2.41it/s][Astep: 168
extend+tolist() time: 0.0016317367553710938

Evaluating:  74%|███████▍  | 169/228 [01:13<00:24,  2.45it/s][Astep: 169
extend+tolist() time: 0.0003695487976074219

Evaluating:  75%|███████▍  | 170/228 [01:13<00:23,  2.50it/s][Astep: 170
extend+tolist() time: 0.0009233951568603516

Evaluating:  75%|███████▌  | 171/228 [01:14<00:23,  2.40it/s][Astep: 171
extend+tolist() time: 0.00029730796813964844

Evaluating:  75%|███████▌  | 172/228 [01:14<00:22,  2.45it/s][Astep: 172
extend+tolist() time: 0.0012786388397216797

Evaluating:  76%|███████▌  | 173/228 [01:15<00:23,  2.38it/s][Astep: 173
extend+tolist() time: 0.0014767646789550781

Evaluating:  76%|███████▋  | 174/228 [01:15<00:22,  2.43it/s][Astep: 174
extend+tolist() time: 0.0015926361083984375

Evaluating:  77%|███████▋  | 175/228 [01:15<00:21,  2.41it/s][Astep: 175
extend+tolist() time: 0.0011928081512451172

Evaluating:  77%|███████▋  | 176/228 [01:16<00:21,  2.40it/s][Astep: 176
extend+tolist() time: 0.0006327629089355469

Evaluating:  78%|███████▊  | 177/228 [01:16<00:20,  2.46it/s][Astep: 177
extend+tolist() time: 0.0009644031524658203

Evaluating:  78%|███████▊  | 178/228 [01:17<00:21,  2.37it/s][Astep: 178
extend+tolist() time: 0.0012276172637939453

Evaluating:  79%|███████▊  | 179/228 [01:17<00:20,  2.40it/s][Astep: 179
extend+tolist() time: 0.0004112720489501953

Evaluating:  79%|███████▉  | 180/228 [01:17<00:19,  2.41it/s][Astep: 180
extend+tolist() time: 0.0008215904235839844

Evaluating:  79%|███████▉  | 181/228 [01:18<00:19,  2.42it/s][Astep: 181
extend+tolist() time: 0.0006082057952880859

Evaluating:  80%|███████▉  | 182/228 [01:18<00:18,  2.48it/s][Astep: 182
extend+tolist() time: 0.0007882118225097656

Evaluating:  80%|████████  | 183/228 [01:19<00:18,  2.39it/s][Astep: 183
extend+tolist() time: 0.001074075698852539

Evaluating:  81%|████████  | 184/228 [01:19<00:18,  2.43it/s][Astep: 184
extend+tolist() time: 0.0004851818084716797

Evaluating:  81%|████████  | 185/228 [01:19<00:17,  2.42it/s][Astep: 185
extend+tolist() time: 0.0015196800231933594

Evaluating:  82%|████████▏ | 186/228 [01:20<00:17,  2.38it/s][Astep: 186
extend+tolist() time: 0.0009999275207519531

Evaluating:  82%|████████▏ | 187/228 [01:20<00:16,  2.43it/s][Astep: 187
extend+tolist() time: 0.0004458427429199219

Evaluating:  82%|████████▏ | 188/228 [01:21<00:16,  2.38it/s][Astep: 188
extend+tolist() time: 0.0012085437774658203

Evaluating:  83%|████████▎ | 189/228 [01:21<00:16,  2.43it/s][Astep: 189
extend+tolist() time: 0.00037479400634765625

Evaluating:  83%|████████▎ | 190/228 [01:22<00:15,  2.40it/s][Astep: 190
extend+tolist() time: 0.0015544891357421875

Evaluating:  84%|████████▍ | 191/228 [01:22<00:15,  2.39it/s][Astep: 191
extend+tolist() time: 0.22170686721801758

Evaluating:  84%|████████▍ | 192/228 [01:23<00:17,  2.11it/s][Astep: 192
extend+tolist() time: 0.00044155120849609375

Evaluating:  85%|████████▍ | 193/228 [01:23<00:15,  2.20it/s][Astep: 193
extend+tolist() time: 0.0014760494232177734

Evaluating:  85%|████████▌ | 194/228 [01:23<00:15,  2.26it/s][Astep: 194
extend+tolist() time: 0.0006289482116699219

Evaluating:  86%|████████▌ | 195/228 [01:24<00:14,  2.26it/s][Astep: 195
extend+tolist() time: 0.000926971435546875

Evaluating:  86%|████████▌ | 196/228 [01:24<00:13,  2.35it/s][Astep: 196
extend+tolist() time: 0.0006508827209472656

Evaluating:  86%|████████▋ | 197/228 [01:25<00:13,  2.32it/s][Astep: 197
extend+tolist() time: 0.0006811618804931641

Evaluating:  87%|████████▋ | 198/228 [01:25<00:12,  2.37it/s][Astep: 198
extend+tolist() time: 0.0013585090637207031

Evaluating:  87%|████████▋ | 199/228 [01:25<00:12,  2.37it/s][Astep: 199
extend+tolist() time: 0.0018351078033447266

Evaluating:  88%|████████▊ | 200/228 [01:26<00:12,  2.32it/s][Astep: 200
extend+tolist() time: 0.0007426738739013672

Evaluating:  88%|████████▊ | 201/228 [01:26<00:11,  2.37it/s][Astep: 201
extend+tolist() time: 0.0006220340728759766

Evaluating:  89%|████████▊ | 202/228 [01:27<00:11,  2.32it/s][Astep: 202
extend+tolist() time: 0.0003993511199951172

Evaluating:  89%|████████▉ | 203/228 [01:27<00:10,  2.38it/s][Astep: 203
extend+tolist() time: 0.0014884471893310547

Evaluating:  89%|████████▉ | 204/228 [01:28<00:10,  2.37it/s][Astep: 204
extend+tolist() time: 0.00038504600524902344

Evaluating:  90%|████████▉ | 205/228 [01:28<00:09,  2.35it/s][Astep: 205
extend+tolist() time: 0.0003352165222167969

Evaluating:  90%|█████████ | 206/228 [01:28<00:09,  2.42it/s][Astep: 206
extend+tolist() time: 0.0005905628204345703

Evaluating:  91%|█████████ | 207/228 [01:29<00:08,  2.35it/s][Astep: 207
extend+tolist() time: 0.0010166168212890625

Evaluating:  91%|█████████ | 208/228 [01:29<00:08,  2.42it/s][Astep: 208
extend+tolist() time: 0.0007419586181640625

Evaluating:  92%|█████████▏| 209/228 [01:30<00:07,  2.38it/s][Astep: 209
extend+tolist() time: 0.0006053447723388672

Evaluating:  92%|█████████▏| 210/228 [01:30<00:07,  2.40it/s][Astep: 210
extend+tolist() time: 0.001047372817993164

Evaluating:  93%|█████████▎| 211/228 [01:31<00:06,  2.45it/s][Astep: 211
extend+tolist() time: 0.0010883808135986328

Evaluating:  93%|█████████▎| 212/228 [01:31<00:06,  2.35it/s][Astep: 212
extend+tolist() time: 0.0013124942779541016

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.41it/s][Astep: 213
extend+tolist() time: 0.0007712841033935547

Evaluating:  94%|█████████▍| 214/228 [01:32<00:06,  2.00it/s][Astep: 214
extend+tolist() time: 0.0012743473052978516

Evaluating:  94%|█████████▍| 215/228 [01:32<00:06,  2.14it/s][Astep: 215
extend+tolist() time: 0.0006740093231201172

Evaluating:  95%|█████████▍| 216/228 [01:33<00:05,  2.17it/s][Astep: 216
extend+tolist() time: 0.0005977153778076172

Evaluating:  95%|█████████▌| 217/228 [01:33<00:04,  2.28it/s][Astep: 217
extend+tolist() time: 0.0009505748748779297

Evaluating:  96%|█████████▌| 218/228 [01:34<00:04,  2.32it/s][Astep: 218
extend+tolist() time: 0.001039743423461914

Evaluating:  96%|█████████▌| 219/228 [01:34<00:03,  2.34it/s][Astep: 219
extend+tolist() time: 0.00047659873962402344

Evaluating:  96%|█████████▋| 220/228 [01:35<00:03,  2.40it/s][Astep: 220
extend+tolist() time: 0.0003943443298339844

Evaluating:  97%|█████████▋| 221/228 [01:35<00:02,  2.34it/s][Astep: 221
extend+tolist() time: 0.0006146430969238281

Evaluating:  97%|█████████▋| 222/228 [01:35<00:02,  2.42it/s][Astep: 222
extend+tolist() time: 0.0004506111145019531

Evaluating:  98%|█████████▊| 223/228 [01:36<00:02,  2.44it/s][Astep: 223
extend+tolist() time: 0.00038814544677734375

Evaluating:  98%|█████████▊| 224/228 [01:36<00:01,  2.44it/s][Astep: 224
extend+tolist() time: 0.0008137226104736328

Evaluating:  99%|█████████▊| 225/228 [01:37<00:01,  2.50it/s][Astep: 225
extend+tolist() time: 0.0004475116729736328

Evaluating:  99%|█████████▉| 226/228 [01:37<00:00,  2.42it/s][Astep: 226
extend+tolist() time: 0.0005116462707519531

Evaluating: 100%|█████████▉| 227/228 [01:37<00:00,  2.49it/s][Astep: 227
extend+tolist() time: 0.0004951953887939453

Evaluating: 100%|██████████| 228/228 [01:38<00:00,  2.43it/s][A09/08/2023 23:56:41 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/08/2023 23:56:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:56:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:56:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:56:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/08/2023 23:56:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:56:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:56:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:56:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/08/2023 23:56:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:56:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:56:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:56:42 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/08/2023 23:56:43 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:56:43 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:56:43 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/08/2023 23:56:43 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:40<00:00,  2.27it/s]
09/08/2023 23:56:43 - INFO - __main__ -   Step: 1680, Validation Metrics: {'pred_1_num': 9511, 'pred_-1_num': 1255, 'pred_0_num': 35, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.788445514304231, 'f1_micro': 0.788445514304231, 'f1_macro': 0.4380450943910124, 'f1_weighted': 0.7581080652421087, 'f1_-1': 0.39844026940801136, 'f1_0': 0.03857566765578634, 'f1_1': 0.8771193461092395, 'precision_micro': 0.788445514304231, 'precision_macro': 0.5513884381664654, 'precision_weighted': 0.7513797132718993, 'precision_-1': 0.447808764940239, 'precision_0': 0.37142857142857144, 'precision_1': 0.8349279781305856, 'recall_micro': 0.788445514304231, 'recall_macro': 0.43434072457034595, 'recall_weighted': 0.788445514304231, 'recall_-1': 0.35887611749680715, 'recall_0': 0.02034428794992175, 'recall_1': 0.9238017682643089, 'roc_auc_micro': 0.9242352717240696, 'roc_auc_macro': 0.7814049728905262, 'roc_auc_weighted': 0.7765504737358687, 'roc_auc_-1': 0.8411733223804989, 'roc_auc_0': 0.7351893072445477, 'roc_auc_1': 0.7678522890465322}
09/08/2023 23:56:57 - INFO - __main__ - Saving state to /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136
09/08/2023 23:56:57 - INFO - accelerate.accelerator - Saving current state to /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136
09/08/2023 23:56:57 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer
[2023-09-08 23:56:57,890] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/data/users/zhangjunlei/anaconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2023-09-08 23:56:57,898] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt...
[2023-09-08 23:56:57,898] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt...
[2023-09-08 23:56:57,898] [INFO] [logging.py:96:log_dist] [Rank 1] Saving model checkpoint: /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt
[2023-09-08 23:56:57,898] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt...
[2023-09-08 23:56:57,899] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt
[2023-09-08 23:56:57,899] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2023-09-08 23:56:57,912] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/zero_pp_rank_2_mp_rank_00_model_states.pt.
[2023-09-08 23:56:57,913] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/zero_pp_rank_3_mp_rank_00_model_states.pt.
[2023-09-08 23:56:57,913] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/zero_pp_rank_1_mp_rank_00_model_states.pt.
[2023-09-08 23:56:57,914] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2023-09-08 23:56:57,917] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2023-09-08 23:56:57,917] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt...
[2023-09-08 23:56:57,917] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt...
[2023-09-08 23:56:57,917] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2023-09-08 23:57:46,808] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2023-09-08 23:57:46,809] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2023-09-08 23:57:47,865] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2023-09-08 23:57:47,865] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2023-09-08 23:57:48,323] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt.
[2023-09-08 23:57:48,323] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt
[2023-09-08 23:57:49,960] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt.
[2023-09-08 23:57:49,961] [INFO] [engine.py:3285:_save_zero_checkpoint] zero checkpoint saved /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt
[2023-09-08 23:57:50,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 23:57:50,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 23:57:50,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2023-09-08 23:57:50,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
09/08/2023 23:57:50 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/pytorch_model
09/08/2023 23:57:50 - INFO - accelerate.checkpointing - Scheduler state saved in /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/scheduler.bin
09/08/2023 23:57:50 - INFO - accelerate.checkpointing - Random states saved in /data/users/zhangjunlei/tyx/reward-by-prm800k/models/wizardmath-13b-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16/step=1680-best-f1_-1=0.39844026940801136/random_states_0.pkl
[2023-09-08 23:58:10,101] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1681/66600 [2:35:19<1271:11:07, 70.49s/it]09/08/2023 23:58:10 - INFO - __main__ -   Step: 1681, LR: 1.6833145575165854e-05, Loss: 0.3765562176704407
[2023-09-08 23:58:30,513] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1682/66600 [2:35:40<1000:14:28, 55.47s/it]09/08/2023 23:58:30 - INFO - __main__ -   Step: 1682, LR: 1.6843159344098135e-05, Loss: 0.4159380793571472
[2023-09-08 23:58:50,752] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1683/66600 [2:36:00<809:38:36, 44.90s/it] 09/08/2023 23:58:50 - INFO - __main__ -   Step: 1683, LR: 1.685317311303042e-05, Loss: 0.32818603515625
[2023-09-08 23:59:11,296] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1684/66600 [2:36:20<677:52:39, 37.59s/it]09/08/2023 23:59:11 - INFO - __main__ -   Step: 1684, LR: 1.6863186881962702e-05, Loss: 0.4830421209335327
[2023-09-08 23:59:31,609] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1685/66600 [2:36:41<584:23:33, 32.41s/it]09/08/2023 23:59:31 - INFO - __main__ -   Step: 1685, LR: 1.6873200650894984e-05, Loss: 0.4646645188331604
[2023-09-08 23:59:52,215] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1686/66600 [2:37:01<520:32:15, 28.87s/it]09/08/2023 23:59:52 - INFO - __main__ -   Step: 1686, LR: 1.6883214419827262e-05, Loss: 0.385832279920578
[2023-09-09 00:00:12,690] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1687/66600 [2:37:22<475:07:30, 26.35s/it]09/09/2023 00:00:12 - INFO - __main__ -   Step: 1687, LR: 1.6893228188759543e-05, Loss: 0.4247434735298157
[2023-09-09 00:00:32,894] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1688/66600 [2:37:42<441:52:30, 24.51s/it]09/09/2023 00:00:32 - INFO - __main__ -   Step: 1688, LR: 1.690324195769183e-05, Loss: 0.43523022532463074
[2023-09-09 00:00:53,926] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1689/66600 [2:38:03<423:04:21, 23.46s/it]09/09/2023 00:00:53 - INFO - __main__ -   Step: 1689, LR: 1.691325572662411e-05, Loss: 0.46389275789260864
[2023-09-09 00:01:14,469] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1690/66600 [2:38:24<407:15:56, 22.59s/it]09/09/2023 00:01:14 - INFO - __main__ -   Step: 1690, LR: 1.692326949555639e-05, Loss: 0.40910977125167847
[2023-09-09 00:01:34,957] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1691/66600 [2:38:44<395:54:13, 21.96s/it]09/09/2023 00:01:34 - INFO - __main__ -   Step: 1691, LR: 1.6933283264488673e-05, Loss: 0.5059300661087036
[2023-09-09 00:01:55,647] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1692/66600 [2:39:05<389:02:38, 21.58s/it]09/09/2023 00:01:55 - INFO - __main__ -   Step: 1692, LR: 1.6943297033420955e-05, Loss: 0.42676782608032227
[2023-09-09 00:02:16,362] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1693/66600 [2:39:25<384:22:13, 21.32s/it]09/09/2023 00:02:16 - INFO - __main__ -   Step: 1693, LR: 1.6953310802353236e-05, Loss: 0.47472402453422546
[2023-09-09 00:02:36,823] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1694/66600 [2:39:46<379:43:33, 21.06s/it]09/09/2023 00:02:36 - INFO - __main__ -   Step: 1694, LR: 1.696332457128552e-05, Loss: 0.4212501049041748
[2023-09-09 00:02:57,038] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1695/66600 [2:40:06<375:08:27, 20.81s/it]09/09/2023 00:02:57 - INFO - __main__ -   Step: 1695, LR: 1.69733383402178e-05, Loss: 0.4414327144622803
[2023-09-09 00:03:17,484] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1696/66600 [2:40:27<373:10:58, 20.70s/it]09/09/2023 00:03:17 - INFO - __main__ -   Step: 1696, LR: 1.698335210915008e-05, Loss: 0.45235946774482727
[2023-09-09 00:03:38,011] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1697/66600 [2:40:47<372:14:42, 20.65s/it]09/09/2023 00:03:38 - INFO - __main__ -   Step: 1697, LR: 1.6993365878082363e-05, Loss: 0.42132291197776794
[2023-09-09 00:03:58,778] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1698/66600 [2:41:08<372:53:02, 20.68s/it]09/09/2023 00:03:58 - INFO - __main__ -   Step: 1698, LR: 1.7003379647014648e-05, Loss: 0.3949568271636963
[2023-09-09 00:04:19,249] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1699/66600 [2:41:28<371:43:51, 20.62s/it]09/09/2023 00:04:19 - INFO - __main__ -   Step: 1699, LR: 1.701339341594693e-05, Loss: 0.4310208559036255
[2023-09-09 00:04:39,385] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1700/66600 [2:41:48<369:06:32, 20.47s/it]09/09/2023 00:04:39 - INFO - __main__ -   Step: 1700, LR: 1.702340718487921e-05, Loss: 0.40348508954048157
09/09/2023 00:04:39 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.00270843505859375

Evaluating:   0%|          | 1/228 [00:00<01:50,  2.05it/s][Astep: 1
extend+tolist() time: 0.0010876655578613281

Evaluating:   1%|          | 2/228 [00:00<01:37,  2.33it/s][Astep: 2
extend+tolist() time: 0.1579279899597168

Evaluating:   1%|▏         | 3/228 [00:01<01:53,  1.98it/s][Astep: 3
extend+tolist() time: 0.0019762516021728516

Evaluating:   2%|▏         | 4/228 [00:01<01:43,  2.16it/s][Astep: 4
extend+tolist() time: 0.0014412403106689453

Evaluating:   2%|▏         | 5/228 [00:02<01:40,  2.23it/s][Astep: 5
extend+tolist() time: 0.0020554065704345703

Evaluating:   3%|▎         | 6/228 [00:02<01:37,  2.28it/s][Astep: 6
extend+tolist() time: 0.0020151138305664062

Evaluating:   3%|▎         | 7/228 [00:03<01:49,  2.02it/s][Astep: 7
extend+tolist() time: 0.0013020038604736328

Evaluating:   4%|▎         | 8/228 [00:03<01:42,  2.14it/s][Astep: 8
extend+tolist() time: 0.0007836818695068359

Evaluating:   4%|▍         | 9/228 [00:04<01:40,  2.19it/s][Astep: 9
extend+tolist() time: 0.0012378692626953125

Evaluating:   4%|▍         | 10/228 [00:04<01:36,  2.25it/s][Astep: 10
extend+tolist() time: 0.0008745193481445312

Evaluating:   5%|▍         | 11/228 [00:04<01:33,  2.32it/s][Astep: 11
extend+tolist() time: 0.0005600452423095703

Evaluating:   5%|▌         | 12/228 [00:05<01:33,  2.32it/s][Astep: 12
extend+tolist() time: 0.0011188983917236328

Evaluating:   6%|▌         | 13/228 [00:05<01:31,  2.35it/s][Astep: 13
extend+tolist() time: 0.0005919933319091797

Evaluating:   6%|▌         | 14/228 [00:06<01:31,  2.33it/s][Astep: 14
extend+tolist() time: 0.0009167194366455078

Evaluating:   7%|▋         | 15/228 [00:06<01:29,  2.37it/s][Astep: 15
extend+tolist() time: 0.0006124973297119141

Evaluating:   7%|▋         | 16/228 [00:07<01:29,  2.36it/s][Astep: 16
extend+tolist() time: 0.0008661746978759766

Evaluating:   7%|▋         | 17/228 [00:07<01:28,  2.40it/s][Astep: 17
extend+tolist() time: 0.0013489723205566406

Evaluating:   8%|▊         | 18/228 [00:07<01:26,  2.43it/s][Astep: 18
extend+tolist() time: 0.0015366077423095703

Evaluating:   8%|▊         | 19/228 [00:08<01:28,  2.37it/s][Astep: 19
extend+tolist() time: 0.0009703636169433594

Evaluating:   9%|▉         | 20/228 [00:08<01:27,  2.38it/s][Astep: 20
extend+tolist() time: 0.0011360645294189453

Evaluating:   9%|▉         | 21/228 [00:09<01:28,  2.35it/s][Astep: 21
extend+tolist() time: 0.0006830692291259766

Evaluating:  10%|▉         | 22/228 [00:09<01:26,  2.39it/s][Astep: 22
extend+tolist() time: 0.0007445812225341797

Evaluating:  10%|█         | 23/228 [00:09<01:23,  2.46it/s][Astep: 23
extend+tolist() time: 0.0006864070892333984

Evaluating:  11%|█         | 24/228 [00:10<01:30,  2.24it/s][Astep: 24
extend+tolist() time: 0.0015108585357666016

Evaluating:  11%|█         | 25/228 [00:10<01:27,  2.31it/s][Astep: 25
extend+tolist() time: 0.0018095970153808594

Evaluating:  11%|█▏        | 26/228 [00:11<01:29,  2.26it/s][Astep: 26
extend+tolist() time: 0.00070953369140625

Evaluating:  12%|█▏        | 27/228 [00:11<01:26,  2.34it/s][Astep: 27
extend+tolist() time: 0.0016942024230957031

Evaluating:  12%|█▏        | 28/228 [00:12<01:26,  2.32it/s][Astep: 28
extend+tolist() time: 0.0003387928009033203

Evaluating:  13%|█▎        | 29/228 [00:12<01:23,  2.39it/s][Astep: 29
extend+tolist() time: 0.0010709762573242188

Evaluating:  13%|█▎        | 30/228 [00:12<01:20,  2.46it/s][Astep: 30
extend+tolist() time: 0.0010733604431152344

Evaluating:  14%|█▎        | 31/228 [00:13<01:21,  2.41it/s][Astep: 31
extend+tolist() time: 0.14225196838378906

Evaluating:  14%|█▍        | 32/228 [00:13<01:28,  2.22it/s][Astep: 32
extend+tolist() time: 0.0010259151458740234

Evaluating:  14%|█▍        | 33/228 [00:14<01:26,  2.24it/s][Astep: 33
extend+tolist() time: 0.0017192363739013672

Evaluating:  15%|█▍        | 34/228 [00:14<01:24,  2.29it/s][Astep: 34
extend+tolist() time: 0.0012013912200927734

Evaluating:  15%|█▌        | 35/228 [00:15<01:22,  2.34it/s][Astep: 35
extend+tolist() time: 0.0006456375122070312

Evaluating:  16%|█▌        | 36/228 [00:15<01:20,  2.39it/s][Astep: 36
extend+tolist() time: 0.0012056827545166016

Evaluating:  16%|█▌        | 37/228 [00:16<01:26,  2.21it/s][Astep: 37
extend+tolist() time: 0.001611471176147461

Evaluating:  17%|█▋        | 38/228 [00:16<01:25,  2.22it/s][Astep: 38
extend+tolist() time: 0.0007412433624267578

Evaluating:  17%|█▋        | 39/228 [00:16<01:22,  2.29it/s][Astep: 39
extend+tolist() time: 0.001138925552368164

Evaluating:  18%|█▊        | 40/228 [00:17<01:21,  2.29it/s][Astep: 40
extend+tolist() time: 0.0006434917449951172

Evaluating:  18%|█▊        | 41/228 [00:17<01:19,  2.34it/s][Astep: 41
extend+tolist() time: 0.0012142658233642578

Evaluating:  18%|█▊        | 42/228 [00:18<01:17,  2.41it/s][Astep: 42
extend+tolist() time: 0.0012021064758300781

Evaluating:  19%|█▉        | 43/228 [00:18<01:18,  2.36it/s][Astep: 43
extend+tolist() time: 0.001861572265625

Evaluating:  19%|█▉        | 44/228 [00:19<01:17,  2.37it/s][Astep: 44
extend+tolist() time: 0.0011188983917236328

Evaluating:  20%|█▉        | 45/228 [00:19<01:17,  2.36it/s][Astep: 45
extend+tolist() time: 0.0016446113586425781

Evaluating:  20%|██        | 46/228 [00:19<01:16,  2.37it/s][Astep: 46
extend+tolist() time: 0.0015587806701660156

Evaluating:  21%|██        | 47/228 [00:20<01:17,  2.34it/s][Astep: 47
extend+tolist() time: 0.001087188720703125

Evaluating:  21%|██        | 48/228 [00:20<01:15,  2.37it/s][Astep: 48
extend+tolist() time: 0.0016410350799560547

Evaluating:  21%|██▏       | 49/228 [00:21<01:14,  2.40it/s][Astep: 49
extend+tolist() time: 0.0012955665588378906

Evaluating:  22%|██▏       | 50/228 [00:21<01:14,  2.38it/s][Astep: 50
extend+tolist() time: 0.0012159347534179688

Evaluating:  22%|██▏       | 51/228 [00:22<01:13,  2.41it/s][Astep: 51
extend+tolist() time: 0.0016298294067382812

Evaluating:  23%|██▎       | 52/228 [00:22<01:13,  2.38it/s][Astep: 52
extend+tolist() time: 0.0013391971588134766

Evaluating:  23%|██▎       | 53/228 [00:22<01:21,  2.16it/s][Astep: 53
extend+tolist() time: 0.0016455650329589844

Evaluating:  24%|██▎       | 54/228 [00:23<01:18,  2.21it/s][Astep: 54
extend+tolist() time: 0.0008368492126464844

Evaluating:  24%|██▍       | 55/228 [00:23<01:15,  2.30it/s][Astep: 55
extend+tolist() time: 0.001178741455078125

Evaluating:  25%|██▍       | 56/228 [00:24<01:11,  2.40it/s][Astep: 56
extend+tolist() time: 0.0015196800231933594

Evaluating:  25%|██▌       | 57/228 [00:24<01:12,  2.37it/s][Astep: 57
extend+tolist() time: 0.0006015300750732422

Evaluating:  25%|██▌       | 58/228 [00:25<01:09,  2.43it/s][Astep: 58
extend+tolist() time: 0.0008380413055419922

Evaluating:  26%|██▌       | 59/228 [00:25<01:10,  2.41it/s][Astep: 59
extend+tolist() time: 0.0013782978057861328

Evaluating:  26%|██▋       | 60/228 [00:25<01:08,  2.45it/s][Astep: 60
extend+tolist() time: 0.0010600090026855469

Evaluating:  27%|██▋       | 61/228 [00:26<01:06,  2.51it/s][Astep: 61
extend+tolist() time: 0.0008401870727539062

Evaluating:  27%|██▋       | 62/228 [00:26<01:07,  2.47it/s][Astep: 62
extend+tolist() time: 0.0011796951293945312

Evaluating:  28%|██▊       | 63/228 [00:27<01:05,  2.50it/s][Astep: 63
extend+tolist() time: 0.0008270740509033203

Evaluating:  28%|██▊       | 64/228 [00:27<01:06,  2.48it/s][Astep: 64
extend+tolist() time: 0.1730344295501709

Evaluating:  29%|██▊       | 65/228 [00:27<01:12,  2.24it/s][Astep: 65
extend+tolist() time: 0.0008046627044677734

Evaluating:  29%|██▉       | 66/228 [00:28<01:09,  2.32it/s][Astep: 66
extend+tolist() time: 0.0011017322540283203

Evaluating:  29%|██▉       | 67/228 [00:28<01:10,  2.28it/s][Astep: 67
extend+tolist() time: 0.0008845329284667969

Evaluating:  30%|██▉       | 68/228 [00:29<01:08,  2.33it/s][Astep: 68
extend+tolist() time: 0.0006785392761230469

Evaluating:  30%|███       | 69/228 [00:29<01:08,  2.33it/s][Astep: 69
extend+tolist() time: 0.0015170574188232422

Evaluating:  31%|███       | 70/228 [00:30<01:07,  2.35it/s][Astep: 70
extend+tolist() time: 0.001074075698852539

Evaluating:  31%|███       | 71/228 [00:30<01:15,  2.08it/s][Astep: 71
extend+tolist() time: 0.0013668537139892578

Evaluating:  32%|███▏      | 72/228 [00:31<01:11,  2.19it/s][Astep: 72
extend+tolist() time: 0.0010886192321777344

Evaluating:  32%|███▏      | 73/228 [00:31<01:08,  2.26it/s][Astep: 73
extend+tolist() time: 0.0007696151733398438

Evaluating:  32%|███▏      | 74/228 [00:31<01:06,  2.30it/s][Astep: 74
extend+tolist() time: 0.0007414817810058594

Evaluating:  33%|███▎      | 75/228 [00:32<01:04,  2.37it/s][Astep: 75
extend+tolist() time: 0.0017495155334472656

Evaluating:  33%|███▎      | 76/228 [00:32<01:05,  2.32it/s][Astep: 76
extend+tolist() time: 0.0009987354278564453

Evaluating:  34%|███▍      | 77/228 [00:33<01:03,  2.38it/s][Astep: 77
extend+tolist() time: 0.0017697811126708984

Evaluating:  34%|███▍      | 78/228 [00:33<01:03,  2.35it/s][Astep: 78
extend+tolist() time: 0.0008645057678222656

Evaluating:  35%|███▍      | 79/228 [00:33<01:01,  2.41it/s][Astep: 79
extend+tolist() time: 0.0013010501861572266

Evaluating:  35%|███▌      | 80/228 [00:34<01:00,  2.44it/s][Astep: 80
extend+tolist() time: 0.0009469985961914062

Evaluating:  36%|███▌      | 81/228 [00:34<01:01,  2.37it/s][Astep: 81
extend+tolist() time: 0.0012941360473632812

Evaluating:  36%|███▌      | 82/228 [00:35<01:01,  2.39it/s][Astep: 82
extend+tolist() time: 0.0008301734924316406

Evaluating:  36%|███▋      | 83/228 [00:35<01:01,  2.36it/s][Astep: 83
extend+tolist() time: 0.0011658668518066406

Evaluating:  37%|███▋      | 84/228 [00:36<01:00,  2.37it/s][Astep: 84
extend+tolist() time: 0.0009737014770507812

Evaluating:  37%|███▋      | 85/228 [00:36<00:59,  2.40it/s][Astep: 85
extend+tolist() time: 0.001317739486694336

Evaluating:  38%|███▊      | 86/228 [00:36<01:00,  2.36it/s][Astep: 86
extend+tolist() time: 0.0012600421905517578

Evaluating:  38%|███▊      | 87/228 [00:37<00:59,  2.36it/s][Astep: 87
extend+tolist() time: 0.0008826255798339844

Evaluating:  39%|███▊      | 88/228 [00:37<01:00,  2.33it/s][Astep: 88
extend+tolist() time: 0.0011696815490722656

Evaluating:  39%|███▉      | 89/228 [00:38<00:58,  2.36it/s][Astep: 89
extend+tolist() time: 0.0007195472717285156

Evaluating:  39%|███▉      | 90/228 [00:38<00:58,  2.35it/s][Astep: 90
extend+tolist() time: 0.0013570785522460938

Evaluating:  40%|███▉      | 91/228 [00:39<00:57,  2.38it/s][Astep: 91
extend+tolist() time: 0.0007243156433105469

Evaluating:  40%|████      | 92/228 [00:39<00:56,  2.42it/s][Astep: 92
extend+tolist() time: 0.0012440681457519531

Evaluating:  41%|████      | 93/228 [00:39<00:57,  2.37it/s][Astep: 93
extend+tolist() time: 0.0010099411010742188

Evaluating:  41%|████      | 94/228 [00:40<00:56,  2.37it/s][Astep: 94
extend+tolist() time: 0.001161813735961914

Evaluating:  42%|████▏     | 95/228 [00:40<01:04,  2.06it/s][Astep: 95
extend+tolist() time: 0.0015497207641601562

Evaluating:  42%|████▏     | 96/228 [00:41<01:01,  2.15it/s][Astep: 96
extend+tolist() time: 0.0009462833404541016

Evaluating:  43%|████▎     | 97/228 [00:41<01:00,  2.18it/s][Astep: 97
extend+tolist() time: 0.0012392997741699219

Evaluating:  43%|████▎     | 98/228 [00:42<00:58,  2.24it/s][Astep: 98
extend+tolist() time: 0.0008864402770996094

Evaluating:  43%|████▎     | 99/228 [00:42<00:57,  2.23it/s][Astep: 99
extend+tolist() time: 0.0015573501586914062

Evaluating:  44%|████▍     | 100/228 [00:43<00:55,  2.29it/s][Astep: 100
extend+tolist() time: 0.0007395744323730469

Evaluating:  44%|████▍     | 101/228 [00:43<00:53,  2.36it/s][Astep: 101
extend+tolist() time: 0.0012574195861816406

Evaluating:  45%|████▍     | 102/228 [00:43<00:54,  2.32it/s][Astep: 102
extend+tolist() time: 0.0007169246673583984

Evaluating:  45%|████▌     | 103/228 [00:44<00:53,  2.34it/s][Astep: 103
extend+tolist() time: 0.0012042522430419922

Evaluating:  46%|████▌     | 104/228 [00:44<00:53,  2.33it/s][Astep: 104
extend+tolist() time: 0.000705718994140625

Evaluating:  46%|████▌     | 105/228 [00:45<00:52,  2.36it/s][Astep: 105
extend+tolist() time: 0.0012366771697998047

Evaluating:  46%|████▋     | 106/228 [00:45<00:50,  2.40it/s][Astep: 106
extend+tolist() time: 0.0017437934875488281

Evaluating:  47%|████▋     | 107/228 [00:46<00:51,  2.33it/s][Astep: 107
extend+tolist() time: 0.0007808208465576172

Evaluating:  47%|████▋     | 108/228 [00:46<00:50,  2.37it/s][Astep: 108
extend+tolist() time: 0.0012183189392089844

Evaluating:  48%|████▊     | 109/228 [00:46<00:51,  2.33it/s][Astep: 109
extend+tolist() time: 0.0008311271667480469

Evaluating:  48%|████▊     | 110/228 [00:47<00:50,  2.35it/s][Astep: 110
extend+tolist() time: 0.001033782958984375

Evaluating:  49%|████▊     | 111/228 [00:47<00:50,  2.32it/s][Astep: 111
extend+tolist() time: 0.1871778964996338

Evaluating:  49%|████▉     | 112/228 [00:48<00:55,  2.07it/s][Astep: 112
extend+tolist() time: 0.0004019737243652344

Evaluating:  50%|████▉     | 113/228 [00:48<00:53,  2.14it/s][Astep: 113
extend+tolist() time: 0.0007154941558837891

Evaluating:  50%|█████     | 114/228 [00:49<00:51,  2.21it/s][Astep: 114
extend+tolist() time: 0.0014824867248535156

Evaluating:  50%|█████     | 115/228 [00:49<00:49,  2.27it/s][Astep: 115
extend+tolist() time: 0.001016378402709961

Evaluating:  51%|█████     | 116/228 [00:50<00:56,  2.00it/s][Astep: 116
extend+tolist() time: 0.00084686279296875

Evaluating:  51%|█████▏    | 117/228 [00:50<00:52,  2.12it/s][Astep: 117
extend+tolist() time: 0.001249551773071289

Evaluating:  52%|█████▏    | 118/228 [00:51<00:51,  2.15it/s][Astep: 118
extend+tolist() time: 0.0005576610565185547

Evaluating:  52%|█████▏    | 119/228 [00:51<00:49,  2.22it/s][Astep: 119
extend+tolist() time: 0.0010862350463867188

Evaluating:  53%|█████▎    | 120/228 [00:51<00:48,  2.23it/s][Astep: 120
extend+tolist() time: 0.0006475448608398438

Evaluating:  53%|█████▎    | 121/228 [00:52<00:46,  2.28it/s][Astep: 121
extend+tolist() time: 0.0006425380706787109

Evaluating:  54%|█████▎    | 122/228 [00:52<00:46,  2.30it/s][Astep: 122
extend+tolist() time: 0.0013718605041503906

Evaluating:  54%|█████▍    | 123/228 [00:53<00:45,  2.32it/s][Astep: 123
extend+tolist() time: 0.0006170272827148438

Evaluating:  54%|█████▍    | 124/228 [00:53<00:43,  2.37it/s][Astep: 124
extend+tolist() time: 0.0012464523315429688

Evaluating:  55%|█████▍    | 125/228 [00:54<00:44,  2.33it/s][Astep: 125
extend+tolist() time: 0.00043010711669921875

Evaluating:  55%|█████▌    | 126/228 [00:54<00:43,  2.36it/s][Astep: 126
extend+tolist() time: 0.001771688461303711

Evaluating:  56%|█████▌    | 127/228 [00:54<00:44,  2.29it/s][Astep: 127
extend+tolist() time: 0.0017423629760742188

Evaluating:  56%|█████▌    | 128/228 [00:55<00:43,  2.28it/s][Astep: 128
extend+tolist() time: 0.0007359981536865234

Evaluating:  57%|█████▋    | 129/228 [00:55<00:42,  2.34it/s][Astep: 129
extend+tolist() time: 0.0012297630310058594

Evaluating:  57%|█████▋    | 130/228 [00:56<00:42,  2.31it/s][Astep: 130
extend+tolist() time: 0.0008916854858398438

Evaluating:  57%|█████▋    | 131/228 [00:56<00:41,  2.32it/s][Astep: 131
extend+tolist() time: 0.0004642009735107422

Evaluating:  58%|█████▊    | 132/228 [00:57<00:41,  2.30it/s][Astep: 132
extend+tolist() time: 0.0015468597412109375

Evaluating:  58%|█████▊    | 133/228 [00:57<00:41,  2.30it/s][Astep: 133
extend+tolist() time: 0.0004405975341796875

Evaluating:  59%|█████▉    | 134/228 [00:58<00:41,  2.28it/s][Astep: 134
extend+tolist() time: 0.0014066696166992188

Evaluating:  59%|█████▉    | 135/228 [00:58<00:40,  2.29it/s][Astep: 135
extend+tolist() time: 0.00043773651123046875

Evaluating:  60%|█████▉    | 136/228 [00:58<00:39,  2.35it/s][Astep: 136
extend+tolist() time: 0.001550912857055664

Evaluating:  60%|██████    | 137/228 [00:59<00:39,  2.29it/s][Astep: 137
extend+tolist() time: 0.00038695335388183594

Evaluating:  61%|██████    | 138/228 [00:59<00:38,  2.34it/s][Astep: 138
extend+tolist() time: 0.0006983280181884766

Evaluating:  61%|██████    | 139/228 [01:00<00:38,  2.34it/s][Astep: 139
extend+tolist() time: 0.000896453857421875

Evaluating:  61%|██████▏   | 140/228 [01:00<00:36,  2.38it/s][Astep: 140
extend+tolist() time: 0.0007581710815429688

Evaluating:  62%|██████▏   | 141/228 [01:00<00:36,  2.36it/s][Astep: 141
extend+tolist() time: 0.0014905929565429688

Evaluating:  62%|██████▏   | 142/228 [01:01<00:35,  2.40it/s][Astep: 142
extend+tolist() time: 0.0005815029144287109

Evaluating:  63%|██████▎   | 143/228 [01:01<00:35,  2.42it/s][Astep: 143
extend+tolist() time: 0.0003464221954345703

Evaluating:  63%|██████▎   | 144/228 [01:02<00:35,  2.39it/s][Astep: 144
extend+tolist() time: 0.0011403560638427734

Evaluating:  64%|██████▎   | 145/228 [01:02<00:34,  2.41it/s][Astep: 145
extend+tolist() time: 0.00046896934509277344

Evaluating:  64%|██████▍   | 146/228 [01:03<00:34,  2.39it/s][Astep: 146
extend+tolist() time: 0.00038433074951171875

Evaluating:  64%|██████▍   | 147/228 [01:03<00:33,  2.42it/s][Astep: 147
extend+tolist() time: 0.0006949901580810547

Evaluating:  65%|██████▍   | 148/228 [01:03<00:32,  2.46it/s][Astep: 148
extend+tolist() time: 0.0011148452758789062

Evaluating:  65%|██████▌   | 149/228 [01:04<00:32,  2.41it/s][Astep: 149
extend+tolist() time: 0.0003654956817626953

Evaluating:  66%|██████▌   | 150/228 [01:04<00:32,  2.42it/s][Astep: 150
extend+tolist() time: 0.0011811256408691406

Evaluating:  66%|██████▌   | 151/228 [01:05<00:32,  2.38it/s][Astep: 151
extend+tolist() time: 0.0006091594696044922

Evaluating:  67%|██████▋   | 152/228 [01:05<00:31,  2.41it/s][Astep: 152
extend+tolist() time: 0.0007891654968261719

Evaluating:  67%|██████▋   | 153/228 [01:05<00:30,  2.45it/s][Astep: 153
extend+tolist() time: 0.0013751983642578125

Evaluating:  68%|██████▊   | 154/228 [01:06<00:30,  2.39it/s][Astep: 154
extend+tolist() time: 0.0018281936645507812

Evaluating:  68%|██████▊   | 155/228 [01:06<00:30,  2.37it/s][Astep: 155
extend+tolist() time: 0.0006718635559082031

Evaluating:  68%|██████▊   | 156/228 [01:07<00:30,  2.35it/s][Astep: 156
extend+tolist() time: 0.0009467601776123047

Evaluating:  69%|██████▉   | 157/228 [01:07<00:34,  2.04it/s][Astep: 157
extend+tolist() time: 0.0007283687591552734

Evaluating:  69%|██████▉   | 158/228 [01:08<00:33,  2.11it/s][Astep: 158
extend+tolist() time: 0.0004901885986328125

Evaluating:  70%|██████▉   | 159/228 [01:08<00:31,  2.21it/s][Astep: 159
extend+tolist() time: 0.0011341571807861328

Evaluating:  70%|███████   | 160/228 [01:09<00:30,  2.27it/s][Astep: 160
extend+tolist() time: 0.0006692409515380859

Evaluating:  71%|███████   | 161/228 [01:09<00:28,  2.34it/s][Astep: 161
extend+tolist() time: 0.0007944107055664062

Evaluating:  71%|███████   | 162/228 [01:09<00:27,  2.40it/s][Astep: 162
extend+tolist() time: 0.000514984130859375

Evaluating:  71%|███████▏  | 163/228 [01:10<00:27,  2.39it/s][Astep: 163
extend+tolist() time: 0.0008444786071777344

Evaluating:  72%|███████▏  | 164/228 [01:10<00:26,  2.42it/s][Astep: 164
extend+tolist() time: 0.0005965232849121094

Evaluating:  72%|███████▏  | 165/228 [01:11<00:26,  2.40it/s][Astep: 165
extend+tolist() time: 0.0007252693176269531

Evaluating:  73%|███████▎  | 166/228 [01:11<00:25,  2.44it/s][Astep: 166
extend+tolist() time: 0.0003955364227294922

Evaluating:  73%|███████▎  | 167/228 [01:11<00:24,  2.49it/s][Astep: 167
extend+tolist() time: 0.0010266304016113281

Evaluating:  74%|███████▎  | 168/228 [01:12<00:24,  2.44it/s][Astep: 168
extend+tolist() time: 0.001216888427734375

Evaluating:  74%|███████▍  | 169/228 [01:12<00:24,  2.42it/s][Astep: 169
extend+tolist() time: 0.0007619857788085938

Evaluating:  75%|███████▍  | 170/228 [01:13<00:24,  2.40it/s][Astep: 170
extend+tolist() time: 0.0009317398071289062

Evaluating:  75%|███████▌  | 171/228 [01:13<00:23,  2.43it/s][Astep: 171
extend+tolist() time: 0.0002853870391845703

Evaluating:  75%|███████▌  | 172/228 [01:13<00:22,  2.48it/s][Astep: 172
extend+tolist() time: 0.0012772083282470703

Evaluating:  76%|███████▌  | 173/228 [01:14<00:22,  2.44it/s][Astep: 173
extend+tolist() time: 0.0011394023895263672

Evaluating:  76%|███████▋  | 174/228 [01:14<00:22,  2.43it/s][Astep: 174
extend+tolist() time: 0.0018804073333740234

Evaluating:  77%|███████▋  | 175/228 [01:15<00:22,  2.38it/s][Astep: 175
extend+tolist() time: 0.0011570453643798828

Evaluating:  77%|███████▋  | 176/228 [01:15<00:21,  2.41it/s][Astep: 176
extend+tolist() time: 0.0006415843963623047

Evaluating:  78%|███████▊  | 177/228 [01:16<00:20,  2.46it/s][Astep: 177
extend+tolist() time: 0.0006017684936523438

Evaluating:  78%|███████▊  | 178/228 [01:16<00:20,  2.45it/s][Astep: 178
extend+tolist() time: 0.001683950424194336

Evaluating:  79%|███████▊  | 179/228 [01:16<00:20,  2.44it/s][Astep: 179
extend+tolist() time: 0.00041174888610839844

Evaluating:  79%|███████▉  | 180/228 [01:17<00:19,  2.43it/s][Astep: 180
extend+tolist() time: 0.00040984153747558594

Evaluating:  79%|███████▉  | 181/228 [01:17<00:19,  2.46it/s][Astep: 181
extend+tolist() time: 0.0010213851928710938

Evaluating:  80%|███████▉  | 182/228 [01:18<00:18,  2.51it/s][Astep: 182
extend+tolist() time: 0.0007710456848144531

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.47it/s][Astep: 183
extend+tolist() time: 0.0006580352783203125

Evaluating:  81%|████████  | 184/228 [01:18<00:17,  2.47it/s][Astep: 184
extend+tolist() time: 0.0008938312530517578

Evaluating:  81%|████████  | 185/228 [01:19<00:17,  2.45it/s][Astep: 185
extend+tolist() time: 0.0011038780212402344

Evaluating:  82%|████████▏ | 186/228 [01:19<00:17,  2.44it/s][Astep: 186
extend+tolist() time: 0.2669956684112549

Evaluating:  82%|████████▏ | 187/228 [01:20<00:19,  2.08it/s][Astep: 187
extend+tolist() time: 0.00045943260192871094

Evaluating:  82%|████████▏ | 188/228 [01:20<00:18,  2.20it/s][Astep: 188
extend+tolist() time: 0.0010592937469482422

Evaluating:  83%|████████▎ | 189/228 [01:21<00:16,  2.30it/s][Astep: 189
extend+tolist() time: 0.0003676414489746094

Evaluating:  83%|████████▎ | 190/228 [01:21<00:16,  2.34it/s][Astep: 190
extend+tolist() time: 0.0011451244354248047

Evaluating:  84%|████████▍ | 191/228 [01:21<00:15,  2.36it/s][Astep: 191
extend+tolist() time: 0.0006899833679199219

Evaluating:  84%|████████▍ | 192/228 [01:22<00:15,  2.37it/s][Astep: 192
extend+tolist() time: 0.00044417381286621094

Evaluating:  85%|████████▍ | 193/228 [01:22<00:14,  2.42it/s][Astep: 193
extend+tolist() time: 0.001459360122680664

Evaluating:  85%|████████▌ | 194/228 [01:23<00:13,  2.48it/s][Astep: 194
extend+tolist() time: 0.0006389617919921875

Evaluating:  86%|████████▌ | 195/228 [01:23<00:13,  2.46it/s][Astep: 195
extend+tolist() time: 0.0005266666412353516

Evaluating:  86%|████████▌ | 196/228 [01:23<00:12,  2.49it/s][Astep: 196
extend+tolist() time: 0.0010304450988769531

Evaluating:  86%|████████▋ | 197/228 [01:24<00:15,  2.06it/s][Astep: 197
extend+tolist() time: 0.000659942626953125

Evaluating:  87%|████████▋ | 198/228 [01:25<00:13,  2.19it/s][Astep: 198
extend+tolist() time: 0.0006284713745117188

Evaluating:  87%|████████▋ | 199/228 [01:25<00:12,  2.25it/s][Astep: 199
extend+tolist() time: 0.0020220279693603516

Evaluating:  88%|████████▊ | 200/228 [01:25<00:12,  2.30it/s][Astep: 200
extend+tolist() time: 0.0010755062103271484

Evaluating:  88%|████████▊ | 201/228 [01:26<00:11,  2.39it/s][Astep: 201
extend+tolist() time: 0.0005967617034912109

Evaluating:  89%|████████▊ | 202/228 [01:26<00:10,  2.40it/s][Astep: 202
extend+tolist() time: 0.0003905296325683594

Evaluating:  89%|████████▉ | 203/228 [01:27<00:10,  2.45it/s][Astep: 203
extend+tolist() time: 0.0005056858062744141

Evaluating:  89%|████████▉ | 204/228 [01:27<00:09,  2.45it/s][Astep: 204
extend+tolist() time: 0.0008370876312255859

Evaluating:  90%|████████▉ | 205/228 [01:27<00:09,  2.49it/s][Astep: 205
extend+tolist() time: 0.00032973289489746094

Evaluating:  90%|█████████ | 206/228 [01:28<00:08,  2.54it/s][Astep: 206
extend+tolist() time: 0.0005788803100585938

Evaluating:  91%|█████████ | 207/228 [01:28<00:08,  2.53it/s][Astep: 207
extend+tolist() time: 0.0005848407745361328

Evaluating:  91%|█████████ | 208/228 [01:29<00:07,  2.53it/s][Astep: 208
extend+tolist() time: 0.0011789798736572266

Evaluating:  92%|█████████▏| 209/228 [01:29<00:07,  2.57it/s][Astep: 209
extend+tolist() time: 0.0005927085876464844

Evaluating:  92%|█████████▏| 210/228 [01:29<00:07,  2.53it/s][Astep: 210
extend+tolist() time: 0.0005927085876464844

Evaluating:  93%|█████████▎| 211/228 [01:30<00:06,  2.54it/s][Astep: 211
extend+tolist() time: 0.0015480518341064453

Evaluating:  93%|█████████▎| 212/228 [01:30<00:06,  2.48it/s][Astep: 212
extend+tolist() time: 0.0009179115295410156

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.49it/s][Astep: 213
extend+tolist() time: 0.0011348724365234375

Evaluating:  94%|█████████▍| 214/228 [01:31<00:05,  2.53it/s][Astep: 214
extend+tolist() time: 0.0008471012115478516

Evaluating:  94%|█████████▍| 215/228 [01:31<00:05,  2.50it/s][Astep: 215
extend+tolist() time: 0.0010237693786621094

Evaluating:  95%|█████████▍| 216/228 [01:32<00:04,  2.52it/s][Astep: 216
extend+tolist() time: 0.000579833984375

Evaluating:  95%|█████████▌| 217/228 [01:32<00:04,  2.51it/s][Astep: 217
extend+tolist() time: 0.0005609989166259766

Evaluating:  96%|█████████▌| 218/228 [01:32<00:03,  2.52it/s][Astep: 218
extend+tolist() time: 0.001486063003540039

Evaluating:  96%|█████████▌| 219/228 [01:33<00:03,  2.55it/s][Astep: 219
extend+tolist() time: 0.0004825592041015625

Evaluating:  96%|█████████▋| 220/228 [01:33<00:03,  2.53it/s][Astep: 220
extend+tolist() time: 0.00040268898010253906

Evaluating:  97%|█████████▋| 221/228 [01:34<00:02,  2.53it/s][Astep: 221
extend+tolist() time: 0.001047372817993164

Evaluating:  97%|█████████▋| 222/228 [01:34<00:02,  2.49it/s][Astep: 222
extend+tolist() time: 0.0004544258117675781

Evaluating:  98%|█████████▊| 223/228 [01:34<00:01,  2.51it/s][Astep: 223
extend+tolist() time: 0.0003883838653564453

Evaluating:  98%|█████████▊| 224/228 [01:35<00:01,  2.56it/s][Astep: 224
extend+tolist() time: 0.0003840923309326172

Evaluating:  99%|█████████▊| 225/228 [01:35<00:01,  2.51it/s][Astep: 225
extend+tolist() time: 0.0008716583251953125

Evaluating:  99%|█████████▉| 226/228 [01:36<00:00,  2.53it/s][Astep: 226
extend+tolist() time: 0.0005044937133789062

Evaluating: 100%|█████████▉| 227/228 [01:36<00:00,  2.50it/s][Astep: 227
extend+tolist() time: 0.0007634162902832031

Evaluating: 100%|██████████| 228/228 [01:36<00:00,  2.49it/s][A09/09/2023 00:06:16 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/09/2023 00:06:16 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:06:16 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:06:16 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:06:16 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:06:16 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:06:16 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:06:17 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:06:17 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:06:17 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:06:17 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:06:17 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:06:17 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:06:17 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:06:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:06:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:06:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:38<00:00,  2.31it/s]
09/09/2023 00:06:18 - INFO - __main__ -   Step: 1700, Validation Metrics: {'pred_1_num': 9840, 'pred_-1_num': 876, 'pred_0_num': 85, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7965929080640681, 'f1_micro': 0.7965929080640681, 'f1_macro': 0.4412800005437039, 'f1_weighted': 0.759243575853518, 'f1_-1': 0.3521703521703522, 'f1_0': 0.08839779005524862, 'f1_1': 0.8832718594055109, 'precision_micro': 0.7965929080640681, 'precision_macro': 0.5649257308447379, 'precision_weighted': 0.7519608545206811, 'precision_-1': 0.4908675799086758, 'precision_0': 0.3764705882352941, 'precision_1': 0.8274390243902439, 'recall_micro': 0.7965929080640681, 'recall_macro': 0.42394930470190223, 'recall_weighted': 0.7965929080640681, 'recall_-1': 0.27458492975734355, 'recall_0': 0.050078247261345854, 'recall_1': 0.9471847370870172, 'roc_auc_micro': 0.9132225906963166, 'roc_auc_macro': 0.7467657473445604, 'roc_auc_weighted': 0.7239334089216122, 'roc_auc_-1': 0.8004741733687089, 'roc_auc_0': 0.7303075158950818, 'roc_auc_1': 0.7095155527698903}
[2023-09-09 00:06:38,483] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1701/66600 [2:43:48<902:29:19, 50.06s/it]09/09/2023 00:06:38 - INFO - __main__ -   Step: 1701, LR: 1.7033420953811493e-05, Loss: 0.4220573604106903
[2023-09-09 00:06:58,739] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1702/66600 [2:44:08<741:16:39, 41.12s/it]09/09/2023 00:06:58 - INFO - __main__ -   Step: 1702, LR: 1.7043434722743774e-05, Loss: 0.4237264394760132
[2023-09-09 00:07:19,488] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1703/66600 [2:44:29<631:05:48, 35.01s/it]09/09/2023 00:07:19 - INFO - __main__ -   Step: 1703, LR: 1.7053448491676056e-05, Loss: 0.4078500270843506
[2023-09-09 00:07:39,804] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1704/66600 [2:44:49<551:38:00, 30.60s/it]09/09/2023 00:07:39 - INFO - __main__ -   Step: 1704, LR: 1.7063462260608337e-05, Loss: 0.3662151098251343
[2023-09-09 00:08:00,690] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1705/66600 [2:45:10<499:04:55, 27.69s/it]09/09/2023 00:08:00 - INFO - __main__ -   Step: 1705, LR: 1.707347602954062e-05, Loss: 0.4007551670074463
[2023-09-09 00:08:21,173] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1706/66600 [2:45:30<460:07:27, 25.53s/it]09/09/2023 00:08:21 - INFO - __main__ -   Step: 1706, LR: 1.70834897984729e-05, Loss: 0.3832901120185852
[2023-09-09 00:08:41,070] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1707/66600 [2:45:50<429:40:40, 23.84s/it]09/09/2023 00:08:41 - INFO - __main__ -   Step: 1707, LR: 1.7093503567405182e-05, Loss: 0.5422882437705994
[2023-09-09 00:09:01,837] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1708/66600 [2:46:11<413:04:17, 22.92s/it]09/09/2023 00:09:01 - INFO - __main__ -   Step: 1708, LR: 1.7103517336337464e-05, Loss: 0.4287776052951813
[2023-09-09 00:09:22,273] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1709/66600 [2:46:31<399:39:17, 22.17s/it]09/09/2023 00:09:22 - INFO - __main__ -   Step: 1709, LR: 1.711353110526975e-05, Loss: 0.4467446208000183
[2023-09-09 00:09:42,510] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1710/66600 [2:46:52<389:11:09, 21.59s/it]09/09/2023 00:09:42 - INFO - __main__ -   Step: 1710, LR: 1.712354487420203e-05, Loss: 0.4748246967792511
[2023-09-09 00:10:03,467] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1711/66600 [2:47:13<385:44:48, 21.40s/it]09/09/2023 00:10:03 - INFO - __main__ -   Step: 1711, LR: 1.7133558643134312e-05, Loss: 0.39493390917778015
[2023-09-09 00:10:23,967] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1712/66600 [2:47:33<380:52:22, 21.13s/it]09/09/2023 00:10:23 - INFO - __main__ -   Step: 1712, LR: 1.7143572412066594e-05, Loss: 0.3614336848258972
[2023-09-09 00:10:44,438] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1713/66600 [2:47:53<377:17:46, 20.93s/it]09/09/2023 00:10:44 - INFO - __main__ -   Step: 1713, LR: 1.7153586180998875e-05, Loss: 0.42717498540878296
[2023-09-09 00:11:04,494] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1714/66600 [2:48:14<372:33:01, 20.67s/it]09/09/2023 00:11:04 - INFO - __main__ -   Step: 1714, LR: 1.7163599949931157e-05, Loss: 0.4056071639060974
[2023-09-09 00:11:25,192] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1715/66600 [2:48:34<372:41:46, 20.68s/it]09/09/2023 00:11:25 - INFO - __main__ -   Step: 1715, LR: 1.717361371886344e-05, Loss: 0.4477715492248535
[2023-09-09 00:11:45,755] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1716/66600 [2:48:55<372:04:03, 20.64s/it]09/09/2023 00:11:45 - INFO - __main__ -   Step: 1716, LR: 1.718362748779572e-05, Loss: 0.3947809338569641
[2023-09-09 00:12:06,745] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1717/66600 [2:49:16<373:56:16, 20.75s/it]09/09/2023 00:12:06 - INFO - __main__ -   Step: 1717, LR: 1.7193641256728e-05, Loss: 0.38666480779647827
[2023-09-09 00:12:27,496] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1718/66600 [2:49:37<373:56:43, 20.75s/it]09/09/2023 00:12:27 - INFO - __main__ -   Step: 1718, LR: 1.7203655025660283e-05, Loss: 0.4854254424571991
[2023-09-09 00:12:48,768] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1719/66600 [2:49:58<376:46:29, 20.91s/it]09/09/2023 00:12:48 - INFO - __main__ -   Step: 1719, LR: 1.7213668794592565e-05, Loss: 0.46190983057022095
[2023-09-09 00:13:09,934] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1720/66600 [2:50:19<378:10:28, 20.98s/it]09/09/2023 00:13:09 - INFO - __main__ -   Step: 1720, LR: 1.722368256352485e-05, Loss: 0.5094581842422485
09/09/2023 00:13:09 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0025947093963623047

Evaluating:   0%|          | 1/228 [00:00<01:49,  2.07it/s][Astep: 1
extend+tolist() time: 0.0010907649993896484

Evaluating:   1%|          | 2/228 [00:00<01:40,  2.25it/s][Astep: 2
extend+tolist() time: 0.002199411392211914

Evaluating:   1%|▏         | 3/228 [00:01<01:35,  2.35it/s][Astep: 3
extend+tolist() time: 0.001981019973754883

Evaluating:   2%|▏         | 4/228 [00:01<01:35,  2.34it/s][Astep: 4
extend+tolist() time: 0.0015156269073486328

Evaluating:   2%|▏         | 5/228 [00:02<01:32,  2.41it/s][Astep: 5
extend+tolist() time: 0.0021169185638427734

Evaluating:   3%|▎         | 6/228 [00:02<01:32,  2.39it/s][Astep: 6
extend+tolist() time: 0.0019466876983642578

Evaluating:   3%|▎         | 7/228 [00:03<01:43,  2.13it/s][Astep: 7
extend+tolist() time: 0.0010030269622802734

Evaluating:   4%|▎         | 8/228 [00:03<01:38,  2.23it/s][Astep: 8
extend+tolist() time: 0.001222848892211914

Evaluating:   4%|▍         | 9/228 [00:03<01:36,  2.27it/s][Astep: 9
extend+tolist() time: 0.0008215904235839844

Evaluating:   4%|▍         | 10/228 [00:04<01:32,  2.36it/s][Astep: 10
extend+tolist() time: 0.0012974739074707031

Evaluating:   5%|▍         | 11/228 [00:04<01:31,  2.37it/s][Astep: 11
extend+tolist() time: 0.0005447864532470703

Evaluating:   5%|▌         | 12/228 [00:05<01:29,  2.41it/s][Astep: 12
extend+tolist() time: 0.0006513595581054688

Evaluating:   6%|▌         | 13/228 [00:05<01:27,  2.45it/s][Astep: 13
extend+tolist() time: 0.001007080078125

Evaluating:   6%|▌         | 14/228 [00:05<01:28,  2.41it/s][Astep: 14
extend+tolist() time: 0.000530242919921875

Evaluating:   7%|▋         | 15/228 [00:06<01:27,  2.42it/s][Astep: 15
extend+tolist() time: 0.000598907470703125

Evaluating:   7%|▋         | 16/228 [00:06<01:30,  2.35it/s][Astep: 16
extend+tolist() time: 0.0010237693786621094

Evaluating:   7%|▋         | 17/228 [00:07<01:28,  2.38it/s][Astep: 17
extend+tolist() time: 0.0008955001831054688

Evaluating:   8%|▊         | 18/228 [00:07<01:28,  2.37it/s][Astep: 18
extend+tolist() time: 0.0015873908996582031

Evaluating:   8%|▊         | 19/228 [00:08<01:29,  2.35it/s][Astep: 19
extend+tolist() time: 0.0013811588287353516

Evaluating:   9%|▉         | 20/228 [00:08<01:27,  2.38it/s][Astep: 20
extend+tolist() time: 0.0007574558258056641

Evaluating:   9%|▉         | 21/228 [00:08<01:28,  2.33it/s][Astep: 21
extend+tolist() time: 0.0010800361633300781

Evaluating:  10%|▉         | 22/228 [00:09<01:27,  2.36it/s][Astep: 22
extend+tolist() time: 0.0007455348968505859

Evaluating:  10%|█         | 23/228 [00:09<01:26,  2.36it/s][Astep: 23
extend+tolist() time: 0.0010442733764648438

Evaluating:  11%|█         | 24/228 [00:10<01:26,  2.36it/s][Astep: 24
extend+tolist() time: 0.0011179447174072266

Evaluating:  11%|█         | 25/228 [00:10<01:26,  2.36it/s][Astep: 25
extend+tolist() time: 0.15509557723999023

Evaluating:  11%|█▏        | 26/228 [00:11<01:37,  2.08it/s][Astep: 26
extend+tolist() time: 0.0012218952178955078

Evaluating:  12%|█▏        | 27/228 [00:11<01:32,  2.18it/s][Astep: 27
extend+tolist() time: 0.0015783309936523438

Evaluating:  12%|█▏        | 28/228 [00:12<01:31,  2.20it/s][Astep: 28
extend+tolist() time: 0.0003349781036376953

Evaluating:  13%|█▎        | 29/228 [00:12<01:27,  2.29it/s][Astep: 29
extend+tolist() time: 0.0006864070892333984

Evaluating:  13%|█▎        | 30/228 [00:12<01:26,  2.29it/s][Astep: 30
extend+tolist() time: 0.001493692398071289

Evaluating:  14%|█▎        | 31/228 [00:13<01:25,  2.32it/s][Astep: 31
extend+tolist() time: 0.0008821487426757812

Evaluating:  14%|█▍        | 32/228 [00:13<01:23,  2.33it/s][Astep: 32
extend+tolist() time: 0.0009984970092773438

Evaluating:  14%|█▍        | 33/228 [00:14<01:23,  2.34it/s][Astep: 33
extend+tolist() time: 0.0016620159149169922

Evaluating:  15%|█▍        | 34/228 [00:14<01:21,  2.37it/s][Astep: 34
extend+tolist() time: 0.0012104511260986328

Evaluating:  15%|█▌        | 35/228 [00:15<01:22,  2.34it/s][Astep: 35
extend+tolist() time: 0.0006737709045410156

Evaluating:  16%|█▌        | 36/228 [00:15<01:20,  2.37it/s][Astep: 36
extend+tolist() time: 0.0011827945709228516

Evaluating:  16%|█▌        | 37/228 [00:16<01:29,  2.13it/s][Astep: 37
extend+tolist() time: 0.0012278556823730469

Evaluating:  17%|█▋        | 38/228 [00:16<01:36,  1.97it/s][Astep: 38
extend+tolist() time: 0.0011897087097167969

Evaluating:  17%|█▋        | 39/228 [00:17<01:31,  2.07it/s][Astep: 39
extend+tolist() time: 0.0007300376892089844

Evaluating:  18%|█▊        | 40/228 [00:17<01:26,  2.17it/s][Astep: 40
extend+tolist() time: 0.001041412353515625

Evaluating:  18%|█▊        | 41/228 [00:17<01:24,  2.22it/s][Astep: 41
extend+tolist() time: 0.0008223056793212891

Evaluating:  18%|█▊        | 42/228 [00:18<01:22,  2.26it/s][Astep: 42
extend+tolist() time: 0.0016374588012695312

Evaluating:  19%|█▉        | 43/228 [00:18<01:21,  2.28it/s][Astep: 43
extend+tolist() time: 0.0018346309661865234

Evaluating:  19%|█▉        | 44/228 [00:19<01:21,  2.24it/s][Astep: 44
extend+tolist() time: 0.0007648468017578125

Evaluating:  20%|█▉        | 45/228 [00:19<01:19,  2.30it/s][Astep: 45
extend+tolist() time: 0.0016176700592041016

Evaluating:  20%|██        | 46/228 [00:20<01:20,  2.27it/s][Astep: 46
extend+tolist() time: 0.0019757747650146484

Evaluating:  21%|██        | 47/228 [00:20<01:19,  2.28it/s][Astep: 47
extend+tolist() time: 0.0014438629150390625

Evaluating:  21%|██        | 48/228 [00:20<01:19,  2.27it/s][Astep: 48
extend+tolist() time: 0.0015308856964111328

Evaluating:  21%|██▏       | 49/228 [00:21<01:18,  2.29it/s][Astep: 49
extend+tolist() time: 0.0009436607360839844

Evaluating:  22%|██▏       | 50/228 [00:21<01:15,  2.35it/s][Astep: 50
extend+tolist() time: 0.001669168472290039

Evaluating:  22%|██▏       | 51/228 [00:22<01:15,  2.35it/s][Astep: 51
extend+tolist() time: 0.0014998912811279297

Evaluating:  23%|██▎       | 52/228 [00:22<01:12,  2.42it/s][Astep: 52
extend+tolist() time: 0.0009546279907226562

Evaluating:  23%|██▎       | 53/228 [00:23<01:12,  2.41it/s][Astep: 53
extend+tolist() time: 0.00177764892578125

Evaluating:  24%|██▎       | 54/228 [00:23<01:13,  2.37it/s][Astep: 54
extend+tolist() time: 0.0011906623840332031

Evaluating:  24%|██▍       | 55/228 [00:23<01:11,  2.42it/s][Astep: 55
extend+tolist() time: 0.0007879734039306641

Evaluating:  25%|██▍       | 56/228 [00:24<01:11,  2.40it/s][Astep: 56
extend+tolist() time: 0.15732860565185547

Evaluating:  25%|██▌       | 57/228 [00:24<01:18,  2.18it/s][Astep: 57
extend+tolist() time: 0.0010008811950683594

Evaluating:  25%|██▌       | 58/228 [00:25<01:15,  2.27it/s][Astep: 58
extend+tolist() time: 0.0008685588836669922

Evaluating:  26%|██▌       | 59/228 [00:25<01:12,  2.33it/s][Astep: 59
extend+tolist() time: 0.0012981891632080078

Evaluating:  26%|██▋       | 60/228 [00:26<01:11,  2.34it/s][Astep: 60
extend+tolist() time: 0.0006868839263916016

Evaluating:  27%|██▋       | 61/228 [00:26<01:11,  2.34it/s][Astep: 61
extend+tolist() time: 0.001226663589477539

Evaluating:  27%|██▋       | 62/228 [00:26<01:10,  2.36it/s][Astep: 62
extend+tolist() time: 0.0011179447174072266

Evaluating:  28%|██▊       | 63/228 [00:27<01:10,  2.33it/s][Astep: 63
extend+tolist() time: 0.0008304119110107422

Evaluating:  28%|██▊       | 64/228 [00:27<01:08,  2.39it/s][Astep: 64
extend+tolist() time: 0.001224517822265625

Evaluating:  29%|██▊       | 65/228 [00:28<01:09,  2.35it/s][Astep: 65
extend+tolist() time: 0.0008344650268554688

Evaluating:  29%|██▉       | 66/228 [00:28<01:08,  2.36it/s][Astep: 66
extend+tolist() time: 0.0012347698211669922

Evaluating:  29%|██▉       | 67/228 [00:29<01:08,  2.37it/s][Astep: 67
extend+tolist() time: 0.0008990764617919922

Evaluating:  30%|██▉       | 68/228 [00:29<01:07,  2.36it/s][Astep: 68
extend+tolist() time: 0.001491546630859375

Evaluating:  30%|███       | 69/228 [00:29<01:06,  2.41it/s][Astep: 69
extend+tolist() time: 0.0010821819305419922

Evaluating:  31%|███       | 70/228 [00:30<01:07,  2.35it/s][Astep: 70
extend+tolist() time: 0.0017757415771484375

Evaluating:  31%|███       | 71/228 [00:30<01:16,  2.06it/s][Astep: 71
extend+tolist() time: 0.0013816356658935547

Evaluating:  32%|███▏      | 72/228 [00:31<01:12,  2.14it/s][Astep: 72
extend+tolist() time: 0.0007660388946533203

Evaluating:  32%|███▏      | 73/228 [00:31<01:09,  2.23it/s][Astep: 73
extend+tolist() time: 0.0005204677581787109

Evaluating:  32%|███▏      | 74/228 [00:32<01:07,  2.27it/s][Astep: 74
extend+tolist() time: 0.0012383460998535156

Evaluating:  33%|███▎      | 75/228 [00:32<01:06,  2.29it/s][Astep: 75
extend+tolist() time: 0.001598358154296875

Evaluating:  33%|███▎      | 76/228 [00:33<01:05,  2.31it/s][Astep: 76
extend+tolist() time: 0.000652313232421875

Evaluating:  34%|███▍      | 77/228 [00:33<01:05,  2.30it/s][Astep: 77
extend+tolist() time: 0.0019044876098632812

Evaluating:  34%|███▍      | 78/228 [00:33<01:04,  2.34it/s][Astep: 78
extend+tolist() time: 0.0012607574462890625

Evaluating:  35%|███▍      | 79/228 [00:34<01:04,  2.31it/s][Astep: 79
extend+tolist() time: 0.0009136199951171875

Evaluating:  35%|███▌      | 80/228 [00:34<01:03,  2.34it/s][Astep: 80
extend+tolist() time: 0.001398324966430664

Evaluating:  36%|███▌      | 81/228 [00:35<01:02,  2.33it/s][Astep: 81
extend+tolist() time: 0.0008440017700195312

Evaluating:  36%|███▌      | 82/228 [00:35<01:02,  2.33it/s][Astep: 82
extend+tolist() time: 0.0014591217041015625

Evaluating:  36%|███▋      | 83/228 [00:35<01:01,  2.37it/s][Astep: 83
extend+tolist() time: 0.0007035732269287109

Evaluating:  37%|███▋      | 84/228 [00:36<01:00,  2.36it/s][Astep: 84
extend+tolist() time: 0.0013833045959472656

Evaluating:  37%|███▋      | 85/228 [00:36<01:00,  2.37it/s][Astep: 85
extend+tolist() time: 0.0012810230255126953

Evaluating:  38%|███▊      | 86/228 [00:37<01:00,  2.36it/s][Astep: 86
extend+tolist() time: 0.0008983612060546875

Evaluating:  38%|███▊      | 87/228 [00:37<01:00,  2.35it/s][Astep: 87
extend+tolist() time: 0.0013513565063476562

Evaluating:  39%|███▊      | 88/228 [00:38<00:59,  2.35it/s][Astep: 88
extend+tolist() time: 0.0007543563842773438

Evaluating:  39%|███▉      | 89/228 [00:38<00:59,  2.35it/s][Astep: 89
extend+tolist() time: 0.0011448860168457031

Evaluating:  39%|███▉      | 90/228 [00:38<00:57,  2.41it/s][Astep: 90
extend+tolist() time: 0.0009500980377197266

Evaluating:  40%|███▉      | 91/228 [00:39<00:57,  2.38it/s][Astep: 91
extend+tolist() time: 0.0011820793151855469

Evaluating:  40%|████      | 92/228 [00:39<00:56,  2.40it/s][Astep: 92
extend+tolist() time: 0.0007808208465576172

Evaluating:  41%|████      | 93/228 [00:40<00:56,  2.39it/s][Astep: 93
extend+tolist() time: 0.0014257431030273438

Evaluating:  41%|████      | 94/228 [00:40<00:56,  2.37it/s][Astep: 94
extend+tolist() time: 0.0007426738739013672

Evaluating:  42%|████▏     | 95/228 [00:41<00:54,  2.43it/s][Astep: 95
extend+tolist() time: 0.0016329288482666016

Evaluating:  42%|████▏     | 96/228 [00:41<00:56,  2.35it/s][Astep: 96
extend+tolist() time: 0.001291036605834961

Evaluating:  43%|████▎     | 97/228 [00:41<00:55,  2.38it/s][Astep: 97
extend+tolist() time: 0.0008342266082763672

Evaluating:  43%|████▎     | 98/228 [00:42<00:54,  2.37it/s][Astep: 98
extend+tolist() time: 0.001331329345703125

Evaluating:  43%|████▎     | 99/228 [00:42<00:54,  2.36it/s][Astep: 99
extend+tolist() time: 0.0008971691131591797

Evaluating:  44%|████▍     | 100/228 [00:43<00:53,  2.39it/s][Astep: 100
extend+tolist() time: 0.22488164901733398

Evaluating:  44%|████▍     | 101/228 [00:43<01:01,  2.05it/s][Astep: 101
extend+tolist() time: 0.0012238025665283203

Evaluating:  45%|████▍     | 102/228 [00:44<00:57,  2.17it/s][Astep: 102
extend+tolist() time: 0.0006921291351318359

Evaluating:  45%|████▌     | 103/228 [00:44<00:56,  2.23it/s][Astep: 103
extend+tolist() time: 0.0010857582092285156

Evaluating:  46%|████▌     | 104/228 [00:44<00:53,  2.33it/s][Astep: 104
extend+tolist() time: 0.0006613731384277344

Evaluating:  46%|████▌     | 105/228 [00:45<00:52,  2.33it/s][Astep: 105
extend+tolist() time: 0.001190185546875

Evaluating:  46%|████▋     | 106/228 [00:45<00:51,  2.38it/s][Astep: 106
extend+tolist() time: 0.001638650894165039

Evaluating:  47%|████▋     | 107/228 [00:46<00:51,  2.35it/s][Astep: 107
extend+tolist() time: 0.0007576942443847656

Evaluating:  47%|████▋     | 108/228 [00:46<00:50,  2.36it/s][Astep: 108
extend+tolist() time: 0.0012235641479492188

Evaluating:  48%|████▊     | 109/228 [00:47<00:49,  2.42it/s][Astep: 109
extend+tolist() time: 0.0008330345153808594

Evaluating:  48%|████▊     | 110/228 [00:47<00:49,  2.39it/s][Astep: 110
extend+tolist() time: 0.0010471343994140625

Evaluating:  49%|████▊     | 111/228 [00:47<00:48,  2.43it/s][Astep: 111
extend+tolist() time: 0.0013763904571533203

Evaluating:  49%|████▉     | 112/228 [00:48<00:48,  2.37it/s][Astep: 112
extend+tolist() time: 0.00038170814514160156

Evaluating:  50%|████▉     | 113/228 [00:48<00:48,  2.37it/s][Astep: 113
extend+tolist() time: 0.000698089599609375

Evaluating:  50%|█████     | 114/228 [00:49<00:47,  2.42it/s][Astep: 114
extend+tolist() time: 0.0015990734100341797

Evaluating:  50%|█████     | 115/228 [00:49<00:48,  2.35it/s][Astep: 115
extend+tolist() time: 0.0006415843963623047

Evaluating:  51%|█████     | 116/228 [00:50<00:53,  2.10it/s][Astep: 116
extend+tolist() time: 0.0012598037719726562

Evaluating:  51%|█████▏    | 117/228 [00:50<00:51,  2.15it/s][Astep: 117
extend+tolist() time: 0.0008697509765625

Evaluating:  52%|█████▏    | 118/228 [00:51<00:49,  2.22it/s][Astep: 118
extend+tolist() time: 0.0010061264038085938

Evaluating:  52%|█████▏    | 119/228 [00:51<00:55,  1.95it/s][Astep: 119
extend+tolist() time: 0.0006973743438720703

Evaluating:  53%|█████▎    | 120/228 [00:52<00:51,  2.09it/s][Astep: 120
extend+tolist() time: 0.001062154769897461

Evaluating:  53%|█████▎    | 121/228 [00:52<00:50,  2.13it/s][Astep: 121
extend+tolist() time: 0.0006611347198486328

Evaluating:  54%|█████▎    | 122/228 [00:52<00:47,  2.21it/s][Astep: 122
extend+tolist() time: 0.0006740093231201172

Evaluating:  54%|█████▍    | 123/228 [00:53<00:46,  2.26it/s][Astep: 123
extend+tolist() time: 0.0010752677917480469

Evaluating:  54%|█████▍    | 124/228 [00:53<00:45,  2.29it/s][Astep: 124
extend+tolist() time: 0.0008189678192138672

Evaluating:  55%|█████▍    | 125/228 [00:54<00:43,  2.36it/s][Astep: 125
extend+tolist() time: 0.0004305839538574219

Evaluating:  55%|█████▌    | 126/228 [00:54<00:43,  2.34it/s][Astep: 126
extend+tolist() time: 0.0017313957214355469

Evaluating:  56%|█████▌    | 127/228 [00:55<00:43,  2.34it/s][Astep: 127
extend+tolist() time: 0.0016715526580810547

Evaluating:  56%|█████▌    | 128/228 [00:55<00:43,  2.32it/s][Astep: 128
extend+tolist() time: 0.0010743141174316406

Evaluating:  57%|█████▋    | 129/228 [00:55<00:42,  2.34it/s][Astep: 129
extend+tolist() time: 0.000965118408203125

Evaluating:  57%|█████▋    | 130/228 [00:56<00:40,  2.40it/s][Astep: 130
extend+tolist() time: 0.0013041496276855469

Evaluating:  57%|█████▋    | 131/228 [00:56<00:40,  2.37it/s][Astep: 131
extend+tolist() time: 0.00044655799865722656

Evaluating:  58%|█████▊    | 132/228 [00:57<00:39,  2.41it/s][Astep: 132
extend+tolist() time: 0.001451730728149414

Evaluating:  58%|█████▊    | 133/228 [00:57<00:39,  2.38it/s][Astep: 133
extend+tolist() time: 0.0004279613494873047

Evaluating:  59%|█████▉    | 134/228 [00:58<00:39,  2.39it/s][Astep: 134
extend+tolist() time: 0.0013775825500488281

Evaluating:  59%|█████▉    | 135/228 [00:58<00:38,  2.41it/s][Astep: 135
extend+tolist() time: 0.0004360675811767578

Evaluating:  60%|█████▉    | 136/228 [00:58<00:38,  2.37it/s][Astep: 136
extend+tolist() time: 0.0008280277252197266

Evaluating:  60%|██████    | 137/228 [00:59<00:37,  2.45it/s][Astep: 137
extend+tolist() time: 0.0008203983306884766

Evaluating:  61%|██████    | 138/228 [00:59<00:36,  2.45it/s][Astep: 138
extend+tolist() time: 0.0007100105285644531

Evaluating:  61%|██████    | 139/228 [01:00<00:36,  2.45it/s][Astep: 139
extend+tolist() time: 0.0004591941833496094

Evaluating:  61%|██████▏   | 140/228 [01:00<00:35,  2.48it/s][Astep: 140
extend+tolist() time: 0.0011920928955078125

Evaluating:  62%|██████▏   | 141/228 [01:00<00:35,  2.44it/s][Astep: 141
extend+tolist() time: 0.0007774829864501953

Evaluating:  62%|██████▏   | 142/228 [01:01<00:34,  2.50it/s][Astep: 142
extend+tolist() time: 0.0009548664093017578

Evaluating:  63%|██████▎   | 143/228 [01:01<00:34,  2.49it/s][Astep: 143
extend+tolist() time: 0.00034427642822265625

Evaluating:  63%|██████▎   | 144/228 [01:02<00:33,  2.49it/s][Astep: 144
extend+tolist() time: 0.0009105205535888672

Evaluating:  64%|██████▎   | 145/228 [01:02<00:32,  2.52it/s][Astep: 145
extend+tolist() time: 0.0004589557647705078

Evaluating:  64%|██████▍   | 146/228 [01:02<00:32,  2.49it/s][Astep: 146
extend+tolist() time: 0.0008449554443359375

Evaluating:  64%|██████▍   | 147/228 [01:03<00:32,  2.49it/s][Astep: 147
extend+tolist() time: 0.0006811618804931641

Evaluating:  65%|██████▍   | 148/228 [01:03<00:32,  2.45it/s][Astep: 148
extend+tolist() time: 0.0006494522094726562

Evaluating:  65%|██████▌   | 149/228 [01:04<00:32,  2.43it/s][Astep: 149
extend+tolist() time: 0.0008270740509033203

Evaluating:  66%|██████▌   | 150/228 [01:04<00:31,  2.44it/s][Astep: 150
extend+tolist() time: 0.0007805824279785156

Evaluating:  66%|██████▌   | 151/228 [01:04<00:32,  2.40it/s][Astep: 151
extend+tolist() time: 0.0005745887756347656

Evaluating:  67%|██████▋   | 152/228 [01:05<00:31,  2.44it/s][Astep: 152
extend+tolist() time: 0.0012023448944091797

Evaluating:  67%|██████▋   | 153/228 [01:05<00:31,  2.41it/s][Astep: 153
extend+tolist() time: 0.0012366771697998047

Evaluating:  68%|██████▊   | 154/228 [01:06<00:30,  2.39it/s][Astep: 154
extend+tolist() time: 0.0013949871063232422

Evaluating:  68%|██████▊   | 155/228 [01:06<00:30,  2.36it/s][Astep: 155
extend+tolist() time: 0.0010325908660888672

Evaluating:  68%|██████▊   | 156/228 [01:07<00:30,  2.37it/s][Astep: 156
extend+tolist() time: 0.0004749298095703125

Evaluating:  69%|██████▉   | 157/228 [01:07<00:29,  2.43it/s][Astep: 157
extend+tolist() time: 0.000993967056274414

Evaluating:  69%|██████▉   | 158/228 [01:07<00:29,  2.38it/s][Astep: 158
extend+tolist() time: 0.0004551410675048828

Evaluating:  70%|██████▉   | 159/228 [01:08<00:28,  2.40it/s][Astep: 159
extend+tolist() time: 0.0006036758422851562

Evaluating:  70%|███████   | 160/228 [01:08<00:29,  2.32it/s][Astep: 160
extend+tolist() time: 0.00036263465881347656

Evaluating:  71%|███████   | 161/228 [01:09<00:28,  2.33it/s][Astep: 161
extend+tolist() time: 0.0014600753784179688

Evaluating:  71%|███████   | 162/228 [01:09<00:27,  2.37it/s][Astep: 162
extend+tolist() time: 0.0005066394805908203

Evaluating:  71%|███████▏  | 163/228 [01:09<00:27,  2.37it/s][Astep: 163
extend+tolist() time: 0.000423431396484375

Evaluating:  72%|███████▏  | 164/228 [01:10<00:26,  2.40it/s][Astep: 164
extend+tolist() time: 0.0009911060333251953

Evaluating:  72%|███████▏  | 165/228 [01:10<00:26,  2.39it/s][Astep: 165
extend+tolist() time: 0.00046896934509277344

Evaluating:  73%|███████▎  | 166/228 [01:11<00:26,  2.38it/s][Astep: 166
extend+tolist() time: 0.00040459632873535156

Evaluating:  73%|███████▎  | 167/228 [01:11<00:25,  2.39it/s][Astep: 167
extend+tolist() time: 0.0005879402160644531

Evaluating:  74%|███████▎  | 168/228 [01:12<00:25,  2.34it/s][Astep: 168
extend+tolist() time: 0.001749277114868164

Evaluating:  74%|███████▍  | 169/228 [01:12<00:24,  2.37it/s][Astep: 169
extend+tolist() time: 0.00038886070251464844

Evaluating:  75%|███████▍  | 170/228 [01:12<00:24,  2.33it/s][Astep: 170
extend+tolist() time: 0.2138829231262207

Evaluating:  75%|███████▌  | 171/228 [01:13<00:27,  2.04it/s][Astep: 171
extend+tolist() time: 0.0002970695495605469

Evaluating:  75%|███████▌  | 172/228 [01:14<00:26,  2.12it/s][Astep: 172
extend+tolist() time: 0.0008339881896972656

Evaluating:  76%|███████▌  | 173/228 [01:14<00:25,  2.20it/s][Astep: 173
extend+tolist() time: 0.0015263557434082031

Evaluating:  76%|███████▋  | 174/228 [01:14<00:24,  2.22it/s][Astep: 174
extend+tolist() time: 0.0018241405487060547

Evaluating:  77%|███████▋  | 175/228 [01:15<00:23,  2.24it/s][Astep: 175
extend+tolist() time: 0.0008165836334228516

Evaluating:  77%|███████▋  | 176/228 [01:15<00:22,  2.29it/s][Astep: 176
extend+tolist() time: 0.0006287097930908203

Evaluating:  78%|███████▊  | 177/228 [01:16<00:22,  2.29it/s][Astep: 177
extend+tolist() time: 0.0006134510040283203

Evaluating:  78%|███████▊  | 178/228 [01:16<00:21,  2.36it/s][Astep: 178
extend+tolist() time: 0.0016927719116210938

Evaluating:  79%|███████▊  | 179/228 [01:16<00:21,  2.33it/s][Astep: 179
extend+tolist() time: 0.000415802001953125

Evaluating:  79%|███████▉  | 180/228 [01:17<00:20,  2.38it/s][Astep: 180
extend+tolist() time: 0.0004112720489501953

Evaluating:  79%|███████▉  | 181/228 [01:17<00:19,  2.39it/s][Astep: 181
extend+tolist() time: 0.0010223388671875

Evaluating:  80%|███████▉  | 182/228 [01:18<00:19,  2.38it/s][Astep: 182
extend+tolist() time: 0.0007631778717041016

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.43it/s][Astep: 183
extend+tolist() time: 0.0006301403045654297

Evaluating:  81%|████████  | 184/228 [01:19<00:18,  2.38it/s][Astep: 184
extend+tolist() time: 0.0008921623229980469

Evaluating:  81%|████████  | 185/228 [01:19<00:17,  2.40it/s][Astep: 185
extend+tolist() time: 0.0011661052703857422

Evaluating:  82%|████████▏ | 186/228 [01:19<00:17,  2.36it/s][Astep: 186
extend+tolist() time: 0.0014815330505371094

Evaluating:  82%|████████▏ | 187/228 [01:20<00:17,  2.34it/s][Astep: 187
extend+tolist() time: 0.0007100105285644531

Evaluating:  82%|████████▏ | 188/228 [01:20<00:16,  2.38it/s][Astep: 188
extend+tolist() time: 0.0007174015045166016

Evaluating:  83%|████████▎ | 189/228 [01:21<00:16,  2.37it/s][Astep: 189
extend+tolist() time: 0.0008106231689453125

Evaluating:  83%|████████▎ | 190/228 [01:21<00:15,  2.39it/s][Astep: 190
extend+tolist() time: 0.0011854171752929688

Evaluating:  84%|████████▍ | 191/228 [01:22<00:15,  2.35it/s][Astep: 191
extend+tolist() time: 0.0011408329010009766

Evaluating:  84%|████████▍ | 192/228 [01:22<00:15,  2.34it/s][Astep: 192
extend+tolist() time: 0.00047469139099121094

Evaluating:  85%|████████▍ | 193/228 [01:22<00:14,  2.37it/s][Astep: 193
extend+tolist() time: 0.0010955333709716797

Evaluating:  85%|████████▌ | 194/228 [01:23<00:14,  2.32it/s][Astep: 194
extend+tolist() time: 0.0012173652648925781

Evaluating:  86%|████████▌ | 195/228 [01:23<00:13,  2.37it/s][Astep: 195
extend+tolist() time: 0.0005295276641845703

Evaluating:  86%|████████▌ | 196/228 [01:24<00:15,  2.01it/s][Astep: 196
extend+tolist() time: 0.0008556842803955078

Evaluating:  86%|████████▋ | 197/228 [01:24<00:14,  2.11it/s][Astep: 197
extend+tolist() time: 0.0010802745819091797

Evaluating:  87%|████████▋ | 198/228 [01:25<00:13,  2.16it/s][Astep: 198
extend+tolist() time: 0.0006320476531982422

Evaluating:  87%|████████▋ | 199/228 [01:25<00:13,  2.23it/s][Astep: 199
extend+tolist() time: 0.0018970966339111328

Evaluating:  88%|████████▊ | 200/228 [01:26<00:12,  2.22it/s][Astep: 200
extend+tolist() time: 0.0007293224334716797

Evaluating:  88%|████████▊ | 201/228 [01:26<00:14,  1.91it/s][Astep: 201
extend+tolist() time: 0.001010894775390625

Evaluating:  89%|████████▊ | 202/228 [01:27<00:12,  2.03it/s][Astep: 202
extend+tolist() time: 0.0004019737243652344

Evaluating:  89%|████████▉ | 203/228 [01:27<00:11,  2.14it/s][Astep: 203
extend+tolist() time: 0.0005145072937011719

Evaluating:  89%|████████▉ | 204/228 [01:28<00:10,  2.21it/s][Astep: 204
extend+tolist() time: 0.0004012584686279297

Evaluating:  90%|████████▉ | 205/228 [01:28<00:10,  2.19it/s][Astep: 205
extend+tolist() time: 0.0003361701965332031

Evaluating:  90%|█████████ | 206/228 [01:28<00:10,  2.19it/s][Astep: 206
extend+tolist() time: 0.0010526180267333984

Evaluating:  91%|█████████ | 207/228 [01:29<00:09,  2.24it/s][Astep: 207
extend+tolist() time: 0.0006000995635986328

Evaluating:  91%|█████████ | 208/228 [01:29<00:08,  2.32it/s][Astep: 208
extend+tolist() time: 0.0007171630859375

Evaluating:  92%|█████████▏| 209/228 [01:30<00:08,  2.29it/s][Astep: 209
extend+tolist() time: 0.0010106563568115234

Evaluating:  92%|█████████▏| 210/228 [01:30<00:07,  2.33it/s][Astep: 210
extend+tolist() time: 0.0005993843078613281

Evaluating:  93%|█████████▎| 211/228 [01:31<00:07,  2.35it/s][Astep: 211
extend+tolist() time: 0.0014789104461669922

Evaluating:  93%|█████████▎| 212/228 [01:31<00:06,  2.33it/s][Astep: 212
extend+tolist() time: 0.001123666763305664

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.37it/s][Astep: 213
extend+tolist() time: 0.0007359981536865234

Evaluating:  94%|█████████▍| 214/228 [01:32<00:05,  2.36it/s][Astep: 214
extend+tolist() time: 0.0012917518615722656

Evaluating:  94%|█████████▍| 215/228 [01:32<00:05,  2.38it/s][Astep: 215
extend+tolist() time: 0.0006601810455322266

Evaluating:  95%|█████████▍| 216/228 [01:33<00:05,  2.36it/s][Astep: 216
extend+tolist() time: 0.000946044921875

Evaluating:  95%|█████████▌| 217/228 [01:33<00:04,  2.36it/s][Astep: 217
extend+tolist() time: 0.0005526542663574219

Evaluating:  96%|█████████▌| 218/228 [01:34<00:04,  2.40it/s][Astep: 218
extend+tolist() time: 0.001026153564453125

Evaluating:  96%|█████████▌| 219/228 [01:34<00:03,  2.36it/s][Astep: 219
extend+tolist() time: 0.00045228004455566406

Evaluating:  96%|█████████▋| 220/228 [01:34<00:03,  2.45it/s][Astep: 220
extend+tolist() time: 0.00038313865661621094

Evaluating:  97%|█████████▋| 221/228 [01:35<00:02,  2.47it/s][Astep: 221
extend+tolist() time: 0.0006382465362548828

Evaluating:  97%|█████████▋| 222/228 [01:35<00:02,  2.48it/s][Astep: 222
extend+tolist() time: 0.0011069774627685547

Evaluating:  98%|█████████▊| 223/228 [01:35<00:01,  2.55it/s][Astep: 223
extend+tolist() time: 0.0003876686096191406

Evaluating:  98%|█████████▊| 224/228 [01:36<00:01,  2.53it/s][Astep: 224
extend+tolist() time: 0.00038051605224609375

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.56it/s][Astep: 225
extend+tolist() time: 0.0004630088806152344

Evaluating:  99%|█████████▉| 226/228 [01:37<00:00,  2.52it/s][Astep: 226
extend+tolist() time: 0.0005125999450683594

Evaluating: 100%|█████████▉| 227/228 [01:37<00:00,  2.50it/s][Astep: 227
extend+tolist() time: 0.0009667873382568359

Evaluating: 100%|██████████| 228/228 [01:37<00:00,  2.51it/s][A09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:14:48 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:14:49 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:14:50 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:14:50 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:14:50 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:40<00:00,  2.27it/s]
09/09/2023 00:14:50 - INFO - __main__ -   Step: 1720, Validation Metrics: {'pred_1_num': 9645, 'pred_-1_num': 1121, 'pred_0_num': 35, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7892787704842145, 'f1_micro': 0.7892787704842144, 'f1_macro': 0.4343904765593365, 'f1_weighted': 0.7557920253820489, 'f1_-1': 0.3684406401190919, 'f1_0': 0.05637982195845697, 'f1_1': 0.8783509676004605, 'precision_micro': 0.7892787704842145, 'precision_macro': 0.6050043217893518, 'precision_weighted': 0.7571613625084646, 'precision_-1': 0.4415700267618198, 'precision_0': 0.5428571428571428, 'precision_1': 0.8305857957490927, 'recall_micro': 0.7892787704842145, 'recall_macro': 0.42592366802476384, 'recall_weighted': 0.7892787704842145, 'recall_-1': 0.3160919540229885, 'recall_0': 0.0297339593114241, 'recall_1': 0.931945090739879, 'roc_auc_micro': 0.9124966813201887, 'roc_auc_macro': 0.7415041470319187, 'roc_auc_weighted': 0.7239921525581254, 'roc_auc_-1': 0.7846005845660458, 'roc_auc_0': 0.7271996474022249, 'roc_auc_1': 0.7127122091274853}
[2023-09-09 00:15:11,179] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1721/66600 [2:52:20<920:14:05, 51.06s/it]09/09/2023 00:15:11 - INFO - __main__ -   Step: 1721, LR: 1.723369633245713e-05, Loss: 0.4045718312263489
[2023-09-09 00:15:31,583] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1722/66600 [2:52:41<754:28:13, 41.86s/it]09/09/2023 00:15:31 - INFO - __main__ -   Step: 1722, LR: 1.7243710101389413e-05, Loss: 0.4179038107395172
[2023-09-09 00:15:51,908] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1723/66600 [2:53:01<638:00:26, 35.40s/it]09/09/2023 00:15:51 - INFO - __main__ -   Step: 1723, LR: 1.7253723870321695e-05, Loss: 0.3495251536369324
[2023-09-09 00:16:12,337] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1724/66600 [2:53:21<557:02:42, 30.91s/it]09/09/2023 00:16:12 - INFO - __main__ -   Step: 1724, LR: 1.7263737639253976e-05, Loss: 0.4785515367984772
[2023-09-09 00:16:32,392] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1725/66600 [2:53:41<498:20:53, 27.65s/it]09/09/2023 00:16:32 - INFO - __main__ -   Step: 1725, LR: 1.7273751408186258e-05, Loss: 0.3964753746986389
[2023-09-09 00:16:52,790] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1726/66600 [2:54:02<459:06:38, 25.48s/it]09/09/2023 00:16:52 - INFO - __main__ -   Step: 1726, LR: 1.728376517711854e-05, Loss: 0.42055055499076843
[2023-09-09 00:17:12,630] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1727/66600 [2:54:22<428:37:55, 23.79s/it]09/09/2023 00:17:12 - INFO - __main__ -   Step: 1727, LR: 1.729377894605082e-05, Loss: 0.41374194622039795
[2023-09-09 00:17:33,772] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1728/66600 [2:54:43<414:19:40, 22.99s/it]09/09/2023 00:17:33 - INFO - __main__ -   Step: 1728, LR: 1.7303792714983103e-05, Loss: 0.4481537342071533
[2023-09-09 00:17:54,687] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1729/66600 [2:55:04<403:05:37, 22.37s/it]09/09/2023 00:17:54 - INFO - __main__ -   Step: 1729, LR: 1.7313806483915384e-05, Loss: 0.4082052409648895
[2023-09-09 00:18:14,644] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1730/66600 [2:55:24<390:02:37, 21.65s/it]09/09/2023 00:18:14 - INFO - __main__ -   Step: 1730, LR: 1.7323820252847666e-05, Loss: 0.3864041566848755
[2023-09-09 00:18:34,877] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1731/66600 [2:55:44<382:24:09, 21.22s/it]09/09/2023 00:18:34 - INFO - __main__ -   Step: 1731, LR: 1.733383402177995e-05, Loss: 0.3887215852737427
[2023-09-09 00:18:55,890] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1732/66600 [2:56:05<381:16:00, 21.16s/it]09/09/2023 00:18:55 - INFO - __main__ -   Step: 1732, LR: 1.7343847790712233e-05, Loss: 0.36268770694732666
[2023-09-09 00:19:16,629] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1733/66600 [2:56:26<378:59:13, 21.03s/it]09/09/2023 00:19:16 - INFO - __main__ -   Step: 1733, LR: 1.7353861559644514e-05, Loss: 0.44218170642852783
[2023-09-09 00:19:37,045] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1734/66600 [2:56:46<375:38:48, 20.85s/it]09/09/2023 00:19:37 - INFO - __main__ -   Step: 1734, LR: 1.7363875328576792e-05, Loss: 0.42931875586509705
[2023-09-09 00:19:57,618] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1735/66600 [2:57:07<374:09:20, 20.77s/it]09/09/2023 00:19:57 - INFO - __main__ -   Step: 1735, LR: 1.7373889097509077e-05, Loss: 0.41636282205581665
[2023-09-09 00:20:18,632] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1736/66600 [2:57:28<375:29:27, 20.84s/it]09/09/2023 00:20:18 - INFO - __main__ -   Step: 1736, LR: 1.738390286644136e-05, Loss: 0.5116096138954163
[2023-09-09 00:20:39,841] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1737/66600 [2:57:49<377:28:49, 20.95s/it]09/09/2023 00:20:39 - INFO - __main__ -   Step: 1737, LR: 1.739391663537364e-05, Loss: 0.4580584168434143
[2023-09-09 00:21:00,290] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1738/66600 [2:58:09<374:45:42, 20.80s/it]09/09/2023 00:21:00 - INFO - __main__ -   Step: 1738, LR: 1.7403930404305922e-05, Loss: 0.49262508749961853
[2023-09-09 00:21:21,036] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1739/66600 [2:58:30<374:27:49, 20.78s/it]09/09/2023 00:21:21 - INFO - __main__ -   Step: 1739, LR: 1.7413944173238204e-05, Loss: 0.4049115777015686
[2023-09-09 00:21:41,061] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1740/66600 [2:58:50<370:21:23, 20.56s/it]09/09/2023 00:21:41 - INFO - __main__ -   Step: 1740, LR: 1.7423957942170485e-05, Loss: 0.40265825390815735
09/09/2023 00:21:41 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0027794837951660156

Evaluating:   0%|          | 1/228 [00:00<01:49,  2.08it/s][Astep: 1
extend+tolist() time: 0.0018503665924072266

Evaluating:   1%|          | 2/228 [00:00<01:38,  2.29it/s][Astep: 2
extend+tolist() time: 0.002206087112426758

Evaluating:   1%|▏         | 3/228 [00:01<01:53,  1.98it/s][Astep: 3
extend+tolist() time: 0.002183675765991211

Evaluating:   2%|▏         | 4/228 [00:01<01:46,  2.11it/s][Astep: 4
extend+tolist() time: 0.0010154247283935547

Evaluating:   2%|▏         | 5/228 [00:02<01:41,  2.21it/s][Astep: 5
extend+tolist() time: 0.002355813980102539

Evaluating:   3%|▎         | 6/228 [00:02<01:38,  2.25it/s][Astep: 6
extend+tolist() time: 0.0020754337310791016

Evaluating:   3%|▎         | 7/228 [00:03<01:39,  2.21it/s][Astep: 7
extend+tolist() time: 0.0014090538024902344

Evaluating:   4%|▎         | 8/228 [00:03<01:36,  2.27it/s][Astep: 8
extend+tolist() time: 0.0007877349853515625

Evaluating:   4%|▍         | 9/228 [00:04<01:36,  2.28it/s][Astep: 9
extend+tolist() time: 0.0012061595916748047

Evaluating:   4%|▍         | 10/228 [00:04<01:33,  2.32it/s][Astep: 10
extend+tolist() time: 0.0012056827545166016

Evaluating:   5%|▍         | 11/228 [00:04<01:31,  2.38it/s][Astep: 11
extend+tolist() time: 0.0005838871002197266

Evaluating:   5%|▌         | 12/228 [00:05<01:37,  2.21it/s][Astep: 12
extend+tolist() time: 0.0006654262542724609

Evaluating:   6%|▌         | 13/228 [00:05<01:33,  2.30it/s][Astep: 13
extend+tolist() time: 0.001041412353515625

Evaluating:   6%|▌         | 14/228 [00:06<01:32,  2.33it/s][Astep: 14
extend+tolist() time: 0.0005476474761962891

Evaluating:   7%|▋         | 15/228 [00:06<01:29,  2.39it/s][Astep: 15
extend+tolist() time: 0.0006055831909179688

Evaluating:   7%|▋         | 16/228 [00:07<01:29,  2.37it/s][Astep: 16
extend+tolist() time: 0.001171112060546875

Evaluating:   7%|▋         | 17/228 [00:07<01:26,  2.43it/s][Astep: 17
extend+tolist() time: 0.0008749961853027344

Evaluating:   8%|▊         | 18/228 [00:07<01:25,  2.44it/s][Astep: 18
extend+tolist() time: 0.001669168472290039

Evaluating:   8%|▊         | 19/228 [00:08<01:28,  2.37it/s][Astep: 19
extend+tolist() time: 0.16332769393920898

Evaluating:   9%|▉         | 20/228 [00:08<01:37,  2.14it/s][Astep: 20
extend+tolist() time: 0.0007688999176025391

Evaluating:   9%|▉         | 21/228 [00:09<01:34,  2.20it/s][Astep: 21
extend+tolist() time: 0.0010077953338623047

Evaluating:  10%|▉         | 22/228 [00:09<01:30,  2.28it/s][Astep: 22
extend+tolist() time: 0.0007314682006835938

Evaluating:  10%|█         | 23/228 [00:10<01:29,  2.30it/s][Astep: 23
extend+tolist() time: 0.001065969467163086

Evaluating:  11%|█         | 24/228 [00:10<01:25,  2.38it/s][Astep: 24
extend+tolist() time: 0.0013132095336914062

Evaluating:  11%|█         | 25/228 [00:10<01:24,  2.40it/s][Astep: 25
extend+tolist() time: 0.0018818378448486328

Evaluating:  11%|█▏        | 26/228 [00:11<01:26,  2.33it/s][Astep: 26
extend+tolist() time: 0.001094818115234375

Evaluating:  12%|█▏        | 27/228 [00:11<01:24,  2.37it/s][Astep: 27
extend+tolist() time: 0.001683950424194336

Evaluating:  12%|█▏        | 28/228 [00:12<01:26,  2.32it/s][Astep: 28
extend+tolist() time: 0.00033664703369140625

Evaluating:  13%|█▎        | 29/228 [00:12<01:33,  2.14it/s][Astep: 29
extend+tolist() time: 0.0007202625274658203

Evaluating:  13%|█▎        | 30/228 [00:13<01:30,  2.19it/s][Astep: 30
extend+tolist() time: 0.0015430450439453125

Evaluating:  14%|█▎        | 31/228 [00:13<01:27,  2.25it/s][Astep: 31
extend+tolist() time: 0.0005507469177246094

Evaluating:  14%|█▍        | 32/228 [00:14<01:23,  2.34it/s][Astep: 32
extend+tolist() time: 0.0013785362243652344

Evaluating:  14%|█▍        | 33/228 [00:14<01:24,  2.32it/s][Astep: 33
extend+tolist() time: 0.0016200542449951172

Evaluating:  15%|█▍        | 34/228 [00:14<01:22,  2.34it/s][Astep: 34
extend+tolist() time: 0.0008196830749511719

Evaluating:  15%|█▌        | 35/228 [00:15<01:22,  2.33it/s][Astep: 35
extend+tolist() time: 0.0010914802551269531

Evaluating:  16%|█▌        | 36/228 [00:15<01:20,  2.37it/s][Astep: 36
extend+tolist() time: 0.0007867813110351562

Evaluating:  16%|█▌        | 37/228 [00:16<01:18,  2.44it/s][Astep: 37
extend+tolist() time: 0.0016388893127441406

Evaluating:  17%|█▋        | 38/228 [00:16<01:19,  2.38it/s][Astep: 38
extend+tolist() time: 0.0010790824890136719

Evaluating:  17%|█▋        | 39/228 [00:16<01:18,  2.42it/s][Astep: 39
extend+tolist() time: 0.0007226467132568359

Evaluating:  18%|█▊        | 40/228 [00:17<01:18,  2.39it/s][Astep: 40
extend+tolist() time: 0.0010154247283935547

Evaluating:  18%|█▊        | 41/228 [00:17<01:17,  2.43it/s][Astep: 41
extend+tolist() time: 0.001046895980834961

Evaluating:  18%|█▊        | 42/228 [00:18<01:15,  2.46it/s][Astep: 42
extend+tolist() time: 0.0016469955444335938

Evaluating:  19%|█▉        | 43/228 [00:18<01:16,  2.43it/s][Astep: 43
extend+tolist() time: 0.0018095970153808594

Evaluating:  19%|█▉        | 44/228 [00:18<01:15,  2.42it/s][Astep: 44
extend+tolist() time: 0.0007946491241455078

Evaluating:  20%|█▉        | 45/228 [00:19<01:25,  2.15it/s][Astep: 45
extend+tolist() time: 0.0016777515411376953

Evaluating:  20%|██        | 46/228 [00:19<01:21,  2.22it/s][Astep: 46
extend+tolist() time: 0.0015556812286376953

Evaluating:  21%|██        | 47/228 [00:20<01:21,  2.23it/s][Astep: 47
extend+tolist() time: 0.0014281272888183594

Evaluating:  21%|██        | 48/228 [00:20<01:19,  2.28it/s][Astep: 48
extend+tolist() time: 0.0011527538299560547

Evaluating:  21%|██▏       | 49/228 [00:21<01:18,  2.29it/s][Astep: 49
extend+tolist() time: 0.001354217529296875

Evaluating:  22%|██▏       | 50/228 [00:21<01:15,  2.36it/s][Astep: 50
extend+tolist() time: 0.1962592601776123

Evaluating:  22%|██▏       | 51/228 [00:22<01:24,  2.09it/s][Astep: 51
extend+tolist() time: 0.0015964508056640625

Evaluating:  23%|██▎       | 52/228 [00:22<01:20,  2.18it/s][Astep: 52
extend+tolist() time: 0.0012614727020263672

Evaluating:  23%|██▎       | 53/228 [00:23<01:18,  2.23it/s][Astep: 53
extend+tolist() time: 0.0012662410736083984

Evaluating:  24%|██▎       | 54/228 [00:23<01:18,  2.23it/s][Astep: 54
extend+tolist() time: 0.0012705326080322266

Evaluating:  24%|██▍       | 55/228 [00:23<01:15,  2.30it/s][Astep: 55
extend+tolist() time: 0.0011425018310546875

Evaluating:  25%|██▍       | 56/228 [00:24<01:14,  2.30it/s][Astep: 56
extend+tolist() time: 0.001111745834350586

Evaluating:  25%|██▌       | 57/228 [00:24<01:13,  2.33it/s][Astep: 57
extend+tolist() time: 0.0009589195251464844

Evaluating:  25%|██▌       | 58/228 [00:25<01:10,  2.41it/s][Astep: 58
extend+tolist() time: 0.0008599758148193359

Evaluating:  26%|██▌       | 59/228 [00:25<01:11,  2.37it/s][Astep: 59
extend+tolist() time: 0.0013458728790283203

Evaluating:  26%|██▋       | 60/228 [00:26<01:10,  2.40it/s][Astep: 60
extend+tolist() time: 0.0007236003875732422

Evaluating:  27%|██▋       | 61/228 [00:26<01:17,  2.14it/s][Astep: 61
extend+tolist() time: 0.0012848377227783203

Evaluating:  27%|██▋       | 62/228 [00:27<01:14,  2.23it/s][Astep: 62
extend+tolist() time: 0.0007989406585693359

Evaluating:  28%|██▊       | 63/228 [00:27<01:13,  2.25it/s][Astep: 63
extend+tolist() time: 0.0012412071228027344

Evaluating:  28%|██▊       | 64/228 [00:27<01:10,  2.32it/s][Astep: 64
extend+tolist() time: 0.0010371208190917969

Evaluating:  29%|██▊       | 65/228 [00:28<01:10,  2.30it/s][Astep: 65
extend+tolist() time: 0.0016789436340332031

Evaluating:  29%|██▉       | 66/228 [00:28<01:09,  2.32it/s][Astep: 66
extend+tolist() time: 0.0007355213165283203

Evaluating:  29%|██▉       | 67/228 [00:29<01:08,  2.36it/s][Astep: 67
extend+tolist() time: 0.001302480697631836

Evaluating:  30%|██▉       | 68/228 [00:29<01:08,  2.34it/s][Astep: 68
extend+tolist() time: 0.0006659030914306641

Evaluating:  30%|███       | 69/228 [00:29<01:06,  2.38it/s][Astep: 69
extend+tolist() time: 0.0015151500701904297

Evaluating:  31%|███       | 70/228 [00:30<01:06,  2.37it/s][Astep: 70
extend+tolist() time: 0.0014004707336425781

Evaluating:  31%|███       | 71/228 [00:30<01:05,  2.38it/s][Astep: 71
extend+tolist() time: 0.0009241104125976562

Evaluating:  32%|███▏      | 72/228 [00:31<01:04,  2.41it/s][Astep: 72
extend+tolist() time: 0.0007536411285400391

Evaluating:  32%|███▏      | 73/228 [00:31<01:05,  2.37it/s][Astep: 73
extend+tolist() time: 0.0005059242248535156

Evaluating:  32%|███▏      | 74/228 [00:32<01:03,  2.42it/s][Astep: 74
extend+tolist() time: 0.0011868476867675781

Evaluating:  33%|███▎      | 75/228 [00:32<01:03,  2.42it/s][Astep: 75
extend+tolist() time: 0.0015997886657714844

Evaluating:  33%|███▎      | 76/228 [00:32<01:02,  2.45it/s][Astep: 76
extend+tolist() time: 0.0006475448608398438

Evaluating:  34%|███▍      | 77/228 [00:33<01:01,  2.47it/s][Astep: 77
extend+tolist() time: 0.0019004344940185547

Evaluating:  34%|███▍      | 78/228 [00:33<01:03,  2.38it/s][Astep: 78
extend+tolist() time: 0.0012090206146240234

Evaluating:  35%|███▍      | 79/228 [00:34<01:01,  2.41it/s][Astep: 79
extend+tolist() time: 0.0008766651153564453

Evaluating:  35%|███▌      | 80/228 [00:34<01:09,  2.14it/s][Astep: 80
extend+tolist() time: 0.001322031021118164

Evaluating:  36%|███▌      | 81/228 [00:35<01:05,  2.24it/s][Astep: 81
extend+tolist() time: 0.0008633136749267578

Evaluating:  36%|███▌      | 82/228 [00:35<01:03,  2.29it/s][Astep: 82
extend+tolist() time: 0.0012459754943847656

Evaluating:  36%|███▋      | 83/228 [00:35<01:01,  2.36it/s][Astep: 83
extend+tolist() time: 0.0006954669952392578

Evaluating:  37%|███▋      | 84/228 [00:36<00:59,  2.41it/s][Astep: 84
extend+tolist() time: 0.0013697147369384766

Evaluating:  37%|███▋      | 85/228 [00:36<01:00,  2.37it/s][Astep: 85
extend+tolist() time: 0.0009210109710693359

Evaluating:  38%|███▊      | 86/228 [00:37<00:59,  2.40it/s][Astep: 86
extend+tolist() time: 0.0012745857238769531

Evaluating:  38%|███▊      | 87/228 [00:37<00:59,  2.38it/s][Astep: 87
extend+tolist() time: 0.0012764930725097656

Evaluating:  39%|███▊      | 88/228 [00:37<00:57,  2.44it/s][Astep: 88
extend+tolist() time: 0.0007474422454833984

Evaluating:  39%|███▉      | 89/228 [00:38<00:56,  2.46it/s][Astep: 89
extend+tolist() time: 0.0011126995086669922

Evaluating:  39%|███▉      | 90/228 [00:38<00:56,  2.44it/s][Astep: 90
extend+tolist() time: 0.0009260177612304688

Evaluating:  40%|███▉      | 91/228 [00:39<00:55,  2.47it/s][Astep: 91
extend+tolist() time: 0.21907925605773926

Evaluating:  40%|████      | 92/228 [00:39<01:04,  2.11it/s][Astep: 92
extend+tolist() time: 0.0008060932159423828

Evaluating:  41%|████      | 93/228 [00:40<01:01,  2.21it/s][Astep: 93
extend+tolist() time: 0.0014333724975585938

Evaluating:  41%|████      | 94/228 [00:40<00:59,  2.24it/s][Astep: 94
extend+tolist() time: 0.0010542869567871094

Evaluating:  42%|████▏     | 95/228 [00:41<00:57,  2.32it/s][Astep: 95
extend+tolist() time: 0.0011453628540039062

Evaluating:  42%|████▏     | 96/228 [00:41<00:55,  2.38it/s][Astep: 96
extend+tolist() time: 0.0013730525970458984

Evaluating:  43%|████▎     | 97/228 [00:41<00:55,  2.36it/s][Astep: 97
extend+tolist() time: 0.0011904239654541016

Evaluating:  43%|████▎     | 98/228 [00:42<00:54,  2.40it/s][Astep: 98
extend+tolist() time: 0.0009038448333740234

Evaluating:  43%|████▎     | 99/228 [00:42<00:54,  2.37it/s][Astep: 99
extend+tolist() time: 0.0014116764068603516

Evaluating:  44%|████▍     | 100/228 [00:43<00:52,  2.44it/s][Astep: 100
extend+tolist() time: 0.0007350444793701172

Evaluating:  44%|████▍     | 101/228 [00:43<00:50,  2.49it/s][Astep: 101
extend+tolist() time: 0.001247406005859375

Evaluating:  45%|████▍     | 102/228 [00:43<00:51,  2.46it/s][Astep: 102
extend+tolist() time: 0.0007040500640869141

Evaluating:  45%|████▌     | 103/228 [00:44<00:50,  2.48it/s][Astep: 103
extend+tolist() time: 0.0011632442474365234

Evaluating:  46%|████▌     | 104/228 [00:44<00:50,  2.44it/s][Astep: 104
extend+tolist() time: 0.0006859302520751953

Evaluating:  46%|████▌     | 105/228 [00:45<00:56,  2.17it/s][Astep: 105
extend+tolist() time: 0.001226663589477539

Evaluating:  46%|████▋     | 106/228 [00:45<00:54,  2.24it/s][Astep: 106
extend+tolist() time: 0.0013318061828613281

Evaluating:  47%|████▋     | 107/228 [00:46<00:51,  2.33it/s][Astep: 107
extend+tolist() time: 0.0012140274047851562

Evaluating:  47%|████▋     | 108/228 [00:46<00:50,  2.39it/s][Astep: 108
extend+tolist() time: 0.0007872581481933594

Evaluating:  48%|████▊     | 109/228 [00:46<00:49,  2.38it/s][Astep: 109
extend+tolist() time: 0.0012540817260742188

Evaluating:  48%|████▊     | 110/228 [00:47<00:48,  2.43it/s][Astep: 110
extend+tolist() time: 0.0006053447723388672

Evaluating:  49%|████▊     | 111/228 [00:47<00:47,  2.44it/s][Astep: 111
extend+tolist() time: 0.0018661022186279297

Evaluating:  49%|████▉     | 112/228 [00:48<00:47,  2.43it/s][Astep: 112
extend+tolist() time: 0.0007336139678955078

Evaluating:  50%|████▉     | 113/228 [00:48<00:46,  2.47it/s][Astep: 113
extend+tolist() time: 0.0006866455078125

Evaluating:  50%|█████     | 114/228 [00:48<00:46,  2.44it/s][Astep: 114
extend+tolist() time: 0.0015339851379394531

Evaluating:  50%|█████     | 115/228 [00:49<00:45,  2.46it/s][Astep: 115
extend+tolist() time: 0.0006482601165771484

Evaluating:  51%|█████     | 116/228 [00:49<00:45,  2.45it/s][Astep: 116
extend+tolist() time: 0.0012404918670654297

Evaluating:  51%|█████▏    | 117/228 [00:50<00:44,  2.48it/s][Astep: 117
extend+tolist() time: 0.0008578300476074219

Evaluating:  52%|█████▏    | 118/228 [00:50<00:44,  2.49it/s][Astep: 118
extend+tolist() time: 0.0005624294281005859

Evaluating:  52%|█████▏    | 119/228 [00:50<00:44,  2.44it/s][Astep: 119
extend+tolist() time: 0.0012447834014892578

Evaluating:  53%|█████▎    | 120/228 [00:51<00:43,  2.46it/s][Astep: 120
extend+tolist() time: 0.0006425380706787109

Evaluating:  53%|█████▎    | 121/228 [00:51<00:43,  2.48it/s][Astep: 121
extend+tolist() time: 0.001041412353515625

Evaluating:  54%|█████▎    | 122/228 [00:52<00:42,  2.49it/s][Astep: 122
extend+tolist() time: 0.0006661415100097656

Evaluating:  54%|█████▍    | 123/228 [00:52<00:41,  2.50it/s][Astep: 123
extend+tolist() time: 0.0010502338409423828

Evaluating:  54%|█████▍    | 124/228 [00:52<00:42,  2.43it/s][Astep: 124
extend+tolist() time: 0.0008046627044677734

Evaluating:  55%|█████▍    | 125/228 [00:53<00:42,  2.45it/s][Astep: 125
extend+tolist() time: 0.00042748451232910156

Evaluating:  55%|█████▌    | 126/228 [00:53<00:41,  2.46it/s][Astep: 126
extend+tolist() time: 0.0017886161804199219

Evaluating:  56%|█████▌    | 127/228 [00:54<00:41,  2.43it/s][Astep: 127
extend+tolist() time: 0.0016541481018066406

Evaluating:  56%|█████▌    | 128/228 [00:54<00:41,  2.43it/s][Astep: 128
extend+tolist() time: 0.0007348060607910156

Evaluating:  57%|█████▋    | 129/228 [00:55<00:41,  2.41it/s][Astep: 129
extend+tolist() time: 0.0012123584747314453

Evaluating:  57%|█████▋    | 130/228 [00:55<00:40,  2.45it/s][Astep: 130
extend+tolist() time: 0.0012812614440917969

Evaluating:  57%|█████▋    | 131/228 [00:55<00:40,  2.41it/s][Astep: 131
extend+tolist() time: 0.0004329681396484375

Evaluating:  58%|█████▊    | 132/228 [00:56<00:45,  2.13it/s][Astep: 132
extend+tolist() time: 0.0010385513305664062

Evaluating:  58%|█████▊    | 133/228 [00:56<00:43,  2.19it/s][Astep: 133
extend+tolist() time: 0.000865936279296875

Evaluating:  59%|█████▉    | 134/228 [00:57<00:40,  2.30it/s][Astep: 134
extend+tolist() time: 0.0009567737579345703

Evaluating:  59%|█████▉    | 135/228 [00:57<00:39,  2.33it/s][Astep: 135
extend+tolist() time: 0.0008878707885742188

Evaluating:  60%|█████▉    | 136/228 [00:58<00:39,  2.33it/s][Astep: 136
extend+tolist() time: 0.0008194446563720703

Evaluating:  60%|██████    | 137/228 [00:58<00:38,  2.37it/s][Astep: 137
extend+tolist() time: 0.0003905296325683594

Evaluating:  61%|██████    | 138/228 [00:58<00:38,  2.35it/s][Astep: 138
extend+tolist() time: 0.0011658668518066406

Evaluating:  61%|██████    | 139/228 [00:59<00:37,  2.39it/s][Astep: 139
extend+tolist() time: 0.0004329681396484375

Evaluating:  61%|██████▏   | 140/228 [00:59<00:35,  2.45it/s][Astep: 140
extend+tolist() time: 0.0007205009460449219

Evaluating:  62%|██████▏   | 141/228 [01:00<00:36,  2.40it/s][Astep: 141
extend+tolist() time: 0.0007319450378417969

Evaluating:  62%|██████▏   | 142/228 [01:00<00:35,  2.42it/s][Astep: 142
extend+tolist() time: 0.0005676746368408203

Evaluating:  63%|██████▎   | 143/228 [01:01<00:35,  2.39it/s][Astep: 143
extend+tolist() time: 0.00037932395935058594

Evaluating:  63%|██████▎   | 144/228 [01:01<00:34,  2.42it/s][Astep: 144
extend+tolist() time: 0.001626729965209961

Evaluating:  64%|██████▎   | 145/228 [01:01<00:33,  2.46it/s][Astep: 145
extend+tolist() time: 0.0004611015319824219

Evaluating:  64%|██████▍   | 146/228 [01:02<00:33,  2.41it/s][Astep: 146
extend+tolist() time: 0.000396728515625

Evaluating:  64%|██████▍   | 147/228 [01:02<00:33,  2.44it/s][Astep: 147
extend+tolist() time: 0.0011298656463623047

Evaluating:  65%|██████▍   | 148/228 [01:03<00:33,  2.39it/s][Astep: 148
extend+tolist() time: 0.0006520748138427734

Evaluating:  65%|██████▌   | 149/228 [01:03<00:32,  2.41it/s][Astep: 149
extend+tolist() time: 0.00035834312438964844

Evaluating:  66%|██████▌   | 150/228 [01:03<00:31,  2.47it/s][Astep: 150
extend+tolist() time: 0.0012094974517822266

Evaluating:  66%|██████▌   | 151/228 [01:04<00:31,  2.41it/s][Astep: 151
extend+tolist() time: 0.0005614757537841797

Evaluating:  67%|██████▋   | 152/228 [01:04<00:31,  2.44it/s][Astep: 152
extend+tolist() time: 0.0011200904846191406

Evaluating:  67%|██████▋   | 153/228 [01:05<00:31,  2.39it/s][Astep: 153
extend+tolist() time: 0.0008738040924072266

Evaluating:  68%|██████▊   | 154/228 [01:05<00:30,  2.41it/s][Astep: 154
extend+tolist() time: 0.24261474609375

Evaluating:  68%|██████▊   | 155/228 [01:06<00:35,  2.04it/s][Astep: 155
extend+tolist() time: 0.001093149185180664

Evaluating:  68%|██████▊   | 156/228 [01:06<00:33,  2.15it/s][Astep: 156
extend+tolist() time: 0.0005483627319335938

Evaluating:  69%|██████▉   | 157/228 [01:07<00:31,  2.23it/s][Astep: 157
extend+tolist() time: 0.0009927749633789062

Evaluating:  69%|██████▉   | 158/228 [01:07<00:30,  2.29it/s][Astep: 158
extend+tolist() time: 0.00047278404235839844

Evaluating:  70%|██████▉   | 159/228 [01:07<00:29,  2.35it/s][Astep: 159
extend+tolist() time: 0.0007107257843017578

Evaluating:  70%|███████   | 160/228 [01:08<00:29,  2.33it/s][Astep: 160
extend+tolist() time: 0.0003974437713623047

Evaluating:  71%|███████   | 161/228 [01:08<00:28,  2.37it/s][Astep: 161
extend+tolist() time: 0.0007822513580322266

Evaluating:  71%|███████   | 162/228 [01:09<00:28,  2.35it/s][Astep: 162
extend+tolist() time: 0.0005061626434326172

Evaluating:  71%|███████▏  | 163/228 [01:09<00:26,  2.42it/s][Astep: 163
extend+tolist() time: 0.00043320655822753906

Evaluating:  72%|███████▏  | 164/228 [01:09<00:26,  2.43it/s][Astep: 164
extend+tolist() time: 0.0010318756103515625

Evaluating:  72%|███████▏  | 165/228 [01:10<00:26,  2.39it/s][Astep: 165
extend+tolist() time: 0.00046062469482421875

Evaluating:  73%|███████▎  | 166/228 [01:10<00:25,  2.42it/s][Astep: 166
extend+tolist() time: 0.0004112720489501953

Evaluating:  73%|███████▎  | 167/228 [01:11<00:25,  2.40it/s][Astep: 167
extend+tolist() time: 0.0005810260772705078

Evaluating:  74%|███████▎  | 168/228 [01:11<00:24,  2.43it/s][Astep: 168
extend+tolist() time: 0.0016536712646484375

Evaluating:  74%|███████▍  | 169/228 [01:11<00:24,  2.45it/s][Astep: 169
extend+tolist() time: 0.00036454200744628906

Evaluating:  75%|███████▍  | 170/228 [01:12<00:24,  2.40it/s][Astep: 170
extend+tolist() time: 0.001300811767578125

Evaluating:  75%|███████▌  | 171/228 [01:12<00:23,  2.41it/s][Astep: 171
extend+tolist() time: 0.0002942085266113281

Evaluating:  75%|███████▌  | 172/228 [01:13<00:23,  2.38it/s][Astep: 172
extend+tolist() time: 0.0008013248443603516

Evaluating:  76%|███████▌  | 173/228 [01:13<00:22,  2.40it/s][Astep: 173
extend+tolist() time: 0.0018548965454101562

Evaluating:  76%|███████▋  | 174/228 [01:14<00:22,  2.41it/s][Astep: 174
extend+tolist() time: 0.0018305778503417969

Evaluating:  77%|███████▋  | 175/228 [01:14<00:22,  2.37it/s][Astep: 175
extend+tolist() time: 0.0008330345153808594

Evaluating:  77%|███████▋  | 176/228 [01:15<00:25,  2.02it/s][Astep: 176
extend+tolist() time: 0.0010330677032470703

Evaluating:  78%|███████▊  | 177/228 [01:15<00:23,  2.14it/s][Astep: 177
extend+tolist() time: 0.0006194114685058594

Evaluating:  78%|███████▊  | 178/228 [01:15<00:22,  2.23it/s][Astep: 178
extend+tolist() time: 0.0016317367553710938

Evaluating:  79%|███████▊  | 179/228 [01:16<00:21,  2.23it/s][Astep: 179
extend+tolist() time: 0.0004067420959472656

Evaluating:  79%|███████▉  | 180/228 [01:16<00:20,  2.31it/s][Astep: 180
extend+tolist() time: 0.0003941059112548828

Evaluating:  79%|███████▉  | 181/228 [01:17<00:20,  2.30it/s][Astep: 181
extend+tolist() time: 0.0006306171417236328

Evaluating:  80%|███████▉  | 182/228 [01:17<00:19,  2.39it/s][Astep: 182
extend+tolist() time: 0.0011928081512451172

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.41it/s][Astep: 183
extend+tolist() time: 0.0006515979766845703

Evaluating:  81%|████████  | 184/228 [01:18<00:18,  2.38it/s][Astep: 184
extend+tolist() time: 0.0004706382751464844

Evaluating:  81%|████████  | 185/228 [01:18<00:17,  2.41it/s][Astep: 185
extend+tolist() time: 0.001569509506225586

Evaluating:  82%|████████▏ | 186/228 [01:19<00:17,  2.36it/s][Astep: 186
extend+tolist() time: 0.0013632774353027344

Evaluating:  82%|████████▏ | 187/228 [01:19<00:17,  2.39it/s][Astep: 187
extend+tolist() time: 0.00045561790466308594

Evaluating:  82%|████████▏ | 188/228 [01:20<00:16,  2.45it/s][Astep: 188
extend+tolist() time: 0.0007200241088867188

Evaluating:  83%|████████▎ | 189/228 [01:20<00:16,  2.41it/s][Astep: 189
extend+tolist() time: 0.00038051605224609375

Evaluating:  83%|████████▎ | 190/228 [01:20<00:15,  2.44it/s][Astep: 190
extend+tolist() time: 0.0016696453094482422

Evaluating:  84%|████████▍ | 191/228 [01:21<00:15,  2.38it/s][Astep: 191
extend+tolist() time: 0.0007007122039794922

Evaluating:  84%|████████▍ | 192/228 [01:21<00:14,  2.40it/s][Astep: 192
extend+tolist() time: 0.001069784164428711

Evaluating:  85%|████████▍ | 193/228 [01:22<00:14,  2.43it/s][Astep: 193
extend+tolist() time: 0.0011074542999267578

Evaluating:  85%|████████▌ | 194/228 [01:22<00:14,  2.40it/s][Astep: 194
extend+tolist() time: 0.0006337165832519531

Evaluating:  86%|████████▌ | 195/228 [01:23<00:13,  2.42it/s][Astep: 195
extend+tolist() time: 0.0010213851928710938

Evaluating:  86%|████████▌ | 196/228 [01:23<00:13,  2.37it/s][Astep: 196
extend+tolist() time: 0.0006074905395507812

Evaluating:  86%|████████▋ | 197/228 [01:23<00:12,  2.40it/s][Astep: 197
extend+tolist() time: 0.0006890296936035156

Evaluating:  87%|████████▋ | 198/228 [01:24<00:12,  2.40it/s][Astep: 198
extend+tolist() time: 0.0010416507720947266

Evaluating:  87%|████████▋ | 199/228 [01:24<00:11,  2.42it/s][Astep: 199
extend+tolist() time: 0.0018374919891357422

Evaluating:  88%|████████▊ | 200/228 [01:25<00:11,  2.40it/s][Astep: 200
extend+tolist() time: 0.0007085800170898438

Evaluating:  88%|████████▊ | 201/228 [01:25<00:11,  2.37it/s][Astep: 201
extend+tolist() time: 0.0006341934204101562

Evaluating:  89%|████████▊ | 202/228 [01:25<00:10,  2.39it/s][Astep: 202
extend+tolist() time: 0.000392913818359375

Evaluating:  89%|████████▉ | 203/228 [01:26<00:10,  2.36it/s][Astep: 203
extend+tolist() time: 0.0009822845458984375

Evaluating:  89%|████████▉ | 204/228 [01:26<00:09,  2.43it/s][Astep: 204
extend+tolist() time: 0.0003979206085205078

Evaluating:  90%|████████▉ | 205/228 [01:27<00:09,  2.44it/s][Astep: 205
extend+tolist() time: 0.00029921531677246094

Evaluating:  90%|█████████ | 206/228 [01:27<00:09,  2.40it/s][Astep: 206
extend+tolist() time: 0.0006213188171386719

Evaluating:  91%|█████████ | 207/228 [01:28<00:08,  2.42it/s][Astep: 207
extend+tolist() time: 0.0010704994201660156

Evaluating:  91%|█████████ | 208/228 [01:28<00:08,  2.37it/s][Astep: 208
extend+tolist() time: 0.0007154941558837891

Evaluating:  92%|█████████▏| 209/228 [01:28<00:07,  2.40it/s][Astep: 209
extend+tolist() time: 0.0005795955657958984

Evaluating:  92%|█████████▏| 210/228 [01:29<00:07,  2.45it/s][Astep: 210
extend+tolist() time: 0.0010385513305664062

Evaluating:  93%|█████████▎| 211/228 [01:29<00:07,  2.40it/s][Astep: 211
extend+tolist() time: 0.001111745834350586

Evaluating:  93%|█████████▎| 212/228 [01:30<00:06,  2.40it/s][Astep: 212
extend+tolist() time: 0.0013294219970703125

Evaluating:  93%|█████████▎| 213/228 [01:30<00:06,  2.35it/s][Astep: 213
extend+tolist() time: 0.0007257461547851562

Evaluating:  94%|█████████▍| 214/228 [01:30<00:05,  2.39it/s][Astep: 214
extend+tolist() time: 0.0014882087707519531

Evaluating:  94%|█████████▍| 215/228 [01:31<00:05,  2.44it/s][Astep: 215
extend+tolist() time: 0.0006647109985351562

Evaluating:  95%|█████████▍| 216/228 [01:31<00:04,  2.43it/s][Astep: 216
extend+tolist() time: 0.0005598068237304688

Evaluating:  95%|█████████▌| 217/228 [01:32<00:04,  2.45it/s][Astep: 217
extend+tolist() time: 0.0009636878967285156

Evaluating:  96%|█████████▌| 218/228 [01:32<00:04,  2.40it/s][Astep: 218
extend+tolist() time: 0.0009851455688476562

Evaluating:  96%|█████████▌| 219/228 [01:33<00:03,  2.40it/s][Astep: 219
extend+tolist() time: 0.0008876323699951172

Evaluating:  96%|█████████▋| 220/228 [01:33<00:03,  2.43it/s][Astep: 220
extend+tolist() time: 0.00040531158447265625

Evaluating:  97%|█████████▋| 221/228 [01:33<00:02,  2.42it/s][Astep: 221
extend+tolist() time: 0.0006434917449951172

Evaluating:  97%|█████████▋| 222/228 [01:34<00:02,  2.42it/s][Astep: 222
extend+tolist() time: 0.00042629241943359375

Evaluating:  98%|█████████▊| 223/228 [01:34<00:02,  2.10it/s][Astep: 223
extend+tolist() time: 0.00039458274841308594

Evaluating:  98%|█████████▊| 224/228 [01:35<00:01,  2.20it/s][Astep: 224
extend+tolist() time: 0.0003707408905029297

Evaluating:  99%|█████████▊| 225/228 [01:35<00:01,  2.22it/s][Astep: 225
extend+tolist() time: 0.0004420280456542969

Evaluating:  99%|█████████▉| 226/228 [01:36<00:00,  2.29it/s][Astep: 226
extend+tolist() time: 0.0005464553833007812

Evaluating: 100%|█████████▉| 227/228 [01:36<00:00,  2.30it/s][Astep: 227
extend+tolist() time: 0.0004811286926269531

Evaluating: 100%|██████████| 228/228 [01:36<00:00,  2.30it/s][A09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:23:18 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:23:19 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:23:19 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:23:19 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:23:19 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:38<00:00,  2.32it/s]
09/09/2023 00:23:19 - INFO - __main__ -   Step: 1740, Validation Metrics: {'pred_1_num': 10010, 'pred_-1_num': 779, 'pred_0_num': 12, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7992778446440144, 'f1_micro': 0.7992778446440144, 'f1_macro': 0.41314459765059747, 'f1_weighted': 0.7540707080501909, 'f1_-1': 0.3326226012793177, 'f1_0': 0.02150537634408602, 'f1_1': 0.8853058153283887, 'precision_micro': 0.7992778446440144, 'precision_macro': 0.6355841348781015, 'precision_weighted': 0.761906132930395, 'precision_-1': 0.5006418485237484, 'precision_0': 0.5833333333333334, 'precision_1': 0.8227772227772228, 'recall_micro': 0.7992778446440144, 'recall_macro': 0.4060389393407382, 'recall_weighted': 0.7992778446440144, 'recall_-1': 0.24904214559386972, 'recall_0': 0.010954616588419406, 'recall_1': 0.9581200558399255, 'roc_auc_micro': 0.92698360962833, 'roc_auc_macro': 0.7802559775908101, 'roc_auc_weighted': 0.7789592063104467, 'roc_auc_-1': 0.8358812502549784, 'roc_auc_0': 0.7328713803519139, 'roc_auc_1': 0.772015302165538}
[2023-09-09 00:23:41,419] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1741/66600 [3:00:50<909:46:08, 50.50s/it]09/09/2023 00:23:41 - INFO - __main__ -   Step: 1741, LR: 1.7433971711102767e-05, Loss: 0.446128785610199
[2023-09-09 00:24:01,755] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1742/66600 [3:01:11<746:44:31, 41.45s/it]09/09/2023 00:24:01 - INFO - __main__ -   Step: 1742, LR: 1.7443985480035052e-05, Loss: 0.4203253388404846
[2023-09-09 00:24:22,620] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1743/66600 [3:01:32<635:28:53, 35.27s/it]09/09/2023 00:24:22 - INFO - __main__ -   Step: 1743, LR: 1.745399924896733e-05, Loss: 0.41228312253952026
[2023-09-09 00:24:43,375] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1744/66600 [3:01:52<557:00:04, 30.92s/it]09/09/2023 00:24:43 - INFO - __main__ -   Step: 1744, LR: 1.7464013017899612e-05, Loss: 0.4072064757347107
[2023-09-09 00:25:03,560] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1745/66600 [3:02:13<498:59:13, 27.70s/it]09/09/2023 00:25:03 - INFO - __main__ -   Step: 1745, LR: 1.7474026786831893e-05, Loss: 0.4831429123878479
[2023-09-09 00:25:23,933] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1746/66600 [3:02:33<459:23:24, 25.50s/it]09/09/2023 00:25:23 - INFO - __main__ -   Step: 1746, LR: 1.748404055576418e-05, Loss: 0.4185890257358551
[2023-09-09 00:25:44,158] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1747/66600 [3:02:53<430:52:30, 23.92s/it]09/09/2023 00:25:44 - INFO - __main__ -   Step: 1747, LR: 1.749405432469646e-05, Loss: 0.40043050050735474
[2023-09-09 00:26:04,826] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1748/66600 [3:03:14<413:18:13, 22.94s/it]09/09/2023 00:26:04 - INFO - __main__ -   Step: 1748, LR: 1.750406809362874e-05, Loss: 0.44867971539497375
[2023-09-09 00:26:25,645] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1749/66600 [3:03:35<401:49:03, 22.31s/it]09/09/2023 00:26:25 - INFO - __main__ -   Step: 1749, LR: 1.7514081862561023e-05, Loss: 0.37306851148605347
[2023-09-09 00:26:46,152] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1750/66600 [3:03:55<392:05:29, 21.77s/it]09/09/2023 00:26:46 - INFO - __main__ -   Step: 1750, LR: 1.7524095631493305e-05, Loss: 0.3877503573894501
[2023-09-09 00:27:06,750] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1751/66600 [3:04:16<385:46:31, 21.42s/it]09/09/2023 00:27:06 - INFO - __main__ -   Step: 1751, LR: 1.7534109400425586e-05, Loss: 0.4549158811569214
[2023-09-09 00:27:26,979] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1752/66600 [3:04:36<379:21:23, 21.06s/it]09/09/2023 00:27:26 - INFO - __main__ -   Step: 1752, LR: 1.7544123169357868e-05, Loss: 0.49964234232902527
[2023-09-09 00:27:46,915] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1753/66600 [3:04:56<373:16:28, 20.72s/it]09/09/2023 00:27:46 - INFO - __main__ -   Step: 1753, LR: 1.755413693829015e-05, Loss: 0.35786503553390503
[2023-09-09 00:28:07,686] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1754/66600 [3:05:17<373:31:51, 20.74s/it]09/09/2023 00:28:07 - INFO - __main__ -   Step: 1754, LR: 1.756415070722243e-05, Loss: 0.4442669153213501
[2023-09-09 00:28:28,310] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1755/66600 [3:05:37<372:55:05, 20.70s/it]09/09/2023 00:28:28 - INFO - __main__ -   Step: 1755, LR: 1.7574164476154713e-05, Loss: 0.4273269772529602
[2023-09-09 00:28:49,598] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1756/66600 [3:05:59<376:04:21, 20.88s/it]09/09/2023 00:28:49 - INFO - __main__ -   Step: 1756, LR: 1.7584178245086994e-05, Loss: 0.43633031845092773
[2023-09-09 00:29:11,316] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1757/66600 [3:06:20<380:35:52, 21.13s/it]09/09/2023 00:29:11 - INFO - __main__ -   Step: 1757, LR: 1.759419201401928e-05, Loss: 0.41758888959884644
[2023-09-09 00:29:32,308] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1758/66600 [3:06:41<379:50:48, 21.09s/it]09/09/2023 00:29:32 - INFO - __main__ -   Step: 1758, LR: 1.760420578295156e-05, Loss: 0.3824242353439331
[2023-09-09 00:29:53,329] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1759/66600 [3:07:02<379:28:15, 21.07s/it]09/09/2023 00:29:53 - INFO - __main__ -   Step: 1759, LR: 1.7614219551883843e-05, Loss: 0.4581261873245239
[2023-09-09 00:30:14,301] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1760/66600 [3:07:23<378:56:48, 21.04s/it]09/09/2023 00:30:14 - INFO - __main__ -   Step: 1760, LR: 1.7624233320816124e-05, Loss: 0.5454246997833252
09/09/2023 00:30:14 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.003137350082397461

Evaluating:   0%|          | 1/228 [00:00<01:52,  2.02it/s][Astep: 1
extend+tolist() time: 0.0016469955444335938

Evaluating:   1%|          | 2/228 [00:01<01:57,  1.92it/s][Astep: 2
extend+tolist() time: 0.0016415119171142578

Evaluating:   1%|▏         | 3/228 [00:01<01:45,  2.14it/s][Astep: 3
extend+tolist() time: 0.1419811248779297

Evaluating:   2%|▏         | 4/228 [00:02<01:53,  1.97it/s][Astep: 4
extend+tolist() time: 0.0015406608581542969

Evaluating:   2%|▏         | 5/228 [00:02<01:43,  2.15it/s][Astep: 5
extend+tolist() time: 0.0020744800567626953

Evaluating:   3%|▎         | 6/228 [00:02<01:40,  2.20it/s][Astep: 6
extend+tolist() time: 0.0020198822021484375

Evaluating:   3%|▎         | 7/228 [00:03<01:38,  2.25it/s][Astep: 7
extend+tolist() time: 0.001323699951171875

Evaluating:   4%|▎         | 8/228 [00:03<01:35,  2.31it/s][Astep: 8
extend+tolist() time: 0.0007951259613037109

Evaluating:   4%|▍         | 9/228 [00:04<01:33,  2.35it/s][Astep: 9
extend+tolist() time: 0.001196146011352539

Evaluating:   4%|▍         | 10/228 [00:04<01:30,  2.42it/s][Astep: 10
extend+tolist() time: 0.0008721351623535156

Evaluating:   5%|▍         | 11/228 [00:04<01:30,  2.40it/s][Astep: 11
extend+tolist() time: 0.0009660720825195312

Evaluating:   5%|▌         | 12/228 [00:05<01:28,  2.43it/s][Astep: 12
extend+tolist() time: 0.0006434917449951172

Evaluating:   6%|▌         | 13/228 [00:05<01:27,  2.45it/s][Astep: 13
extend+tolist() time: 0.0005602836608886719

Evaluating:   6%|▌         | 14/228 [00:06<01:27,  2.44it/s][Astep: 14
extend+tolist() time: 0.0011851787567138672

Evaluating:   7%|▋         | 15/228 [00:06<01:35,  2.24it/s][Astep: 15
extend+tolist() time: 0.0006122589111328125

Evaluating:   7%|▋         | 16/228 [00:07<01:31,  2.32it/s][Astep: 16
extend+tolist() time: 0.0006022453308105469

Evaluating:   7%|▋         | 17/228 [00:07<01:28,  2.39it/s][Astep: 17
extend+tolist() time: 0.0008981227874755859

Evaluating:   8%|▊         | 18/228 [00:07<01:27,  2.40it/s][Astep: 18
extend+tolist() time: 0.0015807151794433594

Evaluating:   8%|▊         | 19/228 [00:08<01:26,  2.43it/s][Astep: 19
extend+tolist() time: 0.0009615421295166016

Evaluating:   9%|▉         | 20/228 [00:08<01:23,  2.48it/s][Astep: 20
extend+tolist() time: 0.0012021064758300781

Evaluating:   9%|▉         | 21/228 [00:09<01:32,  2.23it/s][Astep: 21
extend+tolist() time: 0.00067138671875

Evaluating:  10%|▉         | 22/228 [00:09<01:28,  2.34it/s][Astep: 22
extend+tolist() time: 0.0011625289916992188

Evaluating:  10%|█         | 23/228 [00:09<01:26,  2.36it/s][Astep: 23
extend+tolist() time: 0.0006632804870605469

Evaluating:  11%|█         | 24/228 [00:10<01:24,  2.42it/s][Astep: 24
extend+tolist() time: 0.0015048980712890625

Evaluating:  11%|█         | 25/228 [00:10<01:23,  2.44it/s][Astep: 25
extend+tolist() time: 0.0017971992492675781

Evaluating:  11%|█▏        | 26/228 [00:11<01:23,  2.43it/s][Astep: 26
extend+tolist() time: 0.0007264614105224609

Evaluating:  12%|█▏        | 27/228 [00:11<01:20,  2.50it/s][Astep: 27
extend+tolist() time: 0.0016865730285644531

Evaluating:  12%|█▏        | 28/228 [00:11<01:21,  2.45it/s][Astep: 28
extend+tolist() time: 0.0003256797790527344

Evaluating:  13%|█▎        | 29/228 [00:12<01:28,  2.25it/s][Astep: 29
extend+tolist() time: 0.0010824203491210938

Evaluating:  13%|█▎        | 30/228 [00:12<01:25,  2.31it/s][Astep: 30
extend+tolist() time: 0.0010600090026855469

Evaluating:  14%|█▎        | 31/228 [00:13<01:23,  2.36it/s][Astep: 31
extend+tolist() time: 0.0005712509155273438

Evaluating:  14%|█▍        | 32/228 [00:13<01:20,  2.44it/s][Astep: 32
extend+tolist() time: 0.0010151863098144531

Evaluating:  14%|█▍        | 33/228 [00:14<01:21,  2.40it/s][Astep: 33
extend+tolist() time: 0.1470799446105957

Evaluating:  15%|█▍        | 34/228 [00:14<01:29,  2.18it/s][Astep: 34
extend+tolist() time: 0.0013103485107421875

Evaluating:  15%|█▌        | 35/228 [00:15<01:26,  2.23it/s][Astep: 35
extend+tolist() time: 0.0009059906005859375

Evaluating:  16%|█▌        | 36/228 [00:15<01:22,  2.32it/s][Astep: 36
extend+tolist() time: 0.0007638931274414062

Evaluating:  16%|█▌        | 37/228 [00:15<01:21,  2.35it/s][Astep: 37
extend+tolist() time: 0.0016429424285888672

Evaluating:  17%|█▋        | 38/228 [00:16<01:20,  2.37it/s][Astep: 38
extend+tolist() time: 0.0007452964782714844

Evaluating:  17%|█▋        | 39/228 [00:16<01:17,  2.43it/s][Astep: 39
extend+tolist() time: 0.0011110305786132812

Evaluating:  18%|█▊        | 40/228 [00:17<01:18,  2.40it/s][Astep: 40
extend+tolist() time: 0.0006105899810791016

Evaluating:  18%|█▊        | 41/228 [00:17<01:17,  2.41it/s][Astep: 41
extend+tolist() time: 0.0012710094451904297

Evaluating:  18%|█▊        | 42/228 [00:17<01:18,  2.38it/s][Astep: 42
extend+tolist() time: 0.0015537738800048828

Evaluating:  19%|█▉        | 43/228 [00:18<01:17,  2.38it/s][Astep: 43
extend+tolist() time: 0.002017974853515625

Evaluating:  19%|█▉        | 44/228 [00:18<01:17,  2.36it/s][Astep: 44
extend+tolist() time: 0.0007634162902832031

Evaluating:  20%|█▉        | 45/228 [00:19<01:16,  2.39it/s][Astep: 45
extend+tolist() time: 0.0016674995422363281

Evaluating:  20%|██        | 46/228 [00:19<01:16,  2.38it/s][Astep: 46
extend+tolist() time: 0.0015859603881835938

Evaluating:  21%|██        | 47/228 [00:20<01:25,  2.12it/s][Astep: 47
extend+tolist() time: 0.001432657241821289

Evaluating:  21%|██        | 48/228 [00:20<01:22,  2.19it/s][Astep: 48
extend+tolist() time: 0.0011739730834960938

Evaluating:  21%|██▏       | 49/228 [00:21<01:20,  2.21it/s][Astep: 49
extend+tolist() time: 0.001390695571899414

Evaluating:  22%|██▏       | 50/228 [00:21<01:18,  2.27it/s][Astep: 50
extend+tolist() time: 0.0015430450439453125

Evaluating:  22%|██▏       | 51/228 [00:21<01:17,  2.29it/s][Astep: 51
extend+tolist() time: 0.001520395278930664

Evaluating:  23%|██▎       | 52/228 [00:22<01:25,  2.06it/s][Astep: 52
extend+tolist() time: 0.0009779930114746094

Evaluating:  23%|██▎       | 53/228 [00:22<01:21,  2.15it/s][Astep: 53
extend+tolist() time: 0.0017445087432861328

Evaluating:  24%|██▎       | 54/228 [00:23<01:19,  2.18it/s][Astep: 54
extend+tolist() time: 0.00115966796875

Evaluating:  24%|██▍       | 55/228 [00:23<01:16,  2.28it/s][Astep: 55
extend+tolist() time: 0.0008130073547363281

Evaluating:  25%|██▍       | 56/228 [00:24<01:15,  2.29it/s][Astep: 56
extend+tolist() time: 0.0015606880187988281

Evaluating:  25%|██▌       | 57/228 [00:24<01:13,  2.31it/s][Astep: 57
extend+tolist() time: 0.000606536865234375

Evaluating:  25%|██▌       | 58/228 [00:25<01:13,  2.31it/s][Astep: 58
extend+tolist() time: 0.0012683868408203125

Evaluating:  26%|██▌       | 59/228 [00:25<01:12,  2.33it/s][Astep: 59
extend+tolist() time: 0.0011560916900634766

Evaluating:  26%|██▋       | 60/228 [00:25<01:11,  2.35it/s][Astep: 60
extend+tolist() time: 0.0011534690856933594

Evaluating:  27%|██▋       | 61/228 [00:26<01:18,  2.13it/s][Astep: 61
extend+tolist() time: 0.000843048095703125

Evaluating:  27%|██▋       | 62/228 [00:26<01:14,  2.23it/s][Astep: 62
extend+tolist() time: 0.0012221336364746094

Evaluating:  28%|██▊       | 63/228 [00:27<01:13,  2.23it/s][Astep: 63
extend+tolist() time: 0.0008111000061035156

Evaluating:  28%|██▊       | 64/228 [00:27<01:11,  2.29it/s][Astep: 64
extend+tolist() time: 0.00125885009765625

Evaluating:  29%|██▊       | 65/228 [00:28<01:11,  2.28it/s][Astep: 65
extend+tolist() time: 0.0008094310760498047

Evaluating:  29%|██▉       | 66/228 [00:28<01:09,  2.33it/s][Astep: 66
extend+tolist() time: 0.16371941566467285

Evaluating:  29%|██▉       | 67/228 [00:29<01:16,  2.10it/s][Astep: 67
extend+tolist() time: 0.001299142837524414

Evaluating:  30%|██▉       | 68/228 [00:29<01:12,  2.19it/s][Astep: 68
extend+tolist() time: 0.0008554458618164062

Evaluating:  30%|███       | 69/228 [00:30<01:09,  2.27it/s][Astep: 69
extend+tolist() time: 0.00145721435546875

Evaluating:  31%|███       | 70/228 [00:30<01:08,  2.31it/s][Astep: 70
extend+tolist() time: 0.0014159679412841797

Evaluating:  31%|███       | 71/228 [00:30<01:07,  2.32it/s][Astep: 71
extend+tolist() time: 0.0009849071502685547

Evaluating:  32%|███▏      | 72/228 [00:31<01:08,  2.28it/s][Astep: 72
extend+tolist() time: 0.0011947154998779297

Evaluating:  32%|███▏      | 73/228 [00:31<01:06,  2.34it/s][Astep: 73
extend+tolist() time: 0.0005404949188232422

Evaluating:  32%|███▏      | 74/228 [00:32<01:05,  2.35it/s][Astep: 74
extend+tolist() time: 0.0011472702026367188

Evaluating:  33%|███▎      | 75/228 [00:32<01:05,  2.35it/s][Astep: 75
extend+tolist() time: 0.0012273788452148438

Evaluating:  33%|███▎      | 76/228 [00:32<01:03,  2.39it/s][Astep: 76
extend+tolist() time: 0.0010883808135986328

Evaluating:  34%|███▍      | 77/228 [00:33<01:04,  2.36it/s][Astep: 77
extend+tolist() time: 0.001772165298461914

Evaluating:  34%|███▍      | 78/228 [00:33<01:03,  2.35it/s][Astep: 78
extend+tolist() time: 0.0008683204650878906

Evaluating:  35%|███▍      | 79/228 [00:34<01:04,  2.33it/s][Astep: 79
extend+tolist() time: 0.0013120174407958984

Evaluating:  35%|███▌      | 80/228 [00:34<01:02,  2.36it/s][Astep: 80
extend+tolist() time: 0.001249551773071289

Evaluating:  36%|███▌      | 81/228 [00:35<01:01,  2.41it/s][Astep: 81
extend+tolist() time: 0.0008480548858642578

Evaluating:  36%|███▌      | 82/228 [00:35<01:00,  2.40it/s][Astep: 82
extend+tolist() time: 0.0012202262878417969

Evaluating:  36%|███▋      | 83/228 [00:35<01:00,  2.42it/s][Astep: 83
extend+tolist() time: 0.0006935596466064453

Evaluating:  37%|███▋      | 84/228 [00:36<01:07,  2.14it/s][Astep: 84
extend+tolist() time: 0.001340627670288086

Evaluating:  37%|███▋      | 85/228 [00:36<01:04,  2.22it/s][Astep: 85
extend+tolist() time: 0.0009298324584960938

Evaluating:  38%|███▊      | 86/228 [00:37<01:03,  2.23it/s][Astep: 86
extend+tolist() time: 0.0012907981872558594

Evaluating:  38%|███▊      | 87/228 [00:37<01:01,  2.28it/s][Astep: 87
extend+tolist() time: 0.0008559226989746094

Evaluating:  39%|███▊      | 88/228 [00:38<01:00,  2.30it/s][Astep: 88
extend+tolist() time: 0.0007114410400390625

Evaluating:  39%|███▉      | 89/228 [00:38<00:59,  2.35it/s][Astep: 89
extend+tolist() time: 0.0007147789001464844

Evaluating:  39%|███▉      | 90/228 [00:38<00:57,  2.38it/s][Astep: 90
extend+tolist() time: 0.0013566017150878906

Evaluating:  40%|███▉      | 91/228 [00:39<00:58,  2.35it/s][Astep: 91
extend+tolist() time: 0.0011248588562011719

Evaluating:  40%|████      | 92/228 [00:39<00:57,  2.38it/s][Astep: 92
extend+tolist() time: 0.0007767677307128906

Evaluating:  41%|████      | 93/228 [00:40<01:04,  2.09it/s][Astep: 93
extend+tolist() time: 0.0013859272003173828

Evaluating:  41%|████      | 94/228 [00:40<01:01,  2.18it/s][Astep: 94
extend+tolist() time: 0.0007269382476806641

Evaluating:  42%|████▏     | 95/228 [00:41<00:59,  2.24it/s][Astep: 95
extend+tolist() time: 0.0015568733215332031

Evaluating:  42%|████▏     | 96/228 [00:41<00:58,  2.26it/s][Astep: 96
extend+tolist() time: 0.0009152889251708984

Evaluating:  43%|████▎     | 97/228 [00:42<00:55,  2.34it/s][Astep: 97
extend+tolist() time: 0.0012049674987792969

Evaluating:  43%|████▎     | 98/228 [00:42<00:55,  2.32it/s][Astep: 98
extend+tolist() time: 0.001245260238647461

Evaluating:  43%|████▎     | 99/228 [00:42<00:54,  2.36it/s][Astep: 99
extend+tolist() time: 0.0008778572082519531

Evaluating:  44%|████▍     | 100/228 [00:43<00:54,  2.33it/s][Astep: 100
extend+tolist() time: 0.0011453628540039062

Evaluating:  44%|████▍     | 101/228 [00:43<00:53,  2.37it/s][Astep: 101
extend+tolist() time: 0.000820159912109375

Evaluating:  45%|████▍     | 102/228 [00:44<00:52,  2.39it/s][Astep: 102
extend+tolist() time: 0.0011048316955566406

Evaluating:  45%|████▌     | 103/228 [00:44<00:51,  2.40it/s][Astep: 103
extend+tolist() time: 0.0007545948028564453

Evaluating:  46%|████▌     | 104/228 [00:45<00:51,  2.42it/s][Astep: 104
extend+tolist() time: 0.000682830810546875

Evaluating:  46%|████▌     | 105/228 [00:45<00:58,  2.12it/s][Astep: 105
extend+tolist() time: 0.0007929801940917969

Evaluating:  46%|████▋     | 106/228 [00:46<00:55,  2.21it/s][Astep: 106
extend+tolist() time: 0.0017170906066894531

Evaluating:  47%|████▋     | 107/228 [00:46<00:54,  2.21it/s][Astep: 107
extend+tolist() time: 0.0007569789886474609

Evaluating:  47%|████▋     | 108/228 [00:46<00:52,  2.28it/s][Astep: 108
extend+tolist() time: 0.0011816024780273438

Evaluating:  48%|████▊     | 109/228 [00:47<00:51,  2.31it/s][Astep: 109
extend+tolist() time: 0.0008261203765869141

Evaluating:  48%|████▊     | 110/228 [00:47<00:50,  2.34it/s][Astep: 110
extend+tolist() time: 0.0010418891906738281

Evaluating:  49%|████▊     | 111/228 [00:48<00:49,  2.37it/s][Astep: 111
extend+tolist() time: 0.21321868896484375

Evaluating:  49%|████▉     | 112/228 [00:48<00:57,  2.03it/s][Astep: 112
extend+tolist() time: 0.0003807544708251953

Evaluating:  50%|████▉     | 113/228 [00:49<00:52,  2.17it/s][Astep: 113
extend+tolist() time: 0.00102996826171875

Evaluating:  50%|█████     | 114/228 [00:49<00:51,  2.23it/s][Astep: 114
extend+tolist() time: 0.0011019706726074219

Evaluating:  50%|█████     | 115/228 [00:50<00:49,  2.28it/s][Astep: 115
extend+tolist() time: 0.0010290145874023438

Evaluating:  51%|█████     | 116/228 [00:50<00:48,  2.32it/s][Astep: 116
extend+tolist() time: 0.0008177757263183594

Evaluating:  51%|█████▏    | 117/228 [00:50<00:47,  2.34it/s][Astep: 117
extend+tolist() time: 0.0012514591217041016

Evaluating:  52%|█████▏    | 118/228 [00:51<00:45,  2.40it/s][Astep: 118
extend+tolist() time: 0.0005393028259277344

Evaluating:  52%|█████▏    | 119/228 [00:51<00:45,  2.39it/s][Astep: 119
extend+tolist() time: 0.0011119842529296875

Evaluating:  53%|█████▎    | 120/228 [00:52<00:44,  2.41it/s][Astep: 120
extend+tolist() time: 0.0006482601165771484

Evaluating:  53%|█████▎    | 121/228 [00:52<00:44,  2.39it/s][Astep: 121
extend+tolist() time: 0.0010385513305664062

Evaluating:  54%|█████▎    | 122/228 [00:52<00:43,  2.42it/s][Astep: 122
extend+tolist() time: 0.0006654262542724609

Evaluating:  54%|█████▍    | 123/228 [00:53<00:42,  2.47it/s][Astep: 123
extend+tolist() time: 0.0006115436553955078

Evaluating:  54%|█████▍    | 124/228 [00:53<00:42,  2.43it/s][Astep: 124
extend+tolist() time: 0.0013065338134765625

Evaluating:  55%|█████▍    | 125/228 [00:54<00:42,  2.43it/s][Astep: 125
extend+tolist() time: 0.00043320655822753906

Evaluating:  55%|█████▌    | 126/228 [00:54<00:42,  2.40it/s][Astep: 126
extend+tolist() time: 0.001682281494140625

Evaluating:  56%|█████▌    | 127/228 [00:54<00:42,  2.38it/s][Astep: 127
extend+tolist() time: 0.0018856525421142578

Evaluating:  56%|█████▌    | 128/228 [00:55<00:42,  2.38it/s][Astep: 128
extend+tolist() time: 0.0007405281066894531

Evaluating:  57%|█████▋    | 129/228 [00:55<00:41,  2.40it/s][Astep: 129
extend+tolist() time: 0.0011556148529052734

Evaluating:  57%|█████▋    | 130/228 [00:56<00:40,  2.41it/s][Astep: 130
extend+tolist() time: 0.0008723735809326172

Evaluating:  57%|█████▋    | 131/228 [00:56<00:40,  2.37it/s][Astep: 131
extend+tolist() time: 0.0008263587951660156

Evaluating:  58%|█████▊    | 132/228 [00:57<00:39,  2.41it/s][Astep: 132
extend+tolist() time: 0.0010762214660644531

Evaluating:  58%|█████▊    | 133/228 [00:57<00:39,  2.38it/s][Astep: 133
extend+tolist() time: 0.0008819103240966797

Evaluating:  59%|█████▉    | 134/228 [00:57<00:39,  2.39it/s][Astep: 134
extend+tolist() time: 0.0009701251983642578

Evaluating:  59%|█████▉    | 135/228 [00:58<00:39,  2.38it/s][Astep: 135
extend+tolist() time: 0.00044465065002441406

Evaluating:  60%|█████▉    | 136/228 [00:58<00:39,  2.36it/s][Astep: 136
extend+tolist() time: 0.0012700557708740234

Evaluating:  60%|██████    | 137/228 [00:59<00:43,  2.08it/s][Astep: 137
extend+tolist() time: 0.00037860870361328125

Evaluating:  61%|██████    | 138/228 [00:59<00:41,  2.15it/s][Astep: 138
extend+tolist() time: 0.0011317729949951172

Evaluating:  61%|██████    | 139/228 [01:00<00:39,  2.23it/s][Astep: 139
extend+tolist() time: 0.0004832744598388672

Evaluating:  61%|██████▏   | 140/228 [01:00<00:38,  2.27it/s][Astep: 140
extend+tolist() time: 0.000736236572265625

Evaluating:  62%|██████▏   | 141/228 [01:01<00:37,  2.31it/s][Astep: 141
extend+tolist() time: 0.0012276172637939453

Evaluating:  62%|██████▏   | 142/228 [01:01<00:36,  2.36it/s][Astep: 142
extend+tolist() time: 0.0005571842193603516

Evaluating:  63%|██████▎   | 143/228 [01:01<00:36,  2.34it/s][Astep: 143
extend+tolist() time: 0.0003399848937988281

Evaluating:  63%|██████▎   | 144/228 [01:02<00:35,  2.38it/s][Astep: 144
extend+tolist() time: 0.0011620521545410156

Evaluating:  64%|██████▎   | 145/228 [01:02<00:35,  2.35it/s][Astep: 145
extend+tolist() time: 0.0004668235778808594

Evaluating:  64%|██████▍   | 146/228 [01:03<00:34,  2.38it/s][Astep: 146
extend+tolist() time: 0.0003864765167236328

Evaluating:  64%|██████▍   | 147/228 [01:03<00:34,  2.38it/s][Astep: 147
extend+tolist() time: 0.0010867118835449219

Evaluating:  65%|██████▍   | 148/228 [01:03<00:33,  2.40it/s][Astep: 148
extend+tolist() time: 0.0006566047668457031

Evaluating:  65%|██████▌   | 149/228 [01:04<00:32,  2.41it/s][Astep: 149
extend+tolist() time: 0.0003693103790283203

Evaluating:  66%|██████▌   | 150/228 [01:04<00:32,  2.37it/s][Astep: 150
extend+tolist() time: 0.0012538433074951172

Evaluating:  66%|██████▌   | 151/228 [01:05<00:32,  2.39it/s][Astep: 151
extend+tolist() time: 0.0005857944488525391

Evaluating:  67%|██████▋   | 152/228 [01:05<00:31,  2.38it/s][Astep: 152
extend+tolist() time: 0.0011749267578125

Evaluating:  67%|██████▋   | 153/228 [01:06<00:31,  2.38it/s][Astep: 153
extend+tolist() time: 0.0008826255798339844

Evaluating:  68%|██████▊   | 154/228 [01:06<00:30,  2.42it/s][Astep: 154
extend+tolist() time: 0.0018532276153564453

Evaluating:  68%|██████▊   | 155/228 [01:06<00:31,  2.34it/s][Astep: 155
extend+tolist() time: 0.0010097026824951172

Evaluating:  68%|██████▊   | 156/228 [01:07<00:34,  2.10it/s][Astep: 156
extend+tolist() time: 0.0005228519439697266

Evaluating:  69%|██████▉   | 157/228 [01:07<00:32,  2.16it/s][Astep: 157
extend+tolist() time: 0.0006399154663085938

Evaluating:  69%|██████▉   | 158/228 [01:08<00:31,  2.24it/s][Astep: 158
extend+tolist() time: 0.00047659873962402344

Evaluating:  70%|██████▉   | 159/228 [01:08<00:30,  2.26it/s][Astep: 159
extend+tolist() time: 0.0010983943939208984

Evaluating:  70%|███████   | 160/228 [01:09<00:29,  2.30it/s][Astep: 160
extend+tolist() time: 0.0006129741668701172

Evaluating:  71%|███████   | 161/228 [01:09<00:28,  2.33it/s][Astep: 161
extend+tolist() time: 0.0006895065307617188

Evaluating:  71%|███████   | 162/228 [01:10<00:28,  2.36it/s][Astep: 162
extend+tolist() time: 0.0008864402770996094

Evaluating:  71%|███████▏  | 163/228 [01:10<00:27,  2.39it/s][Astep: 163
extend+tolist() time: 0.00037860870361328125

Evaluating:  72%|███████▏  | 164/228 [01:10<00:27,  2.37it/s][Astep: 164
extend+tolist() time: 0.0005197525024414062

Evaluating:  72%|███████▏  | 165/228 [01:11<00:26,  2.41it/s][Astep: 165
extend+tolist() time: 0.00048232078552246094

Evaluating:  73%|███████▎  | 166/228 [01:11<00:25,  2.42it/s][Astep: 166
extend+tolist() time: 0.0008161067962646484

Evaluating:  73%|███████▎  | 167/228 [01:12<00:24,  2.44it/s][Astep: 167
extend+tolist() time: 0.0005748271942138672

Evaluating:  74%|███████▎  | 168/228 [01:12<00:24,  2.46it/s][Astep: 168
extend+tolist() time: 0.00160980224609375

Evaluating:  74%|███████▍  | 169/228 [01:12<00:24,  2.39it/s][Astep: 169
extend+tolist() time: 0.00036978721618652344

Evaluating:  75%|███████▍  | 170/228 [01:13<00:23,  2.43it/s][Astep: 170
extend+tolist() time: 0.000926971435546875

Evaluating:  75%|███████▌  | 171/228 [01:13<00:23,  2.41it/s][Astep: 171
extend+tolist() time: 0.0002949237823486328

Evaluating:  75%|███████▌  | 172/228 [01:14<00:22,  2.44it/s][Astep: 172
extend+tolist() time: 0.0013086795806884766

Evaluating:  76%|███████▌  | 173/228 [01:14<00:22,  2.45it/s][Astep: 173
extend+tolist() time: 0.0011539459228515625

Evaluating:  76%|███████▋  | 174/228 [01:15<00:22,  2.39it/s][Astep: 174
extend+tolist() time: 0.0014231204986572266

Evaluating:  77%|███████▋  | 175/228 [01:15<00:22,  2.38it/s][Astep: 175
extend+tolist() time: 0.0012278556823730469

Evaluating:  77%|███████▋  | 176/228 [01:16<00:25,  2.04it/s][Astep: 176
extend+tolist() time: 0.0006196498870849609

Evaluating:  78%|███████▊  | 177/228 [01:16<00:23,  2.17it/s][Astep: 177
extend+tolist() time: 0.0006144046783447266

Evaluating:  78%|███████▊  | 178/228 [01:16<00:22,  2.24it/s][Astep: 178
extend+tolist() time: 0.002155780792236328

Evaluating:  79%|███████▊  | 179/228 [01:17<00:21,  2.26it/s][Astep: 179
extend+tolist() time: 0.0004050731658935547

Evaluating:  79%|███████▉  | 180/228 [01:17<00:20,  2.35it/s][Astep: 180
extend+tolist() time: 0.0004088878631591797

Evaluating:  79%|███████▉  | 181/228 [01:18<00:20,  2.35it/s][Astep: 181
extend+tolist() time: 0.0006172657012939453

Evaluating:  80%|███████▉  | 182/228 [01:18<00:19,  2.39it/s][Astep: 182
extend+tolist() time: 0.0007824897766113281

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.37it/s][Astep: 183
extend+tolist() time: 0.0010669231414794922

Evaluating:  81%|████████  | 184/228 [01:19<00:18,  2.40it/s][Astep: 184
extend+tolist() time: 0.0004291534423828125

Evaluating:  81%|████████  | 185/228 [01:19<00:17,  2.45it/s][Astep: 185
extend+tolist() time: 0.0011515617370605469

Evaluating:  82%|████████▏ | 186/228 [01:20<00:17,  2.38it/s][Astep: 186
extend+tolist() time: 0.001447439193725586

Evaluating:  82%|████████▏ | 187/228 [01:20<00:17,  2.40it/s][Astep: 187
extend+tolist() time: 0.0004341602325439453

Evaluating:  82%|████████▏ | 188/228 [01:21<00:16,  2.36it/s][Astep: 188
extend+tolist() time: 0.0010652542114257812

Evaluating:  83%|████████▎ | 189/228 [01:21<00:16,  2.37it/s][Astep: 189
extend+tolist() time: 0.000396728515625

Evaluating:  83%|████████▎ | 190/228 [01:21<00:15,  2.39it/s][Astep: 190
extend+tolist() time: 0.001188039779663086

Evaluating:  84%|████████▍ | 191/228 [01:22<00:15,  2.39it/s][Astep: 191
extend+tolist() time: 0.2608475685119629

Evaluating:  84%|████████▍ | 192/228 [01:22<00:17,  2.02it/s][Astep: 192
extend+tolist() time: 0.0004260540008544922

Evaluating:  85%|████████▍ | 193/228 [01:23<00:16,  2.14it/s][Astep: 193
extend+tolist() time: 0.0014264583587646484

Evaluating:  85%|████████▌ | 194/228 [01:23<00:15,  2.23it/s][Astep: 194
extend+tolist() time: 0.0006284713745117188

Evaluating:  86%|████████▌ | 195/228 [01:24<00:14,  2.25it/s][Astep: 195
extend+tolist() time: 0.0008661746978759766

Evaluating:  86%|████████▌ | 196/228 [01:24<00:13,  2.32it/s][Astep: 196
extend+tolist() time: 0.0005931854248046875

Evaluating:  86%|████████▋ | 197/228 [01:25<00:13,  2.34it/s][Astep: 197
extend+tolist() time: 0.0006415843963623047

Evaluating:  87%|████████▋ | 198/228 [01:25<00:12,  2.35it/s][Astep: 198
extend+tolist() time: 0.0009875297546386719

Evaluating:  87%|████████▋ | 199/228 [01:25<00:12,  2.41it/s][Astep: 199
extend+tolist() time: 0.001489400863647461

Evaluating:  88%|████████▊ | 200/228 [01:26<00:11,  2.34it/s][Astep: 200
extend+tolist() time: 0.0007054805755615234

Evaluating:  88%|████████▊ | 201/228 [01:26<00:11,  2.38it/s][Astep: 201
extend+tolist() time: 0.0006346702575683594

Evaluating:  89%|████████▊ | 202/228 [01:27<00:10,  2.37it/s][Astep: 202
extend+tolist() time: 0.0003867149353027344

Evaluating:  89%|████████▉ | 203/228 [01:27<00:10,  2.41it/s][Astep: 203
extend+tolist() time: 0.0012285709381103516

Evaluating:  89%|████████▉ | 204/228 [01:27<00:09,  2.41it/s][Astep: 204
extend+tolist() time: 0.00039315223693847656

Evaluating:  90%|████████▉ | 205/228 [01:28<00:09,  2.44it/s][Astep: 205
extend+tolist() time: 0.00029778480529785156

Evaluating:  90%|█████████ | 206/228 [01:28<00:08,  2.46it/s][Astep: 206
extend+tolist() time: 0.0006113052368164062

Evaluating:  91%|█████████ | 207/228 [01:29<00:08,  2.41it/s][Astep: 207
extend+tolist() time: 0.0010325908660888672

Evaluating:  91%|█████████ | 208/228 [01:29<00:08,  2.43it/s][Astep: 208
extend+tolist() time: 0.0007123947143554688

Evaluating:  92%|█████████▏| 209/228 [01:30<00:07,  2.41it/s][Astep: 209
extend+tolist() time: 0.0006108283996582031

Evaluating:  92%|█████████▏| 210/228 [01:30<00:07,  2.42it/s][Astep: 210
extend+tolist() time: 0.0010457038879394531

Evaluating:  93%|█████████▎| 211/228 [01:30<00:06,  2.43it/s][Astep: 211
extend+tolist() time: 0.0010952949523925781

Evaluating:  93%|█████████▎| 212/228 [01:31<00:06,  2.37it/s][Astep: 212
extend+tolist() time: 0.0013227462768554688

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.38it/s][Astep: 213
extend+tolist() time: 0.0007905960083007812

Evaluating:  94%|█████████▍| 214/228 [01:32<00:05,  2.37it/s][Astep: 214
extend+tolist() time: 0.0012621879577636719

Evaluating:  94%|█████████▍| 215/228 [01:32<00:05,  2.36it/s][Astep: 215
extend+tolist() time: 0.0006837844848632812

Evaluating:  95%|█████████▍| 216/228 [01:32<00:04,  2.42it/s][Astep: 216
extend+tolist() time: 0.0005400180816650391

Evaluating:  95%|█████████▌| 217/228 [01:33<00:04,  2.38it/s][Astep: 217
extend+tolist() time: 0.0009648799896240234

Evaluating:  96%|█████████▌| 218/228 [01:33<00:04,  2.41it/s][Astep: 218
extend+tolist() time: 0.0010313987731933594

Evaluating:  96%|█████████▌| 219/228 [01:34<00:03,  2.39it/s][Astep: 219
extend+tolist() time: 0.0004901885986328125

Evaluating:  96%|█████████▋| 220/228 [01:34<00:03,  2.39it/s][Astep: 220
extend+tolist() time: 0.0008440017700195312

Evaluating:  97%|█████████▋| 221/228 [01:35<00:02,  2.44it/s][Astep: 221
extend+tolist() time: 0.0006394386291503906

Evaluating:  97%|█████████▋| 222/228 [01:35<00:02,  2.40it/s][Astep: 222
extend+tolist() time: 0.00041604042053222656

Evaluating:  98%|█████████▊| 223/228 [01:35<00:02,  2.43it/s][Astep: 223
extend+tolist() time: 0.0003986358642578125

Evaluating:  98%|█████████▊| 224/228 [01:36<00:01,  2.41it/s][Astep: 224
extend+tolist() time: 0.0007910728454589844

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.43it/s][Astep: 225
extend+tolist() time: 0.0004253387451171875

Evaluating:  99%|█████████▉| 226/228 [01:37<00:00,  2.48it/s][Astep: 226
extend+tolist() time: 0.0005354881286621094

Evaluating: 100%|█████████▉| 227/228 [01:37<00:00,  2.42it/s][Astep: 227
extend+tolist() time: 0.00048661231994628906

Evaluating: 100%|██████████| 228/228 [01:37<00:00,  2.39it/s][A09/09/2023 00:31:52 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/09/2023 00:31:52 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:31:52 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:31:52 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:31:52 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:31:52 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:31:52 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:31:52 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:31:52 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:31:52 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:31:53 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:31:53 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:31:53 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:31:53 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:31:53 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:31:53 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:31:53 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:39<00:00,  2.29it/s]
09/09/2023 00:31:53 - INFO - __main__ -   Step: 1760, Validation Metrics: {'pred_1_num': 9851, 'pred_-1_num': 923, 'pred_0_num': 27, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7956670678640867, 'f1_micro': 0.7956670678640867, 'f1_macro': 0.425810298141579, 'f1_weighted': 0.7560800029351205, 'f1_-1': 0.3527521092808357, 'f1_0': 0.042042042042042045, 'f1_1': 0.8826367431018592, 'precision_micro': 0.7956670678640867, 'precision_macro': 0.6068516830580499, 'precision_weighted': 0.757338198474837, 'precision_-1': 0.47562296858071507, 'precision_0': 0.5185185185185185, 'precision_1': 0.8264135620749162, 'recall_micro': 0.7956670678640867, 'recall_macro': 0.4164365644265862, 'recall_weighted': 0.7956670678640867, 'recall_-1': 0.28033205619412516, 'recall_0': 0.02190923317683881, 'recall_1': 0.9470684039087948, 'roc_auc_micro': 0.9247332140590117, 'roc_auc_macro': 0.7752498769611114, 'roc_auc_weighted': 0.7687466337749044, 'roc_auc_-1': 0.835193932240401, 'roc_auc_0': 0.7311170154606486, 'roc_auc_1': 0.7594386831822848}
[2023-09-09 00:32:14,807] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1761/66600 [3:09:24<916:23:06, 50.88s/it]09/09/2023 00:32:14 - INFO - __main__ -   Step: 1761, LR: 1.7634247089748406e-05, Loss: 0.45079320669174194
[2023-09-09 00:32:35,146] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1762/66600 [3:09:44<751:21:10, 41.72s/it]09/09/2023 00:32:35 - INFO - __main__ -   Step: 1762, LR: 1.7644260858680687e-05, Loss: 0.5404301881790161
[2023-09-09 00:32:56,095] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1763/66600 [3:10:05<639:07:41, 35.49s/it]09/09/2023 00:32:56 - INFO - __main__ -   Step: 1763, LR: 1.765427462761297e-05, Loss: 0.47363361716270447
[2023-09-09 00:33:17,217] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1764/66600 [3:10:26<561:30:13, 31.18s/it]09/09/2023 00:33:17 - INFO - __main__ -   Step: 1764, LR: 1.766428839654525e-05, Loss: 0.48224273324012756
[2023-09-09 00:33:37,607] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1765/66600 [3:10:47<503:12:47, 27.94s/it]09/09/2023 00:33:37 - INFO - __main__ -   Step: 1765, LR: 1.7674302165477532e-05, Loss: 0.45621737837791443
[2023-09-09 00:33:57,939] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1766/66600 [3:11:07<462:05:30, 25.66s/it]09/09/2023 00:33:57 - INFO - __main__ -   Step: 1766, LR: 1.7684315934409814e-05, Loss: 0.471428781747818
[2023-09-09 00:34:18,117] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1767/66600 [3:11:27<432:28:42, 24.01s/it]09/09/2023 00:34:18 - INFO - __main__ -   Step: 1767, LR: 1.7694329703342095e-05, Loss: 0.4629615247249603
[2023-09-09 00:34:38,805] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1768/66600 [3:11:48<414:29:54, 23.02s/it]09/09/2023 00:34:38 - INFO - __main__ -   Step: 1768, LR: 1.770434347227438e-05, Loss: 0.4039396643638611
[2023-09-09 00:34:59,722] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1769/66600 [3:12:09<403:08:55, 22.39s/it]09/09/2023 00:34:59 - INFO - __main__ -   Step: 1769, LR: 1.7714357241206662e-05, Loss: 0.5058006644248962
[2023-09-09 00:35:20,409] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1770/66600 [3:12:29<393:57:53, 21.88s/it]09/09/2023 00:35:20 - INFO - __main__ -   Step: 1770, LR: 1.7724371010138944e-05, Loss: 0.5055689811706543
[2023-09-09 00:35:41,024] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1771/66600 [3:12:50<387:08:19, 21.50s/it]09/09/2023 00:35:41 - INFO - __main__ -   Step: 1771, LR: 1.7734384779071225e-05, Loss: 0.45933571457862854
[2023-09-09 00:36:02,099] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1772/66600 [3:13:11<384:50:54, 21.37s/it]09/09/2023 00:36:02 - INFO - __main__ -   Step: 1772, LR: 1.7744398548003507e-05, Loss: 0.43154817819595337
[2023-09-09 00:36:23,183] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1773/66600 [3:13:32<383:17:32, 21.29s/it]09/09/2023 00:36:23 - INFO - __main__ -   Step: 1773, LR: 1.775441231693579e-05, Loss: 0.4503774344921112
[2023-09-09 00:36:43,642] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1774/66600 [3:13:53<378:49:18, 21.04s/it]09/09/2023 00:36:43 - INFO - __main__ -   Step: 1774, LR: 1.776442608586807e-05, Loss: 0.4331975281238556
[2023-09-09 00:37:04,515] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1775/66600 [3:14:14<377:55:43, 20.99s/it]09/09/2023 00:37:04 - INFO - __main__ -   Step: 1775, LR: 1.777443985480035e-05, Loss: 0.419943630695343
[2023-09-09 00:37:25,065] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1776/66600 [3:14:34<375:33:24, 20.86s/it]09/09/2023 00:37:25 - INFO - __main__ -   Step: 1776, LR: 1.7784453623732633e-05, Loss: 0.44427499175071716
[2023-09-09 00:37:45,429] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1777/66600 [3:14:54<372:53:30, 20.71s/it]09/09/2023 00:37:45 - INFO - __main__ -   Step: 1777, LR: 1.7794467392664915e-05, Loss: 0.37656137347221375
[2023-09-09 00:38:06,141] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1778/66600 [3:15:15<372:54:14, 20.71s/it]09/09/2023 00:38:06 - INFO - __main__ -   Step: 1778, LR: 1.7804481161597196e-05, Loss: 0.5605462789535522
[2023-09-09 00:38:26,415] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1779/66600 [3:15:35<370:32:24, 20.58s/it]09/09/2023 00:38:26 - INFO - __main__ -   Step: 1779, LR: 1.781449493052948e-05, Loss: 0.42389577627182007
[2023-09-09 00:38:46,727] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1780/66600 [3:15:56<369:05:50, 20.50s/it]09/09/2023 00:38:46 - INFO - __main__ -   Step: 1780, LR: 1.7824508699461763e-05, Loss: 0.43704289197921753
09/09/2023 00:38:46 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0019521713256835938

Evaluating:   0%|          | 1/228 [00:00<01:52,  2.02it/s][Astep: 1
extend+tolist() time: 0.0011248588562011719

Evaluating:   1%|          | 2/228 [00:00<01:40,  2.24it/s][Astep: 2
extend+tolist() time: 0.0023298263549804688

Evaluating:   1%|▏         | 3/228 [00:01<01:41,  2.21it/s][Astep: 3
extend+tolist() time: 0.16109871864318848

Evaluating:   2%|▏         | 4/228 [00:01<01:50,  2.03it/s][Astep: 4
extend+tolist() time: 0.0015494823455810547

Evaluating:   2%|▏         | 5/228 [00:02<01:43,  2.15it/s][Astep: 5
extend+tolist() time: 0.0020470619201660156

Evaluating:   3%|▎         | 6/228 [00:02<01:49,  2.02it/s][Astep: 6
extend+tolist() time: 0.0019466876983642578

Evaluating:   3%|▎         | 7/228 [00:03<01:54,  1.93it/s][Astep: 7
extend+tolist() time: 0.0009732246398925781

Evaluating:   4%|▎         | 8/228 [00:03<01:45,  2.09it/s][Astep: 8
extend+tolist() time: 0.0011792182922363281

Evaluating:   4%|▍         | 9/228 [00:04<01:42,  2.15it/s][Astep: 9
extend+tolist() time: 0.0008070468902587891

Evaluating:   4%|▍         | 10/228 [00:04<01:37,  2.23it/s][Astep: 10
extend+tolist() time: 0.0013189315795898438

Evaluating:   5%|▍         | 11/228 [00:05<01:37,  2.24it/s][Astep: 11
extend+tolist() time: 0.0005886554718017578

Evaluating:   5%|▌         | 12/228 [00:05<01:42,  2.10it/s][Astep: 12
extend+tolist() time: 0.001081705093383789

Evaluating:   6%|▌         | 13/228 [00:06<01:40,  2.15it/s][Astep: 13
extend+tolist() time: 0.0005807876586914062

Evaluating:   6%|▌         | 14/228 [00:06<01:36,  2.23it/s][Astep: 14
extend+tolist() time: 0.0005698204040527344

Evaluating:   7%|▋         | 15/228 [00:06<01:32,  2.31it/s][Astep: 15
extend+tolist() time: 0.0011205673217773438

Evaluating:   7%|▋         | 16/228 [00:07<01:32,  2.29it/s][Astep: 16
extend+tolist() time: 0.0006258487701416016

Evaluating:   7%|▋         | 17/228 [00:07<01:30,  2.34it/s][Astep: 17
extend+tolist() time: 0.0013365745544433594

Evaluating:   8%|▊         | 18/228 [00:08<01:30,  2.31it/s][Astep: 18
extend+tolist() time: 0.00115966796875

Evaluating:   8%|▊         | 19/228 [00:08<01:29,  2.34it/s][Astep: 19
extend+tolist() time: 0.0016884803771972656

Evaluating:   9%|▉         | 20/228 [00:09<01:29,  2.32it/s][Astep: 20
extend+tolist() time: 0.0007684230804443359

Evaluating:   9%|▉         | 21/228 [00:09<01:27,  2.36it/s][Astep: 21
extend+tolist() time: 0.0010673999786376953

Evaluating:  10%|▉         | 22/228 [00:09<01:25,  2.41it/s][Astep: 22
extend+tolist() time: 0.0007355213165283203

Evaluating:  10%|█         | 23/228 [00:10<01:26,  2.38it/s][Astep: 23
extend+tolist() time: 0.0011391639709472656

Evaluating:  11%|█         | 24/228 [00:10<01:24,  2.40it/s][Astep: 24
extend+tolist() time: 0.0011410713195800781

Evaluating:  11%|█         | 25/228 [00:11<01:26,  2.35it/s][Astep: 25
extend+tolist() time: 0.0019297599792480469

Evaluating:  11%|█▏        | 26/228 [00:11<01:25,  2.35it/s][Astep: 26
extend+tolist() time: 0.0010976791381835938

Evaluating:  12%|█▏        | 27/228 [00:11<01:23,  2.41it/s][Astep: 27
extend+tolist() time: 0.0016918182373046875

Evaluating:  12%|█▏        | 28/228 [00:12<01:25,  2.35it/s][Astep: 28
extend+tolist() time: 0.00032711029052734375

Evaluating:  13%|█▎        | 29/228 [00:12<01:23,  2.39it/s][Astep: 29
extend+tolist() time: 0.0007421970367431641

Evaluating:  13%|█▎        | 30/228 [00:13<01:23,  2.36it/s][Astep: 30
extend+tolist() time: 0.001577615737915039

Evaluating:  14%|█▎        | 31/228 [00:13<01:23,  2.37it/s][Astep: 31
extend+tolist() time: 0.0005879402160644531

Evaluating:  14%|█▍        | 32/228 [00:14<01:22,  2.39it/s][Astep: 32
extend+tolist() time: 0.001394033432006836

Evaluating:  14%|█▍        | 33/228 [00:14<01:22,  2.36it/s][Astep: 33
extend+tolist() time: 0.14974689483642578

Evaluating:  15%|█▍        | 34/228 [00:15<01:29,  2.16it/s][Astep: 34
extend+tolist() time: 0.0013136863708496094

Evaluating:  15%|█▌        | 35/228 [00:15<01:26,  2.23it/s][Astep: 35
extend+tolist() time: 0.0006916522979736328

Evaluating:  16%|█▌        | 36/228 [00:16<01:30,  2.12it/s][Astep: 36
extend+tolist() time: 0.0011506080627441406

Evaluating:  16%|█▌        | 37/228 [00:16<01:27,  2.19it/s][Astep: 37
extend+tolist() time: 0.00159454345703125

Evaluating:  17%|█▋        | 38/228 [00:17<01:32,  2.05it/s][Astep: 38
extend+tolist() time: 0.0007824897766113281

Evaluating:  17%|█▋        | 39/228 [00:17<01:28,  2.13it/s][Astep: 39
extend+tolist() time: 0.0011136531829833984

Evaluating:  18%|█▊        | 40/228 [00:17<01:24,  2.22it/s][Astep: 40
extend+tolist() time: 0.000659942626953125

Evaluating:  18%|█▊        | 41/228 [00:18<01:22,  2.26it/s][Astep: 41
extend+tolist() time: 0.0008609294891357422

Evaluating:  18%|█▊        | 42/228 [00:18<01:20,  2.31it/s][Astep: 42
extend+tolist() time: 0.0017108917236328125

Evaluating:  19%|█▉        | 43/228 [00:19<01:18,  2.36it/s][Astep: 43
extend+tolist() time: 0.0019383430480957031

Evaluating:  19%|█▉        | 44/228 [00:19<01:19,  2.32it/s][Astep: 44
extend+tolist() time: 0.001123666763305664

Evaluating:  20%|█▉        | 45/228 [00:20<01:25,  2.14it/s][Astep: 45
extend+tolist() time: 0.0016779899597167969

Evaluating:  20%|██        | 46/228 [00:20<01:23,  2.19it/s][Astep: 46
extend+tolist() time: 0.0012466907501220703

Evaluating:  21%|██        | 47/228 [00:20<01:20,  2.25it/s][Astep: 47
extend+tolist() time: 0.0016257762908935547

Evaluating:  21%|██        | 48/228 [00:21<01:19,  2.27it/s][Astep: 48
extend+tolist() time: 0.0015838146209716797

Evaluating:  21%|██▏       | 49/228 [00:21<01:17,  2.30it/s][Astep: 49
extend+tolist() time: 0.0009281635284423828

Evaluating:  22%|██▏       | 50/228 [00:22<01:15,  2.36it/s][Astep: 50
extend+tolist() time: 0.0012426376342773438

Evaluating:  22%|██▏       | 51/228 [00:22<01:16,  2.32it/s][Astep: 51
extend+tolist() time: 0.0016884803771972656

Evaluating:  23%|██▎       | 52/228 [00:23<01:15,  2.34it/s][Astep: 52
extend+tolist() time: 0.0014071464538574219

Evaluating:  23%|██▎       | 53/228 [00:23<01:14,  2.34it/s][Astep: 53
extend+tolist() time: 0.001705169677734375

Evaluating:  24%|██▎       | 54/228 [00:23<01:14,  2.35it/s][Astep: 54
extend+tolist() time: 0.0010504722595214844

Evaluating:  24%|██▍       | 55/228 [00:24<01:13,  2.35it/s][Astep: 55
extend+tolist() time: 0.0012044906616210938

Evaluating:  25%|██▍       | 56/228 [00:24<01:12,  2.38it/s][Astep: 56
extend+tolist() time: 0.0011687278747558594

Evaluating:  25%|██▌       | 57/228 [00:25<01:10,  2.41it/s][Astep: 57
extend+tolist() time: 0.0010371208190917969

Evaluating:  25%|██▌       | 58/228 [00:25<01:10,  2.40it/s][Astep: 58
extend+tolist() time: 0.0008542537689208984

Evaluating:  26%|██▌       | 59/228 [00:25<01:09,  2.42it/s][Astep: 59
extend+tolist() time: 0.0013813972473144531

Evaluating:  26%|██▋       | 60/228 [00:26<01:10,  2.39it/s][Astep: 60
extend+tolist() time: 0.0007436275482177734

Evaluating:  27%|██▋       | 61/228 [00:26<01:09,  2.41it/s][Astep: 61
extend+tolist() time: 0.0012562274932861328

Evaluating:  27%|██▋       | 62/228 [00:27<01:07,  2.46it/s][Astep: 62
extend+tolist() time: 0.0008089542388916016

Evaluating:  28%|██▊       | 63/228 [00:27<01:08,  2.41it/s][Astep: 63
extend+tolist() time: 0.0013072490692138672

Evaluating:  28%|██▊       | 64/228 [00:28<01:07,  2.41it/s][Astep: 64
extend+tolist() time: 0.0008246898651123047

Evaluating:  29%|██▊       | 65/228 [00:28<01:08,  2.38it/s][Astep: 65
extend+tolist() time: 0.0012178421020507812

Evaluating:  29%|██▉       | 66/228 [00:28<01:07,  2.40it/s][Astep: 66
extend+tolist() time: 0.0007669925689697266

Evaluating:  29%|██▉       | 67/228 [00:29<01:05,  2.45it/s][Astep: 67
extend+tolist() time: 0.18695998191833496

Evaluating:  30%|██▉       | 68/228 [00:29<01:15,  2.11it/s][Astep: 68
extend+tolist() time: 0.0011539459228515625

Evaluating:  30%|███       | 69/228 [00:30<01:12,  2.18it/s][Astep: 69
extend+tolist() time: 0.0010941028594970703

Evaluating:  31%|███       | 70/228 [00:30<01:11,  2.22it/s][Astep: 70
extend+tolist() time: 0.0014488697052001953

Evaluating:  31%|███       | 71/228 [00:31<01:17,  2.03it/s][Astep: 71
extend+tolist() time: 0.0012826919555664062

Evaluating:  32%|███▏      | 72/228 [00:31<01:14,  2.11it/s][Astep: 72
extend+tolist() time: 0.0007729530334472656

Evaluating:  32%|███▏      | 73/228 [00:32<01:10,  2.21it/s][Astep: 73
extend+tolist() time: 0.0009567737579345703

Evaluating:  32%|███▏      | 74/228 [00:32<01:08,  2.24it/s][Astep: 74
extend+tolist() time: 0.0007371902465820312

Evaluating:  33%|███▎      | 75/228 [00:33<01:06,  2.30it/s][Astep: 75
extend+tolist() time: 0.0017597675323486328

Evaluating:  33%|███▎      | 76/228 [00:33<01:05,  2.32it/s][Astep: 76
extend+tolist() time: 0.0006439685821533203

Evaluating:  34%|███▍      | 77/228 [00:33<01:05,  2.31it/s][Astep: 77
extend+tolist() time: 0.0018301010131835938

Evaluating:  34%|███▍      | 78/228 [00:34<01:04,  2.34it/s][Astep: 78
extend+tolist() time: 0.0012409687042236328

Evaluating:  35%|███▍      | 79/228 [00:34<01:04,  2.32it/s][Astep: 79
extend+tolist() time: 0.001287221908569336

Evaluating:  35%|███▌      | 80/228 [00:35<01:02,  2.36it/s][Astep: 80
extend+tolist() time: 0.0009510517120361328

Evaluating:  36%|███▌      | 81/228 [00:35<01:03,  2.32it/s][Astep: 81
extend+tolist() time: 0.0012979507446289062

Evaluating:  36%|███▌      | 82/228 [00:36<01:10,  2.07it/s][Astep: 82
extend+tolist() time: 0.0008559226989746094

Evaluating:  36%|███▋      | 83/228 [00:36<01:07,  2.14it/s][Astep: 83
extend+tolist() time: 0.0010933876037597656

Evaluating:  37%|███▋      | 84/228 [00:37<01:04,  2.23it/s][Astep: 84
extend+tolist() time: 0.001001119613647461

Evaluating:  37%|███▋      | 85/228 [00:37<01:02,  2.30it/s][Astep: 85
extend+tolist() time: 0.0013568401336669922

Evaluating:  38%|███▊      | 86/228 [00:37<01:02,  2.28it/s][Astep: 86
extend+tolist() time: 0.0009207725524902344

Evaluating:  38%|███▊      | 87/228 [00:38<01:00,  2.33it/s][Astep: 87
extend+tolist() time: 0.0013802051544189453

Evaluating:  39%|███▊      | 88/228 [00:38<01:01,  2.29it/s][Astep: 88
extend+tolist() time: 0.0010991096496582031

Evaluating:  39%|███▉      | 89/228 [00:39<00:59,  2.33it/s][Astep: 89
extend+tolist() time: 0.0009672641754150391

Evaluating:  39%|███▉      | 90/228 [00:39<00:58,  2.35it/s][Astep: 90
extend+tolist() time: 0.0013692378997802734

Evaluating:  40%|███▉      | 91/228 [00:39<00:58,  2.36it/s][Astep: 91
extend+tolist() time: 0.0007655620574951172

Evaluating:  40%|████      | 92/228 [00:40<00:56,  2.41it/s][Astep: 92
extend+tolist() time: 0.0011947154998779297

Evaluating:  41%|████      | 93/228 [00:40<00:57,  2.37it/s][Astep: 93
extend+tolist() time: 0.0010082721710205078

Evaluating:  41%|████      | 94/228 [00:41<00:56,  2.39it/s][Astep: 94
extend+tolist() time: 0.0011844635009765625

Evaluating:  42%|████▏     | 95/228 [00:41<00:56,  2.35it/s][Astep: 95
extend+tolist() time: 0.0011565685272216797

Evaluating:  42%|████▏     | 96/228 [00:42<00:55,  2.37it/s][Astep: 96
extend+tolist() time: 0.0014672279357910156

Evaluating:  43%|████▎     | 97/228 [00:42<00:54,  2.42it/s][Astep: 97
extend+tolist() time: 0.0011866092681884766

Evaluating:  43%|████▎     | 98/228 [00:42<00:54,  2.38it/s][Astep: 98
extend+tolist() time: 0.0009057521820068359

Evaluating:  43%|████▎     | 99/228 [00:43<00:53,  2.40it/s][Astep: 99
extend+tolist() time: 0.001348733901977539

Evaluating:  44%|████▍     | 100/228 [00:43<00:54,  2.37it/s][Astep: 100
extend+tolist() time: 0.0007545948028564453

Evaluating:  44%|████▍     | 101/228 [00:44<00:52,  2.40it/s][Astep: 101
extend+tolist() time: 0.0012290477752685547

Evaluating:  45%|████▍     | 102/228 [00:44<00:51,  2.44it/s][Astep: 102
extend+tolist() time: 0.0007455348968505859

Evaluating:  45%|████▌     | 103/228 [00:44<00:52,  2.40it/s][Astep: 103
extend+tolist() time: 0.0011336803436279297

Evaluating:  46%|████▌     | 104/228 [00:45<00:51,  2.42it/s][Astep: 104
extend+tolist() time: 0.0007355213165283203

Evaluating:  46%|████▌     | 105/228 [00:45<00:51,  2.38it/s][Astep: 105
extend+tolist() time: 0.0012319087982177734

Evaluating:  46%|████▋     | 106/228 [00:46<00:50,  2.41it/s][Astep: 106
extend+tolist() time: 0.0013194084167480469

Evaluating:  47%|████▋     | 107/228 [00:46<00:49,  2.43it/s][Astep: 107
extend+tolist() time: 0.001253366470336914

Evaluating:  47%|████▋     | 108/228 [00:47<00:50,  2.39it/s][Astep: 108
extend+tolist() time: 0.0008053779602050781

Evaluating:  48%|████▊     | 109/228 [00:47<00:48,  2.44it/s][Astep: 109
extend+tolist() time: 0.0012612342834472656

Evaluating:  48%|████▊     | 110/228 [00:47<00:49,  2.39it/s][Astep: 110
extend+tolist() time: 0.0006403923034667969

Evaluating:  49%|████▊     | 111/228 [00:48<00:48,  2.42it/s][Astep: 111
extend+tolist() time: 0.0019028186798095703

Evaluating:  49%|████▉     | 112/228 [00:48<00:49,  2.36it/s][Astep: 112
extend+tolist() time: 0.0007123947143554688

Evaluating:  50%|████▉     | 113/228 [00:49<00:48,  2.38it/s][Astep: 113
extend+tolist() time: 0.18146729469299316

Evaluating:  50%|█████     | 114/228 [00:49<00:53,  2.14it/s][Astep: 114
extend+tolist() time: 0.0015513896942138672

Evaluating:  50%|█████     | 115/228 [00:50<00:51,  2.20it/s][Astep: 115
extend+tolist() time: 0.00067901611328125

Evaluating:  51%|█████     | 116/228 [00:50<00:56,  1.99it/s][Astep: 116
extend+tolist() time: 0.001222848892211914

Evaluating:  51%|█████▏    | 117/228 [00:51<00:52,  2.10it/s][Astep: 117
extend+tolist() time: 0.0008485317230224609

Evaluating:  52%|█████▏    | 118/228 [00:51<00:49,  2.21it/s][Astep: 118
extend+tolist() time: 0.0005357265472412109

Evaluating:  52%|█████▏    | 119/228 [00:52<00:54,  2.01it/s][Astep: 119
extend+tolist() time: 0.0007302761077880859

Evaluating:  53%|█████▎    | 120/228 [00:52<00:50,  2.15it/s][Astep: 120
extend+tolist() time: 0.0010766983032226562

Evaluating:  53%|█████▎    | 121/228 [00:53<00:48,  2.19it/s][Astep: 121
extend+tolist() time: 0.0006339550018310547

Evaluating:  54%|█████▎    | 122/228 [00:53<00:46,  2.27it/s][Astep: 122
extend+tolist() time: 0.0011317729949951172

Evaluating:  54%|█████▍    | 123/228 [00:53<00:46,  2.27it/s][Astep: 123
extend+tolist() time: 0.0006330013275146484

Evaluating:  54%|█████▍    | 124/228 [00:54<00:44,  2.32it/s][Astep: 124
extend+tolist() time: 0.0008547306060791016

Evaluating:  55%|█████▍    | 125/228 [00:54<00:43,  2.38it/s][Astep: 125
extend+tolist() time: 0.0008966922760009766

Evaluating:  55%|█████▌    | 126/228 [00:55<00:43,  2.36it/s][Astep: 126
extend+tolist() time: 0.0017328262329101562

Evaluating:  56%|█████▌    | 127/228 [00:55<00:44,  2.29it/s][Astep: 127
extend+tolist() time: 0.0012874603271484375

Evaluating:  56%|█████▌    | 128/228 [00:56<00:44,  2.26it/s][Astep: 128
extend+tolist() time: 0.001199483871459961

Evaluating:  57%|█████▋    | 129/228 [00:56<00:42,  2.33it/s][Astep: 129
extend+tolist() time: 0.0008227825164794922

Evaluating:  57%|█████▋    | 130/228 [00:56<00:42,  2.33it/s][Astep: 130
extend+tolist() time: 0.0013861656188964844

Evaluating:  57%|█████▋    | 131/228 [00:57<00:41,  2.33it/s][Astep: 131
extend+tolist() time: 0.00043702125549316406

Evaluating:  58%|█████▊    | 132/228 [00:57<00:40,  2.40it/s][Astep: 132
extend+tolist() time: 0.0014858245849609375

Evaluating:  58%|█████▊    | 133/228 [00:58<00:40,  2.35it/s][Astep: 133
extend+tolist() time: 0.0004220008850097656

Evaluating:  59%|█████▉    | 134/228 [00:58<00:44,  2.10it/s][Astep: 134
extend+tolist() time: 0.0013952255249023438

Evaluating:  59%|█████▉    | 135/228 [00:59<00:43,  2.15it/s][Astep: 135
extend+tolist() time: 0.0004417896270751953

Evaluating:  60%|█████▉    | 136/228 [00:59<00:40,  2.25it/s][Astep: 136
extend+tolist() time: 0.001184225082397461

Evaluating:  60%|██████    | 137/228 [00:59<00:40,  2.25it/s][Astep: 137
extend+tolist() time: 0.0003864765167236328

Evaluating:  61%|██████    | 138/228 [01:00<00:38,  2.33it/s][Astep: 138
extend+tolist() time: 0.0007464885711669922

Evaluating:  61%|██████    | 139/228 [01:00<00:37,  2.40it/s][Astep: 139
extend+tolist() time: 0.0004596710205078125

Evaluating:  61%|██████▏   | 140/228 [01:01<00:37,  2.37it/s][Astep: 140
extend+tolist() time: 0.0012505054473876953

Evaluating:  62%|██████▏   | 141/228 [01:01<00:36,  2.40it/s][Astep: 141
extend+tolist() time: 0.0007634162902832031

Evaluating:  62%|██████▏   | 142/228 [01:02<00:36,  2.36it/s][Astep: 142
extend+tolist() time: 0.0010037422180175781

Evaluating:  63%|██████▎   | 143/228 [01:02<00:35,  2.40it/s][Astep: 143
extend+tolist() time: 0.00032901763916015625

Evaluating:  63%|██████▎   | 144/228 [01:02<00:34,  2.46it/s][Astep: 144
extend+tolist() time: 0.0006768703460693359

Evaluating:  64%|██████▎   | 145/228 [01:03<00:34,  2.40it/s][Astep: 145
extend+tolist() time: 0.0008792877197265625

Evaluating:  64%|██████▍   | 146/228 [01:03<00:33,  2.43it/s][Astep: 146
extend+tolist() time: 0.00038552284240722656

Evaluating:  64%|██████▍   | 147/228 [01:04<00:33,  2.39it/s][Astep: 147
extend+tolist() time: 0.0007214546203613281

Evaluating:  65%|██████▍   | 148/228 [01:04<00:33,  2.41it/s][Astep: 148
extend+tolist() time: 0.0011205673217773438

Evaluating:  65%|██████▌   | 149/228 [01:04<00:32,  2.45it/s][Astep: 149
extend+tolist() time: 0.000354766845703125

Evaluating:  66%|██████▌   | 150/228 [01:05<00:32,  2.40it/s][Astep: 150
extend+tolist() time: 0.0007877349853515625

Evaluating:  66%|██████▌   | 151/228 [01:05<00:31,  2.41it/s][Astep: 151
extend+tolist() time: 0.0010242462158203125

Evaluating:  67%|██████▋   | 152/228 [01:06<00:32,  2.37it/s][Astep: 152
extend+tolist() time: 0.0007877349853515625

Evaluating:  67%|██████▋   | 153/228 [01:06<00:31,  2.40it/s][Astep: 153
extend+tolist() time: 0.001379251480102539

Evaluating:  68%|██████▊   | 154/228 [01:07<00:31,  2.37it/s][Astep: 154
extend+tolist() time: 0.001817941665649414

Evaluating:  68%|██████▊   | 155/228 [01:07<00:31,  2.33it/s][Astep: 155
extend+tolist() time: 0.000598907470703125

Evaluating:  68%|██████▊   | 156/228 [01:07<00:30,  2.39it/s][Astep: 156
extend+tolist() time: 0.0004987716674804688

Evaluating:  69%|██████▉   | 157/228 [01:08<00:29,  2.37it/s][Astep: 157
extend+tolist() time: 0.0010416507720947266

Evaluating:  69%|██████▉   | 158/228 [01:08<00:29,  2.41it/s][Astep: 158
extend+tolist() time: 0.0004611015319824219

Evaluating:  70%|██████▉   | 159/228 [01:09<00:28,  2.39it/s][Astep: 159
extend+tolist() time: 0.0006504058837890625

Evaluating:  70%|███████   | 160/228 [01:09<00:28,  2.42it/s][Astep: 160
extend+tolist() time: 0.0007774829864501953

Evaluating:  71%|███████   | 161/228 [01:09<00:27,  2.48it/s][Astep: 161
extend+tolist() time: 0.0007760524749755859

Evaluating:  71%|███████   | 162/228 [01:10<00:27,  2.43it/s][Astep: 162
extend+tolist() time: 0.0005180835723876953

Evaluating:  71%|███████▏  | 163/228 [01:10<00:26,  2.47it/s][Astep: 163
extend+tolist() time: 0.00045871734619140625

Evaluating:  72%|███████▏  | 164/228 [01:11<00:26,  2.43it/s][Astep: 164
extend+tolist() time: 0.0010426044464111328

Evaluating:  72%|███████▏  | 165/228 [01:11<00:25,  2.46it/s][Astep: 165
extend+tolist() time: 0.0004699230194091797

Evaluating:  73%|███████▎  | 166/228 [01:11<00:24,  2.52it/s][Astep: 166
extend+tolist() time: 0.00037384033203125

Evaluating:  73%|███████▎  | 167/228 [01:12<00:24,  2.46it/s][Astep: 167
extend+tolist() time: 0.0005922317504882812

Evaluating:  74%|███████▎  | 168/228 [01:12<00:24,  2.49it/s][Astep: 168
extend+tolist() time: 0.0016603469848632812

Evaluating:  74%|███████▍  | 169/228 [01:13<00:24,  2.44it/s][Astep: 169
extend+tolist() time: 0.0003895759582519531

Evaluating:  75%|███████▍  | 170/228 [01:13<00:23,  2.47it/s][Astep: 170
extend+tolist() time: 0.0013289451599121094

Evaluating:  75%|███████▌  | 171/228 [01:13<00:22,  2.52it/s][Astep: 171
extend+tolist() time: 0.0002968311309814453

Evaluating:  75%|███████▌  | 172/228 [01:14<00:22,  2.45it/s][Astep: 172
extend+tolist() time: 0.0008249282836914062

Evaluating:  76%|███████▌  | 173/228 [01:14<00:22,  2.45it/s][Astep: 173
extend+tolist() time: 0.001674652099609375

Evaluating:  76%|███████▋  | 174/228 [01:15<00:22,  2.41it/s][Astep: 174
extend+tolist() time: 0.0018322467803955078

Evaluating:  77%|███████▋  | 175/228 [01:15<00:22,  2.40it/s][Astep: 175
extend+tolist() time: 0.0008227825164794922

Evaluating:  77%|███████▋  | 176/228 [01:16<00:21,  2.45it/s][Astep: 176
extend+tolist() time: 0.001035928726196289

Evaluating:  78%|███████▊  | 177/228 [01:16<00:21,  2.39it/s][Astep: 177
extend+tolist() time: 0.0006210803985595703

Evaluating:  78%|███████▊  | 178/228 [01:16<00:20,  2.43it/s][Astep: 178
extend+tolist() time: 0.0016016960144042969

Evaluating:  79%|███████▊  | 179/228 [01:17<00:20,  2.36it/s][Astep: 179
extend+tolist() time: 0.00040721893310546875

Evaluating:  79%|███████▉  | 180/228 [01:17<00:19,  2.40it/s][Astep: 180
extend+tolist() time: 0.00039768218994140625

Evaluating:  79%|███████▉  | 181/228 [01:18<00:19,  2.46it/s][Astep: 181
extend+tolist() time: 0.0006136894226074219

Evaluating:  80%|███████▉  | 182/228 [01:18<00:19,  2.41it/s][Astep: 182
extend+tolist() time: 0.001210927963256836

Evaluating:  80%|████████  | 183/228 [01:18<00:18,  2.41it/s][Astep: 183
extend+tolist() time: 0.0006420612335205078

Evaluating:  81%|████████  | 184/228 [01:19<00:18,  2.38it/s][Astep: 184
extend+tolist() time: 0.00043964385986328125

Evaluating:  81%|████████  | 185/228 [01:19<00:17,  2.41it/s][Astep: 185
extend+tolist() time: 0.001535177230834961

Evaluating:  82%|████████▏ | 186/228 [01:20<00:17,  2.43it/s][Astep: 186
extend+tolist() time: 0.0013794898986816406

Evaluating:  82%|████████▏ | 187/228 [01:20<00:17,  2.40it/s][Astep: 187
extend+tolist() time: 0.0004658699035644531

Evaluating:  82%|████████▏ | 188/228 [01:21<00:16,  2.42it/s][Astep: 188
extend+tolist() time: 0.0007064342498779297

Evaluating:  83%|████████▎ | 189/228 [01:21<00:16,  2.36it/s][Astep: 189
extend+tolist() time: 0.0003795623779296875

Evaluating:  83%|████████▎ | 190/228 [01:21<00:15,  2.39it/s][Astep: 190
extend+tolist() time: 0.0016317367553710938

Evaluating:  84%|████████▍ | 191/228 [01:22<00:15,  2.36it/s][Astep: 191
extend+tolist() time: 0.0007221698760986328

Evaluating:  84%|████████▍ | 192/228 [01:22<00:15,  2.36it/s][Astep: 192
extend+tolist() time: 0.0008134841918945312

Evaluating:  85%|████████▍ | 193/228 [01:23<00:14,  2.43it/s][Astep: 193
extend+tolist() time: 0.2687406539916992

Evaluating:  85%|████████▌ | 194/228 [01:23<00:17,  1.99it/s][Astep: 194
extend+tolist() time: 0.0010077953338623047

Evaluating:  86%|████████▌ | 195/228 [01:24<00:15,  2.13it/s][Astep: 195
extend+tolist() time: 0.0005209445953369141

Evaluating:  86%|████████▌ | 196/228 [01:24<00:14,  2.21it/s][Astep: 196
extend+tolist() time: 0.0006024837493896484

Evaluating:  86%|████████▋ | 197/228 [01:25<00:13,  2.29it/s][Astep: 197
extend+tolist() time: 0.001018524169921875

Evaluating:  87%|████████▋ | 198/228 [01:25<00:13,  2.29it/s][Astep: 198
extend+tolist() time: 0.0006029605865478516

Evaluating:  87%|████████▋ | 199/228 [01:25<00:12,  2.34it/s][Astep: 199
extend+tolist() time: 0.0018966197967529297

Evaluating:  88%|████████▊ | 200/228 [01:26<00:11,  2.37it/s][Astep: 200
extend+tolist() time: 0.0007026195526123047

Evaluating:  88%|████████▊ | 201/228 [01:26<00:13,  2.01it/s][Astep: 201
extend+tolist() time: 0.0009903907775878906

Evaluating:  89%|████████▊ | 202/228 [01:27<00:12,  2.12it/s][Astep: 202
extend+tolist() time: 0.0003864765167236328

Evaluating:  89%|████████▉ | 203/228 [01:27<00:11,  2.20it/s][Astep: 203
extend+tolist() time: 0.0004899501800537109

Evaluating:  89%|████████▉ | 204/228 [01:28<00:10,  2.31it/s][Astep: 204
extend+tolist() time: 0.00038743019104003906

Evaluating:  90%|████████▉ | 205/228 [01:28<00:09,  2.31it/s][Astep: 205
extend+tolist() time: 0.0003039836883544922

Evaluating:  90%|█████████ | 206/228 [01:28<00:09,  2.37it/s][Astep: 206
extend+tolist() time: 0.001085519790649414

Evaluating:  91%|█████████ | 207/228 [01:29<00:08,  2.37it/s][Astep: 207
extend+tolist() time: 0.0006120204925537109

Evaluating:  91%|█████████ | 208/228 [01:29<00:08,  2.38it/s][Astep: 208
extend+tolist() time: 0.0007047653198242188

Evaluating:  92%|█████████▏| 209/228 [01:30<00:07,  2.44it/s][Astep: 209
extend+tolist() time: 0.0010247230529785156

Evaluating:  92%|█████████▏| 210/228 [01:30<00:07,  2.39it/s][Astep: 210
extend+tolist() time: 0.0006046295166015625

Evaluating:  93%|█████████▎| 211/228 [01:31<00:07,  2.42it/s][Astep: 211
extend+tolist() time: 0.0015094280242919922

Evaluating:  93%|█████████▎| 212/228 [01:31<00:06,  2.39it/s][Astep: 212
extend+tolist() time: 0.0009181499481201172

Evaluating:  93%|█████████▎| 213/228 [01:31<00:06,  2.40it/s][Astep: 213
extend+tolist() time: 0.0011892318725585938

Evaluating:  94%|█████████▍| 214/228 [01:32<00:05,  2.45it/s][Astep: 214
extend+tolist() time: 0.0008575916290283203

Evaluating:  94%|█████████▍| 215/228 [01:32<00:05,  2.40it/s][Astep: 215
extend+tolist() time: 0.0006785392761230469

Evaluating:  95%|█████████▍| 216/228 [01:33<00:04,  2.42it/s][Astep: 216
extend+tolist() time: 0.0005629062652587891

Evaluating:  95%|█████████▌| 217/228 [01:33<00:04,  2.38it/s][Astep: 217
extend+tolist() time: 0.0005681514739990234

Evaluating:  96%|█████████▌| 218/228 [01:33<00:04,  2.41it/s][Astep: 218
extend+tolist() time: 0.0014312267303466797

Evaluating:  96%|█████████▌| 219/228 [01:34<00:03,  2.44it/s][Astep: 219
extend+tolist() time: 0.0004954338073730469

Evaluating:  96%|█████████▋| 220/228 [01:34<00:03,  2.40it/s][Astep: 220
extend+tolist() time: 0.0003955364227294922

Evaluating:  97%|█████████▋| 221/228 [01:35<00:02,  2.43it/s][Astep: 221
extend+tolist() time: 0.0006601810455322266

Evaluating:  97%|█████████▋| 222/228 [01:35<00:02,  2.38it/s][Astep: 222
extend+tolist() time: 0.00042629241943359375

Evaluating:  98%|█████████▊| 223/228 [01:36<00:02,  2.41it/s][Astep: 223
extend+tolist() time: 0.0003952980041503906

Evaluating:  98%|█████████▊| 224/228 [01:36<00:01,  2.46it/s][Astep: 224
extend+tolist() time: 0.0003705024719238281

Evaluating:  99%|█████████▊| 225/228 [01:36<00:01,  2.41it/s][Astep: 225
extend+tolist() time: 0.0004303455352783203

Evaluating:  99%|█████████▉| 226/228 [01:37<00:00,  2.44it/s][Astep: 226
extend+tolist() time: 0.0010302066802978516

Evaluating: 100%|█████████▉| 227/228 [01:37<00:00,  2.39it/s][Astep: 227
extend+tolist() time: 0.0004928112030029297

Evaluating: 100%|██████████| 228/228 [01:38<00:00,  2.38it/s][A09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:40:25 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:40:26 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:40:26 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:40:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:40:27 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:40<00:00,  2.27it/s]
09/09/2023 00:40:27 - INFO - __main__ -   Step: 1780, Validation Metrics: {'pred_1_num': 9577, 'pred_-1_num': 1191, 'pred_0_num': 33, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7889084344042219, 'f1_micro': 0.7889084344042219, 'f1_macro': 0.43993122523902994, 'f1_weighted': 0.7573804949289692, 'f1_-1': 0.3793978962640551, 'f1_0': 0.0625, 'f1_1': 0.8778957794530347, 'precision_micro': 0.7889084344042219, 'precision_macro': 0.636141163129758, 'precision_weighted': 0.7642071629676584, 'precision_-1': 0.43912678421494544, 'precision_0': 0.6363636363636364, 'precision_1': 0.8329330688106923, 'recall_micro': 0.7889084344042219, 'recall_macro': 0.43160850512766497, 'recall_weighted': 0.7889084344042219, 'recall_-1': 0.3339719029374202, 'recall_0': 0.03286384976525822, 'recall_1': 0.9279897626803164, 'roc_auc_micro': 0.922475995336289, 'roc_auc_macro': 0.77550431844502, 'roc_auc_weighted': 0.7663959439360436, 'roc_auc_-1': 0.8361350531495968, 'roc_auc_0': 0.7343010368185627, 'roc_auc_1': 0.7560768653669006}
[2023-09-09 00:40:47,759] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1781/66600 [3:17:57<912:07:38, 50.66s/it]09/09/2023 00:40:47 - INFO - __main__ -   Step: 1781, LR: 1.7834522468394045e-05, Loss: 0.49313074350357056
[2023-09-09 00:41:08,407] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1782/66600 [3:18:17<750:00:25, 41.66s/it]09/09/2023 00:41:08 - INFO - __main__ -   Step: 1782, LR: 1.7844536237326323e-05, Loss: 0.4289393126964569
[2023-09-09 00:41:29,285] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1783/66600 [3:18:38<637:46:07, 35.42s/it]09/09/2023 00:41:29 - INFO - __main__ -   Step: 1783, LR: 1.7854550006258608e-05, Loss: 0.5215308666229248
[2023-09-09 00:41:50,080] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1784/66600 [3:18:59<558:45:01, 31.03s/it]09/09/2023 00:41:50 - INFO - __main__ -   Step: 1784, LR: 1.786456377519089e-05, Loss: 0.44314318895339966
[2023-09-09 00:42:10,910] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1785/66600 [3:19:20<503:37:44, 27.97s/it]09/09/2023 00:42:10 - INFO - __main__ -   Step: 1785, LR: 1.787457754412317e-05, Loss: 0.46273893117904663
[2023-09-09 00:42:31,744] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1786/66600 [3:19:41<465:03:49, 25.83s/it]09/09/2023 00:42:31 - INFO - __main__ -   Step: 1786, LR: 1.7884591313055453e-05, Loss: 0.40713411569595337
[2023-09-09 00:42:52,789] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1787/66600 [3:20:02<439:12:10, 24.40s/it]09/09/2023 00:42:52 - INFO - __main__ -   Step: 1787, LR: 1.7894605081987734e-05, Loss: 0.4623953402042389
[2023-09-09 00:43:13,433] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1788/66600 [3:20:22<418:56:20, 23.27s/it]09/09/2023 00:43:13 - INFO - __main__ -   Step: 1788, LR: 1.7904618850920016e-05, Loss: 0.36066776514053345
[2023-09-09 00:43:33,951] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1789/66600 [3:20:43<404:04:12, 22.44s/it]09/09/2023 00:43:33 - INFO - __main__ -   Step: 1789, LR: 1.7914632619852297e-05, Loss: 0.6175934672355652
[2023-09-09 00:43:54,468] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1790/66600 [3:21:04<393:38:59, 21.87s/it]09/09/2023 00:43:54 - INFO - __main__ -   Step: 1790, LR: 1.7924646388784582e-05, Loss: 0.43945133686065674
[2023-09-09 00:44:14,780] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1791/66600 [3:21:24<385:15:11, 21.40s/it]09/09/2023 00:44:14 - INFO - __main__ -   Step: 1791, LR: 1.793466015771686e-05, Loss: 0.44051605463027954
[2023-09-09 00:44:35,487] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1792/66600 [3:21:45<381:30:08, 21.19s/it]09/09/2023 00:44:35 - INFO - __main__ -   Step: 1792, LR: 1.7944673926649142e-05, Loss: 0.379244863986969
[2023-09-09 00:44:55,856] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1793/66600 [3:22:05<377:03:06, 20.95s/it]09/09/2023 00:44:55 - INFO - __main__ -   Step: 1793, LR: 1.7954687695581424e-05, Loss: 0.3557787239551544
[2023-09-09 00:45:16,754] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1794/66600 [3:22:26<376:47:23, 20.93s/it]09/09/2023 00:45:16 - INFO - __main__ -   Step: 1794, LR: 1.796470146451371e-05, Loss: 0.4253193736076355
[2023-09-09 00:45:37,042] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1795/66600 [3:22:46<373:18:57, 20.74s/it]09/09/2023 00:45:37 - INFO - __main__ -   Step: 1795, LR: 1.797471523344599e-05, Loss: 0.4256836771965027
[2023-09-09 00:45:57,165] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1796/66600 [3:23:06<369:59:18, 20.55s/it]09/09/2023 00:45:57 - INFO - __main__ -   Step: 1796, LR: 1.7984729002378272e-05, Loss: 0.48698925971984863
[2023-09-09 00:46:17,504] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1797/66600 [3:23:27<368:49:12, 20.49s/it]09/09/2023 00:46:17 - INFO - __main__ -   Step: 1797, LR: 1.7994742771310554e-05, Loss: 0.3244294226169586
[2023-09-09 00:46:38,197] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1798/66600 [3:23:47<369:55:07, 20.55s/it]09/09/2023 00:46:38 - INFO - __main__ -   Step: 1798, LR: 1.8004756540242835e-05, Loss: 0.47335028648376465
[2023-09-09 00:46:58,410] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1799/66600 [3:24:07<368:05:32, 20.45s/it]09/09/2023 00:46:58 - INFO - __main__ -   Step: 1799, LR: 1.8014770309175117e-05, Loss: 0.40391260385513306
[2023-09-09 00:47:18,778] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1800/66600 [3:24:28<367:38:33, 20.42s/it]09/09/2023 00:47:18 - INFO - __main__ -   Step: 1800, LR: 1.80247840781074e-05, Loss: 0.39889806509017944
09/09/2023 00:47:18 - INFO - __main__ - ***** Running Validation *****

Evaluating:   0%|          | 0/228 [00:00<?, ?it/s][Astep: 0
extend+tolist() time: 0.0018973350524902344

Evaluating:   0%|          | 1/228 [00:00<01:50,  2.05it/s][Astep: 1
extend+tolist() time: 0.0010786056518554688

Evaluating:   1%|          | 2/228 [00:00<01:41,  2.23it/s][Astep: 2
extend+tolist() time: 0.0022401809692382812

Evaluating:   1%|▏         | 3/228 [00:01<01:36,  2.32it/s][Astep: 3
extend+tolist() time: 0.002026081085205078

Evaluating:   2%|▏         | 4/228 [00:01<01:33,  2.39it/s][Astep: 4
extend+tolist() time: 0.0010497570037841797

Evaluating:   2%|▏         | 5/228 [00:02<01:33,  2.40it/s][Astep: 5
extend+tolist() time: 0.0023450851440429688

Evaluating:   3%|▎         | 6/228 [00:02<01:31,  2.43it/s][Astep: 6
extend+tolist() time: 0.002133607864379883

Evaluating:   3%|▎         | 7/228 [00:03<01:42,  2.15it/s][Astep: 7
extend+tolist() time: 0.13198637962341309

Evaluating:   4%|▎         | 8/228 [00:03<01:45,  2.08it/s][Astep: 8
extend+tolist() time: 0.0011932849884033203

Evaluating:   4%|▍         | 9/228 [00:04<01:41,  2.17it/s][Astep: 9
extend+tolist() time: 0.0008084774017333984

Evaluating:   4%|▍         | 10/228 [00:04<01:35,  2.29it/s][Astep: 10
extend+tolist() time: 0.0012469291687011719

Evaluating:   5%|▍         | 11/228 [00:04<01:31,  2.38it/s][Astep: 11
extend+tolist() time: 0.000553131103515625

Evaluating:   5%|▌         | 12/228 [00:05<01:30,  2.40it/s][Astep: 12
extend+tolist() time: 0.0010781288146972656

Evaluating:   6%|▌         | 13/228 [00:05<01:26,  2.47it/s][Astep: 13
extend+tolist() time: 0.0005819797515869141

Evaluating:   6%|▌         | 14/228 [00:06<01:27,  2.45it/s][Astep: 14
extend+tolist() time: 0.0005447864532470703

Evaluating:   7%|▋         | 15/228 [00:06<01:24,  2.51it/s][Astep: 15
extend+tolist() time: 0.001024007797241211

Evaluating:   7%|▋         | 16/228 [00:06<01:23,  2.55it/s][Astep: 16
extend+tolist() time: 0.0006120204925537109

Evaluating:   7%|▋         | 17/228 [00:07<01:24,  2.51it/s][Astep: 17
extend+tolist() time: 0.001329183578491211

Evaluating:   8%|▊         | 18/228 [00:07<01:22,  2.54it/s][Astep: 18
extend+tolist() time: 0.0011627674102783203

Evaluating:   8%|▊         | 19/228 [00:08<01:25,  2.45it/s][Astep: 19
extend+tolist() time: 0.0014486312866210938

Evaluating:   9%|▉         | 20/228 [00:08<01:24,  2.47it/s][Astep: 20
extend+tolist() time: 0.0007755756378173828

Evaluating:   9%|▉         | 21/228 [00:08<01:22,  2.50it/s][Astep: 21
extend+tolist() time: 0.001085042953491211

Evaluating:  10%|▉         | 22/228 [00:09<01:24,  2.44it/s][Astep: 22
extend+tolist() time: 0.0007677078247070312

Evaluating:  10%|█         | 23/228 [00:09<01:22,  2.48it/s][Astep: 23
extend+tolist() time: 0.0011103153228759766

Evaluating:  11%|█         | 24/228 [00:10<01:23,  2.44it/s][Astep: 24
extend+tolist() time: 0.0011436939239501953

Evaluating:  11%|█         | 25/228 [00:10<01:22,  2.47it/s][Astep: 25
extend+tolist() time: 0.0018925666809082031

Evaluating:  11%|█▏        | 26/228 [00:10<01:22,  2.46it/s][Astep: 26
extend+tolist() time: 0.0010864734649658203

Evaluating:  12%|█▏        | 27/228 [00:11<01:23,  2.40it/s][Astep: 27
extend+tolist() time: 0.001630544662475586

Evaluating:  12%|█▏        | 28/228 [00:11<01:23,  2.40it/s][Astep: 28
extend+tolist() time: 0.00034427642822265625

Evaluating:  13%|█▎        | 29/228 [00:12<01:23,  2.37it/s][Astep: 29
extend+tolist() time: 0.0007147789001464844

Evaluating:  13%|█▎        | 30/228 [00:12<01:22,  2.41it/s][Astep: 30
extend+tolist() time: 0.0015952587127685547

Evaluating:  14%|█▎        | 31/228 [00:12<01:21,  2.42it/s][Astep: 31
extend+tolist() time: 0.0005590915679931641

Evaluating:  14%|█▍        | 32/228 [00:13<01:22,  2.37it/s][Astep: 32
extend+tolist() time: 0.0014026165008544922

Evaluating:  14%|█▍        | 33/228 [00:13<01:21,  2.40it/s][Astep: 33
extend+tolist() time: 0.00167083740234375

Evaluating:  15%|█▍        | 34/228 [00:14<01:23,  2.34it/s][Astep: 34
extend+tolist() time: 0.0008530616760253906

Evaluating:  15%|█▌        | 35/228 [00:14<01:20,  2.39it/s][Astep: 35
extend+tolist() time: 0.001100778579711914

Evaluating:  16%|█▌        | 36/228 [00:15<01:21,  2.37it/s][Astep: 36
extend+tolist() time: 0.0007762908935546875

Evaluating:  16%|█▌        | 37/228 [00:15<01:18,  2.42it/s][Astep: 37
extend+tolist() time: 0.0017359256744384766

Evaluating:  17%|█▋        | 38/228 [00:16<01:30,  2.09it/s][Astep: 38
extend+tolist() time: 0.0011096000671386719

Evaluating:  17%|█▋        | 39/228 [00:16<01:24,  2.22it/s][Astep: 39
extend+tolist() time: 0.0007183551788330078

Evaluating:  18%|█▊        | 40/228 [00:16<01:20,  2.33it/s][Astep: 40
extend+tolist() time: 0.0010645389556884766

Evaluating:  18%|█▊        | 41/228 [00:17<01:20,  2.33it/s][Astep: 41
extend+tolist() time: 0.16076087951660156

Evaluating:  18%|█▊        | 42/228 [00:17<01:26,  2.16it/s][Astep: 42
extend+tolist() time: 0.0017299652099609375

Evaluating:  19%|█▉        | 43/228 [00:18<01:25,  2.17it/s][Astep: 43
extend+tolist() time: 0.001760244369506836

Evaluating:  19%|█▉        | 44/228 [00:18<01:22,  2.24it/s][Astep: 44
extend+tolist() time: 0.0010781288146972656

Evaluating:  20%|█▉        | 45/228 [00:19<01:21,  2.25it/s][Astep: 45
extend+tolist() time: 0.0012476444244384766

Evaluating:  20%|██        | 46/228 [00:19<01:18,  2.31it/s][Astep: 46
extend+tolist() time: 0.0016357898712158203

Evaluating:  21%|██        | 47/228 [00:19<01:16,  2.35it/s][Astep: 47
extend+tolist() time: 0.0014600753784179688

Evaluating:  21%|██        | 48/228 [00:20<01:17,  2.32it/s][Astep: 48
extend+tolist() time: 0.0015146732330322266

Evaluating:  21%|██▏       | 49/228 [00:20<01:15,  2.38it/s][Astep: 49
extend+tolist() time: 0.0013036727905273438

Evaluating:  22%|██▏       | 50/228 [00:21<01:15,  2.36it/s][Astep: 50
extend+tolist() time: 0.001210927963256836

Evaluating:  22%|██▏       | 51/228 [00:21<01:13,  2.40it/s][Astep: 51
extend+tolist() time: 0.0016531944274902344

Evaluating:  23%|██▎       | 52/228 [00:22<01:12,  2.43it/s][Astep: 52
extend+tolist() time: 0.0013480186462402344

Evaluating:  23%|██▎       | 53/228 [00:22<01:13,  2.37it/s][Astep: 53
extend+tolist() time: 0.0016138553619384766

Evaluating:  24%|██▎       | 54/228 [00:22<01:12,  2.41it/s][Astep: 54
extend+tolist() time: 0.0008294582366943359

Evaluating:  24%|██▍       | 55/228 [00:23<01:12,  2.38it/s][Astep: 55
extend+tolist() time: 0.0012187957763671875

Evaluating:  25%|██▍       | 56/228 [00:23<01:10,  2.45it/s][Astep: 56
extend+tolist() time: 0.0011401176452636719

Evaluating:  25%|██▌       | 57/228 [00:24<01:08,  2.48it/s][Astep: 57
extend+tolist() time: 0.001558542251586914

Evaluating:  25%|██▌       | 58/228 [00:24<01:09,  2.43it/s][Astep: 58
extend+tolist() time: 0.00086212158203125

Evaluating:  26%|██▌       | 59/228 [00:24<01:08,  2.48it/s][Astep: 59
extend+tolist() time: 0.0013904571533203125

Evaluating:  26%|██▋       | 60/228 [00:25<01:09,  2.43it/s][Astep: 60
extend+tolist() time: 0.0007243156433105469

Evaluating:  27%|██▋       | 61/228 [00:25<01:07,  2.49it/s][Astep: 61
extend+tolist() time: 0.0013043880462646484

Evaluating:  27%|██▋       | 62/228 [00:26<01:05,  2.53it/s][Astep: 62
extend+tolist() time: 0.0008015632629394531

Evaluating:  28%|██▊       | 63/228 [00:26<01:07,  2.45it/s][Astep: 63
extend+tolist() time: 0.001279592514038086

Evaluating:  28%|██▊       | 64/228 [00:26<01:05,  2.49it/s][Astep: 64
extend+tolist() time: 0.0008168220520019531

Evaluating:  29%|██▊       | 65/228 [00:27<01:07,  2.43it/s][Astep: 65
extend+tolist() time: 0.0012178421020507812

Evaluating:  29%|██▉       | 66/228 [00:27<01:05,  2.48it/s][Astep: 66
extend+tolist() time: 0.0007627010345458984

Evaluating:  29%|██▉       | 67/228 [00:28<01:03,  2.53it/s][Astep: 67
extend+tolist() time: 0.0013301372528076172

Evaluating:  30%|██▉       | 68/228 [00:28<01:05,  2.46it/s][Astep: 68
extend+tolist() time: 0.0006749629974365234

Evaluating:  30%|███       | 69/228 [00:28<01:03,  2.51it/s][Astep: 69
extend+tolist() time: 0.0015418529510498047

Evaluating:  31%|███       | 70/228 [00:29<01:04,  2.47it/s][Astep: 70
extend+tolist() time: 0.0014758110046386719

Evaluating:  31%|███       | 71/228 [00:30<01:20,  1.94it/s][Astep: 71
extend+tolist() time: 0.0009772777557373047

Evaluating:  32%|███▏      | 72/228 [00:30<01:15,  2.06it/s][Astep: 72
extend+tolist() time: 0.0007524490356445312

Evaluating:  32%|███▏      | 73/228 [00:30<01:10,  2.21it/s][Astep: 73
extend+tolist() time: 0.0005280971527099609

Evaluating:  32%|███▏      | 74/228 [00:31<01:07,  2.27it/s][Astep: 74
extend+tolist() time: 0.001220703125

Evaluating:  33%|███▎      | 75/228 [00:31<01:05,  2.34it/s][Astep: 75
extend+tolist() time: 0.2058885097503662

Evaluating:  33%|███▎      | 76/228 [00:32<01:12,  2.09it/s][Astep: 76
extend+tolist() time: 0.0006260871887207031

Evaluating:  34%|███▍      | 77/228 [00:32<01:08,  2.21it/s][Astep: 77
extend+tolist() time: 0.0018644332885742188

Evaluating:  34%|███▍      | 78/228 [00:33<01:05,  2.28it/s][Astep: 78
extend+tolist() time: 0.0012390613555908203

Evaluating:  35%|███▍      | 79/228 [00:33<01:05,  2.28it/s][Astep: 79
extend+tolist() time: 0.0008852481842041016

Evaluating:  35%|███▌      | 80/228 [00:33<01:02,  2.37it/s][Astep: 80
extend+tolist() time: 0.0009207725524902344

Evaluating:  36%|███▌      | 81/228 [00:34<01:02,  2.36it/s][Astep: 81
extend+tolist() time: 0.0012602806091308594

Evaluating:  36%|███▌      | 82/228 [00:34<01:00,  2.40it/s][Astep: 82
extend+tolist() time: 0.0008103847503662109

Evaluating:  36%|███▋      | 83/228 [00:35<00:59,  2.45it/s][Astep: 83
extend+tolist() time: 0.0011680126190185547

Evaluating:  37%|███▋      | 84/228 [00:35<01:00,  2.39it/s][Astep: 84
extend+tolist() time: 0.000995635986328125

Evaluating:  37%|███▋      | 85/228 [00:35<00:58,  2.43it/s][Astep: 85
extend+tolist() time: 0.0013513565063476562

Evaluating:  38%|███▊      | 86/228 [00:36<00:59,  2.40it/s][Astep: 86
extend+tolist() time: 0.0008678436279296875

Evaluating:  38%|███▊      | 87/228 [00:36<00:58,  2.42it/s][Astep: 87
extend+tolist() time: 0.0008599758148193359

Evaluating:  39%|███▊      | 88/228 [00:37<00:56,  2.47it/s][Astep: 88
extend+tolist() time: 0.0011658668518066406

Evaluating:  39%|███▉      | 89/228 [00:37<00:57,  2.41it/s][Astep: 89
extend+tolist() time: 0.0007448196411132812

Evaluating:  39%|███▉      | 90/228 [00:38<00:55,  2.47it/s][Astep: 90
extend+tolist() time: 0.0013768672943115234

Evaluating:  40%|███▉      | 91/228 [00:38<00:56,  2.41it/s][Astep: 91
extend+tolist() time: 0.0007333755493164062

Evaluating:  40%|████      | 92/228 [00:38<00:56,  2.43it/s][Astep: 92
extend+tolist() time: 0.0011684894561767578

Evaluating:  41%|████      | 93/228 [00:39<00:54,  2.49it/s][Astep: 93
extend+tolist() time: 0.0009722709655761719

Evaluating:  41%|████      | 94/228 [00:39<00:55,  2.41it/s][Astep: 94
extend+tolist() time: 0.0011470317840576172

Evaluating:  42%|████▏     | 95/228 [00:40<00:53,  2.48it/s][Astep: 95
extend+tolist() time: 0.0011508464813232422

Evaluating:  42%|████▏     | 96/228 [00:40<00:55,  2.39it/s][Astep: 96
extend+tolist() time: 0.0013575553894042969

Evaluating:  43%|████▎     | 97/228 [00:40<00:53,  2.45it/s][Astep: 97
extend+tolist() time: 0.0011780261993408203

Evaluating:  43%|████▎     | 98/228 [00:41<00:51,  2.50it/s][Astep: 98
extend+tolist() time: 0.0008890628814697266

Evaluating:  43%|████▎     | 99/228 [00:41<00:53,  2.42it/s][Astep: 99
extend+tolist() time: 0.0013506412506103516

Evaluating:  44%|████▍     | 100/228 [00:42<00:51,  2.48it/s][Astep: 100
extend+tolist() time: 0.000736236572265625

Evaluating:  44%|████▍     | 101/228 [00:42<00:51,  2.46it/s][Astep: 101
extend+tolist() time: 0.0012063980102539062

Evaluating:  45%|████▍     | 102/228 [00:42<00:50,  2.48it/s][Astep: 102
extend+tolist() time: 0.0007219314575195312

Evaluating:  45%|████▌     | 103/228 [00:43<00:49,  2.54it/s][Astep: 103
extend+tolist() time: 0.0011568069458007812

Evaluating:  46%|████▌     | 104/228 [00:43<00:50,  2.45it/s][Astep: 104
extend+tolist() time: 0.0006890296936035156

Evaluating:  46%|████▌     | 105/228 [00:44<00:49,  2.50it/s][Astep: 105
extend+tolist() time: 0.001216888427734375

Evaluating:  46%|████▋     | 106/228 [00:44<00:50,  2.44it/s][Astep: 106
extend+tolist() time: 0.0013086795806884766

Evaluating:  47%|████▋     | 107/228 [00:44<00:49,  2.42it/s][Astep: 107
extend+tolist() time: 0.0007548332214355469

Evaluating:  47%|████▋     | 108/228 [00:45<00:48,  2.47it/s][Astep: 108
extend+tolist() time: 0.001224517822265625

Evaluating:  48%|████▊     | 109/228 [00:45<00:49,  2.39it/s][Astep: 109
extend+tolist() time: 0.0008244514465332031

Evaluating:  48%|████▊     | 110/228 [00:46<00:48,  2.45it/s][Astep: 110
extend+tolist() time: 0.0006494522094726562

Evaluating:  49%|████▊     | 111/228 [00:46<00:49,  2.39it/s][Astep: 111
extend+tolist() time: 0.0018703937530517578

Evaluating:  49%|████▉     | 112/228 [00:47<00:47,  2.42it/s][Astep: 112
extend+tolist() time: 0.0007309913635253906

Evaluating:  50%|████▉     | 113/228 [00:47<00:46,  2.49it/s][Astep: 113
extend+tolist() time: 0.0007026195526123047

Evaluating:  50%|█████     | 114/228 [00:47<00:46,  2.43it/s][Astep: 114
extend+tolist() time: 0.0014901161193847656

Evaluating:  50%|█████     | 115/228 [00:48<00:45,  2.47it/s][Astep: 115
extend+tolist() time: 0.0006647109985351562

Evaluating:  51%|█████     | 116/228 [00:48<00:46,  2.41it/s][Astep: 116
extend+tolist() time: 0.0013000965118408203

Evaluating:  51%|█████▏    | 117/228 [00:49<00:44,  2.47it/s][Astep: 117
extend+tolist() time: 0.0008816719055175781

Evaluating:  52%|█████▏    | 118/228 [00:49<00:43,  2.52it/s][Astep: 118
extend+tolist() time: 0.0010242462158203125

Evaluating:  52%|█████▏    | 119/228 [00:49<00:48,  2.22it/s][Astep: 119
extend+tolist() time: 0.0007266998291015625

Evaluating:  53%|█████▎    | 120/228 [00:50<00:52,  2.04it/s][Astep: 120
extend+tolist() time: 0.0006394386291503906

Evaluating:  53%|█████▎    | 121/228 [00:50<00:50,  2.14it/s][Astep: 121
extend+tolist() time: 0.0011374950408935547

Evaluating:  54%|█████▎    | 122/228 [00:51<00:46,  2.27it/s][Astep: 122
extend+tolist() time: 0.0006773471832275391

Evaluating:  54%|█████▍    | 123/228 [00:51<00:46,  2.27it/s][Astep: 123
extend+tolist() time: 0.0009987354278564453

Evaluating:  54%|█████▍    | 124/228 [00:52<00:43,  2.38it/s][Astep: 124
extend+tolist() time: 0.0008096694946289062

Evaluating:  55%|█████▍    | 125/228 [00:52<00:42,  2.45it/s][Astep: 125
extend+tolist() time: 0.00043392181396484375

Evaluating:  55%|█████▌    | 126/228 [00:52<00:42,  2.40it/s][Astep: 126
extend+tolist() time: 0.0017848014831542969

Evaluating:  56%|█████▌    | 127/228 [00:53<00:41,  2.44it/s][Astep: 127
extend+tolist() time: 0.19908738136291504

Evaluating:  56%|█████▌    | 128/228 [00:54<00:53,  1.86it/s][Astep: 128
extend+tolist() time: 0.0011501312255859375

Evaluating:  57%|█████▋    | 129/228 [00:54<00:48,  2.04it/s][Astep: 129
extend+tolist() time: 0.000751495361328125

Evaluating:  57%|█████▋    | 130/228 [00:55<00:46,  2.12it/s][Astep: 130
extend+tolist() time: 0.001253366470336914

Evaluating:  57%|█████▋    | 131/228 [00:55<00:43,  2.25it/s][Astep: 131
extend+tolist() time: 0.00043702125549316406

Evaluating:  58%|█████▊    | 132/228 [00:55<00:42,  2.26it/s][Astep: 132
extend+tolist() time: 0.0014367103576660156

Evaluating:  58%|█████▊    | 133/228 [00:56<00:40,  2.35it/s][Astep: 133
extend+tolist() time: 0.00042748451232910156

Evaluating:  59%|█████▉    | 134/228 [00:56<00:38,  2.44it/s][Astep: 134
extend+tolist() time: 0.001340627670288086

Evaluating:  59%|█████▉    | 135/228 [00:57<00:39,  2.37it/s][Astep: 135
extend+tolist() time: 0.00042700767517089844

Evaluating:  60%|█████▉    | 136/228 [00:57<00:37,  2.46it/s][Astep: 136
extend+tolist() time: 0.001207113265991211

Evaluating:  60%|██████    | 137/228 [00:57<00:37,  2.40it/s][Astep: 137
extend+tolist() time: 0.000370025634765625

Evaluating:  61%|██████    | 138/228 [00:58<00:36,  2.45it/s][Astep: 138
extend+tolist() time: 0.0007281303405761719

Evaluating:  61%|██████    | 139/228 [00:58<00:35,  2.50it/s][Astep: 139
extend+tolist() time: 0.0004558563232421875

Evaluating:  61%|██████▏   | 140/228 [00:59<00:36,  2.43it/s][Astep: 140
extend+tolist() time: 0.0007252693176269531

Evaluating:  62%|██████▏   | 141/228 [00:59<00:34,  2.49it/s][Astep: 141
extend+tolist() time: 0.0007734298706054688

Evaluating:  62%|██████▏   | 142/228 [00:59<00:35,  2.42it/s][Astep: 142
extend+tolist() time: 0.0010497570037841797

Evaluating:  63%|██████▎   | 143/228 [01:00<00:34,  2.49it/s][Astep: 143
extend+tolist() time: 0.0003414154052734375

Evaluating:  63%|██████▎   | 144/228 [01:00<00:32,  2.55it/s][Astep: 144
extend+tolist() time: 0.0006923675537109375

Evaluating:  64%|██████▎   | 145/228 [01:01<00:33,  2.45it/s][Astep: 145
extend+tolist() time: 0.0008895397186279297

Evaluating:  64%|██████▍   | 146/228 [01:01<00:32,  2.52it/s][Astep: 146
extend+tolist() time: 0.00038123130798339844

Evaluating:  64%|██████▍   | 147/228 [01:01<00:32,  2.48it/s][Astep: 147
extend+tolist() time: 0.0006940364837646484

Evaluating:  65%|██████▍   | 148/228 [01:02<00:31,  2.53it/s][Astep: 148
extend+tolist() time: 0.0010766983032226562

Evaluating:  65%|██████▌   | 149/228 [01:02<00:30,  2.57it/s][Astep: 149
extend+tolist() time: 0.0003428459167480469

Evaluating:  66%|██████▌   | 150/228 [01:03<00:31,  2.49it/s][Astep: 150
extend+tolist() time: 0.0007977485656738281

Evaluating:  66%|██████▌   | 151/228 [01:03<00:30,  2.54it/s][Astep: 151
extend+tolist() time: 0.0010106563568115234

Evaluating:  67%|██████▋   | 152/228 [01:03<00:30,  2.50it/s][Astep: 152
extend+tolist() time: 0.0007433891296386719

Evaluating:  67%|██████▋   | 153/228 [01:04<00:30,  2.49it/s][Astep: 153
extend+tolist() time: 0.0012860298156738281

Evaluating:  68%|██████▊   | 154/228 [01:04<00:29,  2.51it/s][Astep: 154
extend+tolist() time: 0.0018019676208496094

Evaluating:  68%|██████▊   | 155/228 [01:05<00:30,  2.41it/s][Astep: 155
extend+tolist() time: 0.0006167888641357422

Evaluating:  68%|██████▊   | 156/228 [01:05<00:28,  2.49it/s][Astep: 156
extend+tolist() time: 0.0004799365997314453

Evaluating:  69%|██████▉   | 157/228 [01:05<00:28,  2.47it/s][Astep: 157
extend+tolist() time: 0.0010585784912109375

Evaluating:  69%|██████▉   | 158/228 [01:06<00:27,  2.52it/s][Astep: 158
extend+tolist() time: 0.00046443939208984375

Evaluating:  70%|██████▉   | 159/228 [01:06<00:26,  2.57it/s][Astep: 159
extend+tolist() time: 0.0007090568542480469

Evaluating:  70%|███████   | 160/228 [01:07<00:27,  2.49it/s][Astep: 160
extend+tolist() time: 0.0008084774017333984

Evaluating:  71%|███████   | 161/228 [01:07<00:26,  2.55it/s][Astep: 161
extend+tolist() time: 0.0007913112640380859

Evaluating:  71%|███████   | 162/228 [01:07<00:25,  2.58it/s][Astep: 162
extend+tolist() time: 0.0005075931549072266

Evaluating:  71%|███████▏  | 163/228 [01:08<00:26,  2.49it/s][Astep: 163
extend+tolist() time: 0.0004208087921142578

Evaluating:  72%|███████▏  | 164/228 [01:08<00:25,  2.54it/s][Astep: 164
extend+tolist() time: 0.0010237693786621094

Evaluating:  72%|███████▏  | 165/228 [01:09<00:25,  2.47it/s][Astep: 165
extend+tolist() time: 0.00045871734619140625

Evaluating:  73%|███████▎  | 166/228 [01:09<00:24,  2.53it/s][Astep: 166
extend+tolist() time: 0.00039577484130859375

Evaluating:  73%|███████▎  | 167/228 [01:09<00:23,  2.58it/s][Astep: 167
extend+tolist() time: 0.0005581378936767578

Evaluating:  74%|███████▎  | 168/228 [01:10<00:24,  2.49it/s][Astep: 168
extend+tolist() time: 0.0012099742889404297

Evaluating:  74%|███████▍  | 169/228 [01:10<00:23,  2.51it/s][Astep: 169
extend+tolist() time: 0.00037360191345214844

Evaluating:  75%|███████▍  | 170/228 [01:11<00:23,  2.47it/s][Astep: 170
extend+tolist() time: 0.0013422966003417969

Evaluating:  75%|███████▌  | 171/228 [01:11<00:22,  2.50it/s][Astep: 171
extend+tolist() time: 0.00028324127197265625

Evaluating:  75%|███████▌  | 172/228 [01:11<00:22,  2.54it/s][Astep: 172
extend+tolist() time: 0.0008175373077392578

Evaluating:  76%|███████▌  | 173/228 [01:12<00:22,  2.44it/s][Astep: 173
extend+tolist() time: 0.0015532970428466797

Evaluating:  76%|███████▋  | 174/228 [01:12<00:21,  2.48it/s][Astep: 174
extend+tolist() time: 0.00179290771484375

Evaluating:  77%|███████▋  | 175/228 [01:13<00:21,  2.42it/s][Astep: 175
extend+tolist() time: 0.0007927417755126953

Evaluating:  77%|███████▋  | 176/228 [01:13<00:20,  2.48it/s][Astep: 176
extend+tolist() time: 0.0010447502136230469

Evaluating:  78%|███████▊  | 177/228 [01:13<00:20,  2.53it/s][Astep: 177
extend+tolist() time: 0.0006256103515625

Evaluating:  78%|███████▊  | 178/228 [01:14<00:20,  2.45it/s][Astep: 178
extend+tolist() time: 0.001634836196899414

Evaluating:  79%|███████▊  | 179/228 [01:14<00:19,  2.48it/s][Astep: 179
extend+tolist() time: 0.0004222393035888672

Evaluating:  79%|███████▉  | 180/228 [01:15<00:19,  2.46it/s][Astep: 180
extend+tolist() time: 0.0003943443298339844

Evaluating:  79%|███████▉  | 181/228 [01:15<00:18,  2.49it/s][Astep: 181
extend+tolist() time: 0.0005979537963867188

Evaluating:  80%|███████▉  | 182/228 [01:15<00:18,  2.54it/s][Astep: 182
extend+tolist() time: 0.001226186752319336

Evaluating:  80%|████████  | 183/228 [01:16<00:18,  2.45it/s][Astep: 183
extend+tolist() time: 0.0006592273712158203

Evaluating:  81%|████████  | 184/228 [01:16<00:17,  2.51it/s][Astep: 184
extend+tolist() time: 0.0004315376281738281

Evaluating:  81%|████████  | 185/228 [01:17<00:17,  2.48it/s][Astep: 185
extend+tolist() time: 0.0015437602996826172

Evaluating:  82%|████████▏ | 186/228 [01:17<00:16,  2.49it/s][Astep: 186
extend+tolist() time: 0.001374959945678711

Evaluating:  82%|████████▏ | 187/228 [01:17<00:16,  2.53it/s][Astep: 187
extend+tolist() time: 0.0004515647888183594

Evaluating:  82%|████████▏ | 188/228 [01:18<00:16,  2.47it/s][Astep: 188
extend+tolist() time: 0.0007259845733642578

Evaluating:  83%|████████▎ | 189/228 [01:18<00:15,  2.52it/s][Astep: 189
extend+tolist() time: 0.0003840923309326172

Evaluating:  83%|████████▎ | 190/228 [01:19<00:14,  2.57it/s][Astep: 190
extend+tolist() time: 0.0017666816711425781

Evaluating:  84%|████████▍ | 191/228 [01:19<00:15,  2.46it/s][Astep: 191
extend+tolist() time: 0.0006978511810302734

Evaluating:  84%|████████▍ | 192/228 [01:19<00:14,  2.52it/s][Astep: 192
extend+tolist() time: 0.0008313655853271484

Evaluating:  85%|████████▍ | 193/228 [01:20<00:14,  2.46it/s][Astep: 193
extend+tolist() time: 0.0010693073272705078

Evaluating:  85%|████████▌ | 194/228 [01:20<00:13,  2.52it/s][Astep: 194
extend+tolist() time: 0.0010614395141601562

Evaluating:  86%|████████▌ | 195/228 [01:21<00:12,  2.57it/s][Astep: 195
extend+tolist() time: 0.0005557537078857422

Evaluating:  86%|████████▌ | 196/228 [01:21<00:12,  2.48it/s][Astep: 196
extend+tolist() time: 0.0006253719329833984

Evaluating:  86%|████████▋ | 197/228 [01:21<00:12,  2.50it/s][Astep: 197
extend+tolist() time: 0.0006761550903320312

Evaluating:  87%|████████▋ | 198/228 [01:22<00:12,  2.43it/s][Astep: 198
extend+tolist() time: 0.0010695457458496094

Evaluating:  87%|████████▋ | 199/228 [01:22<00:11,  2.48it/s][Astep: 199
extend+tolist() time: 0.0018165111541748047

Evaluating:  88%|████████▊ | 200/228 [01:23<00:11,  2.48it/s][Astep: 200
extend+tolist() time: 0.0007483959197998047

Evaluating:  88%|████████▊ | 201/228 [01:23<00:12,  2.11it/s][Astep: 201
extend+tolist() time: 0.0005931854248046875

Evaluating:  89%|████████▊ | 202/228 [01:24<00:11,  2.26it/s][Astep: 202
extend+tolist() time: 0.0008099079132080078

Evaluating:  89%|████████▉ | 203/228 [01:24<00:10,  2.28it/s][Astep: 203
extend+tolist() time: 0.0005035400390625

Evaluating:  89%|████████▉ | 204/228 [01:24<00:10,  2.40it/s][Astep: 204
extend+tolist() time: 0.00040841102600097656

Evaluating:  90%|████████▉ | 205/228 [01:25<00:09,  2.37it/s][Astep: 205
extend+tolist() time: 0.0003190040588378906

Evaluating:  90%|█████████ | 206/228 [01:25<00:08,  2.47it/s][Astep: 206
extend+tolist() time: 0.0005753040313720703

Evaluating:  91%|█████████ | 207/228 [01:26<00:08,  2.53it/s][Astep: 207
extend+tolist() time: 0.0010509490966796875

Evaluating:  91%|█████████ | 208/228 [01:26<00:08,  2.46it/s][Astep: 208
extend+tolist() time: 0.0007255077362060547

Evaluating:  92%|█████████▏| 209/228 [01:26<00:07,  2.52it/s][Astep: 209
extend+tolist() time: 0.0006091594696044922

Evaluating:  92%|█████████▏| 210/228 [01:27<00:07,  2.48it/s][Astep: 210
extend+tolist() time: 0.0009999275207519531

Evaluating:  93%|█████████▎| 211/228 [01:27<00:06,  2.49it/s][Astep: 211
extend+tolist() time: 0.0011227130889892578

Evaluating:  93%|█████████▎| 212/228 [01:28<00:06,  2.50it/s][Astep: 212
extend+tolist() time: 0.0013661384582519531

Evaluating:  93%|█████████▎| 213/228 [01:28<00:06,  2.41it/s][Astep: 213
extend+tolist() time: 0.0007503032684326172

Evaluating:  94%|█████████▍| 214/228 [01:29<00:06,  2.05it/s][Astep: 214
extend+tolist() time: 0.2293393611907959

Evaluating:  94%|█████████▍| 215/228 [01:29<00:06,  1.86it/s][Astep: 215
extend+tolist() time: 0.0006546974182128906

Evaluating:  95%|█████████▍| 216/228 [01:30<00:05,  2.04it/s][Astep: 216
extend+tolist() time: 0.0009603500366210938

Evaluating:  95%|█████████▌| 217/228 [01:30<00:05,  2.13it/s][Astep: 217
extend+tolist() time: 0.0005450248718261719

Evaluating:  96%|█████████▌| 218/228 [01:30<00:04,  2.27it/s][Astep: 218
extend+tolist() time: 0.00140380859375

Evaluating:  96%|█████████▌| 219/228 [01:31<00:03,  2.27it/s][Astep: 219
extend+tolist() time: 0.00048160552978515625

Evaluating:  96%|█████████▋| 220/228 [01:31<00:03,  2.38it/s][Astep: 220
extend+tolist() time: 0.00041031837463378906

Evaluating:  97%|█████████▋| 221/228 [01:32<00:02,  2.47it/s][Astep: 221
extend+tolist() time: 0.0010030269622802734

Evaluating:  97%|█████████▋| 222/228 [01:32<00:02,  2.42it/s][Astep: 222
extend+tolist() time: 0.00043702125549316406

Evaluating:  98%|█████████▊| 223/228 [01:32<00:01,  2.50it/s][Astep: 223
extend+tolist() time: 0.0003998279571533203

Evaluating:  98%|█████████▊| 224/228 [01:33<00:01,  2.47it/s][Astep: 224
extend+tolist() time: 0.00037980079650878906

Evaluating:  99%|█████████▊| 225/228 [01:33<00:01,  2.52it/s][Astep: 225
extend+tolist() time: 0.00044918060302734375

Evaluating:  99%|█████████▉| 226/228 [01:34<00:00,  2.54it/s][Astep: 226
extend+tolist() time: 0.00099945068359375

Evaluating: 100%|█████████▉| 227/228 [01:34<00:00,  2.46it/s][Astep: 227
extend+tolist() time: 0.0004901885986328125

Evaluating: 100%|██████████| 228/228 [01:35<00:00,  2.47it/s][A09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow
09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow
09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/precision/default/default_experiment-1-0.arrow
09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:48:54 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/recall/default/default_experiment-1-0.arrow
09/09/2023 00:48:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:48:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:48:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
09/09/2023 00:48:55 - INFO - evaluate.module - Removing /data/users/zhangjunlei/tyx/.cache/huggingface/metrics/rocauc/multiclass/default_experiment-1-0.arrow
Evaluating: 100%|██████████| 228/228 [01:37<00:00,  2.35it/s]
09/09/2023 00:48:55 - INFO - __main__ -   Step: 1800, Validation Metrics: {'pred_1_num': 9809, 'pred_-1_num': 916, 'pred_0_num': 76, 'ref_1_num': 8596, 'ref_0_num': 639, 'ref_-1_num': 1566, 'accuracy': 0.7957596518840848, 'f1_micro': 0.7957596518840848, 'f1_macro': 0.4467002889436096, 'f1_weighted': 0.7595482948463669, 'f1_-1': 0.35132957292506045, 'f1_0': 0.1062937062937063, 'f1_1': 0.882477587612062, 'precision_micro': 0.7957596518840848, 'precision_macro': 0.6012985579146858, 'precision_weighted': 0.7574881961173726, 'precision_-1': 0.4759825327510917, 'precision_0': 0.5, 'precision_1': 0.8279131409929656, 'recall_micro': 0.7957596518840848, 'recall_macro': 0.427542002116353, 'recall_weighted': 0.7957596518840848, 'recall_-1': 0.2784163473818646, 'recall_0': 0.0594679186228482, 'recall_1': 0.9447417403443462, 'roc_auc_micro': 0.9084656420067474, 'roc_auc_macro': 0.7310911866104984, 'roc_auc_weighted': 0.7000036758876572, 'roc_auc_-1': 0.7754939320329608, 'roc_auc_0': 0.7340602582452225, 'roc_auc_1': 0.6837193695533123}
[2023-09-09 00:49:16,098] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1801/66600 [3:26:25<890:51:59, 49.49s/it]09/09/2023 00:49:16 - INFO - __main__ -   Step: 1801, LR: 1.803479784703968e-05, Loss: 0.4168139696121216
[2023-09-09 00:49:37,235] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1802/66600 [3:26:46<737:44:00, 40.99s/it]09/09/2023 00:49:37 - INFO - __main__ -   Step: 1802, LR: 1.8044811615971962e-05, Loss: 0.4046681821346283
[2023-09-09 00:49:57,716] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1803/66600 [3:27:07<626:59:59, 34.83s/it]09/09/2023 00:49:57 - INFO - __main__ -   Step: 1803, LR: 1.8054825384904243e-05, Loss: 0.4428737759590149
[2023-09-09 00:50:18,184] [WARNING] [stage3.py:1898:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1804/66600 [3:27:27<549:24:44, 30.52s/it]09/09/2023 00:50:18 - INFO - __main__ -   Step: 1804, LR: 1.8064839153836525e-05, Loss: 0.48109832406044006
[2023-09-09 00:50:39,552] [WARNING] [stage3.py:1898:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  3%|▎         | 1805/66600 [3:27:49<499:57:46, 27.78s/it]09/09/2023 00:50:39 - INFO - __main__ -   Step: 1805, LR: 1.807485292276881e-05, Loss: 0.3688775897026062
