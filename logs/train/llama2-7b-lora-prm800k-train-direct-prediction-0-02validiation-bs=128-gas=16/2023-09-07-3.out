nohup: ignoring input
[2023-09-07 07:08:13,264] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-07 07:08:14,559] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2023-09-07 07:08:14,559] [INFO] [runner.py:555:main] cmd = /data/users/zhangjunlei/anaconda3/envs/open-instruct/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMywgNF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None /data/users/zhangjunlei/tyx/FastChat/fastchat/train/train_all_linear_modules_with_qlora.py --model_name_or_path /data/users/zhangjunlei/tyx/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9 --data_path /data/users/zhangjunlei/tyx/reward-by-prm800k/datasets/prm800k-train-direct-prediction-0-02validiation-encoded-datasets --output_dir /data/users/zhangjunlei/tyx/reward-by-prm800k/models/llama2-7b-lora-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16 --model_max_length 1024 --per_device_train_batch_size 2 --per_device_eval_batch_size 4 --gradient_checkpointing True --gradient_accumulation_steps 16 --num_train_epochs 100 --evaluation_strategy steps --eval_steps 100 --eval_first True --save_strategy steps --save_steps 100 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --lora_r 256 --lora_alpha 256 --lora_dropout 0.05 --lora_target_modules all_linear --q_lora True --bf16 True --tf32 True --use_accelerate_lib flash-attn-v2 --logging_strategy steps --logging_steps 1
[2023-09-07 07:08:16,033] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-07 07:08:17,336] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 3, 4]}
[2023-09-07 07:08:17,336] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2023-09-07 07:08:17,336] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2023-09-07 07:08:17,336] [INFO] [launch.py:163:main] dist_world_size=4
[2023-09-07 07:08:17,336] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,3,4
[2023-09-07 07:08:19,301] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-07 07:08:19,301] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-07 07:08:19,385] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2023-09-07 07:08:19,399] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.61s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.01s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.66s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
[DEBUG] lora_args.lora_target_modules = ['all_linear']
Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]
trainable params: 639,631,360 || all params: 4,140,044,288 || trainable%: 15.449867573977025
  0%|          | 0/114 [00:00<?, ?it/s]  2%|▏         | 2/114 [00:00<00:28,  3.96it/s]  3%|▎         | 3/114 [00:00<00:38,  2.91it/s]  4%|▎         | 4/114 [00:01<00:42,  2.56it/s]  4%|▍         | 5/114 [00:01<00:45,  2.40it/s]  5%|▌         | 6/114 [00:02<00:46,  2.30it/s]  6%|▌         | 7/114 [00:02<00:47,  2.25it/s]  7%|▋         | 8/114 [00:03<00:47,  2.21it/s]  8%|▊         | 9/114 [00:03<00:48,  2.19it/s]  9%|▉         | 10/114 [00:04<00:47,  2.17it/s] 10%|▉         | 11/114 [00:04<00:47,  2.16it/s] 11%|█         | 12/114 [00:05<00:47,  2.15it/s] 11%|█▏        | 13/114 [00:05<00:46,  2.15it/s] 12%|█▏        | 14/114 [00:06<00:46,  2.14it/s] 13%|█▎        | 15/114 [00:06<00:46,  2.15it/s] 14%|█▍        | 16/114 [00:07<00:45,  2.14it/s] 15%|█▍        | 17/114 [00:07<00:45,  2.14it/s] 16%|█▌        | 18/114 [00:07<00:44,  2.14it/s] 17%|█▋        | 19/114 [00:08<00:44,  2.14it/s] 18%|█▊        | 20/114 [00:08<00:43,  2.14it/s] 18%|█▊        | 21/114 [00:09<00:43,  2.14it/s] 19%|█▉        | 22/114 [00:09<00:43,  2.14it/s] 20%|██        | 23/114 [00:10<00:42,  2.14it/s] 21%|██        | 24/114 [00:10<00:42,  2.14it/s] 22%|██▏       | 25/114 [00:11<00:41,  2.14it/s] 23%|██▎       | 26/114 [00:11<00:41,  2.14it/s] 24%|██▎       | 27/114 [00:12<00:40,  2.13it/s] 25%|██▍       | 28/114 [00:12<00:40,  2.14it/s] 25%|██▌       | 29/114 [00:13<00:39,  2.14it/s] 26%|██▋       | 30/114 [00:13<00:39,  2.14it/s] 27%|██▋       | 31/114 [00:14<00:38,  2.14it/s] 28%|██▊       | 32/114 [00:14<00:38,  2.14it/s] 29%|██▉       | 33/114 [00:15<00:37,  2.14it/s] 30%|██▉       | 34/114 [00:15<00:37,  2.14it/s] 31%|███       | 35/114 [00:15<00:36,  2.14it/s] 32%|███▏      | 36/114 [00:16<00:36,  2.14it/s] 32%|███▏      | 37/114 [00:16<00:35,  2.14it/s] 33%|███▎      | 38/114 [00:17<00:35,  2.14it/s] 34%|███▍      | 39/114 [00:17<00:34,  2.14it/s] 35%|███▌      | 40/114 [00:18<00:34,  2.14it/s] 36%|███▌      | 41/114 [00:18<00:34,  2.14it/s] 37%|███▋      | 42/114 [00:19<00:33,  2.14it/s] 38%|███▊      | 43/114 [00:19<00:33,  2.14it/s] 39%|███▊      | 44/114 [00:20<00:32,  2.14it/s] 39%|███▉      | 45/114 [00:20<00:32,  2.14it/s] 40%|████      | 46/114 [00:21<00:31,  2.14it/s] 41%|████      | 47/114 [00:21<00:31,  2.14it/s] 42%|████▏     | 48/114 [00:22<00:30,  2.14it/s] 43%|████▎     | 49/114 [00:22<00:30,  2.14it/s] 44%|████▍     | 50/114 [00:22<00:29,  2.14it/s] 45%|████▍     | 51/114 [00:23<00:29,  2.14it/s] 46%|████▌     | 52/114 [00:23<00:28,  2.14it/s] 46%|████▋     | 53/114 [00:24<00:28,  2.15it/s] 47%|████▋     | 54/114 [00:24<00:27,  2.14it/s] 48%|████▊     | 55/114 [00:25<00:27,  2.14it/s] 49%|████▉     | 56/114 [00:25<00:27,  2.14it/s] 50%|█████     | 57/114 [00:26<00:26,  2.14it/s] 51%|█████     | 58/114 [00:26<00:26,  2.14it/s] 52%|█████▏    | 59/114 [00:27<00:25,  2.14it/s] 53%|█████▎    | 60/114 [00:27<00:25,  2.14it/s] 54%|█████▎    | 61/114 [00:28<00:24,  2.15it/s] 54%|█████▍    | 62/114 [00:28<00:24,  2.14it/s] 55%|█████▌    | 63/114 [00:29<00:23,  2.14it/s] 56%|█████▌    | 64/114 [00:29<00:23,  2.14it/s] 57%|█████▋    | 65/114 [00:29<00:22,  2.14it/s] 58%|█████▊    | 66/114 [00:30<00:22,  2.15it/s] 59%|█████▉    | 67/114 [00:30<00:21,  2.15it/s] 60%|█████▉    | 68/114 [00:31<00:21,  2.15it/s] 61%|██████    | 69/114 [00:31<00:20,  2.15it/s] 61%|██████▏   | 70/114 [00:32<00:20,  2.15it/s] 62%|██████▏   | 71/114 [00:32<00:20,  2.15it/s] 63%|██████▎   | 72/114 [00:33<00:19,  2.15it/s] 64%|██████▍   | 73/114 [00:33<00:19,  2.15it/s] 65%|██████▍   | 74/114 [00:34<00:18,  2.15it/s] 66%|██████▌   | 75/114 [00:34<00:18,  2.15it/s] 67%|██████▋   | 76/114 [00:35<00:17,  2.15it/s] 68%|██████▊   | 77/114 [00:35<00:17,  2.15it/s] 68%|██████▊   | 78/114 [00:35<00:16,  2.15it/s] 69%|██████▉   | 79/114 [00:36<00:16,  2.15it/s] 70%|███████   | 80/114 [00:36<00:15,  2.15it/s] 71%|███████   | 81/114 [00:37<00:15,  2.15it/s] 72%|███████▏  | 82/114 [00:37<00:14,  2.15it/s] 73%|███████▎  | 83/114 [00:38<00:14,  2.15it/s] 74%|███████▎  | 84/114 [00:38<00:13,  2.15it/s] 75%|███████▍  | 85/114 [00:39<00:13,  2.15it/s] 75%|███████▌  | 86/114 [00:39<00:13,  2.15it/s] 76%|███████▋  | 87/114 [00:40<00:12,  2.15it/s] 77%|███████▋  | 88/114 [00:40<00:12,  2.15it/s] 78%|███████▊  | 89/114 [00:41<00:11,  2.15it/s] 79%|███████▉  | 90/114 [00:41<00:11,  2.15it/s] 80%|███████▉  | 91/114 [00:42<00:10,  2.15it/s] 81%|████████  | 92/114 [00:42<00:10,  2.15it/s] 82%|████████▏ | 93/114 [00:42<00:09,  2.15it/s] 82%|████████▏ | 94/114 [00:43<00:09,  2.15it/s] 83%|████████▎ | 95/114 [00:43<00:08,  2.15it/s] 84%|████████▍ | 96/114 [00:44<00:08,  2.14it/s] 85%|████████▌ | 97/114 [00:44<00:07,  2.15it/s] 86%|████████▌ | 98/114 [00:45<00:07,  2.14it/s] 87%|████████▋ | 99/114 [00:45<00:06,  2.15it/s] 88%|████████▊ | 100/114 [00:46<00:06,  2.14it/s] 89%|████████▊ | 101/114 [00:46<00:06,  2.15it/s] 89%|████████▉ | 102/114 [00:47<00:05,  2.14it/s] 90%|█████████ | 103/114 [00:47<00:05,  2.14it/s] 91%|█████████ | 104/114 [00:48<00:04,  2.14it/s] 92%|█████████▏| 105/114 [00:48<00:04,  2.15it/s] 93%|█████████▎| 106/114 [00:49<00:03,  2.15it/s] 94%|█████████▍| 107/114 [00:49<00:03,  2.14it/s] 95%|█████████▍| 108/114 [00:49<00:02,  2.14it/s] 96%|█████████▌| 109/114 [00:50<00:02,  2.15it/s] 96%|█████████▋| 110/114 [00:50<00:01,  2.15it/s] 97%|█████████▋| 111/114 [00:51<00:01,  2.14it/s] 98%|█████████▊| 112/114 [00:51<00:00,  2.14it/s] 99%|█████████▉| 113/114 [00:52<00:00,  2.15it/s]100%|██████████| 114/114 [00:52<00:00,  2.15it/s](1818, 1024, 3)
wandb: Currently logged in as: kidrain61. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /data/users/zhangjunlei/tyx/wandb/wandb/run-20230907_071040-w63mu7tv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run llama2-7b-lora-prm800k-train-direct-prediction-0-02validiation-bs=128-gas=16-2023-09-07-3
wandb: ⭐️ View project at https://wandb.ai/kidrain61/step-reward
wandb: 🚀 View run at https://wandb.ai/kidrain61/step-reward/runs/w63mu7tv
100%|██████████| 114/114 [01:33<00:00,  1.22it/s]
  0%|          | 0/66500 [00:00<?, ?it/s]  0%|          | 1/66500 [00:14<269:33:18, 14.59s/it]                                                     {'loss': 18.7359, 'learning_rate': 1.0025062656641605e-08, 'epoch': 0.0}
  0%|          | 1/66500 [00:14<269:33:18, 14.59s/it]  0%|          | 2/66500 [00:28<266:13:29, 14.41s/it]                                                     {'loss': 18.3576, 'learning_rate': 2.005012531328321e-08, 'epoch': 0.0}
  0%|          | 2/66500 [00:28<266:13:29, 14.41s/it]  0%|          | 3/66500 [00:43<265:20:39, 14.37s/it]                                                     {'loss': 18.8437, 'learning_rate': 3.0075187969924815e-08, 'epoch': 0.0}
  0%|          | 3/66500 [00:43<265:20:39, 14.37s/it]  0%|          | 4/66500 [00:57<264:50:26, 14.34s/it]                                                     {'loss': 18.4509, 'learning_rate': 4.010025062656642e-08, 'epoch': 0.01}
  0%|          | 4/66500 [00:57<264:50:26, 14.34s/it]  0%|          | 5/66500 [01:11<264:32:26, 14.32s/it]                                                     {'loss': 18.704, 'learning_rate': 5.0125313283208025e-08, 'epoch': 0.01}
  0%|          | 5/66500 [01:11<264:32:26, 14.32s/it]  0%|          | 6/66500 [01:26<264:28:20, 14.32s/it]                                                     {'loss': 18.7398, 'learning_rate': 6.015037593984963e-08, 'epoch': 0.01}
  0%|          | 6/66500 [01:26<264:28:20, 14.32s/it]  0%|          | 7/66500 [01:40<264:21:25, 14.31s/it]                                                     {'loss': 18.7115, 'learning_rate': 7.017543859649123e-08, 'epoch': 0.01}
  0%|          | 7/66500 [01:40<264:21:25, 14.31s/it]  0%|          | 8/66500 [01:54<264:06:12, 14.30s/it]                                                     {'loss': 18.6507, 'learning_rate': 8.020050125313284e-08, 'epoch': 0.01}
  0%|          | 8/66500 [01:54<264:06:12, 14.30s/it]  0%|          | 9/66500 [02:08<264:10:33, 14.30s/it]                                                     {'loss': 18.9079, 'learning_rate': 9.022556390977444e-08, 'epoch': 0.01}
  0%|          | 9/66500 [02:09<264:10:33, 14.30s/it]  0%|          | 10/66500 [02:23<264:02:08, 14.30s/it]                                                      {'loss': 18.7804, 'learning_rate': 1.0025062656641605e-07, 'epoch': 0.02}
  0%|          | 10/66500 [02:23<264:02:08, 14.30s/it]